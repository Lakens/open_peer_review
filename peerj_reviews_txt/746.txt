Review History for Temporal variability predicts the magnitude of between-group attentional blink differences in developmental dyslexia: a meta-analysis [PeerJ]
PeerJ Journals Peer-reviewed PeerJ – the Journal of Life & Environmental Sciences PeerJ Computer Science PeerJ Physical Chemistry PeerJ Organic Chemistry PeerJ Inorganic Chemistry PeerJ Analytical Chemistry PeerJ Materials Science Preprints PeerJ Preprints Visit PeerJ.org and get involved About PeerJ Journals Overview PeerJ Journals FAQ What we publish 5 Years publishing Solutions for authors Reputation High quality peer review Fast publishing Indexing and Impact Factor Global readership Feature comparison Reduced cost publishing Author feedback Early career researcher benefits Senior researcher benefits Open review (optional) Rebuttal letters Sections About the journal Sections Aquatic Biology Biochemistry, Biophysics and Molecular Biology Biodiversity and Conservation Bioinformatics and Genomics Brain and Cognition Ecology Environmental Science Microbiology Paleontology and Evolutionary Science Plant Biology Zoological Science About PeerJ Journals Overview PeerJ Journals FAQ What we publish 5 Years publishing Solutions for authors Reputation High quality peer review Fast publishing Indexing and Impact Factor Global readership Feature comparison Reduced cost publishing Author feedback Early career researcher benefits Senior researcher benefits Open review (optional) Rebuttal letters More Subjects Search articles Advanced search of articles & preprints PeerJ - Medicine articles PeerJ - Biology & Life science articles PeerJ Computer Science PeerJ Preprints Table of contents Table of Contents - current and archives PeerJ - Medicine articles PeerJ - Biology & Life science articles PeerJ - Environmental Science articles PeerJ - General bio (stats, legal, policy, edu) PeerJ Computer Science PeerJ Preprints Academic advisors Volunteer to review Collections Job listings Discussions Blog Institutional plans Reviews and awards Spread the word Who are we? Contact Login AUTHORS Peer Journals Overview Submission Guidelines Subject Areas Editorial Board Editorial Criteria Pricing General FAQ Computer Science FAQ Aims and Scope Author Interviews Policies and Procedures SUBMIT ARTICLE
Review History Temporal variability predicts the magnitude of between-group attentional blink differences in developmental dyslexia: a meta-analysis To increase transparency, PeerJ operates a system of 'optional signed reviews and history'. This takes two forms: (1) peer reviewers are encouraged, but not required, to provide their names (if they do so, then their profile page records the articles they have reviewed), and (2) authors are given the option of reproducing their entire peer review history alongside their published article (in which case the complete peer review process is provided, including revisions, rebuttal letters and editor decision letters). New to public reviews? Learn more about optional signed reviews and how to write a better rebuttal letter .
Summary
The initial submission of this article was received on March 29th, 2014 and was peer-reviewed by 2 reviewers and the Academic Editor. The Academic Editor made their initial decision on April 22nd, 2014. The first revision was submitted on November 19th, 2014 and was reviewed by 1 reviewer and the Academic Editor. A further revision was submitted on January 7th, 2015 and was reviewed by the Academic Editor. The article was Accepted by the Academic Editor on January 7th, 2015.
label_version_1
Version 0.3 (accepted)
Jafri Abdullah
·
Jan 7, 2015
label_recommendation_1
·
Academic Editor
Accept
Dear Authors, This manuscript after two revisions is now suitable for publication in Peer J.Thank you for your patience in attending to the comments of the peer reviewers so as this manuscript could be made more citable as well as the experiment methodology more reproducible in other labs around the world.
Download Version 0.3 (PDF)
Download author's rebuttal letter
- submitted Jan 7, 2015
label_version_2
Version 0.2
Jafri Abdullah
·
Dec 8, 2014
label_recommendation_2
·
Academic Editor
Minor Revisions
Dear Authors,You manuscript will need to undergo minor revisions.Please do the revisions as soon as possible as the revised manuscript will need to undergo another round of peer review.
label_author_1
Franck Ramus ·
Dec 7, 2014
Basic reporting
label_br_1
Abstract: I don't think it is the test of homogeneity of variances that yields the group difference. line 40: I would remove "as it ostensibly does in dyslexia", as this is a controversial statement that would require justification, and here it's not crucial. line 43: regressive eye movements may occur in dyslexic individuals simply because they read less well, so this may have nothing to do with attentional blink. Method: it is odd to present all the moderators before the section on group difference (contrary to the results section). line 129: these experiments were excluded FROM THIS ANALYSIS; It would be good to explicitly state on how many experiments this moderator is analysed. line 183: it would be good to add to this section a sentence about how moderation was tested. line 224: it would be helpful to spell out the interpretation of beta values. Is it that each extra millisecond of pre-RSVP time increases the group difference by 0.001 d? So one second pre-RSVP time for one standard deviation of group difference? Same for the other moderator. line 227: the interval does not include the beta value. line 247: fixation should probably be replaced with time. line 272: accuracy -> accurate line 303: why are the rho values negative? This seems contrary to the explanation in the text. 346 and following: a discussion of subtypes is welcome but should not be limited to phonological vs. surface subtypes of reading disability, whose validity is debatable. It would seem more relevant to discuss phonological (in the broad sense of a phonological deficit, not of a deficit in the phonological route of the reading system) vs. visual/attentional subtypes. Table 1: add a column with the number of experiments contributing to each moderator. Supplementary material: I think that the supplementary table contains useful enough information to be integrated in the article. In fact it could be merged with Table 1, with mean, median and Shapiro-Wilk statistic (and nb of experiments as indicated above) listed as additional lines to the supplementary table.
Experimental design
label_ed_1
OK
Validity of the findings
label_votf_1
Overall I find that it remains difficult to wrap one's head around the results: why are these moderators significant and why do they seem to act in opposite directions? One reason may be that the real moderators are variables correlated with the current ones. On line 257, the authors suggest that T2 temporal variability might be a proxy for T2 timing. If they think that T2 timing is more interpretable, then why not use that variable as a moderator in the first place? After all, why analyse moderators for which there would be no plausible interpretation, when they are highly correlated variables that would be more easily interpreted? In a similar vein, the authors go on to interpret their moderators in terms of task set. This is quite troubling given that task set complexity was one of their moderators and that it was not significant. Of course, in a sense, all the moderators reflect some aspect of task set. But then one still needs to explain why this particular timing aspect of task set affects the group difference more than others. Now it occurs to me that the puzzling direction of pre-RSVP time is compatible with Ahissar's anchoring deficit theory. Here basically dyslexics fail to benefit from task-specific regularities that benefit controls. May be worth discussing. But this cannot explain the opposite effect of T2 temporal variability.
Comments for the author
label_cfta_1
This new version of the paper is much improved and largely satisfactory. I mostly have minor comments. The discussion is the main area that could still be improved. Cite this review as
Ramus F ( 2015 ) Peer Review #1 of "Temporal variability predicts the magnitude of between-group attentional blink differences in developmental dyslexia: a meta-analysis (v0.2)" . PeerJ https://doi.org/10.7287/peerj.746v0.2/reviews/1 Download Version 0.2 (PDF)
Download author's rebuttal letter
- submitted Nov 19, 2014
label_version_3
Version 0.1 (original submission)
Jafri Abdullah
·
Apr 22, 2014
label_recommendation_3
·
Academic Editor
Major Revisions
Dear Authors, Could you do the necessary revisions as per the comments by the two reviewers especially those from Reviewer 1, who akes several suggestions to improve the quality of the manuscript.
label_author_2
Franck Ramus ·
Apr 18, 2014
Basic reporting
label_br_2
•The acronym RSVP is often used in ways that seem to mean something other than « rapid serial visual presentation ». Sometimes to refer to the fixation symbol at the beginning of a trial, sometimes to refer to a trial or to items within a trial. The language should be clarified in this respect. My impression is that removing RSVP in many instances will help. •Line 153 the fixation duration parameter should be better explained. It is actually the fixation symbol duration. It remains unclear to me what a duration of 0 ms means. If it means “no fixation symbol”, is it legitimate to treat this situation on the same scale as those with a fixation symbol? •Line 161: “if T2 is a FIXED letter of the alphabet” would be clearer. •Line 163: there -> they •Line 187: remove “in” •Lines 231-232: r values differ slightly from those reported in the table.
Experimental design
label_ed_2
Although I am not an expert of meta-analyses (I hope that another reviewer is), I have a few important concerns with the way the meta-analysis is conducted in the present paper : •Three studies are excluded from the meta-analysis, two of which for reasons that seem hardly justified (lines 128-135). One is excluded on the grounds that the effect is in the opposite direction from the others. In my view this is no reason for exclusion. Imagine if a meta-analysis of clinical trials excluded trials where the treatment had a negative (rather than positive) effect on patients! The virtue of meta-analyses is to provide an objective synthesis of contradictory research findings. It defies the entire purpose of a meta-analysis to a priori exclude a study because it seems in contradiction with the others. The same reasoning applies for the second study that is excluded on the grounds that the authors judge the effect size to be anomalous. If they suspect that the odd effect size results from a typo in a table or a miscalculation, then they should contact the authors to clarify this. But if it turns out that the numbers do reflect the actual data, then the study should be included in the meta-analysis. With respect to the third study (whose effect size could not be computed from the reported results), it should be easy enough to contact the authors and obtain the desired numbers. Given that the number of studies in this meta-analysis is quite low for the purpose of the mediation analyses proposed, all reasonable efforts should be made to include as many as possible. •I wonder if the approach consisting of just testing simple correlations between effect size and all possible parameters represents the state of the art for this kind of research. First, shouldn’t a test of heterogeneity (of effect sizes) be done to justify the search for mediators? Second, shouldn’t slightly more sophisticated meta-regression models be used? Again, I am not an expert on meta-analysis so I might be wrong on this. The view of a real expert would be welcome. •The number of parameters investigated (18) is disproportionately large compared to the number of studies meta-analysed (6 to 9). Given that many parameters are confounded with each other, maybe a more parsimonious approach would be to start with a factor analysis, use it (if its results are clear enough) to compute a more limited number of composite measures (average z-scores of some variables) to be tested as mediators in the meta-regression, and when some of them turn out to be significant, discuss which of the underlying variables is likely to produce the effect. It may well be that in some cases this is undecidable because some parameters are equally plausible and turn out to be confounded in published studies. This approach may be preferable to adjudicating between parameters on the basis of small, non-significant differences between correlations (as has been done between distractor ID and T2 time max and difference, for instance). An alternative approach would be to carry out multiple rather than simple regressions, in order to try and disentangle between confounded variables. But this will still be limited by the small number of studies. More minor comments: •The justification for rescuing the non-significant effect of SOA with R=-0.66 but not the non-significant effect of distractor ID with R=-0.78 is a bit awkward. Either Pearson’s test applies or it doesn’t. Perhaps reporting and reasoning only on Pearson when distribution is normal, and on Spearman when not, would make it clearer. This problem would disappear with the factor analysis approach mentioned above.
Validity of the findings
label_votf_2
Apart from the problem of confounded variables that are impossible to disentangle, I am not entirely convinced by some of the interpretations offered in the discussion. With respect to fixation duration, wouldn’t the authors’ interpretation predict a negative correlation instead? If the task is more difficult with shorter fixation duration, and if dyslexics need more preparation time, they should be at a greater disadvantage (large effect size) when fixation duration is short (thus negative correlation). The idea that dyslexics would not benefit at all from greater preparation does not seem very plausible. Similarly for T2 temporal position and variability, it is suggested that in the more variable and difficult conditions, the task is so challenging that floor effects are reached for both groups (hence small effect size), and it is in the less variable (easier) conditions that group differences emerge. In many tasks with dyslexic participants, this is just the contrary: performance is at ceiling in easy conditions and group differences emerge in more difficult conditions (see for instance discussion of task difficulty in Ramus and Ahissar 2012). Furthermore the Badcock et al (2011) study that is cited does not seem to support the authors’ interpretation: if there is a group difference in the first half of the experiment (without practice, difficult) but not in the second half (with practice, easier), then this is a ceiling, not a floor effect. At any rate, any conjecture on a floor or on a ceiling effect could be tested by looking at absolute performance in the initial studies. I can’t see clearly the link between SOA and the discussion in lines 349-365. In their discussion (section 7.1) of the “anomalous” results of Lacroix et al. and Buchholz et al., the authors speculate about experimental parameters that might explain such results: children rather than adult participants, number stimuli, target-distractor relationship, and task-set. But the proper way to test these hypotheses would be to include these studies and these additional parameters in the analysis. Line 390: I don’t understand how the effect might reverse (as opposed to just disappearing) in adults as retrieval becomes more automatic.
Cite this review as
Ramus F ( 2015 ) Peer Review #1 of "Temporal variability predicts the magnitude of between-group attentional blink differences in developmental dyslexia: a meta-analysis (v0.1)" . PeerJ https://doi.org/10.7287/peerj.746v0.1/reviews/1
label_author_3
Reviewer 2 ·
Apr 22, 2014
Basic reporting
label_br_3
No Comments
Experimental design
label_ed_3
No Comments
Validity of the findings
label_votf_3
No Comments
Comments for the author
minor clarification: Method in abstract states 13 experiments (11 papers) returned when search conducted, but experimental section states 26 entries returned in search. Otherwise a very well written and informative manuscript Cite this review as
Anonymous Reviewer ( 2015 ) Peer Review #2 of "Temporal variability predicts the magnitude of between-group attentional blink differences in developmental dyslexia: a meta-analysis (v0.1)" . PeerJ https://doi.org/10.7287/peerj.746v0.1/reviews/2 Download Original Submission (PDF)
- submitted Mar 29, 2014 All text and materials provided via this peer-review history page are made available under a Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.
About us - PeerJ team | Our publications | Benefits | Partnerships | Endorsements Awards Resources - FAQ | Careers | Pressroom | Terms of use | Privacy | Contact Academic boards - Advisors | Editors | Subject areas Follow us - PeerJ blog | Twitter | Facebook | LinkedIn | Pinterest Submission guides - PeerJ (life - bio - med) | Computer Science | Chemistry | PeerJ Preprints instructions Spread the word - Activities | Resources PeerJ feeds - Atom | RSS 1.0 | RSS 2.0 | JSON PeerJ Computer Science feeds - Atom | RSS 1.0 | RSS 2.0 | JSON PeerJ Preprint feeds - Atom | RSS 1.0 | RSS 2.0 | JSON Archives - PeerJ | PeerJ Computer Science | PeerJ Preprints
©2012-2019 PeerJ, Inc | Public user content licensed CC BY 4.0 unless otherwise specified. PeerJ ISSN: 2167-8359 PeerJ Comput. Sci. ISSN: 2376-5992 PeerJ Preprints ISSN: 2167-9843
brain cognition
