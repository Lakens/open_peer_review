Review History for The effect of using games in teaching conservation [PeerJ]
PeerJ Journals Peer-reviewed PeerJ – the Journal of Life & Environmental Sciences PeerJ Computer Science PeerJ Physical Chemistry PeerJ Organic Chemistry PeerJ Inorganic Chemistry PeerJ Analytical Chemistry PeerJ Materials Science Preprints PeerJ Preprints Visit PeerJ.org and get involved About PeerJ Journals Overview PeerJ Journals FAQ What we publish 5 Years publishing Solutions for authors Reputation High quality peer review Fast publishing Indexing and Impact Factor Global readership Feature comparison Reduced cost publishing Author feedback Early career researcher benefits Senior researcher benefits Open review (optional) Rebuttal letters Sections About the journal Sections Aquatic Biology Biochemistry, Biophysics and Molecular Biology Biodiversity and Conservation Bioinformatics and Genomics Brain and Cognition Ecology Environmental Science Microbiology Paleontology and Evolutionary Science Plant Biology Zoological Science About PeerJ Journals Overview PeerJ Journals FAQ What we publish 5 Years publishing Solutions for authors Reputation High quality peer review Fast publishing Indexing and Impact Factor Global readership Feature comparison Reduced cost publishing Author feedback Early career researcher benefits Senior researcher benefits Open review (optional) Rebuttal letters More Subjects Search articles Advanced search of articles & preprints PeerJ - Medicine articles PeerJ - Biology & Life science articles PeerJ Computer Science PeerJ Preprints Table of contents Table of Contents - current and archives PeerJ - Medicine articles PeerJ - Biology & Life science articles PeerJ - Environmental Science articles PeerJ - General bio (stats, legal, policy, edu) PeerJ Computer Science PeerJ Preprints Academic advisors Volunteer to review Collections Job listings Discussions Blog Institutional plans Reviews and awards Spread the word Who are we? Contact Login AUTHORS Peer Journals Overview Submission Guidelines Subject Areas Editorial Board Editorial Criteria Pricing General FAQ Computer Science FAQ Aims and Scope Author Interviews Policies and Procedures SUBMIT ARTICLE
Review History The effect of using games in teaching conservation To increase transparency, PeerJ operates a system of 'optional signed reviews and history'. This takes two forms: (1) peer reviewers are encouraged, but not required, to provide their names (if they do so, then their profile page records the articles they have reviewed), and (2) authors are given the option of reproducing their entire peer review history alongside their published article (in which case the complete peer review process is provided, including revisions, rebuttal letters and editor decision letters). New to public reviews? Learn more about optional signed reviews and how to write a better rebuttal letter .
Summary
The initial submission of this article was received on September 5th, 2017 and was peer-reviewed by 3 reviewers and the Academic Editor. The Academic Editor made their initial decision on October 5th, 2017. The first revision was submitted on January 23rd, 2018 and was reviewed by the Academic Editor. A further revision was submitted on February 24th, 2018 and was reviewed by the Academic Editor. The article was Accepted by the Academic Editor on February 26th, 2018.
label_version_1
Version 0.3 (accepted)
Julia Sewall
·
Feb 26, 2018
label_recommendation_1
·
Academic Editor
Accept
Thanks for addressing the comments I made. The manuscript is now ready for publication, congratulations!
Download Version 0.3 (PDF)
Download author's rebuttal letter
- submitted Feb 24, 2018
label_version_2
Version 0.2
Julia Sewall
·
Feb 1, 2018
label_recommendation_2
·
Academic Editor
Minor Revisions
Let me start by saying that we truly appreciate the expensive revisions you have introduced. It has dramatically improved the manuscript. Before the current version is ready for publication, please address the following: -Despite the popularity of learning styles there is no evidence to support the idea that matching activities to one’s learning style improves learning. Please discuss the work of Harold Pashler, Mark McDaniel, Doug Rohrer, and Robert Bjork. The instrument and learning styles you are using doesn't seem to be up to date with current literature in the field. Please discuss this. -In assessments you describe quizzes pre and post-session to examine the knowledge acquired by each individual. Where the questions administered the same pre and post? if not, how where they compared pre/post? I understand they were classified in different types (reproduction-, meaning- or application) complementary to the learning styles, can you clarify what this means? How do they classify in terms of cognitive level/difficulty (e.g. Blooms taxonomy)? and how are they matched pre and post? Are the questions validated (for difficulty, discrimination and reliability)? Psychometric item validation is recommended. -In assessments you also mention that behavior was evaluated via observational surveys and video recording during the classroom. Can you add citations and/or describe the validity of protocols? if the protocol is new, we suggest adding statistical validation of the method used. -Figure 1 doesn't explain how supplemental game or experiential game were alternated. The experimental design should be reflected in every figure. For example, how do results in figure 2 aligning with design in figure 1. Clarify. -Figure 2: please clarify how each score shown in figure 2 was calculated. Clarify meaning of axes. e.g. "after minus before relationship"? -Figure 4 must include description and validation of items used to calculate learning pre and post. Are questions used the same? comparing apples to apples? or difficulty level (e.g. Blooms taxonomy) varies? -All supplementary material figure legends need to include correlation coefficients, statistics associated to it. For tables the variables tested are hard to follow. -All legends need to be expanded to clarify variables, calculated scores, validation and statistics used.
Download Version 0.2 (PDF)
Download author's rebuttal letter
- submitted Jan 23, 2018
label_version_3
Version 0.1 (original submission)
Julia Sewall
·
Oct 5, 2017
label_recommendation_3
·
Academic Editor
Major Revisions
Please address all of the reviewers' comments, as listed below, In addition, please improve the following: -Clarity of the protocol. It is quite difficult to follow the details of how the experiment was done. -Demographics and number of participants used is unclear. Combine the participants details (main manuscript plus Suppl material) and write a clear paragraph, including a cohort demographics description table. -Include the questionnaires and observations protocols used, or add citations for them at all times. In addition, discuss validation scores and explain why those surveys/observations protocols were chosen for this study. Discuss surveys and observation protocols limitations. Authors mention some modification to the surveys. More information and rationale is needed for these choices. -Explain how observations were performed and discuss bias. -The experimental design section does not fully describe the intervention and approach for teaching styles. Include a detailed explanation of the choices made for approaches, design and controls/experimental groups. -Please discuss recent literature on learning styles and explain your experimental choice to use the 1994 survey. -Please include Institutional review board information. Importantly: -Discuss how the study was framed to be objective towards the treatments.
label_author_1
Reviewer 1 ·
Sep 26, 2017
Basic reporting
label_br_1
The manuscript lacks clarity in many respects, and in particular on the methods and experimental design. The manuscript also needs additional review by an English speaker for clarity of language.
Experimental design
label_ed_1
This study was designed to investigate the effect of using different types of games in conservation training courses for early-career professionals. The topic and questions explored in this study are interesting and worthy of attention, and the effort to collect data on instructional effectiveness and learning outcomes is commendable. The authors are clearly thoughtful educators and raise important questions in the discussion that are worthy of further investigation. However, the study seems to have a number of weaknesses in terms of the experimental design and data collection methods, and the manuscript lacks clarity in many respects. The latter would require significant re-writing, but the former are harder to address.
Validity of the findings
label_votf_1
I was unable to fully evaluate the statistical analyses in detail because of my lack of familiarity with the methods used, but have important concerns about the methods. Concerns with the experimental design and justification of methods: - The overall design is not clearly described or justified. Table 1 supplies some information, but it is that comprehensive and leaves many open questions. How long was each game played for? Can they be considered analogous? How was the data binned or combined for analyses? What would be required is a table or figure that clearly lays out: a global picture of how many students were included in the data collection in each course and each year, with each set of analogous questionnaires (since these changed over time), that is, which sets of student experienced the same questionnaires and design (repeated measures versus counterbalanced), and what the sample size was for each set. - Why were two different designs used (repeated measures and counterbalanced)? There is no explanation for the choice of these approaches, nor sources cited, or why both were used in this study, nor how they affected the results. The potential for order effects is raised in the methods section (Line 178) but not furher discussed. - The application of three types of instruction (supplememntal games, experiential games, and didactic instruction) is evaluated in terms of its effect on perception (through questionnaires), learning (through content quizzes), and behavior (through observations). Unsufficient information is provided on how these data collection tools were designed and validated and the questionnaires and quizzes themselves do not seem to be available. How were the questions formulated? Where they tested in any way? For example, in the observations of behavior, the asking/answering of questions was quantified - were the type of questions relevant? When observing and recording behaviors, was this done for the whole group playing the game, or were these recorded per individual? If a single individual asked most of the questions this could impact the data. - Why were changes made to the questionnaires over time (as per lines 194-195) and how did these potentially affect the results? This is not explained or discussed. - There is no discussion of the possible limitations of self-assessment questions. A suggestion: A summary of good practices for validation can be found in Dirks, Clarissa, Mary Pat Wenderoth, and Michelle Withers. Assessment in the college science classroom. WH Freeman, 2014. Chapter 7.
Comments for the author
label_cfta_1
Additional / specific comments: Line 97 - I would disagree with the authors that conservation biology focuses on cause-and-effect systems. In my view, they are dynamic and complex systems with feedbacks and time-delays, not cause-and-effect. The authors should include citations to support this characterization. - In Line 186 the authors state that additional assessment was done for a portion of the students after one week to assess "long-term” knowledge acquisition. I would disagree that one week can be considered long-term, or would like to see references supporting this characterization. Line 205-207 is unclear. Line 222 - it is not clear what is meant by “statement" here. Lines 342-344 are unclear Line 372 Sentence starting with "Second, instead of regurgitating..” is poorly written and unclear. It is unclear, who is regurgitating the knowledge here and what is being proposed instead and on what grounds. Line 391 - what is meant by “first-hand”? Lines 354-356 The authors interpret the lack of interaction between personality scores and lesson type on questionnaire scores (behavior) as evidence that the preference for EG over DI is universal. I would argue that this but one interpretation. This could also be interpreted as limited sensitivity of these tools or the experimental design to changes in preferences. These other interpretations should also be discussed as opposed to making this strong claim. Minor errors: Line 366 centre or central? Line 325 uleast = least There is a typing error in Question 3 in Supplemental material “Learning_style_survey" The manuscript needs additional review by an English speaker for clarity of language. For example, the second sentence in the abstract is confusing: Line 22 - "Games are an increasingly popular approach for conservation teaching. However, we know little about the effectiveness of the games on conservation teaching.” Do the authors intend to mean effectivess of the teaching? That is not what is being measured in the study, but rather the effects of the games on student experiences and knowledge acquisition. Other examples of sentences that would benefit from a review of language for clarity and precision are: Line 24-25 - I think was is meant is: goal-oriented tasks found in real-life situations Line 60 - both or all? Line 95 emphasizes Cite this review as
Anonymous Reviewer ( 2018 ) Peer Review #1 of "The effect of using games in teaching conservation (v0.1)" . PeerJ https://doi.org/10.7287/peerj.4509v0.1/reviews/1
label_author_2
Reviewer 2 ·
Sep 29, 2017
Basic reporting
label_br_2
The manuscript can be improved by making the writing clearer and more concise. Because there are many elements to the study, it is difficult to keep track of the different components, so making sure that the same terms are used, clarifying definitions, and putting details into table form can do much in helping the reader navigate. There also repetitions of statements and extraneous language, particularly in the introduction.
Experimental design
label_ed_2
The authors have collected data on many aspects of the students' experience and performance over several groups and years, which makes it difficult to organize in a coherent manner. More clarity about some aspects of the methodology are needed, particularly why certain parts of the data collection only applied to certain groups and especially how biases were eliminated (example, the person conducting the sessions giving equal effort to all treatments; how the concepts and content of different modes of instruction were made comparable). The behavioural data collected on 'joyful behavior' seems particularly biased towards showing positive outcomes for the games versus the didactic instruction, so I am not sure if this should even be included. The presentation of the results may benefit from being summarized both in text and figures.
Validity of the findings
label_votf_2
I do think the findings are interesting, but am concerned that there are statements that try to explicitly link what happens in the classroom setting will also result in behaviors and attitudes with positive outcomes for conservation are an overreach. I would suggest really being careful and specific about where the findings/conclusions of this study, especially outside of a learning environment, would apply. The conclusion section should probably be rewritten with this in mind.
Comments for the author
label_cfta_2
I do think that this study has merit and interesting results, but how the manuscript was put together was confusing at times. I think that it can be made more coherent and cohesive - links are needed between the perception of the students about the experience of games in the classroom and the benefits this provides for learning or social outcomes. I provide more comments in the pdf which I hope will improve it. Cite this review as
Anonymous Reviewer ( 2018 ) Peer Review #2 of "The effect of using games in teaching conservation (v0.1)" . PeerJ https://doi.org/10.7287/peerj.4509v0.1/reviews/2
label_author_3
Reviewer 3 ·
Oct 3, 2017
Basic reporting
label_br_3
High standard of academic English used that was clear and easy to understand to someone versed in the discipline. Good and correct use of referencing. Some of the data could perhaps be more easily conveyed to the reader through the used of tables or charts. Overall well structured and presented.
Experimental design
label_ed_3
Overall a very good experimental design that used multiple approaches to triangulate th results of the data. Some more description of the observational aspects of the research (e.g. observing the behaviour students) might be required within the main text of the article.
Validity of the findings
label_votf_3
Findings appear valid and well constructed. The use of multiple avenues of data collection as well as more than one research design (i.e. both counterbalanced and repeated-measures) provided reliability to the data.
Comments for the author
Overall an excellent paper. Some minor adjustments in terms of the presentation of the results and the data could just improve the overall quality of the paper. Cite this review as
Anonymous Reviewer ( 2018 ) Peer Review #3 of "The effect of using games in teaching conservation (v0.1)" . PeerJ https://doi.org/10.7287/peerj.4509v0.1/reviews/3 Download Original Submission (PDF)
- submitted Sep 5, 2017 All text and materials provided via this peer-review history page are made available under a Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.
About us - PeerJ team | Our publications | Benefits | Partnerships | Endorsements Awards Resources - FAQ | Careers | Pressroom | Terms of use | Privacy | Contact Academic boards - Advisors | Editors | Subject areas Follow us - PeerJ blog | Twitter | Facebook | LinkedIn | Pinterest Submission guides - PeerJ (life - bio - med) | Computer Science | Chemistry | PeerJ Preprints instructions Spread the word - Activities | Resources PeerJ feeds - Atom | RSS 1.0 | RSS 2.0 | JSON PeerJ Computer Science feeds - Atom | RSS 1.0 | RSS 2.0 | JSON PeerJ Preprint feeds - Atom | RSS 1.0 | RSS 2.0 | JSON Archives - PeerJ | PeerJ Computer Science | PeerJ Preprints
©2012-2019 PeerJ, Inc | Public user content licensed CC BY 4.0 unless otherwise specified. PeerJ ISSN: 2167-8359 PeerJ Comput. Sci. ISSN: 2376-5992 PeerJ Preprints ISSN: 2167-9843
biodiversity conservation
