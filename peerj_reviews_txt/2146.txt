Review History for Interrater reliability of quantitative ultrasound using force feedback among examiners with varied levels of experience [PeerJ]
PeerJ Journals Peer-reviewed PeerJ – the Journal of Life & Environmental Sciences PeerJ Computer Science PeerJ Physical Chemistry PeerJ Organic Chemistry PeerJ Inorganic Chemistry PeerJ Analytical Chemistry PeerJ Materials Science Preprints PeerJ Preprints Visit PeerJ.org and get involved About PeerJ Journals Overview PeerJ Journals FAQ What we publish 5 Years publishing Solutions for authors Reputation High quality peer review Fast publishing Indexing and Impact Factor Global readership Feature comparison Reduced cost publishing Author feedback Early career researcher benefits Senior researcher benefits Open review (optional) Rebuttal letters Sections About the journal Sections Aquatic Biology Biochemistry, Biophysics and Molecular Biology Biodiversity and Conservation Bioinformatics and Genomics Brain and Cognition Ecology Environmental Science Microbiology Paleontology and Evolutionary Science Plant Biology Zoological Science About PeerJ Journals Overview PeerJ Journals FAQ What we publish 5 Years publishing Solutions for authors Reputation High quality peer review Fast publishing Indexing and Impact Factor Global readership Feature comparison Reduced cost publishing Author feedback Early career researcher benefits Senior researcher benefits Open review (optional) Rebuttal letters More Subjects Search articles Advanced search of articles & preprints PeerJ - Medicine articles PeerJ - Biology & Life science articles PeerJ Computer Science PeerJ Preprints Table of contents Table of Contents - current and archives PeerJ - Medicine articles PeerJ - Biology & Life science articles PeerJ - Environmental Science articles PeerJ - General bio (stats, legal, policy, edu) PeerJ Computer Science PeerJ Preprints Academic advisors Volunteer to review Collections Job listings Discussions Blog Institutional plans Reviews and awards Spread the word Who are we? Contact Login AUTHORS Peer Journals Overview Submission Guidelines Subject Areas Editorial Board Editorial Criteria Pricing General FAQ Computer Science FAQ Aims and Scope Author Interviews Policies and Procedures SUBMIT ARTICLE
Review History Interrater reliability of quantitative ultrasound using force feedback among examiners with varied levels of experience To increase transparency, PeerJ operates a system of 'optional signed reviews and history'. This takes two forms: (1) peer reviewers are encouraged, but not required, to provide their names (if they do so, then their profile page records the articles they have reviewed), and (2) authors are given the option of reproducing their entire peer review history alongside their published article (in which case the complete peer review process is provided, including revisions, rebuttal letters and editor decision letters). New to public reviews? Learn more about optional signed reviews and how to write a better rebuttal letter .
Summary
The initial submission of this article was received on April 5th, 2016 and was peer-reviewed by 2 reviewers and the Academic Editor. The Academic Editor made their initial decision on May 17th, 2016. The first revision was submitted on May 23rd, 2016 and was reviewed by 2 reviewers and the Academic Editor. The article was Accepted by the Academic Editor on May 27th, 2016.
label_version_1
Version 0.2 (accepted)
Justin Keogh
·
May 27, 2016
label_recommendation_1
·
Academic Editor
Accept
We appreciate the effort you have made in addressing some of the initial concerns of the reviewers. As a consequence we are happy to recommend acceptance of this manuscript.
label_author_1
Ryan Timmins ·
May 26, 2016
Basic reporting
label_br_1
No comments
Experimental design
label_ed_1
No comments
Validity of the findings
label_votf_1
No comments
Comments for the author
label_cfta_1
All revisions address the concerns raised. Cite this review as
Timmins R ( 2016 ) Peer Review #1 of "Interrater reliability of quantitative ultrasound using force feedback among examiners with varied levels of experience (v0.2)" . PeerJ https://doi.org/10.7287/peerj.2146v0.2/reviews/1
label_author_2
Glen Lichtwark ·
May 24, 2016
Basic reporting
label_br_2
I am happy with the changes made to the document. The description of how the images were acquired and the changes to the aims of the study make things more clear.
Experimental design
label_ed_2
I believe this is appropriate for the purposes of the analysis.
Validity of the findings
label_votf_2
The findings are robust, statistically sound and controlled.
Cite this review as
Lichtwark GA ( 2016 ) Peer Review #2 of "Interrater reliability of quantitative ultrasound using force feedback among examiners with varied levels of experience (v0.2)" . PeerJ https://doi.org/10.7287/peerj.2146v0.2/reviews/2 Download Version 0.2 (PDF)
Download author's rebuttal letter
- submitted May 23, 2016
label_version_2
Version 0.1 (original submission)
Justin Keogh
·
May 17, 2016
label_recommendation_2
·
Academic Editor
Minor Revisions
The reviewers are impressed with many aspects of the manuscript and study. Additonal clarifiication is required on some aspects of the image acquisition process and how this was actually performed. Such details are vital if this method is to be used in clincial practice.
label_author_3
Ryan Timmins ·
Apr 22, 2016
Basic reporting
label_br_3
No mention of funding. It seems like a study which may not have been possible without associated funding (robotics etc). If this is the case, then the authors should be commended. However this might be worth double checking. As a reviewer I lack the technical knowledge of the processes behind the development of the device and processes. However my comments will be designed around the practical and clinical applications of the paper. ABSTRACT: This section is concise and contains the required information. TITLE: The title is appropriate INTRODUCTION: The introduction is well structured and provides sufficient direction to the development of the hypothesis and aims.
Experimental design
label_ed_3
The number of sonographers may be too minimal to draw significant causational conclusions from. This may explain the lack of difference between the levels of expertise in the study. As this wasn’t a main aim of the study, the paper should not be rejected because of it. However I believe it does limit some of the implications to be drawn from only 6 sonographers (2 per level of expertise). The authors should consider mentioning this point in their limitations section. I was quite surprised there was no difference in the results between the levels of proficiency.
Validity of the findings
label_votf_3
No Comments
Comments for the author
label_cfta_3
As a reviewer I lack the technical knowledge of the processes behind the development of the device and processes. However my comments will be designed around the practical and clinical applications of the paper. The authors should be commended for their work. It is a well thought out study with some useful practical implications. However I believe determining how to implement these findings in a practical setting is the next step. I understand the paper current paper was more of a ‘proof of concept’ approach and it achieves this. However I believe it might be worth spending sometime on trying to figure out how this might have some transmission to practice. Are we all going to purchase these housings and use them when scanning? From a clinical perspective, it doesn’t seem to have the necessary links to its application. Yet from a research and laboratory perspective, it is golden! It is a great way of standardizing process of data acquisition. Cite this review as
Timmins R ( 2016 ) Peer Review #1 of "Interrater reliability of quantitative ultrasound using force feedback among examiners with varied levels of experience (v0.1)" . PeerJ https://doi.org/10.7287/peerj.2146v0.1/reviews/1
label_author_4
Glen Lichtwark ·
May 17, 2016
Basic reporting
label_br_4
In general this is a well reported reliability study. The premise for the study is sufficient. The methods suitable and the results are reported adequately. Finally, the authors critically analyse their data well, and put the results into context with other similar approaches that have been utilised. My main criticism that I believe need editing is that the section explaining the automated image acquisition needs to be improved. It took me three reads to know what this process was about, so I suggest that the paragraph of 165-186 should be prefaced with a sentence explaining what this process is required for (ie. to create criterion referenced measures for comparison).
Experimental design
label_ed_4
The experimental design is certainly adequate and the aims clear and approach to achieve the aims suitable. My only criticism of the reporting of the methods is that it is not mentioned anywhere how the images were collected and whether this was a manual or automated process. Were the images manually recorded when the target forces were met, or was this process automated? Some extra detail is needed here, because this could potential influence the results.
Validity of the findings
The data is robust and the statistics are suitable and the conclusions are reasonable - the reliability is excellent.
Cite this review as
Lichtwark GA ( 2016 ) Peer Review #2 of "Interrater reliability of quantitative ultrasound using force feedback among examiners with varied levels of experience (v0.1)" . PeerJ https://doi.org/10.7287/peerj.2146v0.1/reviews/2 Download Original Submission (PDF)
- submitted Apr 5, 2016 All text and materials provided via this peer-review history page are made available under a Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.
About us - PeerJ team | Our publications | Benefits | Partnerships | Endorsements Awards Resources - FAQ | Careers | Pressroom | Terms of use | Privacy | Contact Academic boards - Advisors | Editors | Subject areas Follow us - PeerJ blog | Twitter | Facebook | LinkedIn | Pinterest Submission guides - PeerJ (life - bio - med) | Computer Science | Chemistry | PeerJ Preprints instructions Spread the word - Activities | Resources PeerJ feeds - Atom | RSS 1.0 | RSS 2.0 | JSON PeerJ Computer Science feeds - Atom | RSS 1.0 | RSS 2.0 | JSON PeerJ Preprint feeds - Atom | RSS 1.0 | RSS 2.0 | JSON Archives - PeerJ | PeerJ Computer Science | PeerJ Preprints
©2012-2019 PeerJ, Inc | Public user content licensed CC BY 4.0 unless otherwise specified. PeerJ ISSN: 2167-8359 PeerJ Comput. Sci. ISSN: 2376-5992 PeerJ Preprints ISSN: 2167-9843
NA
