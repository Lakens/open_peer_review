Review History for Some methods to improve the utility of conditioned Latin hypercube sampling [PeerJ]
PeerJ Journals Peer-reviewed PeerJ – the Journal of Life & Environmental Sciences PeerJ Computer Science PeerJ Physical Chemistry PeerJ Organic Chemistry PeerJ Inorganic Chemistry PeerJ Analytical Chemistry PeerJ Materials Science Preprints PeerJ Preprints Visit PeerJ.org and get involved About PeerJ Journals Overview PeerJ Journals FAQ What we publish 5 Years publishing Solutions for authors Reputation High quality peer review Fast publishing Indexing and Impact Factor Global readership Feature comparison Reduced cost publishing Author feedback Early career researcher benefits Senior researcher benefits Open review (optional) Rebuttal letters Sections About the journal Sections Aquatic Biology Biochemistry, Biophysics and Molecular Biology Biodiversity and Conservation Bioinformatics and Genomics Brain and Cognition Ecology Environmental Science Microbiology Paleontology and Evolutionary Science Plant Biology Zoological Science About PeerJ Journals Overview PeerJ Journals FAQ What we publish 5 Years publishing Solutions for authors Reputation High quality peer review Fast publishing Indexing and Impact Factor Global readership Feature comparison Reduced cost publishing Author feedback Early career researcher benefits Senior researcher benefits Open review (optional) Rebuttal letters More Subjects Search articles Advanced search of articles & preprints PeerJ - Medicine articles PeerJ - Biology & Life science articles PeerJ Computer Science PeerJ Preprints Table of contents Table of Contents - current and archives PeerJ - Medicine articles PeerJ - Biology & Life science articles PeerJ - Environmental Science articles PeerJ - General bio (stats, legal, policy, edu) PeerJ Computer Science PeerJ Preprints Academic advisors Volunteer to review Collections Job listings Discussions Blog Institutional plans Reviews and awards Spread the word Who are we? Contact Login AUTHORS Peer Journals Overview Submission Guidelines Subject Areas Editorial Board Editorial Criteria Pricing General FAQ Computer Science FAQ Aims and Scope Author Interviews Policies and Procedures SUBMIT ARTICLE
Review History Some methods to improve the utility of conditioned Latin hypercube sampling To increase transparency, PeerJ operates a system of 'optional signed reviews and history'. This takes two forms: (1) peer reviewers are encouraged, but not required, to provide their names (if they do so, then their profile page records the articles they have reviewed), and (2) authors are given the option of reproducing their entire peer review history alongside their published article (in which case the complete peer review process is provided, including revisions, rebuttal letters and editor decision letters). New to public reviews? Learn more about optional signed reviews and how to write a better rebuttal letter .
Summary
The initial submission of this article was received on October 2nd, 2018 and was peer-reviewed by 3 reviewers and the Academic Editor. The Academic Editor made their initial decision on November 30th, 2018. The first revision was submitted on December 21st, 2018 and was reviewed by 1 reviewer and the Academic Editor. The article was Accepted by the Academic Editor on January 15th, 2019.
label_version_1
Version 0.2 (accepted)
Paolo Giordani
·
Jan 15, 2019
label_recommendation_1
·
Academic Editor
Accept
In the revised version of the manuscript very detailed responses are provided to comments raised by all the reviewers. Requested changes have been mainly applied and most important choices have been fully discussed both in the rebuttal letter and in the revised text (see e.g. the question raised by the reviewer about the structure of Table 2). I think that the ms is now suitable for publication in PeerJ.
label_author_1
Reviewer 2 ·
Jan 5, 2019
Basic reporting
label_br_1
The English of the manuscript is clear to the readers and sufficient references are provided. The article structure meets the standard and R scripts of the study are provided. The results confirm the aims/hypotheses of the paper.
Experimental design
label_ed_1
The article is novel as it provides modifications to a previous widely used sampling algorithm proposed by one of the authors. The research questions are well defined and the three problems related to sampling identified in the article are also widely faced in other field studies. The use of various statistical indices are rigorous and provides useful insights into the validity of the new algorithms the author proposed. The R scripts provided by the authors enable others to repeat the results.
Validity of the findings
label_votf_1
The data, methods, and results are robust for the algorithms and case studies.
Comments for the author
label_cfta_1
The authors have provided detailed responses to comments raised by all the reviewers. The manuscript has been materially improved and become much clearer to the readers after extra figures and tables have been inserted. Cite this review as
Anonymous Reviewer ( 2019 ) Peer Review #2 of "Some methods to improve the utility of conditioned Latin hypercube sampling (v0.2)" . PeerJ https://doi.org/10.7287/peerj.6451v0.2/reviews/2 Download Version 0.2 (PDF)
Download author's rebuttal letter
- submitted Dec 21, 2018
label_version_2
Version 0.1 (original submission)
Paolo Giordani
·
Nov 30, 2018
label_recommendation_2
·
Academic Editor
Minor Revisions
There are some minor issues that could be addressed for improving the readability of the paper. They mainly concern changes to the figures (e.g. for showing the additional sample data coverage across the study area in fig.3) and in table 2 (where it could be useful to see some additional information about the ancillary data used). Moreover, it is also suggested to include three separate flowcharts for algorithms 1–3. Reviewer #3 suggests that a worked example with real data near a cLHS-proposed sampling site would be a nice addition.
label_author_2
Reviewer 1 ·
Nov 1, 2018
Basic reporting
label_br_2
It is clear.
Experimental design
label_ed_2
It is clear.
Validity of the findings
label_votf_2
It is clear.
Cite this review as
Anonymous Reviewer ( 2019 ) Peer Review #1 of "Some methods to improve the utility of conditioned Latin hypercube sampling (v0.1)" . PeerJ https://doi.org/10.7287/peerj.6451v0.1/reviews/1
label_author_3
Reviewer 2 ·
Nov 4, 2018
Basic reporting
label_br_3
The English of the manuscript is clear to the readers and sufficient references are provided. The article structure meets the standard and R scripts of the study are provided. The results confirm the aims/hypotheses of the paper.
Experimental design
label_ed_3
The article is novel because it provides modifications to a previous widely used sampling algorithm proposed by one of the authors. The research questions are well defined and the three problems related to sampling identified in the article are also widely faced in other field studies. The use of various statistical indices are rigorous and provides useful insights into the validity of the new algorithms the author proposed. The R scripts provided by the authors enable others to repeat the results.
Validity of the findings
label_votf_3
The data, methods and results and robust for the first two algorithms and case studies. Additional statistical metrics should be provided for the third case study.
Comments for the author
label_cfta_3
In this study, the authors collated, summarized, and extended existing solutions to problems that field scientists face when using cLHS sampling. They provided solutions to optimize the sample size, re-locate sites when an original site is inaccessible, and to account for existing sample data when additional samples are to be taken. The authors also provided the R scripts to facilitate other researchers with the sampling design in the field. In general, the manuscript was well written and the ideas are novel to the audience in the related fields. I believe that the manuscript will interest a large number of researchers who face similar problems in using the popular cLHS sampling in the field and provide guidance for people who attempt to improve the existing random stratified sampling algorithms. I have a few minor comments on the manuscript. Lines 134-135: Why the penalty of missing a sampling from the tail of a distribution is larger than that close to the mode? When the sample has a small distribution, O_i should be smaller, isn’t it? Figure 1: the legends are too small to read. Figure 3: Please provide a new subfigure that shows the additional sample data coverage across the study area. Table 2: Please provide the proportions of the existing sample data coverage. Please also provide the mean values of the ancillary data calculated from the existing samples, additional samples, and total samples as well as the mean values of the ancillary data across the whole study area. It will be better for the authors to include three separate flowcharts for algorithms 1–3. This way, the readers can understand the algorithms more easily. Cite this review as
Anonymous Reviewer ( 2019 ) Peer Review #2 of "Some methods to improve the utility of conditioned Latin hypercube sampling (v0.1)" . PeerJ https://doi.org/10.7287/peerj.6451v0.1/reviews/2
label_author_4
Reviewer 3 ·
Nov 29, 2018
Basic reporting
label_br_4
The basic pieces of this manuscript are in place and flow together nicely. There are some grammatical errors (e.g. lines 377-378) that need to be fixed. Another example is on line 403: soil samples are not being re-located, the sampling location is. I recommend one more proof-reading to find these errors. They are small but jarring. The background on KL divergence was helpful. I suggesting linking it to the concept of entropy if possible in 1-2 sentences and suitable citation. Reviewing the literature on entropy helped me understand how the authors are using KL divergence. I think that it is important to elaborate on the fact that KL divergence is based on probability distributions--which have to be estimated by histogram / binning when applied to continuous variables. Number of bins, bin size, and interval selection are critical aspects of this step and need to be described. A couple of sentences with a concrete example would likely bring more readers closer to the methods. It is not clear to me if the statement on line 141 is correct: "...bin size of 25 (effectively 25 quantiles)...". 25 equally-spaces bins dividing a distribution are not the same as the locations of 25 quantiles estimated from said distribution. Is there an assumption that has been left out of the description whereby the bin width is not equal? Please elaborate. Lines 192--194 are confusing: Gower's (generalized) distance metric applies to collections of nominal, ordinal, and ratio data. What are the differences between "numerical and continuous variables" (line 194)? The topic of sampling and sample location selection has been heavily influenced by the work of de Gruijter, J., Brus, D.J., Bierkens, M.F.P., Knotters, M. -- consider mentioning some of this work and citing either their book or specific papers. Tables need to have units listed for each column: Table 2 is very hard to understand due to this omission. Figure 1 would benefit greatly from labels near color legends. What do they mean and what are the units (if appropriate). Figures 1 [a,b,c] could benefit from a line denoting the 500m buffer. It was not clear at first as to what the non-circular shape represented. Figure 2, consider changing "sample number" to "Number of Samples".
Experimental design
label_ed_4
Commenting on specific methods here since there is no experimental design. Lines 216-222: Why not just use distance? Converting to a similarity score seems like further abstraction of an otherwise abstract notion. Please elaborate. Line: 224 What is the significance of the selected threshold? Why is a threshold needed when a ranked list of alternatives is the goal? Lines 309-322: This is an interesting idea although without tremendous computing power not likely the be of practical use to the intended audience. Imagine a situation where the scientist has 6 10,000 x 10,000 pixel maps of interest--that is a lot work for a single (?) maximum distance. Given the spatial correlation in most environmental data, 1/10th -- 1/100th of the original pixels could probably be used to compute "magpd". Step 2 in this section, is this computed per pixel or over all pixels? I expect dd to have a very large range and deviate from a normal distribution. Would the equation on line 317 be overly biased by the distribution of distances?
Validity of the findings
label_votf_4
Overall this is a nice synthesis of what has been done, what is possible with current software (cLHS package for R), existing shortcomings, and some reasonable improvements. The paper is written as a technical note but provides very little in terms of concrete example and viable implementation. A worked example with real data near a cLHS-proposed sampling site would be a nice addition. Ultimately someone using cLHS and related methods should have a practical understanding of the results. Referencing the Brungard and Johnanson paper is one avenue but an additional figure and commentary would be more useful. This example would also provide an opportunity to inject some reality into the discussion: distances a fine way to rank pixels but fail to accommodate our understanding of the world. We do not go out into the wild blindly searching for sampling locations. As for implementation: would the authors consider submitting material to the cited cLHS package for R? This would be a fine way to make the theoretical available to the target audience. Typically, methods papers cite an implementation that is already been made available or is available post-publication.
Comments for the author
I think that the methods outlined in this paper will be of great interest to those in the fields of Earth and environmental sciences. The popularity of the cLHS algorithm is evidence enough. In addition to my comments above I would like to add one more thing, more of a philosophical comment. Anyone who has worked in the field understands that pre-specified sampling locations are more useful as suggestions. Access, local (unexpected) disturbances, etc. all contribute to re-evaluation of what otherwise seemed like a great place to dig a hole. Furthermore, we never have a complete "stack" of covariates that describe the processes we are trying to wrangle. Therefore, it might be helpful to include a a reminder that cLHS and related sample-optimization strategies leave room for _more_ thought about how limited resources should be spent, and should not replace subject expertise or experience when theory meets practice. I am sure you all can make this point more effectively than I just did here. Cite this review as
Anonymous Reviewer ( 2019 ) Peer Review #3 of "Some methods to improve the utility of conditioned Latin hypercube sampling (v0.1)" . PeerJ https://doi.org/10.7287/peerj.6451v0.1/reviews/3 Download Original Submission (PDF)
- submitted Oct 2, 2018 All text and materials provided via this peer-review history page are made available under a Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.
About us - PeerJ team | Our publications | Benefits | Partnerships | Endorsements Awards Resources - FAQ | Careers | Pressroom | Terms of use | Privacy | Contact Academic boards - Advisors | Editors | Subject areas Follow us - PeerJ blog | Twitter | Facebook | LinkedIn | Pinterest Submission guides - PeerJ (life - bio - med) | Computer Science | Chemistry | PeerJ Preprints instructions Spread the word - Activities | Resources PeerJ feeds - Atom | RSS 1.0 | RSS 2.0 | JSON PeerJ Computer Science feeds - Atom | RSS 1.0 | RSS 2.0 | JSON PeerJ Preprint feeds - Atom | RSS 1.0 | RSS 2.0 | JSON Archives - PeerJ | PeerJ Computer Science | PeerJ Preprints
©2012-2019 PeerJ, Inc | Public user content licensed CC BY 4.0 unless otherwise specified. PeerJ ISSN: 2167-8359 PeerJ Comput. Sci. ISSN: 2376-5992 PeerJ Preprints ISSN: 2167-9843
NA
