Review History for A framework for smartphone-enabled, patient-generated health data analysis [PeerJ]
PeerJ Journals Peer-reviewed PeerJ – the Journal of Life & Environmental Sciences PeerJ Computer Science PeerJ Physical Chemistry PeerJ Organic Chemistry PeerJ Inorganic Chemistry PeerJ Analytical Chemistry PeerJ Materials Science Preprints PeerJ Preprints Visit PeerJ.org and get involved About PeerJ Journals Overview PeerJ Journals FAQ What we publish 5 Years publishing Solutions for authors Reputation High quality peer review Fast publishing Indexing and Impact Factor Global readership Feature comparison Reduced cost publishing Author feedback Early career researcher benefits Senior researcher benefits Open review (optional) Rebuttal letters Sections About the journal Sections Aquatic Biology Biochemistry, Biophysics and Molecular Biology Biodiversity and Conservation Bioinformatics and Genomics Brain and Cognition Ecology Environmental Science Microbiology Paleontology and Evolutionary Science Plant Biology Zoological Science About PeerJ Journals Overview PeerJ Journals FAQ What we publish 5 Years publishing Solutions for authors Reputation High quality peer review Fast publishing Indexing and Impact Factor Global readership Feature comparison Reduced cost publishing Author feedback Early career researcher benefits Senior researcher benefits Open review (optional) Rebuttal letters More Subjects Search articles Advanced search of articles & preprints PeerJ - Medicine articles PeerJ - Biology & Life science articles PeerJ Computer Science PeerJ Preprints Table of contents Table of Contents - current and archives PeerJ - Medicine articles PeerJ - Biology & Life science articles PeerJ - Environmental Science articles PeerJ - General bio (stats, legal, policy, edu) PeerJ Computer Science PeerJ Preprints Academic advisors Volunteer to review Collections Job listings Discussions Blog Institutional plans Reviews and awards Spread the word Who are we? Contact Login AUTHORS Peer Journals Overview Submission Guidelines Subject Areas Editorial Board Editorial Criteria Pricing General FAQ Computer Science FAQ Aims and Scope Author Interviews Policies and Procedures SUBMIT ARTICLE
Review History A framework for smartphone-enabled, patient-generated health data analysis To increase transparency, PeerJ operates a system of 'optional signed reviews and history'. This takes two forms: (1) peer reviewers are encouraged, but not required, to provide their names (if they do so, then their profile page records the articles they have reviewed), and (2) authors are given the option of reproducing their entire peer review history alongside their published article (in which case the complete peer review process is provided, including revisions, rebuttal letters and editor decision letters). New to public reviews? Learn more about optional signed reviews and how to write a better rebuttal letter .
Summary
The initial submission of this article was received on March 22nd, 2016 and was peer-reviewed by 2 reviewers and the Academic Editor. The Academic Editor made their initial decision on May 17th, 2016. The first revision was submitted on June 28th, 2016 and was reviewed by the Academic Editor. The article was Accepted by the Academic Editor on July 3rd, 2016.
label_version_1
Version 0.2 (accepted)
George Perry
·
Jul 3, 2016
label_recommendation_1
·
Academic Editor
Accept
I have examined the revision. Thank you for throughly addressing the concerns raised and supporting PeerJ
Download Version 0.2 (PDF)
Download author's rebuttal letter
- submitted Jun 28, 2016
label_version_2
Version 0.1 (original submission)
George Perry
·
May 17, 2016
label_recommendation_2
·
Academic Editor
Major Revisions
Thank you for the very interesting article. I have received 2 expert reviews and in my opinion their concerns are entirely addressable. I encourage you to resubmit with a rebuttal. George
label_author_1
Andrew Hardin ·
Apr 29, 2016
Basic reporting
label_br_1
No Comments
Experimental design
label_ed_1
The paper makes the claim that the hypothesis testing framework provides can be applied to further studies. However, the formal model definition is unclear for both the N-of-1 model and the Mixed Effects Model. The N-of-1 model is described a linear regression model, but it is unclear in the paper what the covariate are in the model. It is stated that model accounted for the time of day, but the details of the approach are not clarified. For example: Was the time of day modeled using fixed effects for each hour/six-hours or was some other approach used? Were the systolic/dialostic measurements modeled individually and were they modeled using the same covariates? The mixed effects model was formally specified, but the details are unclear. For example, are the fixed effects modeled as regression type slopes, or fixed changes in means. I understand the auto-regressive structure and it is clear why the power law approach was used, but what are the fixed effects? Additionally, though this outside my expertise and is therefore a general question, is there daily seasonality and if so was this modeled or addressed in any way other than the autoregressive structure? An appendix that explains the model details and shows how to recreate the model in other studies would address many of these concerns. Finally, just a pure comment but was there any consideration of modeling the systolic and diastolic measurements using a multivariate model and incorporating the correlation between these two measures?
Validity of the findings
label_votf_1
If I understand the stated results correctly the N-of-1 model is a null result at .05 alpha level (your stated CI's overlap 0, though only barely in the case of diastolic). Statistically speaking this is a null result and even the statement 'limited evidence' is too strong a claim. Also, I don't have any sense of the general quality of fit metrics for the mixed effects model. You show that the AIC and BIC metrics are better with the model, but it is unclear what the null model you are comparing against is and how much the AIC actually improves. Looking at Figures 1 and 3 I am concerned that you have are detecting a small signal in a very large amount of noise. You have enough degrees of freedom to detect small differences (it is unclear because the model is not formally stated, but I would suspect you have at least 1,000 df if not several times that) so the low p-values may just reflect a very high level of sensitivity. If I understand Supplemental Figures 1 and 3 correctly, some individuals have increasing slopes, others have decreasing slopes and the noise is often quite large compared to the slope (suggesting you would have low R^2 values) and it is unclear if the model diagnostics are solid. These issues are purely with the statistical conclusions, but I would like to see some additional diagnostics that help put the results into context. For example, have the auto-correlation or spatial power law reduced the assumed temporal correlation, and do the residuals truly look like noise? Are there any signs of model fitting problems, or is it merely the case that the effect size is very small relative to the noise but the effect really is real? Finally, the changes may in fact be negative for the population, but a large percentage of the population would be estimated to have positive changes, so do these effects have any practical significance?
Comments for the author
label_cfta_1
It feels like you really have two papers, and this is where I think the paper has the biggest challenge. The way the paper is described you are going to provide a useful framework for modeling and then are going to show an example of how this can be used. What happens instead is that you have a paper where you describe an experiment, then you describe the model, then you state the results of the experiment while explaining some of the modeling challenges. Is this a paper focused on the methodology or the experiment? If the focus is on the methodology (which is what it feels like from the explanation) then more details need to be provided to flesh out what makes this model particularly powerful. If the focus is on the experimental results then the title is misleading. If I understand the point of the paper (and this may be a point of confusion on my side) then you want to show how to model unstructured time series data where you can't use ARIMA or exponential smoothing or other sophisticated time series models. So you model these effects using a mixed effects model that captures all these features. But the details are very unclear. What are your fixed effects, what random effects did you actually use. There is no specification of the model at a detailed level and is unfortunate because I found it unclear even understanding what the benefit is. This may be a case that you are so familiar with what you are doing that the lack of clarity is not obvious. In my case it may be because my expertise is primarily in structured time series, traditional statistics, and some biostatistics and the audience may be expected to be more comfortable with these ideas. But for me, looking at it from a modeling perspective, I didn't really get a proper sense of the model. Cite this review as
Hardin A ( 2016 ) Peer Review #1 of "A framework for smartphone-enabled, patient-generated health data analysis (v0.1)" . PeerJ https://doi.org/10.7287/peerj.2284v0.1/reviews/1
label_author_2
Ray Palmer ·
May 10, 2016
Basic reporting
label_br_2
no comment
Experimental design
label_ed_2
No comments
Validity of the findings
label_votf_2
Valid but non-generalizable as the sample were primarily middle age female.
Comments for the author
label_cfta_2
This manuscript concerns a timely topic and is well written with a pertinent introduction concerning the interpretation of quantified health information coming from the growing field of personal passive measurement devices. The use of regression, mixed model regression, and sequential analysis is appropriate and prudent. The authors stated that no covariates where introduced in the model. This is curious to me. Shouldn’t BMI and or medication use be considered as confounders? The authors should address this issue. In all the manuscripts represents a much needed advance in the field of interpreting data from the ever growing device market. Cite this review as
Palmer R ( 2016 ) Peer Review #2 of "A framework for smartphone-enabled, patient-generated health data analysis (v0.1)" . PeerJ https://doi.org/10.7287/peerj.2284v0.1/reviews/2 Download Original Submission (PDF)
- submitted Mar 22, 2016 All text and materials provided via this peer-review history page are made available under a Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.
About us - PeerJ team | Our publications | Benefits | Partnerships | Endorsements Awards Resources - FAQ | Careers | Pressroom | Terms of use | Privacy | Contact Academic boards - Advisors | Editors | Subject areas Follow us - PeerJ blog | Twitter | Facebook | LinkedIn | Pinterest Submission guides - PeerJ (life - bio - med) | Computer Science | Chemistry | PeerJ Preprints instructions Spread the word - Activities | Resources PeerJ feeds - Atom | RSS 1.0 | RSS 2.0 | JSON PeerJ Computer Science feeds - Atom | RSS 1.0 | RSS 2.0 | JSON PeerJ Preprint feeds - Atom | RSS 1.0 | RSS 2.0 | JSON Archives - PeerJ | PeerJ Computer Science | PeerJ Preprints
©2012-2019 PeerJ, Inc | Public user content licensed CC BY 4.0 unless otherwise specified. PeerJ ISSN: 2167-8359 PeerJ Comput. Sci. ISSN: 2376-5992 PeerJ Preprints ISSN: 2167-9843
NA
