Review History for Performance evaluation of deep neural ensembles toward malaria parasite detection in thin-blood smear images [PeerJ]
PeerJ Journals Peer-reviewed PeerJ – the Journal of Life & Environmental Sciences PeerJ Computer Science PeerJ Physical Chemistry PeerJ Organic Chemistry PeerJ Inorganic Chemistry PeerJ Analytical Chemistry PeerJ Materials Science Preprints PeerJ Preprints Visit PeerJ.org and get involved About PeerJ Journals Overview PeerJ Journals FAQ What we publish 5 Years publishing Solutions for authors Reputation High quality peer review Fast publishing Indexing and Impact Factor Global readership Feature comparison Reduced cost publishing Author feedback Early career researcher benefits Senior researcher benefits Open review (optional) Rebuttal letters Sections About the journal Sections Aquatic Biology Biochemistry, Biophysics and Molecular Biology Biodiversity and Conservation Bioinformatics and Genomics Brain and Cognition Ecology Environmental Science Microbiology Paleontology and Evolutionary Science Plant Biology Zoological Science About PeerJ Journals Overview PeerJ Journals FAQ What we publish 5 Years publishing Solutions for authors Reputation High quality peer review Fast publishing Indexing and Impact Factor Global readership Feature comparison Reduced cost publishing Author feedback Early career researcher benefits Senior researcher benefits Open review (optional) Rebuttal letters More Subjects Search articles Advanced search of articles & preprints PeerJ - Medicine articles PeerJ - Biology & Life science articles PeerJ Computer Science PeerJ Preprints Table of contents Table of Contents - current and archives PeerJ - Medicine articles PeerJ - Biology & Life science articles PeerJ - Environmental Science articles PeerJ - General bio (stats, legal, policy, edu) PeerJ Computer Science PeerJ Preprints Academic advisors Volunteer to review Collections Job listings Discussions Blog Institutional plans Reviews and awards Spread the word Who are we? Contact Login AUTHORS Peer Journals Overview Submission Guidelines Subject Areas Editorial Board Editorial Criteria Pricing General FAQ Computer Science FAQ Aims and Scope Author Interviews Policies and Procedures SUBMIT ARTICLE
Review History Performance evaluation of deep neural ensembles toward malaria parasite detection in thin-blood smear images To increase transparency, PeerJ operates a system of 'optional signed reviews and history'. This takes two forms: (1) peer reviewers are encouraged, but not required, to provide their names (if they do so, then their profile page records the articles they have reviewed), and (2) authors are given the option of reproducing their entire peer review history alongside their published article (in which case the complete peer review process is provided, including revisions, rebuttal letters and editor decision letters). New to public reviews? Learn more about optional signed reviews and how to write a better rebuttal letter .
Summary
The initial submission of this article was received on February 5th, 2019 and was peer-reviewed by 2 reviewers and the Academic Editor. The Academic Editor made their initial decision on February 20th, 2019. The first revision was submitted on March 8th, 2019 and was reviewed by 2 reviewers and the Academic Editor. A further revision was submitted on April 1st, 2019 and was reviewed by the Academic Editor. A further revision was submitted on April 12th, 2019 and was reviewed by the Academic Editor. The article was Accepted by the Academic Editor on April 19th, 2019.
label_version_1
Version 0.4 (accepted)
Henkjan Huisman
·
Apr 19, 2019
label_recommendation_1
·
Academic Editor
Accept
I agree with the final revisions. # PeerJ Staff Note - this decision was reviewed and approved by Keith Crandall, a PeerJ Section Editor covering this Section #
Download Version 0.4 (PDF)
Download author's rebuttal letter
- submitted Apr 12, 2019
label_version_2
Version 0.3
Henkjan Huisman
·
Apr 8, 2019
label_recommendation_2
·
Academic Editor
Minor Revisions
A few minor edits, please. I still see sensitivity and specificity as performance measures in the manuscript and the abstract while you agreed to remove it in your rebuttal. Remove these. BTW still weird to see a statistical analysis sub-section in the results section. Sloppy formatting. In the abstract change the sentence: "It is observed that the ensemble model constructed with VGG-19 and SqueezeNet outperformed the state-of-the-art in all performance metrics toward classifying the parasitized and uninfected cells to aid in improved disease screening. " to ''It is observed that the ensemble model constructed with VGG-19 and SqueezeNet outperformed the state-of-the-art in several performance metrics toward classifying the parasitized and uninfected cells to aid in improved disease screening.'' Change the sentence: ''A similar trend is observed for AUC where the Ensemble-D model (0.9993±0.0004) outperformed VGG-19 (0.993±0.0006, p > 0.05)'' to ''A similar trend is observed for AUC where the AUC for Ensemble-D model and VGG-19 is 0.9993±0.0004) and 0.993±0.0006, p > 0.05) respectively'
Download Version 0.3 (PDF)
Download author's rebuttal letter
- submitted Apr 1, 2019
label_version_3
Version 0.2
Henkjan Huisman
·
Mar 27, 2019
label_recommendation_3
·
Academic Editor
Minor Revisions
The substantial improvements to the manuscript have rendered the manuscript acceptable to the reviewers. I read the manuscript once again and still found a few issues that need attention. 1. The key result is table 6 in which VGG is compared to the new ensemble models. The most important performance measure in diagnostic studies is AUC. The main p-value is 0.06 which is not significant. Therefore you should remove any statement that says this method outperforms or is better than the state of the art. 2. Careful inspection of table 6 reveals other issues. Comparing sensitivity and specificity is nonsense. Changing the decision threshold for exactly the same method (say VGG) will always create significant differences, but these differences obviously do not provide evidence of the method being better. Remove sensitivity and specificity as performance measures. Fail to see the relevance for F-score, MCC, MSE as performance measures. The best thing to do is to provide three ROC curves to provide visual evidence and then provide p-values. This is very common. 3. In the same table 6, the M1,M2,M3 comparisons are also randomly presented in arbitrary order. This makes this data in this table questionable. Provide a systematic presentation. 4. You removed the tSNE figures, but still a whole paragrahp in the results section describes tSNE details. The whole paragraph is incomprehensible and should be removed. 5. The results section contains a statistical analysis subparagraph which is a weird style and not at all compatible with ICMJE guidelines that you claimed to have read. 6. The abstract is not properly formatted in a sense that it provides an introduction, methods, results and conclusion section.
label_author_1
Reviewer 1 ·
Mar 25, 2019
Basic reporting
label_br_1
no comment
Experimental design
label_ed_1
no comment
Validity of the findings
label_votf_1
no comment
Comments for the author
label_cfta_1
The authors addressed all the comments. The paper is easy to read, very interesting and presenting a model with great results. Congratulations! Cite this review as
Anonymous Reviewer ( 2019 ) Peer Review #1 of "Performance evaluation of deep neural ensembles toward malaria parasite detection in thin-blood smear images (v0.2)" . PeerJ https://doi.org/10.7287/peerj.6977v0.2/reviews/1
label_author_2
Kc Santosh ·
Mar 21, 2019
Basic reporting
label_br_2
Good paper.
Experimental design
label_ed_2
Accept
Validity of the findings
label_votf_2
Accept
Comments for the author
label_cfta_2
The paper has been revised well. Cite this review as
Santosh K ( 2019 ) Peer Review #2 of "Performance evaluation of deep neural ensembles toward malaria parasite detection in thin-blood smear images (v0.2)" . PeerJ https://doi.org/10.7287/peerj.6977v0.2/reviews/2 Download Version 0.2 (PDF)
Download author's rebuttal letter
- submitted Mar 8, 2019
label_version_4
Version 0.1 (original submission)
Henkjan Huisman
·
Feb 20, 2019
label_recommendation_4
·
Academic Editor
Major Revisions
I agree with the reviewers that this is an interesting paper. I also agree that it needs some changes. Please properly address the comments of the reviewers and my comments: 1. The introduction is too long. We don't need an incomplete review of deep learning. Be to the point and provide relevant info for this paper. 2. The 'major contributions' are all invalid. Please remove. These are not research questions or hypothesis. A quick read tells me that you do again DL on the same data as before in your PeerJ paper of last year. Clearly tell that in your introduction and make clear why the method in that paper requires improvement. The achieved performance increase is rather little and on an AUC basis insignificant. The question is: what do you claim to improve the performance compared to your previous paper? That would be the currently missing claim/hypothesis. So, I expect a formulation at the last paragraph like ''ensemble learning improves performance''. Then you do an experiment with and without ensemble learning and show that it improves results. Simple as that. 3. Please remove the ''the paper is organized as follows statement'' this is obvious. 4. Tell a bit more about the data. At the bare minimum, I'd expect data size and a bit about the collection process. 5. Fig 5 -11 are way too much information and I question the relevance. The tSNE plots look pretty, but I fail to see how they support your conclusions. Suggest removing them. 6. In the conclusions start with a statement on whether your hypothesis (ensemble) is helpful. Remove the conclusion that it outperforms the state-of-the-art because that is not shown yet. 7. Please re-read the ICMJE guidelines, as many of my comments above are clearly addressed and explained.
label_author_3
Reviewer 1 ·
Feb 15, 2019
Basic reporting
label_br_3
Clear and unambiguous, professional English used throughout. Literature references, sufficient field background/context provided although more recent literature (2018) should be included Figures and tables are appropriate and complement the text. More self-descriptive caption should be included. Self-contained with relevant results to hypotheses
Experimental design
label_ed_3
Original primary research within Aims and Scope of the journal. The article clearly states the contributions of the article however the research question is not so clear, is this a review of DL ,methodologies or are you presenting a new method? Rigorous investigation performed to a high technical & ethical standard including a deep analysis of the outcomes. Methods described with sufficient detail & information to replicate.
Validity of the findings
label_votf_3
Novel comparison of methodologies and novel framework with lot of details for a replication. Also a web-based model is proposed. Data is available on-line from a previous work and the statistical analysis is well done. Conclusions and contributions are well stated
Comments for the author
label_cfta_3
The paper is really interesting and a great analysis of the state of the art on the use of DL for malaria detection. However I missed more recent reference since most of them are from early's 2000. The captions from the figures and tables are in general poor, it would be easier to follow if they were self-explanatory. Line 85 proposes protocols from WHO 2010, why not WHO 2018? Can you give some references for this sentence: "2015). In particular, convolutional neural networks (CNN), a class of DL models have demonstrated promising results in image classification, recognition, and localization tasks"? Between lines 125 and 140 you compare CNN with other methods and give the accuracy of the CNN approach, what is the performance of the other methods such as SVM? It is not clear the improvement achieved. Lines 142-143 presents your previous article, could you make clear what is the novelty in this work? In the Material and Methods section I am missing a more general overview of the whole process since sometimes is difficult to follow.. A flowchart would help. Indeed I am not sure if figure 2 is presenting this but the steps in figure 2 do not correspond with subsections. In fact Figure 2 is not well explained in the text Line 232 could be a break line. Line 283 states that you used both custom and pretrained models, this is not clear until this moment. Giving and explanation of the whole process at the beginning of the section will also clarify this. At the beginning of the results section you could also states what you want to analyse Tables 4 and 5 can be fuse in one table. Line 435, what are you losing? Rewrite sentence in line 436. Figure 11 and table 6 can be fuse. I don't understand what you are trying to show in table 7 Which model are you using in the web-based model? Where can we find the web-based model? Table 8 should be include in the results but not in the conclusions. Clarify sentence in line516 Cite this review as
Anonymous Reviewer ( 2019 ) Peer Review #1 of "Performance evaluation of deep neural ensembles toward malaria parasite detection in thin-blood smear images (v0.1)" . PeerJ https://doi.org/10.7287/peerj.6977v0.1/reviews/1
label_author_4
Kc Santosh ·
Feb 19, 2019
Basic reporting
label_br_4
Please check overall summary (below).
Experimental design
label_ed_4
Please check overall summary (below).
Validity of the findings
Please check overall summary (below).
Comments for the author
The authors have evaluated the performance of model ensembles in an attempt to reduce variance and optimally combine the models’ predictions toward classifying parasitized and uninflected cells in thin-blood smear images. The study demonstrates significant improvement in performance, compared to the state of the art and would appeal to the research community. However the authors have to clarify on a few aspects pertaining to the methods, results, and related discussions. Specific comments: 1. How did the authors detect and segment the red blood cells? How did they evaluate the segmentation accuracy? 2. How did the performance of the proposed ensemble compare to that of the human readers? 3. How effectively could the proposed ensemble be deployed into mobile devices or cloud for the ease of predictions? 4. How did the authors settle for the optimal t-sne hyper parameters for the current study? Could the process be generalized? Cite this review as
Santosh K ( 2019 ) Peer Review #2 of "Performance evaluation of deep neural ensembles toward malaria parasite detection in thin-blood smear images (v0.1)" . PeerJ https://doi.org/10.7287/peerj.6977v0.1/reviews/2 Download Original Submission (PDF)
- submitted Feb 5, 2019 All text and materials provided via this peer-review history page are made available under a Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.
About us - PeerJ team | Our publications | Benefits | Partnerships | Endorsements Awards Resources - FAQ | Careers | Pressroom | Terms of use | Privacy | Contact Academic boards - Advisors | Editors | Subject areas Follow us - PeerJ blog | Twitter | Facebook | LinkedIn | Pinterest Submission guides - PeerJ (life - bio - med) | Computer Science | Chemistry | PeerJ Preprints instructions Spread the word - Activities | Resources PeerJ feeds - Atom | RSS 1.0 | RSS 2.0 | JSON PeerJ Computer Science feeds - Atom | RSS 1.0 | RSS 2.0 | JSON PeerJ Preprint feeds - Atom | RSS 1.0 | RSS 2.0 | JSON Archives - PeerJ | PeerJ Computer Science | PeerJ Preprints
©2012-2019 PeerJ, Inc | Public user content licensed CC BY 4.0 unless otherwise specified. PeerJ ISSN: 2167-8359 PeerJ Comput. Sci. ISSN: 2376-5992 PeerJ Preprints ISSN: 2167-9843
bioinformatics genomics
