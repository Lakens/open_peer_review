---
title: "Open Peer Review"
author: "Daniel Lakens"
date: "22-9-2019"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(data.table)
library(dplyr)
library(formattable)
library(tidyr)
library(ggplot2)
library(here)

here::here()

```

## Accessing Open Peer Reviews

PeerJ assigns all articles a number from 1, increasing consequtively with each published manuscript. Reviews are always accessible in html (i.e., at https://peerj.com/articles/1/reviews for the first article). Using text-mining tools in R (cite R, RCurl, XML, stringer) we downloaded all reviews and stored them as individual text files. 

```{r}
# Read open science and open biology rds datafiles
TRS_data_os <- readRDS(file = "royal_society_data_os.rds")
TRS_data_ob <- readRDS(file = "royal_society_data_ob.rds")

# Combine both datasets into one.
TRS_data <- rbind(TRS_data_os, TRS_data_ob)

PeerJ_data <- readRDS(file = "peerj_data.rds")

#TRS_data_sorted <- TRS_data[ with( TRS_data , order ( df_link)),]

#Create dataframe for TRS and PeerJ of unique rows (e.g., for days)
TRS_unique <- TRS_data[!duplicated(TRS_data$df_link),]
PeerJ_unique <- PeerJ_data[!duplicated(PeerJ_data$df_link),]

# One submission to PeerJ was accepted but no reviewer info. It means they are accepted by the editor? Or just an early mistake.
sum(is.na(PeerJ_unique$df_days))

# Mean review time (almost the same as Nino original - we have a few more pdf's)
TRS_mean_review_time <- mean(TRS_unique$df_days)
PeerJ_mean_review_time <- mean(PeerJ_unique$df_days, na.rm = TRUE)

# How many reviews are masked?
mean(TRS_data$df_masked)
mean(PeerJ_data$df_masked)

# # Using data.table command
# group <- as.data.table(PeerJ_data)
# TEST <- group[group[, .I[df_version == max(df_version)], by=df_link]$V1]

# Select only those reviews for each paper with the highest version (first review)
# For PeerJ the highest number is the first review (for RSOS this is reversed)
PeerJ_data_R1 <- group_by(PeerJ_data, df_link)
PeerJ_data_R1 <- top_n(PeerJ_data_R1, 1, df_version)

TRS_data_R1 <- group_by(TRS_data, df_link)
TRS_data_R1 <- top_n(TRS_data_R1, -1, df_version) #use top_n but specify -1 for bottom 1, or first review. 

### general numbers
sum(PeerJ_data_R1$df_masked == 0)
sum(PeerJ_data_R1$df_masked == 1)

sum(TRS_data_R1$df_masked == 0)
sum(TRS_data_R1$df_masked == 1)

# It is useful to select only cases that have a recommendation
TRS_data_complete <- TRS_data[complete.cases(TRS_data$df_recommendation),]



x <- group_by(PeerJ_data_R1, df_recommendation)
x <- summarize(x, m = mean(df_masked))
x

x <- group_by(PeerJ_data_R1, df_recommendation)
x <- summarize(x, m = sum(df_masked))
x

x <- group_by(TRS_data, df_recommendation)
x <- summarize(x, m = mean(df_masked))
x

x <- group_by(TRS_data, df_recommendation)
rowsum(TRS_data_complete[,c(5,7)], group = TRS_data_complete$df_recommendation, na.rm = TRUE)


count(TRS_data$df_recommendation)

x <- summarize(x, m = sum(df_masked))
x <- x[1:4,1:2]
chisq.test(x, correct=FALSE)

x <- x[2:3,1:2]
chisq.test(x, correct=FALSE)

length(TRS_data$df_link)
length(PeerJ_data$df_link)

# Exploratory
# Randomly split masked over 100 subgroups to see progression over time - seems stable.
df_over_time <- data.frame(TRS_data$df_masked[1:3600], rep(seq(1,100,1),each = 360))
colnames(df_over_time) <- c("masked", "time") # specify columns names
x <- group_by(df_over_time, time)
x <- summarize(x, m = mean(masked))

df_over_time <- data.frame(PeerJ_data$df_masked[1:12300], rep(seq(1,100,1),each = 1230))
colnames(df_over_time) <- c("masked", "time") # specify columns names
x <- group_by(df_over_time, time)
x <- summarize(x, m = mean(masked))



```

In Nino's BEP there were  3552 reviews in RSOS. I have 3629 after running all his code. 


Older Royal Society journals have the comment: Note: This manuscript was transferred from another Royal Society journal without peer review.
What does this mean?
