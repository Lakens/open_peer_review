
@article{wang_open_2016,
  title = {Open Peer Review in Scientific Publishing: {{A Web}} Mining Study of {{PeerJ}} Authors and Reviewers},
  volume = {1},
  shorttitle = {Open Peer Review in Scientific Publishing},
  number = {4},
  journal = {Journal of Data and Information Science},
  author = {Wang, Peiling and You, Sukjin and Manasa, Rath and Wolfram, Dietmar},
  year = {2016},
  pages = {60--80}
}

@book{ooms_pdftools_2019,
  title = {Pdftools: Text Extraction, Rendering and Converting of {{PDF}} Documents},
  author = {Ooms, Jeroen},
  year = {2019},
  note = {R package version 2.2}
}

@book{wickham_stringr_2019,
  title = {Stringr: Simple, Consistent Wrappers for Common String Operations},
  author = {Wickham, Hadley},
  year = {2019},
  note = {R package version 1.4.0}
}

@article{walsh_open_2000,
  title = {Open Peer Review: {{A}} Randomised Controlled Trial},
  volume = {176},
  issn = {0007-1250, 1472-1465},
  shorttitle = {Open Peer Review},
  abstract = {Background
Most scientific journals practise anonymous peer review. There is no evidence, however, that this is any better than an open system.

Aims
To evaluate the feasibility of an open peer review system.

Method
Reviewers for the British Journal of Psychiatry were asked whether they would agree to have their name revealed to the authors whose papers they review; 408 manuscripts assigned to reviewers who agreed were randomised to signed or unsigned groups. We measured review quality, tone, recommendation for publication and time taken to complete each review.

Results
A total of 245 reviewers (76\%) agreed to sign. Signed reviews were of higher quality, were more courteous and took longer to complete than unsigned reviews. Reviewers who signed were more likely to recommend publication.

Conclusions
This study supports the feasibility of an open peer review system and identifies such a system's potential drawbacks.},
  language = {en},
  number = {1},
  journal = {The British Journal of Psychiatry},
  doi = {10.1192/bjp.176.1.47},
  author = {Walsh, Elizabeth and Rooney, Maeve and Appleby, Louis and Wilkinson, Greg},
  month = jan,
  year = {2000},
  pages = {47-51}
}

@article{rooyen_effect_2010,
  title = {Effect on Peer Review of Telling Reviewers That Their Signed Reviews Might Be Posted on the Web: Randomised Controlled Trial},
  volume = {341},
  copyright = {\textcopyright{} van Rooyen et al 2010. This is an open-access article distributed under the terms of the Creative Commons Attribution Non-commercial License, which permits use, distribution, and reproduction in any medium, provided the original work is properly cited, the use is non commercial and is otherwise in compliance with the license. See: http://creativecommons.org/licenses/by-nc/2.0/  and  http://creativecommons.org/licenses/by-nc/2.0/legalcode.},
  issn = {0959-8138, 1468-5833},
  shorttitle = {Effect on Peer Review of Telling Reviewers That Their Signed Reviews Might Be Posted on the Web},
  abstract = {Objectives To see whether telling peer reviewers that their signed reviews of original research papers might be posted on the BMJ's website would affect the quality of their reviews.
Design Randomised controlled trial.
Setting A large international general medical journal based in the United Kingdom.
Participants 541 authors, 471 peer reviewers, and 12 editors.
Intervention Consecutive eligible papers were randomised either to have the reviewer's signed report made available on the BMJ's website alongside the published paper (intervention group) or to have the report made available only to the author\textemdash{}the BMJ's normal procedure (control group). The intervention was the act of revealing to reviewers\textemdash{}after they had agreed to review but before they undertook their review\textemdash{}that their signed report might appear on the website.
Main outcome measures The main outcome measure was the quality of the reviews, as independently rated on a scale of 1 to 5 using a validated instrument by two editors and the corresponding author. Authors and editors were blind to the intervention group. Authors rated review quality before the fate of their paper had been decided. Additional outcomes were the time taken to complete the review and the reviewer's recommendation regarding publication.
Results 558 manuscripts were randomised, and 471 manuscripts remained after exclusions. Of the 1039 reviewers approached to take part in the study, 568 (55\%) declined. Two editors' evaluations of the quality of the peer review were obtained for all 471 manuscripts, with the corresponding author's evaluation obtained for 453. There was no significant difference in review quality between the intervention and control groups (mean difference for editors 0.04, 95\% CI -0.09 to 0.17; for authors 0.06, 95\% CI -0.09 to 0.20). Any possible difference in favour of the control group was well below the level regarded as editorially significant. Reviewers in the intervention group took significantly longer to review (mean difference 25 minutes, 95\% CI 3.0 to 47.0 minutes).
Conclusion Telling peer reviewers that their signed reviews might be available in the public domain on the BMJ's website had no important effect on review quality. Although the possibility of posting reviews online was associated with a high refusal rate among potential peer reviewers and an increase in the amount of time taken to write a review, we believe that the ethical arguments in favour of open peer review more than outweigh these disadvantages.},
  language = {en},
  journal = {BMJ},
  doi = {10.1136/bmj.c5729},
  author = {van Rooyen, Susan and Delamothe, Tony and Evans, Stephen J. W.},
  month = nov,
  year = {2010},
  pages = {c5729},
  pmid = {21081600}
}

@article{mulligan_peer_2013,
  title = {Peer Review in a Changing World: {{An}} International Study Measuring the Attitudes of Researchers},
  volume = {64},
  copyright = {\textcopyright{} 2012 ASIS\&T},
  issn = {1532-2890},
  shorttitle = {Peer Review in a Changing World},
  abstract = {This large-scale international study measures the attitudes of more than 4,000 researchers toward peer review. In 2009, 40,000 authors of research papers from across the globe were invited to complete an online survey. Researchers were asked to rate a number of general statements about peer review, and then a subset of respondents, who had themselves peer reviewed, rated a series of statements concerning their experience of peer review. The study found that the peer review process is highly regarded by the vast majority of researchers and considered by most to be essential to the communication of scholarly research. Nine out of 10 authors believe that peer review improved the last paper they published. Double-blind peer review is considered the most effective form of peer review. Nearly three quarters of researchers think that technological advances are making peer review more effective. Most researchers believe that although peer review should identify fraud, it is very difficult for it to do so. Reviewers are committed to conducting peer review in the future and believe that simple practical steps, such as training new reviewers would further improve peer review.},
  language = {en},
  number = {1},
  journal = {Journal of the American Society for Information Science and Technology},
  doi = {10.1002/asi.22798},
  author = {Mulligan, Adrian and Hall, Louise and Raphael, Ellen},
  year = {2013},
  keywords = {publishing,evaluation,questionnaires},
  pages = {132-161}
}

@article{ross-hellauer_survey_2017,
  title = {Survey on Open Peer Review: {{Attitudes}} and Experience amongst Editors, Authors and Reviewers},
  volume = {12},
  issn = {1932-6203},
  shorttitle = {Survey on Open Peer Review},
  abstract = {Open peer review (OPR) is a cornerstone of the emergent Open Science agenda. Yet to date no large-scale survey of attitudes towards OPR amongst academic editors, authors, reviewers and publishers has been undertaken. This paper presents the findings of an online survey, conducted for the OpenAIRE2020 project during September and October 2016, that sought to bridge this information gap in order to aid the development of appropriate OPR approaches by providing evidence about attitudes towards and levels of experience with OPR. The results of this cross-disciplinary survey, which received 3,062 full responses, show the majority (60.3\%) of respondents to be believe that OPR as a general concept should be mainstream scholarly practice (although attitudes to individual traits varied, and open identities peer review was not generally favoured). Respondents were also in favour of other areas of Open Science, like Open Access (88.2\%) and Open Data (80.3\%). Among respondents we observed high levels of experience with OPR, with three out of four (76.2\%) reporting having taken part in an OPR process as author, reviewer or editor. There were also high levels of support for most of the traits of OPR, particularly open interaction, open reports and final-version commenting. Respondents were against opening reviewer identities to authors, however, with more than half believing it would make peer review worse. Overall satisfaction with the peer review system used by scholarly journals seems to strongly vary across disciplines. Taken together, these findings are very encouraging for OPR's prospects for moving mainstream but indicate that due care must be taken to avoid a ``one-size fits all'' solution and to tailor such systems to differing (especially disciplinary) contexts. OPR is an evolving phenomenon and hence future studies are to be encouraged, especially to further explore differences between disciplines and monitor the evolution of attitudes.},
  language = {en},
  number = {12},
  journal = {PLOS ONE},
  doi = {10.1371/journal.pone.0189311},
  author = {{Ross-Hellauer}, Tony and Deppe, Arvid and Schmidt, Birgit},
  month = dec,
  year = {2017},
  keywords = {Social sciences,Open science,Scientific publishing,Peer review,Surveys,Agriculture,Open access publishing,Ecology and environmental sciences},
  pages = {e0189311}
}

@article{janowicz_open_2012,
  title = {Open and Transparent: The Review Process of the {{Semantic Web}} Journal},
  volume = {25},
  copyright = {\textcopyright{} 2012 The Authors},
  issn = {1741-4857},
  shorttitle = {Open and Transparent},
  abstract = {While open access is established in the world of academic publishing, open reviews are rare. The Semantic Web journal goes further than just open review by implementing an open and transparent review process in which reviews are publicly available, and the assigned editors and reviewers are known by name, and are published together with accepted manuscripts. In this article we introduce the steps to realize such a process from the conceptual design, over the implementation, a overview of the results so far, and up to lessons learned.},
  language = {en},
  number = {1},
  journal = {Learned Publishing},
  doi = {10.1087/20120107},
  author = {Janowicz, Krzysztof and Hitzler, Pascal},
  year = {2012},
  pages = {48-55}
}

@article{moylan_open_2014,
  title = {Open, Single-Blind, Double-Blind: Which Peer Review Process Do You Prefer?},
  volume = {15},
  issn = {2050-6511},
  shorttitle = {Open, Single-Blind, Double-Blind},
  abstract = {BMC Pharmacology and Toxicology was created from the merger of two journals within the BMC series published by BioMed Central: BMC Pharmacology and BMC Clinical Pharmacology. BMC Pharmacology operated anonymous peer review whereas BMC Clinical Pharmacology operated a fully open peer review policy where the identity of the reviewers was known to the editors, authors and readers. The merged journal also adopted a fully open peer review policy. Two years on we discuss the views and experiences of our Editorial Board Members towards open peer review on this biomedical journal.},
  number = {1},
  journal = {BMC Pharmacology and Toxicology},
  doi = {10.1186/2050-6511-15-55},
  author = {Moylan, Elizabeth C. and Harold, Simon and O'Neill, Ciaran and Kowalczuk, Maria K.},
  month = sep,
  year = {2014},
  pages = {55}
}

@article{rodriguezbravo_peer_2017,
  title = {Peer Review: {{The}} Experience and Views of Early Career Researchers},
  volume = {30},
  copyright = {\textcopyright{} 2017 The Author(s). Learned Publishing \textcopyright{} 2017 ALPSP.},
  issn = {1741-4857},
  shorttitle = {Peer Review},
  abstract = {This paper presents selected findings from the first year of a 3-year longitudinal study of early career researchers (ECRs), which sought to ascertain current and changing habits in scholarly communication. Specifically, the aims of the paper are to show: (1) how much experience and knowledge ECRs had of peer review \textendash{} both as authors and as reviewers; (2) what they felt the benefits were and what suggestions they had for improvement; (3) what they thought of open peer review (OPR); and (4) who they felt should organize peer review. Data were obtained from 116 science and social science ECRs, most of whom had published and were subject to in-depth interviews conducted face-to-face, via Skype, or over the telephone. An extensive literature review was also conducted to provide a context and supplementary data for the findings. The main findings were that: (1) most ECRS are well informed about peer review and generally like the experience, largely because of the learning experiences obtained; (2) they like blind double-peer review, but would like some improvements, especially with regards to reviewer quality; (3) most are uncomfortable with the idea of OPR; and (4) most would like publishers to continue organizing peer review because of their perceived independence.},
  language = {en},
  number = {4},
  journal = {Learned Publishing},
  doi = {10.1002/leap.1111},
  author = {Rodr{\'i}guez-Bravo, Blanca and Nicholas, David and Herman, Eti and Boukacem-Zeghmouri, Ch{\'e}rifa and Watkinson, Anthony and Xu, Jie and Abrizah, Abdullah and {\'S}wigo{\'n}, Marzena},
  year = {2017},
  pages = {269-277}
}

@article{spellman_short_2015,
  title = {A {{Short}} ({{Personal}}) {{Future History}} of {{Revolution}} 2.0},
  volume = {10},
  issn = {1745-6916, 1745-6924},
  abstract = {Crisis of replicability is one term that psychological scientists use for the current introspective phase we are in\textemdash{}I argue instead that we are going through a revolution analogous to a political revolution. Revolution 2.0 is an uprising focused on how we should be doing science now (i.e., in a 2.0 world). The precipitating events of the revolution have already been well-documented: failures to replicate, questionable research practices, fraud, etc. And the fact that none of these events is new to our field has also been well-documented. I suggest four interconnected reasons as to why this time is different: changing technology, changing demographics of researchers, limited resources, and misaligned incentives. I then describe two reasons why the revolution is more likely to catch on this time: technology (as part of the solution) and the fact that these concerns cut across social and life sciences\textemdash{}that is, we are not alone. Neither side in the revolution has behaved well, and each has characterized the other in extreme terms (although, of course, each has had a few extreme actors). Some suggested reforms are already taking hold (e.g., journals asking for more transparency in methods and analysis decisions; journals publishing replications) but the feared tyrannical requirements have, of course, not taken root (e.g., few journals require open data; there is no ban on exploratory analyses). Still, we have not yet made needed advances in the ways in which we accumulate, connect, and extract conclusions from our aggregated research. However, we are now ready to move forward by adopting incremental changes and by acknowledging the multiplicity of goals within psychological science.},
  language = {en},
  number = {6},
  journal = {Perspectives on Psychological Science},
  doi = {10.1177/1745691615609918},
  author = {Spellman, Barbara A.},
  month = nov,
  year = {2015},
  keywords = {Methodology,replication,scientific practices,journal practices},
  pages = {886-899},
  pmid = {26581743}
}

@article{godlee_effect_1998,
  title = {Effect on the {{Quality}} of {{Peer Review}} of {{Blinding Reviewers}} and {{Asking Them}} to {{Sign Their Reports}}: {{A Randomized Controlled Trial}}},
  volume = {280},
  issn = {0098-7484},
  shorttitle = {Effect on the {{Quality}} of {{Peer Review}} of {{Blinding Reviewers}} and {{Asking Them}} to {{Sign Their Reports}}},
  abstract = {Context.\textemdash{}Anxiety about bias, lack of accountability, and poor quality of peer review has led to questions about the imbalance in anonymity between reviewers and authors.Objective.\textemdash{}To evaluate the effect on the quality of peer review of blinding reviewers to the authors' identities and requiring reviewers to sign their reports.Design.\textemdash{}Randomized controlled trial.Setting.\textemdash{}A general medical journal.Participants.\textemdash{}A total of 420 reviewers from the journal's database.Intervention.\textemdash{}We modified a paper accepted for publication introducing 8 areas of weakness. Reviewers were randomly allocated to 5 groups. Groups 1 and 2 received manuscripts from which the authors' names and affiliations had been removed, while groups 3 and 4 were aware of the authors' identities. Groups 1 and 3 were asked to sign their reports, while groups 2 and 4 were asked to return their reports unsigned. The fifth group was sent the paper in the usual manner of the journal, with authors' identities revealed and a request to comment anonymously. Group 5 differed from group 4 only in that its members were unaware that they were taking part in a study.Main Outcome Measure.\textemdash{}The number of weaknesses in the paper that were commented on by the reviewers.Results.\textemdash{}Reports were received from 221 reviewers (53\%). The mean number of weaknesses commented on was 2 (1.7, 2.1, 1.8, and 1.9 for groups 1, 2, 3, and 4 and 5 combined, respectively). There were no statistically significant differences between groups in their performance. Reviewers who were blinded to authors' identities were less likely to recommend rejection than those who were aware of the authors' identities (odds ratio, 0.5; 95\% confidence interval, 0.3-1.0).Conclusions.\textemdash{}Neither blinding reviewers to the authors and origin of the paper nor requiring them to sign their reports had any effect on rate of detection of errors. Such measures are unlikely to improve the quality of peer review reports.},
  language = {en},
  number = {3},
  journal = {JAMA},
  doi = {10.1001/jama.280.3.237},
  author = {Godlee, Fiona and Gale, Catharine R. and Martyn, Christopher N.},
  month = jul,
  year = {1998},
  pages = {237-240}
}

@article{bruce_impact_2016,
  title = {Impact of Interventions to Improve the Quality of Peer Review of Biomedical Journals: A Systematic Review and Meta-Analysis},
  volume = {14},
  issn = {1741-7015},
  shorttitle = {Impact of Interventions to Improve the Quality of Peer Review of Biomedical Journals},
  abstract = {Background
The peer review process is a cornerstone of biomedical research. We aimed to evaluate the impact of interventions to improve the quality of peer review for biomedical publications.

Methods
We performed a systematic review and meta-analysis. We searched CENTRAL, MEDLINE (PubMed), Embase, Cochrane Database of Systematic Reviews, and WHO ICTRP databases, for all randomized controlled trials (RCTs) evaluating the impact of interventions to improve the quality of peer review for biomedical publications. 

Results
We selected 22 reports of randomized controlled trials, for 25 comparisons evaluating training interventions (n\,=\,5), the addition of a statistical peer reviewer (n\,=\,2), use of a checklist (n\,=\,2), open peer review (i.e., peer reviewers informed that their identity would be revealed; n\,=\,7), blinded peer review (i.e., peer reviewers blinded to author names and affiliation; n\,=\,6) and other interventions to increase the speed of the peer review process (n\,=\,3). Results from only seven RCTs were published since 2004. As compared with the standard peer review process, training did not improve the quality of the peer review report and use of a checklist did not improve the quality of the final manuscript. Adding a statistical peer review improved the quality of the final manuscript (standardized mean difference (SMD), 0.58; 95~\% CI, 0.19 to 0.98). Open peer review improved the quality of the peer review report (SMD, 0.14; 95~\% CI, 0.05 to 0.24), did not affect the time peer reviewers spent on the peer review (mean difference, 0.18; 95~\% CI, \textendash{}0.06 to 0.43), and decreased the rate of rejection (odds ratio, 0.56; 95~\% CI, 0.33 to 0.94). Blinded peer review did not affect the quality of the peer review report or rejection rate. Interventions to increase the speed of the peer review process were too heterogeneous to allow for pooling the results.

Conclusion
Despite the essential role of peer review, only a few interventions have been assessed in randomized controlled trials. Evidence-based peer review needs to be developed in biomedical journals.

Electronic supplementary material
The online version of this article (doi:10.1186/s12916-016-0631-5) contains supplementary material, which is available to authorized users.},
  journal = {BMC Medicine},
  doi = {10.1186/s12916-016-0631-5},
  author = {Bruce, Rachel and Chauvin, Anthony and Trinquart, Ludovic and Ravaud, Philippe and Boutron, Isabelle},
  month = jun,
  year = {2016},
  pmid = {27287500},
  pmcid = {PMC4902984}
}

@misc{seiver_assessment_nodate,
  title = {Assessment of {{Signing Peer Reviews}} in {{Principle}} and in {{Practice}} at {{Public Library}} of {{Science}} ({{PLOS}}) {{Journals}} | {{Peer Review Congress}}},
  howpublished = {https://peerreviewcongress.org/prc17-0369},
  author = {Seiver, Elizabeth and Atkins, Helen}
}

@article{godlee_making_2002,
  title = {Making {{Reviewers Visible}}: {{Openness}}, {{Accountability}}, and {{Credit}}},
  volume = {287},
  issn = {0098-7484},
  shorttitle = {Making {{Reviewers Visible}}},
  abstract = {Anonymity for peer reviewers remains the overwhelming norm within biomedical journals. While acknowledging that open review is not without challenges, this article presents 4 key arguments in its favor: (1) ethical superiority, (2) lack of important adverse effects, (3) feasibility in practice, and (4) potential to balance greater accountability for reviewers with credit for the work they do. Barriers to more widespread use of open review include conservatism within the research community and the fact that openness makes editors publicly responsible for their choice of reviewers and their interpretation of reviewers' comments. Forces for change include the growing use of preprint servers combined with open commentary. I look forward to a time when open commentary and review replace the current, flawed system of closed prepublication peer review and its false reassurances about the reliability of what is published.},
  language = {en},
  number = {21},
  journal = {JAMA},
  doi = {10.1001/jama.287.21.2762},
  author = {Godlee, Fiona},
  month = jun,
  year = {2002},
  pages = {2762-2765}
}

@article{bravo_effect_2019,
  title = {The Effect of Publishing Peer Review Reports on Referee Behavior in Five Scholarly Journals},
  volume = {10},
  copyright = {2019 The Author(s)},
  issn = {2041-1723},
  abstract = {To increase transparency in science, some scholarly journals have begun publishing peer review reports. Here, the authors show how this policy shift affects reviewer behavior by analyzing data from five journals piloting open peer review.},
  language = {en},
  number = {1},
  journal = {Nature Communications},
  doi = {10.1038/s41467-018-08250-2},
  author = {Bravo, Giangiacomo and Grimaldo, Francisco and {L{\'o}pez-I{\~n}esta}, Emilia and Mehmani, Bahar and Squazzoni, Flaminio},
  month = jan,
  year = {2019},
  pages = {1-8}
}

@article{bornmann_content_2010,
  title = {A Content Analysis of Referees' Comments: How Do Comments on Manuscripts Rejected by a High-Impact Journal and Later Published in Either a Low- or High-Impact Journal Differ?},
  volume = {83},
  issn = {1588-2861},
  shorttitle = {A Content Analysis of Referees' Comments},
  abstract = {Using the data of a comprehensive evaluation study on the peer review process of Angewandte Chemie International Edition (AC-IE), we examined in this study the way in which referees' comments differ on manuscripts rejected at AC-IE and later published in either a low-impact journal (Tetrahedron Letters, n = 54) or a high-impact journal (Journal of the American Chemical Society, n = 42). For this purpose, a content analysis was performed of comments which led to the rejection of the manuscripts at AC-IE. For the content analysis, a classification scheme with thematic areas developed by Bornmann et al. (2008) was used. As the results of the analysis demonstrate, a large number of negative comments from referees in the areas ``Relevance of contribution'' and ``Design/Conception'' are clear signs that a manuscript rejected at AC-IE will not be published later in a high-impact journal. The number of negative statements in the areas ``Writing/Presentation,'' ``Discussion of results,'' ``Method/Statistics,'' and ``Reference to the literature and documentation,'' on the other hand, had no statistically significant influence on the probability that a rejected manuscript would later be published in a low- or high-impact journal. The results of this study have various implications for authors, journal editors and referees.},
  language = {en},
  number = {2},
  journal = {Scientometrics},
  doi = {10.1007/s11192-009-0011-4},
  author = {Bornmann, Lutz and Weymuth, Christophe and Daniel, Hans-Dieter},
  month = may,
  year = {2010},
  keywords = {Content analysis,Fate of rejected manuscripts,Journal peer review,Thematic areas for manuscript review},
  pages = {493-506}
}

@misc{bastian_signing_2018,
  title = {Signing {{Critical Peer Reviews}} \& the {{Fear}} of {{Retaliation}}: {{What Should We Do}}? | {{Absolutely Maybe}}},
  howpublished = {https://blogs.plos.org/absolutely-maybe/2018/03/22/signing-critical-peer-reviews-the-fear-of-retaliation-what-should-we-do/},
  author = {Bastian, Hilda},
  year = {2018}
}

@book{r_core_team_r_2013,
  address = {{Vienna, Austria}},
  title = {R: {{A}} Language and Environment for Statistical Computing},
  author = {{R Core Team}},
  year = {2013},
  organization = {{R Foundation for Statistical Computing}}
}


