Review History for Challenges as enablers for high quality Linked Data: insights from the Semantic Publishing Challenge [PeerJ]
PeerJ Computer Science PeerJ – the Journal of Life & Environmental Sciences PeerJ Computer Science PeerJ Physical Chemistry PeerJ Organic Chemistry PeerJ Inorganic Chemistry PeerJ Analytical Chemistry PeerJ Materials Science Visit PeerJ.org and get involved About PeerJ Journals Overview PeerJ Journals FAQ What we publish 5 Years publishing Solutions for authors Reputation High quality peer review Fast publishing Indexing and Impact Factor Global readership Feature comparison Reduced cost publishing Author feedback Early career researcher benefits Senior researcher benefits Open review (optional) Rebuttal letters Sections About the journal Sections Aquatic Biology Biochemistry, Biophysics and Molecular Biology Biodiversity and Conservation Bioinformatics and Genomics Brain and Cognition Ecology Environmental Science Microbiology Paleontology and Evolutionary Science Plant Biology Zoological Science About PeerJ Journals Overview PeerJ Journals FAQ What we publish 5 Years publishing Solutions for authors Reputation High quality peer review Fast publishing Indexing and Impact Factor Global readership Feature comparison Reduced cost publishing Author feedback Early career researcher benefits Senior researcher benefits Open review (optional) Rebuttal letters More Subjects Search articles Peer-reviewed Journals PeerJ (Life, Biological, Environmental and Health Sciences) PeerJ Computer Science PeerJ Physical Chemistry PeerJ Organic Chemistry PeerJ Inorganic Chemistry PeerJ Analytical Chemistry PeerJ Materials Science Preprints PeerJ Preprints Table of contents Table of Contents - current and archives PeerJ - Medicine articles PeerJ - Biology & Life science articles PeerJ - Environmental Science articles PeerJ - General bio (stats, legal, policy, edu) PeerJ Computer Science PeerJ Preprints Academic advisors Volunteer to review Collections Job listings Discussions Blog Institutional plans Reviews and awards Spread the word Who are we? Contact Login AUTHORS Peer Journals Overview Submission Guidelines Subject Areas Editorial Board Editorial Criteria Pricing General FAQ Computer Science FAQ Aims and Scope Author Interviews Policies and Procedures SUBMIT ARTICLE
Review History Challenges as enablers for high quality Linked Data: insights from the Semantic Publishing Challenge To increase transparency, PeerJ operates a system of 'optional signed reviews and history'. This takes two forms: (1) peer reviewers are encouraged, but not required, to provide their names (if they do so, then their profile page records the articles they have reviewed), and (2) authors are given the option of reproducing their entire peer review history alongside their published article (in which case the complete peer review process is provided, including revisions, rebuttal letters and editor decision letters). New to public reviews? Learn more about optional signed reviews and how to write a better rebuttal letter .
Summary
The initial submission of this article was received on July 19th, 2016 and was peer-reviewed by 2 reviewers and the Academic Editor. The Academic Editor made their initial decision on September 7th, 2016. The first revision was submitted on December 3rd, 2016 and was reviewed by the Academic Editor. The article was Accepted by the Academic Editor on December 12th, 2016.
label_version_1
Version 0.2 (accepted)
Ana Maguitman
·
Dec 12, 2016
label_recommendation_1
·
Academic Editor
Accept
The authors have addressed all the reviewers' comments in this new submission.
External reviews were received for this submission. These reviews were used by the Editor when they made their decision, and can be downloaded below. Download Version 0.2 (PDF)
Download author's rebuttal letter Download external reviews
- submitted Dec 3, 2016
label_version_2
Version 0.1 (original submission)
Ana Maguitman
·
Sep 7, 2016
label_recommendation_2
·
Academic Editor
Major Revisions
The reviewers felt that the work is interesting, but have indicated that major revisions are needed. We encourage you to revise the manuscript and resubmit it for reconsideration. If you decide to submit a revised version you must address all the reviewers' comments. We look forward to seeing your revision.
label_author_1
Reviewer 1 ·
Aug 4, 2016
Basic reporting
label_br_1
The paper is written in clear, professional English. The structure of the paper is clear and it corresponds to the presented topic although it does not fully conform to the recommended PeerJ standard. The Introduction and Background sections provide the necessary context, the referenced sources are relevant to the topic. The presented tables provide important and useful additional information. The table formatting should be improved, for example the structure of Table 2 is not very clear and it takes time to understand the meaning of the rows and overlapping columns. Raw datasets mentioned in the paper seem to be available in a public repository at GitHub.com.
Experimental design
label_ed_1
The paper focuses on summarizing the experience gained during three years of organizing The Semantic Publishing Challenge. Thus, it is not a typical research paper presenting hard experimental results. The relevant methods of linked dataset creation are mentioned only briefly and the main focus is given to sharing the experience and "lessons learned". In this part, the summarization of the findings corresponds to the evolution of the Challenge - authors thoroughly describe the aspects of the Challenge that turned out to be beneficial or counterproductive. The description is sufficiently detailed. The only thing I am missing is a more thorough description of the process of preparing the "golden standard" data used for evaluating the submitted datasets and evaluation process in general. Many questions arise here: Which tools have been used for creating the "golden standard"? Was the result validated with the source documents (how?) or was any other data source used for its validation? Does some of the submitted tools actually provide better results in some situation that the golden standard and could such situation be detected properly?
Validity of the findings
label_votf_1
The findings regarding the Challenge organization are compared and sufficiently validated with the results of a survey conducted among the organizers of similar challenges. Moreover, the paper provides an interesting statistical summary of the properties of the obtained data sets including the usage of the existing ontologies, their concepts, etc. which come from the available raw data.
Comments for the author
label_cfta_1
Although the topic of the paper is not typical for informatics and computer science, it is definitely very interesting and the experience is worth sharing. I find the paper well structured and the findings are presented in detail. I recommend only minor revisions regarding (1) the table data presentation and (2) more detailed description of the Challenge evaluation process and the "golden standard" preparation. Cite this review as
Anonymous Reviewer ( 2017 ) Peer Review #1 of "Challenges as enablers for high quality Linked Data: insights from the Semantic Publishing Challenge (v0.1)" . PeerJ Computer Science https://doi.org/10.7287/peerj-cs.105v0.1/reviews/1
label_author_2
Reviewer 2 ·
Sep 5, 2016
Basic reporting
label_br_2
"No Comments"
Experimental design
label_ed_2
"No Comments"
Validity of the findings
label_votf_2
"No Comments"
Comments for the author
label_cfta_2
The paper provides a description and analysis of the Semantic Web Publishing Challenge, deriving a set of challenge organization best practices and providing a description of Linked Data produced as a result of the challenge. The proposed analysis is relevant and the focussed scope of the analysis corpus (as well as some of the author's involvement with the challenge organization) brings the opportunity for a deeper analysis of the problem space. The paper needs more effort on the analysis and on communication side. Improvement points are provided below. - As it is the paper is rather descriptive and fails to create a process of abstraction and generalization of interesting patterns within the challenge. This is the main limitation of the paper. To address this, the paper needs to be seriously reworked. For example the tables in the paper concentrate on comparing lower-level attributes, rather then using higher level categories which can shed some light on the challenges and insights of Linked Data production and publication. - The authors here have a great opportunity of providing the core insights, from a 'lab' perspective (the challenge here working as an experiment) on the critical aspects of representation, infrastructure and cultural that influence the practice of Linked Data publication. Can you dig into the dataset heterogeneity problems, for example? Which aspects of the representation provide more complete/high quality Linked Data? - The paper is well-written but it lacks structure. As it is, the paper is a collection of low-level descriptions of observations and attributes of the challenges put together as a continuous text flow. The paper fails to generalize the observations into higher-level categories. Introducing more structure into the paper (Bullet points, subsections) is a very central improvement for the discourse. - Some more 'soft' but very fundamental aspects are left out of the analysis at Section 3. In which communities the Semantic Web Publishing challenge had better traction (Semantic Web, Biomedical domain)? How the perception about the core communities which would be the main stakeholders in the challenge changed? - Comparative analysis with related work is limited (and for a good reason as there are not many works on the evaluation of campaigns). One suggestion would be to better link Section 4 with related work on Linked Data Quality? Information retrieval has a long tradition on evaluation campaigns. Can you link to any work on this community? Cite this review as
Anonymous Reviewer ( 2017 ) Peer Review #2 of "Challenges as enablers for high quality Linked Data: insights from the Semantic Publishing Challenge (v0.1)" . PeerJ Computer Science https://doi.org/10.7287/peerj-cs.105v0.1/reviews/2 External reviews were received for this submission. These reviews were used by the Editor when they made their decision, and can be downloaded below. Download Original Submission (PDF)
Download external reviews
- submitted Jul 19, 2016 All text and materials provided via this peer-review history page are made available under a Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.
About us - PeerJ team | Our publications | Benefits | Partnerships | Endorsements Awards Resources - FAQ | Careers | Pressroom | Terms of use | Privacy | Contact Academic boards - Advisors | Editors | Subject areas Follow us - PeerJ blog | Twitter | Facebook | LinkedIn | Pinterest Submission guides - PeerJ – Life and Environment | PeerJ Computer Science | PeerJ Chemistry Spread the word - Activities | Resources PeerJ feeds - Atom | RSS 1.0 | RSS 2.0 | JSON PeerJ Computer Science feeds - Atom | RSS 1.0 | RSS 2.0 | JSON Archives - PeerJ – Life and Environment | PeerJ Computer Science
©2012-2019 PeerJ, Inc | Public user content licensed CC BY 4.0 unless otherwise specified. PeerJ ISSN: 2167-8359 PeerJ Comput. Sci. ISSN: 2376-5992 PeerJ Preprints ISSN: 2167-9843
computer science
