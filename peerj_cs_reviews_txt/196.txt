Review History for Data-based intervention approach for Complexity-Causality measure [PeerJ]
PeerJ Computer Science PeerJ – the Journal of Life & Environmental Sciences PeerJ Computer Science PeerJ Physical Chemistry PeerJ Organic Chemistry PeerJ Inorganic Chemistry PeerJ Analytical Chemistry PeerJ Materials Science Visit PeerJ.org and get involved About PeerJ Journals Overview PeerJ Journals FAQ What we publish 5 Years publishing Solutions for authors Reputation High quality peer review Fast publishing Indexing and Impact Factor Global readership Feature comparison Reduced cost publishing Author feedback Early career researcher benefits Senior researcher benefits Open review (optional) Rebuttal letters Sections About the journal Sections Aquatic Biology Biochemistry, Biophysics and Molecular Biology Biodiversity and Conservation Bioinformatics and Genomics Brain and Cognition Ecology Environmental Science Microbiology Paleontology and Evolutionary Science Plant Biology Zoological Science About PeerJ Journals Overview PeerJ Journals FAQ What we publish 5 Years publishing Solutions for authors Reputation High quality peer review Fast publishing Indexing and Impact Factor Global readership Feature comparison Reduced cost publishing Author feedback Early career researcher benefits Senior researcher benefits Open review (optional) Rebuttal letters More Subjects Search articles Peer-reviewed Journals PeerJ (Life, Biological, Environmental and Health Sciences) PeerJ Computer Science PeerJ Physical Chemistry PeerJ Organic Chemistry PeerJ Inorganic Chemistry PeerJ Analytical Chemistry PeerJ Materials Science Preprints PeerJ Preprints Table of contents Table of Contents - current and archives PeerJ - Medicine articles PeerJ - Biology & Life science articles PeerJ - Environmental Science articles PeerJ - General bio (stats, legal, policy, edu) PeerJ Computer Science PeerJ Preprints Academic advisors Volunteer to review Collections Job listings Discussions Blog Institutional plans Reviews and awards Spread the word Who are we? Contact Login AUTHORS Peer Journals Overview Submission Guidelines Subject Areas Editorial Board Editorial Criteria Pricing General FAQ Computer Science FAQ Aims and Scope Author Interviews Policies and Procedures SUBMIT ARTICLE
Review History Data-based intervention approach for Complexity-Causality measure To increase transparency, PeerJ operates a system of 'optional signed reviews and history'. This takes two forms: (1) peer reviewers are encouraged, but not required, to provide their names (if they do so, then their profile page records the articles they have reviewed), and (2) authors are given the option of reproducing their entire peer review history alongside their published article (in which case the complete peer review process is provided, including revisions, rebuttal letters and editor decision letters). New to public reviews? Learn more about optional signed reviews and how to write a better rebuttal letter .
Summary
The initial submission of this article was received on December 6th, 2018 and was peer-reviewed by 2 reviewers and the Academic Editor. The Academic Editor made their initial decision on January 17th, 2019. The first revision was submitted on March 21st, 2019 and was reviewed by 3 reviewers and the Academic Editor. A further revision was submitted on April 22nd, 2019 and was reviewed by the Academic Editor. The article was Accepted by the Academic Editor on April 29th, 2019.
label_version_1
Version 0.3 (accepted)
Ciro Cattuto
·
Apr 29, 2019
label_recommendation_1
·
Academic Editor
Accept
The submitted minor revision satisfactorily addresses the remaining observation by the Reviewers.
Download Version 0.3 (PDF)
Download author's rebuttal letter
- submitted Apr 22, 2019
label_version_2
Version 0.2
Ciro Cattuto
·
Apr 15, 2019
label_recommendation_2
·
Academic Editor
Minor Revisions
Based on combined assessment of the two Reviewers who read the original manuscript, and of an additional Reviewer, I'm glad to see that the manuscript has significantly improved. The issue raised by Reviewer 1 regarding the comparison to DCM, however, needs to be addressed by either 1) dropping the DCM comparison in a minor revision of the manuscript, or 2) carrying out a major revision where the DCM comparison is carried out more exhaustively (see comments by Reviewer 1 to this end). I don't think that this would fit well the scope of the current manuscript, so I would recommend to proceed as in 1) and drop the DCM comparison. Hence my decision to ask for a minor revision. In the context of this new revision, I would kindly ask the Authors to also compulsorily address as many of the comments by Reviewer 3 as possible.
label_author_1
Reviewer 1 ·
Mar 28, 2019
Basic reporting
label_br_1
nothing to add
Experimental design
label_ed_1
There are many EEG and fMRI data available, openneuro.org has hundreds of them, not to mention the benchmark EEG and fMRI data included in the SPM package. So a comparison with DCM is certainly feasible. On the other hand we should not put all connectivity estimates in the same box, DCM is a confirmatory approach meant to disclose the involvment of synaptic parameters, and should not be used for network discovery and to assess the simple presence of links. A benchmark should be carefully chosen in order to map the effects of an intervention in the two cases.
Validity of the findings
label_votf_1
The findings are valid, but I see the risk that all possible connectivity (or "causality") estimates are conflated, and in this case any comparison and interpretation is meaningless.
Cite this review as
Anonymous Reviewer ( 2019 ) Peer Review #1 of "Data-based intervention approach for Complexity-Causality measure (v0.2)" . PeerJ Computer Science https://doi.org/10.7287/peerj-cs.196v0.2/reviews/1
label_author_2
Reviewer 2 ·
Apr 13, 2019
Basic reporting
label_br_2
The authors improved significantly the manuscript according to my previous and the other referees' suggestions. In particular, they showed the effectiveness of their measure in specific cases of biological relevance.
Experimental design
label_ed_2
no comment.
Validity of the findings
label_votf_2
no comments
Cite this review as
Anonymous Reviewer ( 2019 ) Peer Review #2 of "Data-based intervention approach for Complexity-Causality measure (v0.2)" . PeerJ Computer Science https://doi.org/10.7287/peerj-cs.196v0.2/reviews/2
label_author_3
Reviewer 3 ·
Apr 8, 2019
Basic reporting
label_br_3
Overall the manuscript is clearly reported. A couple of minor issues... The proposed method is based on the Effort-to-compress measure, but this is not described in the manuscript (only in the supplementary material). This severely effects the clarity of the article. This is particularly strange given that a number of other measures, which are not central to the proposed measure, are defined in the manuscript (e.g., KL-divergence and JS-divergence). I suggest including more details about the ETS in the main text. The large number of acronyms make the manuscript bothersome to read. It would be useful to remove some of these or at least provides some reminders along the way. Also it seems that ICC and CCC are the same thing except that the latter is specifically using ETC as the notion of complexity.
Experimental design
label_ed_3
The experimental design seems adequate.
Validity of the findings
label_votf_3
The validity of the findings appear to be sound. However, I'd like to echo reviewer one's comment on stating the scenarios in which performance can be expected to be good and the scenarios for which it is expected to be bad. Perhaps a thorough analysis of this is beyond the scope of the current work. But without such analysis, the usefulness of the proposed approach may be limited as one can never be sure under what circumstances the method is applicable. Indeed this is a general limitation for so-called "model-free" approaches since the assumptions are ignored rather than clearly stated.
Cite this review as
Anonymous Reviewer ( 2019 ) Peer Review #3 of "Data-based intervention approach for Complexity-Causality measure (v0.2)" . PeerJ Computer Science https://doi.org/10.7287/peerj-cs.196v0.2/reviews/3 Download Version 0.2 (PDF)
Download author's rebuttal letter
- submitted Mar 21, 2019
label_version_3
Version 0.1 (original submission)
Ciro Cattuto
·
Jan 17, 2019
label_recommendation_3
·
Academic Editor
Major Revisions
I encourage the Authors to carry out a major revision of the manuscript that takes into account the observations of the reviewers, with special attention to addressing the major observations of Reviewer #2, which I consider critically important to consider acceptance of the manuscript.
label_author_4
Reviewer 1 ·
Dec 22, 2018
Basic reporting
label_br_4
Dear authors thanks for submitting this interesting paper. The results seem promising, the description needs some smoothing and some extra info, and it would be good to abandon the too often used approach of "here's a good method that outperforms other", since this is rarely the case, and the field would benefit from a more global view in which convenient aspects of several approaches are merged. You mention that Granger causality is a "model free" approach, which it isn't. Transfer Entropy is. GC is rooted on autoregressive models. Maybe you meant "data driven". The introduction of the paper is a bit confusing. I don't think that these methods address any of the ladders of causality, and maybe they shouldn't either. Of course when we apply these methods to real data, we are in a causal framework in the sense of the counterfactuals, but again, I find the introductory sentences misleading and dissociated from the actual content of the paper.
Experimental design
label_ed_4
You could maybe better explain the philosophy behind your method, and whether it addresses the effects or the mechanism. Also the applications are either abstract benchmarks (still useful) or a case in which a ground truth or intervention is difficult to assess.
Validity of the findings
label_votf_4
While your approach seems powerful for the data presented, it would be good and fair to state possible scenarios in which the performance is not so good. I understand that Granger Causality and Transfer Entropy are among the most used approach, but other measures exist, such as the Convergent Cross Mapping http://science.sciencemag.org/content/338/6106/496 . Also, other approaches have proposed compression as a tool to evaluate causality, see for example https://arxiv.org/abs/1611.00261 https://eda.mmci.uni-saarland.de/pubs/2016/origo-budhathoki,vreeken.pdf Could you maybe comment on these aspects?
Cite this review as
Anonymous Reviewer ( 2019 ) Peer Review #1 of "Data-based intervention approach for Complexity-Causality measure (v0.1)" . PeerJ Computer Science https://doi.org/10.7287/peerj-cs.196v0.1/reviews/1
label_author_5
Reviewer 2 ·
Jan 7, 2019
Basic reporting
label_br_5
The paper "Data based intervention approach for Complexity-Causality measure" proposes a new model-independent measure aimed at describing high-order causal relations between signals. The authors provide context for the relevance of the proposed measure, comparing it against traditional model-free measures and show that their measure is generally able to provide better discrimination in simple synthetic cases and a couple of real systems. I commend the authors for their extensive work explaining the new measure with different examples of growing complexity. I highlight a weakness in my comments below regarding the lack of comparison with a model-dependent case. The manuscript is written clearly, although occasionally there is a missing preposition or article. I recommend a further thorough check of the manuscript. Moreover, code is provided to replicate the analysis. Overall, I think the manuscript is a valid contribution. I however harbor some doubts about the capacity and usefulness of the new measure in complex networked systems, which are the systems where most likely model-based measures fail or are unavailable. Hence, as mentioned in the comments below, I think that, before being accepted, the paper should include the comparison with a case where model-dependent is available, even if for a simple system.
Experimental design
label_ed_5
no comment
Validity of the findings
Major comments: - the authors throughout the paper compare first-order with high-order AR models in order to show that, while TE/GC sometimes work for AR(1) models, they consistently fail for higher-order one, thus highlighting the capacity of CCC to capture hierarchically higher causality effects. This is good, but what I would like to see is whether CCC is able to outperform specific model-dependent measures and observations in systems where we do have such specific equations. Indeed, the authors mention DCM and SEM too: it would be great if it were possible to show that the direction and intensity of interactions picked up by DCM in real-data (even in one of the examples with few-nodes in Friston's DCM toolbox on EEG or fMRI data) corresponds to that captured by CCC. I understand that the authors mention something similar as future work, but given their claims about CCC, I would really like to see this in the paper. - Following up, how hard computationally is to compute CCC versus existing measures of complexity? Is this a tool that can be thrown at data cheaply or is it instead to heavy to use as a first general-purpose step of analysis? Can we imagine to scale this up to the case of hundreds of signals, as is typically the case in neuroimaging applications?
Comments for the author
- There are no error bars reported anywhere in the plots. Assuming that the curves shown are obtained over repeated simulations of the processes for each parameter choice, it would be interesting to understand the variance/magnitude of fluctuations around the reported mean values for both GC, TE and CCC. - the figure labels are acceptable, but a little small; I'd recommend making the labels larger for improved readability. Cite this review as
Anonymous Reviewer ( 2019 ) Peer Review #2 of "Data-based intervention approach for Complexity-Causality measure (v0.1)" . PeerJ Computer Science https://doi.org/10.7287/peerj-cs.196v0.1/reviews/2 Download Original Submission (PDF)
- submitted Dec 6, 2018 All text and materials provided via this peer-review history page are made available under a Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.
About us - PeerJ team | Our publications | Benefits | Partnerships | Endorsements Awards Resources - FAQ | Careers | Pressroom | Terms of use | Privacy | Contact Academic boards - Advisors | Editors | Subject areas Follow us - PeerJ blog | Twitter | Facebook | LinkedIn | Pinterest Submission guides - PeerJ – Life and Environment | PeerJ Computer Science | PeerJ Chemistry Spread the word - Activities | Resources PeerJ feeds - Atom | RSS 1.0 | RSS 2.0 | JSON PeerJ Computer Science feeds - Atom | RSS 1.0 | RSS 2.0 | JSON Archives - PeerJ – Life and Environment | PeerJ Computer Science
©2012-2019 PeerJ, Inc | Public user content licensed CC BY 4.0 unless otherwise specified. PeerJ ISSN: 2167-8359 PeerJ Comput. Sci. ISSN: 2376-5992 PeerJ Preprints ISSN: 2167-9843
computer science
