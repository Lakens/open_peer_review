Review History for Leveraging aspect phrase embeddings for cross-domain review rating prediction [PeerJ]
PeerJ Computer Science PeerJ – the Journal of Life & Environmental Sciences PeerJ Computer Science PeerJ Physical Chemistry PeerJ Organic Chemistry PeerJ Inorganic Chemistry PeerJ Analytical Chemistry PeerJ Materials Science Visit PeerJ.org and get involved About PeerJ Journals Overview PeerJ Journals FAQ What we publish 5 Years publishing Solutions for authors Reputation High quality peer review Fast publishing Indexing and Impact Factor Global readership Feature comparison Reduced cost publishing Author feedback Early career researcher benefits Senior researcher benefits Open review (optional) Rebuttal letters Sections About the journal Sections Aquatic Biology Biochemistry, Biophysics and Molecular Biology Biodiversity and Conservation Bioinformatics and Genomics Brain and Cognition Ecology Environmental Science Microbiology Paleontology and Evolutionary Science Plant Biology Zoological Science About PeerJ Journals Overview PeerJ Journals FAQ What we publish 5 Years publishing Solutions for authors Reputation High quality peer review Fast publishing Indexing and Impact Factor Global readership Feature comparison Reduced cost publishing Author feedback Early career researcher benefits Senior researcher benefits Open review (optional) Rebuttal letters More Subjects Search articles Peer-reviewed Journals PeerJ (Life, Biological, Environmental and Health Sciences) PeerJ Computer Science PeerJ Physical Chemistry PeerJ Organic Chemistry PeerJ Inorganic Chemistry PeerJ Analytical Chemistry PeerJ Materials Science Preprints PeerJ Preprints Table of contents Table of Contents - current and archives PeerJ - Medicine articles PeerJ - Biology & Life science articles PeerJ - Environmental Science articles PeerJ - General bio (stats, legal, policy, edu) PeerJ Computer Science PeerJ Preprints Academic advisors Volunteer to review Collections Job listings Discussions Blog Institutional plans Reviews and awards Spread the word Who are we? Contact Login AUTHORS Peer Journals Overview Submission Guidelines Subject Areas Editorial Board Editorial Criteria Pricing General FAQ Computer Science FAQ Aims and Scope Author Interviews Policies and Procedures SUBMIT ARTICLE
Review History Leveraging aspect phrase embeddings for cross-domain review rating prediction To increase transparency, PeerJ operates a system of 'optional signed reviews and history'. This takes two forms: (1) peer reviewers are encouraged, but not required, to provide their names (if they do so, then their profile page records the articles they have reviewed), and (2) authors are given the option of reproducing their entire peer review history alongside their published article (in which case the complete peer review process is provided, including revisions, rebuttal letters and editor decision letters). New to public reviews? Learn more about optional signed reviews and how to write a better rebuttal letter .
Summary
The initial submission of this article was received on April 25th, 2019 and was peer-reviewed by 2 reviewers and the Academic Editor. The Academic Editor made their initial decision on June 23rd, 2019. The first revision was submitted on August 24th, 2019 and was reviewed by the Academic Editor. A further revision was submitted on September 5th, 2019 and was reviewed by the Academic Editor. The article was Accepted by the Academic Editor on September 6th, 2019.
label_version_1
Version 0.3 (accepted)
Eibe Frank
·
Sep 6, 2019
label_recommendation_1
·
Academic Editor
Accept
The submission looks fine now, but there is one new little problem in the second line of the introduction: "also can also contribute". Please fix that in the final version.
Download Version 0.3 (PDF)
Download author's rebuttal letter
- submitted Sep 5, 2019
label_version_2
Version 0.2
Eibe Frank
·
Aug 28, 2019
label_recommendation_2
·
Academic Editor
Minor Revisions
The submission looks good and is basically ready to be accepted, but there are some minor wording problems, etc., that need fixing. They are listed below and in the order in which they occur (first) in the document. "as well as they are valuable" -> "and they are valuable" "likert" -> "Likert" "have the possibility for the contribution" -> "can also contribute" "one is expected to use phrases" -> "reviewers are expected to use phrases" "knowledge, the review rating prediction" -> "knowledge, review rating prediction" "pursue the review rating prediction" -> "pursue review rating prediction" "i.e. where phrases " -> "where phrases " "system, which creates" -> "system that creates" "found on the Internet, which do " -> "found on the Internet that do " "consists in " -> "consists of " (multiple times) "e.g. " -> "e.g., " (multiple times) and the same for "i.e. "! "the score of specific feature" -> "the score of specific features" (?) "prediction, which are still limited " -> "prediction but are still limited" (?) "did not study its effectiveness" -> "did not study their effectiveness" "Subsequenty" "In this work, we use " -> "We will use" "except the cases" -> "except in the cases" "we refer to aspect phrases" -> "we refer to as aspect phrases" "the tuples conforming aspect phrases " -> "the tuples corresponding to aspect phrases " (?) "that judges it " -> "that judges the object or action concerned" "Representationn " "two variants;" -> "two variants:" "We generated the embedding vector" -> "We generate the embedding vector" For the w2v baseline, how is a single vector created based on the entire text? By averaging all the embeddings? "Where our objective is to build " -> "Because our objective is to build " ", which include " -> ":" "on top of the list." -> "at the top of the list." (multiple times) "where the combination of both" -> "whereas their combination with w2v" "is also useful " -> "is useful " "emphasises " "popularity in the x axis" -> "popularity on the x axis" (twice) Please include labels for the x axis in each of the sub plots in Figure 2. "in-domain prediction system perform better " -> "the in-domain prediction system performs better " "keeps improve " -> "keeps improving " Make sure that all publications in the bibliography have page numbers and that the publisher is noted for conference proceedings!
Download Version 0.2 (PDF)
Download author's rebuttal letter
- submitted Aug 24, 2019
label_version_3
Version 0.1 (original submission)
Eibe Frank
·
Jun 23, 2019
label_recommendation_3
·
Academic Editor
Major Revisions
The reviewers have identified opportunities for improving the paper and, in particular, are concerned about the baselines used in the paper. More relevant baselines are needed.
label_author_1
Reviewer 1 ·
Jun 20, 2019
Basic reporting
label_br_1
The paper is well written, self-contained and easy to read. Literature review is comprehensive.
Experimental design
label_ed_1
The experimental design is appropriate. However, I feel that a very relevant baseline is missing. Some background is required to make my point clear: The two models in this paper create vectorial representations of reviews. These representations are built by concatenating a general word embedding-based representation (aggregating the embeddings of all words within the review) with aspect phrase embeddings (aggregating embeddings of words within phrases formed by opinions words + nouns or verbs). The opinion words are taken from a given opinion lexicon. Proposed representations outperform the baseline that uses only a "general" word embedding representation. This is because representations coming from opinion words are being amplified in the final vector (they are included in the general embedding and the the aspect phrase embedding). The paper would benefit a lot from further experiments including representations based purely on the opinion words. Perhaps simple representations that only use the embeddings of the opinion words or just the polarities of these words would work well. It is hard to judge the contribution of this work without seeing these results.
Validity of the findings
label_votf_1
Conclusions are well stated, but as discussed above, some additional experiments are required in order to judge the validity of the findings.
Cite this review as
Anonymous Reviewer ( 2019 ) Peer Review #1 of "Leveraging aspect phrase embeddings for cross-domain review rating prediction (v0.1)" . PeerJ Computer Science https://doi.org/10.7287/peerj-cs.225v0.1/reviews/1
label_author_2
Reviewer 2 ·
Jun 21, 2019
Basic reporting
label_br_2
The paper presents an approach for rating prediction based on reviews leveraging on aspect phrase embeddings extracted from the reviews. This, in turn, enables the development of both in-domain and cross-domain review rating prediction systems. Particularly, the paper address an interesting issue within the rating prediction problem, which is the prediction for less popular, usually neglected domains. I think the problem of cross-domain in small domains is interesting and the experimental results suggest that there is an improvement in prediction for such domains.
Experimental design
label_ed_2
The experimental results and the dataset used are correctly reported. The selection of the baselines need, however, more justification. The selection of the work of Fan and Khademi (2014) is hard to understand. It is a baseline using only text, which is the relevance of this particular work? And also why not to include other state-of-the-art works as baselines. The explanation of that other works made use of user data is not clear, which kind of data and why not to use it here?.
Validity of the findings
label_votf_2
I think the conclusions can be more compelling about the contribution to the cross-domain prediction in small domains and include a discussion analyzing possible implications or even further improvements. For example, the results would be even better considering translating the knowledge from big domains (like hotels or restaurants) to small ones that are somehow related? What if domains can be hierarchically organized?
Comments for the author
The paper have, however, some issues that can be improved. I believe the first three sections (Introduction, Background and Related Works) are a little misleading about clarifying the motivation and contribution of the paper. On the one hand, the authors emphasize the problem of the cross-domain in small domains, this problem is hardly discussed in the related works (which is the novelty of the paper in this regard? why not transfer learning or other approaches?). On the other hand, they also claim as a contribution to the extraction of aspect phrases mentioned in the text, but it is not clear the significance or previous works in adding phrases to aspect opinion mining. The three sections should be more focused toward highlighting the contribution(s) and the difference with other approaches. The second section may be even removed or merged with the other two. Cite this review as
Anonymous Reviewer ( 2019 ) Peer Review #2 of "Leveraging aspect phrase embeddings for cross-domain review rating prediction (v0.1)" . PeerJ Computer Science https://doi.org/10.7287/peerj-cs.225v0.1/reviews/2 Download Original Submission (PDF)
- submitted Apr 25, 2019 All text and materials provided via this peer-review history page are made available under a Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.
About us - PeerJ team | Our publications | Benefits | Partnerships | Endorsements Awards Resources - FAQ | Careers | Pressroom | Terms of use | Privacy | Contact Academic boards - Advisors | Editors | Subject areas Follow us - PeerJ blog | Twitter | Facebook | LinkedIn | Pinterest Submission guides - PeerJ – Life and Environment | PeerJ Computer Science | PeerJ Chemistry Spread the word - Activities | Resources PeerJ feeds - Atom | RSS 1.0 | RSS 2.0 | JSON PeerJ Computer Science feeds - Atom | RSS 1.0 | RSS 2.0 | JSON Archives - PeerJ – Life and Environment | PeerJ Computer Science
©2012-2019 PeerJ, Inc | Public user content licensed CC BY 4.0 unless otherwise specified. PeerJ ISSN: 2167-8359 PeerJ Comput. Sci. ISSN: 2376-5992 PeerJ Preprints ISSN: 2167-9843
computer science
