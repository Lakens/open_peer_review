Review History for Software process improvement: a systematic mapping study on the state of the art [PeerJ]
PeerJ Computer Science PeerJ – the Journal of Life & Environmental Sciences PeerJ Computer Science PeerJ Physical Chemistry PeerJ Organic Chemistry PeerJ Inorganic Chemistry PeerJ Analytical Chemistry PeerJ Materials Science Visit PeerJ.org and get involved About PeerJ Journals Overview PeerJ Journals FAQ What we publish 5 Years publishing Solutions for authors Reputation High quality peer review Fast publishing Indexing and Impact Factor Global readership Feature comparison Reduced cost publishing Author feedback Early career researcher benefits Senior researcher benefits Open review (optional) Rebuttal letters Sections About the journal Sections Aquatic Biology Biochemistry, Biophysics and Molecular Biology Biodiversity and Conservation Bioinformatics and Genomics Brain and Cognition Ecology Environmental Science Microbiology Paleontology and Evolutionary Science Plant Biology Zoological Science About PeerJ Journals Overview PeerJ Journals FAQ What we publish 5 Years publishing Solutions for authors Reputation High quality peer review Fast publishing Indexing and Impact Factor Global readership Feature comparison Reduced cost publishing Author feedback Early career researcher benefits Senior researcher benefits Open review (optional) Rebuttal letters More Subjects Search articles Peer-reviewed Journals PeerJ (Life, Biological, Environmental and Health Sciences) PeerJ Computer Science PeerJ Physical Chemistry PeerJ Organic Chemistry PeerJ Inorganic Chemistry PeerJ Analytical Chemistry PeerJ Materials Science Preprints PeerJ Preprints Table of contents Table of Contents - current and archives PeerJ - Medicine articles PeerJ - Biology & Life science articles PeerJ - Environmental Science articles PeerJ - General bio (stats, legal, policy, edu) PeerJ Computer Science PeerJ Preprints Academic advisors Volunteer to review Collections Job listings Discussions Blog Institutional plans Reviews and awards Spread the word Who are we? Contact Login AUTHORS Peer Journals Overview Submission Guidelines Subject Areas Editorial Board Editorial Criteria Pricing General FAQ Computer Science FAQ Aims and Scope Author Interviews Policies and Procedures SUBMIT ARTICLE
Review History Software process improvement: a systematic mapping study on the state of the art To increase transparency, PeerJ operates a system of 'optional signed reviews and history'. This takes two forms: (1) peer reviewers are encouraged, but not required, to provide their names (if they do so, then their profile page records the articles they have reviewed), and (2) authors are given the option of reproducing their entire peer review history alongside their published article (in which case the complete peer review process is provided, including revisions, rebuttal letters and editor decision letters). New to public reviews? Learn more about optional signed reviews and how to write a better rebuttal letter .
Summary
The initial submission of this article was received on February 25th, 2016 and was peer-reviewed by 2 reviewers and the Academic Editor. The Academic Editor made their initial decision on March 19th, 2016. The first revision was submitted on April 20th, 2016 and was reviewed by the Academic Editor. The article was Accepted by the Academic Editor on April 28th, 2016.
label_version_1
Version 0.2 (accepted)
Marlon Dumas
·
Apr 28, 2016
label_recommendation_1
·
Academic Editor
Accept
This acceptance is conditional on you making the raw data publicly available (i.e. the table in the supplemental file 2016-04-19_data-final-cleaned.xlsx should be made available as "raw data")
Download Version 0.2 (PDF)
Download author's rebuttal letter
- submitted Apr 20, 2016
label_version_2
Version 0.1 (original submission)
Marlon Dumas
·
Mar 19, 2016
label_recommendation_2
·
Academic Editor
Minor Revisions
The reviewers are positive about the paper. It is clear that the systematic mapping study reported in this paper is thorough and conducted according to well accepted practices. One of the reviewers requires a minor revision listing a few technical concerns and requests for clarification (see "Comments for the author" of the second review). The same reviewer notes some repetition between Discussion and Conclusion. The Conclusion section could perhaps be slightly shortened. The reviewer also makes a comment about the overlap between this manuscript and the previous version of the paper. I leave it to the authors to decide if and how to handle this comment. It is clear that this manuscript substantially extends the conference paper and thus requirements are met in this respect. The conference papers has more authors than the ones listed in this submission - we assume that the authors that were left out from the conference paper are aware of it and agree. The result set of the literature search is "raw data". In line with the review policy of PeerJ CS, the authors should submit this material for review as supplementary material. Please check point number 4 of the following instructions: https://peerj.com/about/author-instructions/cs It is claimed in the submission that the dataset is too large. In this case please upload it to an archived open data management system (PeerJ recommends using figshare). I recommend the authors to package the result set as a table (e.g. Excel file) and upload it together with the revised version of the paper. I also recommend that the table with the result set should include a column classifying each paper according to the "publication objective" categorization introduced in lines 330-339 of page 11 (and any other additional metadata the authors deem useful). If the authors wish to submit the entire search result (on top of the result set) they are welcome to do so as well.
label_author_1
Tom McBride ·
Mar 3, 2016
Basic reporting
label_br_1
The paper is excellently written, clear and unambiguous.
Experimental design
label_ed_1
The research design is rigorous, conforming to all guidelines for systematic mapping. The method is extensively described, research questions clearly identified and subsequently addressed.
Validity of the findings
label_votf_1
The findings are valid. More specifically the findings are useful to any researcher in the general area of software process improvement.
Comments for the author
label_cfta_1
There have been so many poorly done systematic literature reviews that it was refreshing to find one that was done well, rigorously and produced valid and useful findings. Cite this review as
McBride T ( 2016 ) Peer Review #1 of "Software process improvement: a systematic mapping study on the state of the art (v0.1)" . PeerJ Computer Science https://doi.org/10.7287/peerj-cs.62v0.1/reviews/1
label_author_2
Reviewer 2 ·
Mar 14, 2016
Basic reporting
label_br_2
This paper is an extension of the authors' earlier paper providing a systematic mapping of Software Process Improvement updating their previous study findings. The paper follows the guidelines of SLRs by Kitchenham and Charters as well as SMS by Petersen et al. The authors propose 3 research questions and describe their data collection and analysis procedures in great detail.
Experimental design
label_ed_2
The motivation of the study is "to shed light on" the field of SPI and to present the state of the art of SPI. I would have preferred the motivation being related to findings or hypothesis of the previous studies by the authors. Despite the fact that this paper is an extension of the authors' earlier mapping study of SPI, I find it seriously disturbing that the authors have identical abstract, introduction, related works section, research design, data collection and analysis sections to their earlier paper that was published at ICSSP conference in 2015. First, after having conducted such an extensive literature review, surely the authors can come up with a different abstract and introduction sections with citing different articles. Secondly, the extended paper could focus considerably more on the discussion if it wasn't repeating the first sections of the paper - a reference to the previous paper would have sufficed.
Validity of the findings
label_votf_2
The authors describe their findings clearly even though it is a very technical and long section. The Discussion section is particularly valuable to this paper. At the same time, there is a lot of repetition between Discussion and Conclusion sections which the authors should revise.
Comments for the author
label_cfta_2
There are some comments that the authors could take into account in improving their paper: 1. When a research topic is as applied as SPI and has been around for a long time, there could be little novelty in it for research to investigate much further (in Discussion/Limitation sections). 2. In Introduction, the authors say that "we still struggle to answer the question like: What is out there?..." Could you please refer to papers that would support such a claim - who is struggling? 3. About agile SPI, mentioned in Introduction, there should also be a reference to Salo and Abrahamsson whose agile SPI paper was one of the first ones and is heavily cited. 4. In Section 3.5 the authors describe how they called further researchers to confirm their publication classification. How did you select these researchers? How many were there? Did you have anybody from ISO/IEC JTC1 SC7 WG10 that develops ISO/IEC 15504/33000 standards? Both space and nuclear SPI fields are completely missing from the classification. 5. Table 11 - search strings. In the opinion of this reviewer, the authors have mixed up process models with methods, and assessment methods with improvement methods. SPICE/ISO/IEC 15504 should have been in the S4 string rather than in S8 as it is, first and foremost, a process model (having both a process reference and a process assessment model in it) rather than a method. SPICE has a 7-step improvement cycle in ISO/IEC 15504 Part 7. CMMI improvement method is called IDEAL while SCAMPI is the assessment method for CMMI. Cite this review as
Anonymous Reviewer ( 2016 ) Peer Review #2 of "Software process improvement: a systematic mapping study on the state of the art (v0.1)" . PeerJ Computer Science https://doi.org/10.7287/peerj-cs.62v0.1/reviews/2 Download Original Submission (PDF)
- submitted Feb 25, 2016 All text and materials provided via this peer-review history page are made available under a Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.
About us - PeerJ team | Our publications | Benefits | Partnerships | Endorsements Awards Resources - FAQ | Careers | Pressroom | Terms of use | Privacy | Contact Academic boards - Advisors | Editors | Subject areas Follow us - PeerJ blog | Twitter | Facebook | LinkedIn | Pinterest Submission guides - PeerJ – Life and Environment | PeerJ Computer Science | PeerJ Chemistry Spread the word - Activities | Resources PeerJ feeds - Atom | RSS 1.0 | RSS 2.0 | JSON PeerJ Computer Science feeds - Atom | RSS 1.0 | RSS 2.0 | JSON Archives - PeerJ – Life and Environment | PeerJ Computer Science
©2012-2019 PeerJ, Inc | Public user content licensed CC BY 4.0 unless otherwise specified. PeerJ ISSN: 2167-8359 PeerJ Comput. Sci. ISSN: 2376-5992 PeerJ Preprints ISSN: 2167-9843
computer science
