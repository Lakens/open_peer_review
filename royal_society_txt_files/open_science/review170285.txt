Perception of global image contrast involves transparent
spatial filtering and the integration and suppression of local
contrasts (not RMS contrast)
Tim S. Meese, Daniel H. Baker and Robert J. Summers
Article citation details
R. Soc. open sci. 4: 170285.
http://dx.doi.org/10.1098/rsos.170285
Review timeline
Original submission: 20 May 2016 Note: Reports are unedited and appear as
1st revised submission: 28 March 2017 submitted by the referee. The review history
2nd revised submission: 25 July 2017 appears in chronological order.
Final acceptance: 26 July 2017
Note: This manuscript was transferred from another Royal Society journal without peer review.
Review History
label_version_1
RSOS-160354.R0 (Original submission)
label_author_1
Review form: Reviewer 1
Is the manuscript scientifically sound in its present form?
Yes
Are the interpretations and conclusions justified by the results?
No
Is the language acceptable?
Yes
Is it clear how to access all supporting data?
I didn't look
Do you have any ethical concerns with this paper?
No
© 2017 The Authors. Published by the Royal Society under the terms of the Creative Commons
Attribution License http://creativecommons.org/licenses/by/4.0/, which permits unrestricted use,
provided the original author and source are credited
2
Have you any concerns about statistical analyses in this paper?
No
Recommendation?
label_recommendation_1
Reject
Comments to the Author(s)
label_comment_1
Dear Editor
There can be no debate regarding the credentials of these authors. They are world-leading
authorities on contrast (a.k.a. luminance contrast, as opposed to chromatic and higher-order
types of contrast). Perhaps this expertise helps to explain their failure to describe important
subtleties the casual reader needs to understand. To wit: there are at least three wholly
unambiguous ways of quantifying luminance contrast: The Weber ratio (local luminance divided
by background luminance), the Michelson ratio, and the root-mean-square (RMS) of a (digital)
image's greylevels. Whereas the first of these measures describes the contrast of a specific point in
an image, the latter two describe entire images. As described in the manuscript, the Michelson
ratio is appropriate only when roughly equal areas in an image have maximum and minimum
luminance.
All three quantities are similarly affected when a television's "contrast" is adjusted. Thus, if you
ask an observer about the apparent contrast of a television image, there really is no inherent
ambiguity. However, the authors of this study are manipulating something that is very different
from a television, and its effect on the Michelson ratio is very different from its effect on RMS
contrast. Indeed, this was the point of the authors' experiment. Their methods allowed for pairs
of images, in which one image had a greater Michelson ratio, and the other had a greater RMS
contrast. It isn't clear to me what I would do in this situation. It is possible that I might not notice,
but what if I did?
I probably would have asked the experimenters, "Do you want me to make decisions based on
(my estimates of) RMS contrast, or do you want me to make decisions based on (my estimates of)
Michelson contrast?" What did the observers actually do? Oh. The only observers were the
authors themselves. Given their aforementioned expertise, I would be surprised if they couldn't
adopt both of those strategies. Unfortunately no such attempt is reported. Instead, they report
that "Only one model provided a good account of the results, namely the M(eese)&S(ummers)
contrast gain control model." The authors must acknowledge the possibility of an expectation
effect here! All these data really show is that the authors are capable of making responses similar
to those predicted by their model. In no way do these data preclude other response strategies.
This is my primary concern.
Finally, I feel obligated to convey some dissatisfaction regarding the way this study was
motivated. In the very first paragraph, the authors contend that we are able to make a judgment
about global image contrast (whatever that means), and cite Figure 1 as evidence. This evidence is
very unconvincing. Since the contrast in every local region of panel (a) exceeds the contrast in the
corresponding region of panel (b), no "global" processing is necessary. NB: The fact that panels (a)
and (b) show the same image is immaterial. Had they shown different images, then it still could
be the case that any single, randomly selected region of panel (a) would have greater contrast
than most regions in panel (b).
Surely, the real question is whether (and if so, how) global statistics, like the average apparent
contrast or the variance of greylevels, can be computed within the visual system.
3
label_author_2
Review form: Reviewer 2
Is the manuscript scientifically sound in its present form?
No
Are the interpretations and conclusions justified by the results?
No
Is the language acceptable?
Yes
Is it clear how to access all supporting data?
No
Do you have any ethical concerns with this paper?
No
Have you any concerns about statistical analyses in this paper?
Yes
Recommendation?
label_recommendation_2
Major revision is needed (please make suggestions in comments)
Comments to the Author(s)
label_comment_2
Meese et al examine the perception of global contrast in images that have uneven distributions of
local contrast. Observers matched the contrast of Battenberg stimuli, which contained controlled
regions of high contrast and low contrast texture. They found that most of the time, global
contrast was predicted by Michelson contrast or the maximum contrast texture. However, low
contrast textures sometimes reduced the global contrast of the image. This result is not consistent
with most image contrast metrics, but is predicted by a nonlinear gain control model that
incorporates spatial summation and suppression.
Most models of contrast perception have dealt with contrast detection threshold, however most
of the images we experience are at much higher contrasts. There is therefore a general need and
interest in visual neuroscience and image quality engineering for data and models that fill this
gap. This paper therefore has the potential to address this need, but there are several major
limitations that need to be addressed.
Most importantly, there were only three observers and all of them were authors. Not only were
these authors aware of the research hypotheses, but they also have a very specific understanding
of image contrast. This is especially concerning given that the methods are subjective matches
(not 2IFC, as the authors state on P6 L54). For the results to have a general impact, the authors
need to collect data on a group of naïve observers.
There are a number of key omission from the literature cited. Several previous authors have
examined contrast in complex images. Most notably Peli (1990) and Bex et al (2009) both argued
that a single metric for an image with variable contrast may fail to capture contrast perception.
Both groups introduced alternative spatial contrast metrics that should be discussed: Peli (1990)
introduced band-limited contrast and Bex et al (2009) introduced local RMS contrast.
The authors reject various models without ever applying model selection criteria, such as Bayes
Factor or Akaike information criteria. Eyeballing the data in figure 3, Michelson contrast (or
equivalently Max contrast) does extremely well with no free parameters. The authors’ favored
model is no more successful in the Dual Component conditions at low contrasts, where j>=4. It is
4
important to apply these measures of model quality before rejecting or accepting any particular
model.
References
Bex, P. J., S. G. Solomon, and S. C. Dakin. “Contrast Sensitivity in Natural Scenes Depends on
Edge as Well as Spatial Frequency Structure.” Journal of Vision 9, no. 10 (2009): 1 1-19.
Peli, E. “Contrast in Complex Images.” J Opt Soc Am A 7, no. 10 (1990): 2032–40.
label_author_3
Review form: Reviewer 3 (Keith May)
Is the manuscript scientifically sound in its present form?
Yes
Are the interpretations and conclusions justified by the results?
No
Is the language acceptable?
Yes
Is it clear how to access all supporting data?
Yes, the supporting data are available by following a link in the manuscript.
Do you have any ethical concerns with this paper?
No
Have you any concerns about statistical analyses in this paper?
No
Recommendation?
label_recommendation_3
Accept with minor revision (please list in comments)
Comments to the Author(s)
label_comment_3
This is a very nice paper indeed. The writing style is concise and clear. The introduction sets the
scene and explains the rationale and wider relevance of the work in a way that would make the
paper readable to nonspecialists. The discussion covers most of the important issues with brevity
and clarity.
Although the motivation for this study is to understand human vision, this paper will be of great
interest to the image processing community because it provides a new metric for global image
contrast that is easily calculated directly from the image, and accurately predicts perceived global
contrast.
I have provided some comments and suggestions below. Most of my comments are superficial
and can be dealt with easily, but major comment 2, about matched filtering, is more fundamental.
I am happy to be identified to the authors.
Best wishes,
Keith May
University College London
5
MAJOR COMMENTS
1. I'm not 100% certain how the filter version of the model works. Is it like this: Filter the image
with odd and even filters, and then apply the pixel-by-pixel version of the model to the entire set
of pixels from the two filtered images? It would be helpful to have some clarification about this in
the paper.
2. I didn't fully understand the section that is potentially the most interesting (headed "Matched
spatial filtering?"). In this section, the authors tackle the fact that the model is most successful
when applied directly to the unfiltered image. The authors argue that, above threshold, the visual
system constructs a matched filter, so that the filtering characteristics become transparent and the
filter has no apparent effect. Firstly, what is the proposed filter matched to? Secondly, why would
this make the filter have no effect? The identity kernel for convolution is the delta function, not
the matched filter. So, if you want a filter model that behaves identically to a model without a
filter, the appropriate filter kernel is the delta function. I'm genuinely struggling to understand
why the authors have proposed a matched filter, so I think it's essential that they provide some
further justification for their conclusions about matched filtering, especially as this features
prominently in the title and abstract.
Presumably, the filter version of the model would fit the data if the filter kernel were smaller than
an individual element, so that summation across stimulus elements was negligible? Are the
authors proposing that the matched filter kernel has the profile an individual element of the
Battenberg stimulus? If so, how can they be sure that this is sufficiently small to avoid behaviour
similar to the linear sum model due to summation across elements?
3. In the Legge-Foley and M&S models, the saturation constant, z is arbitrarily set to 1. What is
the justification for this? The authors say that this is not critical for their conclusions, but have
they tried varying the value of z? What difference does it make?
4. The finding that the model requires a front-end filter to explain the detection thresholds, but
requires no such filter when dealing with suprathreshold contrast matching reminds me of
Georgeson & Sullivan's (1975) finding that one needs to apply filtering with the MTF to explain
contrast thresholds but not suprathreshold contrast matching (contrast constancy). I wonder if
this would be worth discussing in the current manuscript?
MINOR SUGGESTIONS
1. The final sentence of the abstract sensibly flags up the fact that this study proposes a new
metric for global image contrast, but I don't think the authors are as explicit as they should be:
"The global contrast statistic from our model is as easily derived as the RMS contrast of an image;
and since it more closely relates to human perception, we suggest it be used instead." This last
sentence could be interpreted as the authors merely suggesting that their model should be used
instead of RMS contrast as a model of human vision; they have not explicitly stated that it should
be used as an image contrast metric in practical image processing applications. It might be
beneficial to be more explicit about this. Even in the Discussion, this important point in buried in
a section headed "Key model rejections"
2. I very much like Figure 1, but perhaps the gaps between the panels could be enlarged slightly,
for clarity?
3. p. 7 "Note that in the example stimuli in Figure 2, the phase of the global checks is fixed,
whereas in the experiments this was randomised across trials and intervals, such that over the
duration of the experiment, A and B components were presented evenly across the display."
6
This is not completely clear. Do you mean that the phase of each square-wave contrast envelope
was set to n/(2*j) periods, where n is a random integer from 0 to (2*j - 1), and j is the cluster size?
4. p. 8. "The experiment was blocked by target contrast,"
This is the only time that the word "target" is used to describe the stimuli in this study, so it's not
immediately clear what the word "target" refers to - maybe, for consistency, the authors should
say "The experiment was blocked by the contrast of the 'A' pattern of the test stimulus" (if that is
what they mean)?
5. p. 8 "We fitted a cumulative log-Gaussian to the psychometric data from each repetition"
Did this include lapse rate parameters; if so, how was the PSE defined?
6. p.13, line 19: "because it's footprint"
Remove the apostrophe!
label_end_comment
Decision letter (RSOS-160354)
2nd July 2016
Dear Dr Meese:
Manuscript ID RSOS-160354 entitled "Perception of global image contrast is predicted by
matched filtering and the integration and suppression of local contrasts (not RMS contrast)"
which you submitted to Royal Society Open Science, has been reviewed. The comments from
reviewers are included at the bottom of this letter.
In view of the criticisms of the reviewers, the manuscript has been rejected in its current form.
However, a new manuscript may be submitted which takes into consideration these comments.
In particular, I would like to highlight that we can only accept a new submission of this work if
new data are collected.
Please note that resubmitting your manuscript does not guarantee eventual acceptance, and that
your resubmission will be subject to peer review before a decision is made.
You will be unable to make your revisions on the originally submitted version of your
manuscript. Instead, revise your manuscript and upload the files via your author centre.
Once you have revised your manuscript, go to https://mc.manuscriptcentral.com/rsos and login
to your Author Center. Click on "Manuscripts with Decisions," and then click on "Create a
Resubmission" located next to the manuscript number. Then, follow the steps for resubmitting
your manuscript.
Your resubmitted manuscript should be submitted by 2nd October 2016. If you are unable to
submit by this date please contact the Editorial Office and we can discuss what would be a
realistic time scale for you.
We look forward to receiving your resubmission.
Sincerely,
Andrew Dunn
Senior Publishing Editor
Royal Society Open Science
7
on behalf of
Essi Viding, Royal Society Open Science
openscience@royalsociety.org
Associate Editor Comments to Author):
Associate Editor: 1
Comments to the Author:
label_comment_4
Having received the comments from 3 expert reviewers, the manuscript is rejected in its current
form. Two of the reviewers raised the same serious problem which is that only the authors were
observers (and knew the hypothesis). A new manuscript can be submitted but the authors would
need to collect a new data set on naive observers and address the other issues raised by the
reviewers.
Reviewers' Comments to Author:
Reviewer: 1
Comments to the Author(s)
label_comment_5
Dear Editor
There can be no debate regarding the credentials of these authors. They are world-leading
authorities on contrast (a.k.a. luminance contrast, as opposed to chromatic and higher-order
types of contrast). Perhaps this expertise helps to explain their failure to describe important
subtleties the casual reader needs to understand. To wit: there are at least three wholly
unambiguous ways of quantifying luminance contrast: The Weber ratio (local luminance divided
by background luminance), the Michelson ratio, and the root-mean-square (RMS) of a (digital)
image's greylevels. Whereas the first of these measures describes the contrast of a specific point in
an image, the latter two describe entire images. As described in the manuscript, the Michelson
ratio is appropriate only when roughly equal areas in an image have maximum and minimum
luminance.
All three quantities are similarly affected when a television's "contrast" is adjusted. Thus, if you
ask an observer about the apparent contrast of a television image, there really is no inherent
ambiguity. However, the authors of this study are manipulating something that is very different
from a television, and its effect on the Michelson ratio is very different from its effect on RMS
contrast. Indeed, this was the point of the authors' experiment. Their methods allowed for pairs
of images, in which one image had a greater Michelson ratio, and the other had a greater RMS
contrast. It isn't clear to me what I would do in this situation. It is possible that I might not notice,
but what if I did?
I probably would have asked the experimenters, "Do you want me to make decisions based on
(my estimates of) RMS contrast, or do you want me to make decisions based on (my estimates of)
Michelson contrast?" What did the observers actually do? Oh. The only observers were the
authors themselves. Given their aforementioned expertise, I would be surprised if they couldn't
adopt both of those strategies. Unfortunately no such attempt is reported. Instead, they report
that "Only one model provided a good account of the results, namely the M(eese)&S(ummers)
contrast gain control model." The authors must acknowledge the possibility of an expectation
effect here! All these data really show is that the authors are capable of making responses similar
to those predicted by their model. In no way do these data preclude other response strategies.
This is my primary concern.
Finally, I feel obligated to convey some dissatisfaction regarding the way this study was
motivated. In the very first paragraph, the authors contend that we are able to make a judgment
about global image contrast (whatever that means), and cite Figure 1 as evidence. This evidence is
very unconvincing. Since the contrast in every local region of panel (a) exceeds the contrast in the
8
corresponding region of panel (b), no "global" processing is necessary. NB: The fact that panels (a)
and (b) show the same image is immaterial. Had they shown different images, then it still could
be the case that any single, randomly selected region of panel (a) would have greater contrast
than most regions in panel (b).
Surely, the real question is whether (and if so, how) global statistics, like the average apparent
contrast or the variance of greylevels, can be computed within the visual system.
Reviewer: 2
Comments to the Author(s)
label_comment_6
Meese et al examine the perception of global contrast in images that have uneven distributions of
local contrast. Observers matched the contrast of Battenberg stimuli, which contained controlled
regions of high contrast and low contrast texture. They found that most of the time, global
contrast was predicted by Michelson contrast or the maximum contrast texture. However, low
contrast textures sometimes reduced the global contrast of the image. This result is not consistent
with most image contrast metrics, but is predicted by a nonlinear gain control model that
incorporates spatial summation and suppression.
Most models of contrast perception have dealt with contrast detection threshold, however most
of the images we experience are at much higher contrasts. There is therefore a general need and
interest in visual neuroscience and image quality engineering for data and models that fill this
gap. This paper therefore has the potential to address this need, but there are several major
limitations that need to be addressed.
Most importantly, there were only three observers and all of them were authors. Not only were
these authors aware of the research hypotheses, but they also have a very specific understanding
of image contrast. This is especially concerning given that the methods are subjective matches
(not 2IFC, as the authors state on P6 L54). For the results to have a general impact, the authors
need to collect data on a group of naïve observers.
There are a number of key omission from the literature cited. Several previous authors have
examined contrast in complex images. Most notably Peli (1990) and Bex et al (2009) both argued
that a single metric for an image with variable contrast may fail to capture contrast perception.
Both groups introduced alternative spatial contrast metrics that should be discussed: Peli (1990)
introduced band-limited contrast and Bex et al (2009) introduced local RMS contrast.
The authors reject various models without ever applying model selection criteria, such as Bayes
Factor or Akaike information criteria. Eyeballing the data in figure 3, Michelson contrast (or
equivalently Max contrast) does extremely well with no free parameters. The authors’ favored
model is no more successful in the Dual Component conditions at low contrasts, where j>=4. It is
important to apply these measures of model quality before rejecting or accepting any particular
model.
References
Bex, P. J., S. G. Solomon, and S. C. Dakin. “Contrast Sensitivity in Natural Scenes Depends on
Edge as Well as Spatial Frequency Structure.” Journal of Vision 9, no. 10 (2009): 1 1-19.
Peli, E. “Contrast in Complex Images.” J Opt Soc Am A 7, no. 10 (1990): 2032–40.
Reviewer: 3
Comments to the Author(s)
label_comment_7
This is a very nice paper indeed. The writing style is concise and clear. The introduction sets the
scene and explains the rationale and wider relevance of the work in a way that would make the
9
paper readable to nonspecialists. The discussion covers most of the important issues with brevity
and clarity.
Although the motivation for this study is to understand human vision, this paper will be of great
interest to the image processing community because it provides a new metric for global image
contrast that is easily calculated directly from the image, and accurately predicts perceived global
contrast.
I have provided some comments and suggestions below. Most of my comments are superficial
and can be dealt with easily, but major comment 2, about matched filtering, is more fundamental.
I am happy to be identified to the authors.
Best wishes,
Keith May
University College London
MAJOR COMMENTS
1. I'm not 100% certain how the filter version of the model works. Is it like this: Filter the image
with odd and even filters, and then apply the pixel-by-pixel version of the model to the entire set
of pixels from the two filtered images? It would be helpful to have some clarification about this in
the paper.
2. I didn't fully understand the section that is potentially the most interesting (headed "Matched
spatial filtering?"). In this section, the authors tackle the fact that the model is most successful
when applied directly to the unfiltered image. The authors argue that, above threshold, the visual
system constructs a matched filter, so that the filtering characteristics become transparent and the
filter has no apparent effect. Firstly, what is the proposed filter matched to? Secondly, why would
this make the filter have no effect? The identity kernel for convolution is the delta function, not
the matched filter. So, if you want a filter model that behaves identically to a model without a
filter, the appropriate filter kernel is the delta function. I'm genuinely struggling to understand
why the authors have proposed a matched filter, so I think it's essential that they provide some
further justification for their conclusions about matched filtering, especially as this features
prominently in the title and abstract.
Presumably, the filter version of the model would fit the data if the filter kernel were smaller than
an individual element, so that summation across stimulus elements was negligible? Are the
authors proposing that the matched filter kernel has the profile an individual element of the
Battenberg stimulus? If so, how can they be sure that this is sufficiently small to avoid behaviour
similar to the linear sum model due to summation across elements?
3. In the Legge-Foley and M&S models, the saturation constant, z is arbitrarily set to 1. What is
the justification for this? The authors say that this is not critical for their conclusions, but have
they tried varying the value of z? What difference does it make?
4. The finding that the model requires a front-end filter to explain the detection thresholds, but
requires no such filter when dealing with suprathreshold contrast matching reminds me of
Georgeson & Sullivan's (1975) finding that one needs to apply filtering with the MTF to explain
contrast thresholds but not suprathreshold contrast matching (contrast constancy). I wonder if
this would be worth discussing in the current manuscript?
10
MINOR SUGGESTIONS
1. The final sentence of the abstract sensibly flags up the fact that this study proposes a new
metric for global image contrast, but I don't think the authors are as explicit as they should be:
"The global contrast statistic from our model is as easily derived as the RMS contrast of an image;
and since it more closely relates to human perception, we suggest it be used instead." This last
sentence could be interpreted as the authors merely suggesting that their model should be used
instead of RMS contrast as a model of human vision; they have not explicitly stated that it should
be used as an image contrast metric in practical image processing applications. It might be
beneficial to be more explicit about this. Even in the Discussion, this important point in buried in
a section headed "Key model rejections"
2. I very much like Figure 1, but perhaps the gaps between the panels could be enlarged slightly,
for clarity?
3. p. 7 "Note that in the example stimuli in Figure 2, the phase of the global checks is fixed,
whereas in the experiments this was randomised across trials and intervals, such that over the
duration of the experiment, A and B components were presented evenly across the display."
This is not completely clear. Do you mean that the phase of each square-wave contrast envelope
was set to n/(2*j) periods, where n is a random integer from 0 to (2*j - 1), and j is the cluster size?
4. p. 8. "The experiment was blocked by target contrast,"
This is the only time that the word "target" is used to describe the stimuli in this study, so it's not
immediately clear what the word "target" refers to - maybe, for consistency, the authors should
say "The experiment was blocked by the contrast of the 'A' pattern of the test stimulus" (if that is
what they mean)?
5. p. 8 "We fitted a cumulative log-Gaussian to the psychometric data from each repetition"
Did this include lapse rate parameters; if so, how was the PSE defined?
6. p.13, line 19: "because it's footprint"
Remove the apostrophe!
Author's Response to Decision Letter for (RSOS-160354)
See Appendix A.
label_version_2
RSOS-170285.R0 (Revision)
label_author_4
Review form: Reviewer 1
Is the manuscript scientifically sound in its present form?
Yes
Are the interpretations and conclusions justified by the results?
Yes
Is the language acceptable?
Yes
11
Is it clear how to access all supporting data?
No
Do you have any ethical concerns with this paper?
No
Have you any concerns about statistical analyses in this paper?
No
Recommendation?
label_recommendation_4
Accept with minor revision (please list in comments)
Comments to the Author(s)
label_comment_8
See attached (Appendix B).
label_author_5
Review form: Reviewer 2
Is the manuscript scientifically sound in its present form?
Yes
Are the interpretations and conclusions justified by the results?
Yes
Is the language acceptable?
Yes
Is it clear how to access all supporting data?
Not Applicable
Do you have any ethical concerns with this paper?
No
Have you any concerns about statistical analyses in this paper?
No
Recommendation?
label_recommendation_5
Accept as is
Comments to the Author(s)
label_comment_9
The authors have addressed my concerns
label_end_comment
Decision letter (RSOS-170285)
12th April 2017
Dear Dr Meese
On behalf of the Editor, I am pleased to inform you that your Manuscript RSOS-170285 entitled
"Perception of Global Image Contrast Involves Transparent Spatial Filtering and the Integration
and Suppression of Local Contrasts (not RMS contrast)" has been accepted for publication in
12
Royal Society Open Science subject to minor revision in accordance with the referee suggestions.
Please find the referees' comments at the end of this email.
The reviewers and Subject Editor have recommended publication, but also suggest some minor
revisions to your manuscript. Therefore, I invite you to respond to the comments and revise your
manuscript.
• Ethics statement
If your study uses humans or animals please include details of the ethical approval received,
including the name of the committee that granted approval. For human studies please also detail
whether informed consent was obtained. For field studies on animals please include details of all
permissions, licences and/or approvals granted to carry out the fieldwork.
• Data accessibility
It is a condition of publication that all supporting data are made available either as
supplementary information or preferably in a suitable permanent repository. The data
accessibility section should state where the article's supporting data can be accessed. This section
should also include details, where possible of where to access other relevant research materials
such as statistical tools, protocols, software etc can be accessed. If the data has been deposited in
an external repository this section should list the database, accession number and link to the DOI
for all data from the article that has been made publicly available. Data sets that have been
deposited in an external repository and have a DOI should also be appropriately cited in the
manuscript and included in the reference list.
If you wish to submit your supporting data or code to Dryad (http://datadryad.org/), or modify
your current submission to dryad, please use the following link:
http://datadryad.org/submit?journalID=RSOS&manu=RSOS-170285
• Competing interests
Please declare any financial or non-financial competing interests, or state that you have no
competing interests.
• Authors’ contributions
All submissions, other than those with a single author, must include an Authors’ Contributions
section which individually lists the specific contribution of each author. The list of Authors
should meet all of the following criteria; 1) substantial contributions to conception and design, or
acquisition of data, or analysis and interpretation of data; 2) drafting the article or revising it
critically for important intellectual content; and 3) final approval of the version to be published.
All contributors who do not meet all of these criteria should be included in the
acknowledgements.
We suggest the following format:
AB carried out the molecular lab work, participated in data analysis, carried out sequence
alignments, participated in the design of the study and drafted the manuscript; CD carried out
the statistical analyses; EF collected field data; GH conceived of the study, designed the study,
coordinated the study and helped draft the manuscript. All authors gave final approval for
publication.
• Acknowledgements
Please acknowledge anyone who contributed to the study but did not meet the authorship
criteria.
• Funding statement
Please list the source of funding for each author.
13
Please note that we cannot publish your manuscript without these end statements included. We
have included a screenshot example of the end statements for reference. If you feel that a given
heading is not relevant to your paper, please nevertheless include the heading and explicitly state
that it is not relevant to your work.
Because the schedule for publication is very tight, it is a condition of publication that you submit
the revised version of your manuscript within 7 days (i.e. by the 20th April 2017). If you do not
think you will be able to meet this date please let me know immediately.
To revise your manuscript, log into https://mc.manuscriptcentral.com/rsos and enter your
Author Centre, where you will find your manuscript title listed under "Manuscripts with
Decisions". Under "Actions," click on "Create a Revision." You will be unable to make your
revisions on the originally submitted version of the manuscript. Instead, revise your manuscript
and upload a new version through your Author Centre.
When submitting your revised manuscript, you will be able to respond to the comments made by
the referees and upload a file "Response to Referees" in "Section 6 - File Upload". You can use this
to document any changes you make to the original manuscript. In order to expedite the
processing of the revised manuscript, please be as specific as possible in your response to the
referees.
When uploading your revised files please make sure that you have:
1) A text file of the manuscript (tex, txt, rtf, docx or doc), references, tables (including captions)
and figure captions. Do not upload a PDF as your "Main Document".
2) A separate electronic file of each figure (EPS or print-quality PDF preferred (either format
should be produced directly from original creation package), or original software format)
3) Included a 100 word media summary of your paper when requested at submission. Please
ensure you have entered correct contact details (email, institution and telephone) in your user
account
4) Included the raw data to support the claims made in your paper. You can either include your
data as electronic supplementary material or upload to a repository and include the relevant doi
within your manuscript
5) All supplementary materials accompanying an accepted article will be treated as in their final
form. Note that the Royal Society will neither edit nor typeset supplementary material and it will
be hosted as provided. Please ensure that the supplementary material includes the paper details
where possible (authors, article title, journal name).
Supplementary files will be published alongside the paper on the journal website and posted on
the online figshare repository (https://figshare.com). The heading and legend provided for each
supplementary file during the submission process will be used to create the figshare page, so
please ensure these are accurate and informative so that your files can be found in searches. Files
on figshare will be made available approximately one week before the accompanying article so
that the supplementary material can be attributed a unique DOI.
Once again, thank you for submitting your manuscript to Royal Society Open Science and I look
forward to receiving your revision. If you have any questions at all, please do not hesitate to get
in touch.
Kind regards,
Alice Power
Editorial Coordinator
Royal Society Open Science
on behalf of Essi Viding
Subject Editor, Royal Society Open Science
openscience@royalsociety.org
14
Associate Editor Comments to Author:
Comments to the Author:
label_comment_10
Both reviewers find the paper significantly improved. Please address the two remaining queries
regarding the discussion of global contrast and the interpretation of the new data.
Comments to Author:
Reviewer: 1
Comments to the Author(s)
label_comment_11
See attached
Reviewer: 2
Comments to the Author(s)
label_comment_12
The authors have addressed my concerns
Author's Response to Decision Letter for (RSOS-170285)
See Appendix C.
label_end_comment
Decision letter (RSOS-170285.R1)
26-Jul-2017
Dear Dr Meese,
I am pleased to inform you that your manuscript entitled "Perception of Global Image Contrast
Involves Transparent Spatial Filtering and the Integration and Suppression of Local Contrasts
(not RMS contrast)" is now accepted for publication in Royal Society Open Science.
You can expect to receive a proof of your article in the near future. Please contact the editorial
office (openscience_proofs@royalsociety.org and openscience@royalsociety.org) to let us know if
you are likely to be away from e-mail contact. Due to rapid publication and an extremely tight
schedule, if comments are not received, your paper may experience a delay in publication.
Royal Society Open Science operates under a continuous publication model
(http://bit.ly/cpFAQ). Your article will be published straight into the next open issue and this
will be the final version of the paper. As such, it can be cited immediately by other researchers.
As the issue version of your paper will be the only version to be published I would advise you to
check your proofs thoroughly as changes cannot be made once the paper is published.
In order to raise the profile of your paper once it is published, we can send through a PDF of your
paper to selected colleagues. If you wish to take advantage of this, please reply to this email with
the name and email addresses of up to 10 people who you feel would wish to read your article.
15
On behalf of the Editors of Royal Society Open Science, we look forward to your continued
contributions to the Journal.
Best wishes,
Andrew Dunn
Senior Publishing Editor
Royal Society Open Science
openscience@royalsociety.org
Appendix A
Dear Andrew
Please find our resubmission of our paper on contrast perception to Open Science. Thank
you for the editor’s and reviewer’s comments which we have read carefully. We have
revised our paper accordingly, including further data collection (as confirmed would be
necessary by the editor), and provide a point-by-point response to the reviewers below. We
thank the reviewers for their support in what we have set out to achieve and trust that our
revisions now meet with their and your satisfaction.
Reviewer 1.
There can be no debate regarding the credentials of these authors. They are world-leading authorities
on contrast (a.k.a. luminance contrast, as opposed to chromatic and higher-order types of contrast).
Perhaps this expertise helps to explain their failure to describe important subtleties the casual
reader needs to understand. To wit: there are at least three wholly unambiguous ways of quantifying
luminance contrast: The Weber ratio (local luminance divided by background luminance), the Michelson
ratio, and the root-mean-square (RMS) of a (digital) image's greylevels. Whereas the first of these
measures describes the contrast of a specific point in an image, the latter two describe entire
images. As described in the manuscript, the Michelson ratio is appropriate only when roughly equal
areas in an image have maximum and minimum luminance.
The introduction now provides a clear coverage of the various contrast metrics. We have
avoided the added complication of discussing Weber contrast here in detail since (1) this is
an inherently local measure and the work here is concerned with global perception of
contrast, (2) for the Battenberg stimuli used in our experiments the weber contrast of each
element is directly proportional to the Michelson contrast of each element and (3) in
general, this metric raises the complicating factor of choosing the size of the background
region for which mean luminance is to be calculated against which the peak luminance can
be judged. This might be handled using the spatial frequency sub-band pyramidal technique
of Peli (1990). But since we did not manipulate the spatial frequency of our stimuli, this
interesting possibility is not directly relevant here; we do, however, now pick up on this
point in the discussion. Nonetheless, the Weber fraction metric is now mentioned in the
middle of the second paragraph.
All three quantities are similarly affected when a television's "contrast" is adjusted. Thus, if you
ask an observer about the apparent contrast of a television image, there really is no inherent
ambiguity. However, the authors of this study are manipulating something that is very different from a
television, and its effect on the Michelson ratio is very different from its effect on RMS contrast.
Indeed, this was the point of the authors' experiment. Their methods allowed for pairs of images, in
which one image had a greater Michelson ratio, and the other had a greater RMS contrast. It isn't
clear to me what I would do in this situation. It is possible that I might not notice, but what if I
did?
Indeed, the TV images in Fig 1 are there to set up the general issue. But it is only by
manipulating stimuli like our Battenbergs in controlled ways (that are more complex than
just adjusting the contrast knob) that we are able to determine which metric is actually used
by human vision (and the answer is none of the standard metrics!).
I probably would have asked the experimenters, "Do you want me to make decisions based on (my
estimates of) RMS contrast, or do you want me to make decisions based on (my estimates of) Michelson
contrast?" What did the observers actually do? Oh. The only observers were the authors themselves.
Given their aforementioned expertise, I would be surprised if they couldn't adopt both of those
strategies. Unfortunately no such attempt is reported. Instead, they report that "Only one model
provided a good account of the results, namely the M(eese)&S(ummers) contrast gain control model." The
authors must acknowledge the possibility of an expectation effect here! All these data really show is
that the authors are capable of making responses similar to those predicted by their model. In no way
do these data preclude other response strategies. This is my primary concern.
The reviewer raises the interesting possibility that our observers might have used top down
knowledge to, in some sense, swing the results in a particular direction. We now present
evidence against this idea. First, we gathered data from three naïve observers on a subset of
experimental conditions. Their results had the same characteristics as those from the
practiced observers, yet the naïve observers had no knowledge of the details of the metrics
we were investigating, least of all how they might respond to swing the result in favour of a
particular metric about which they knew nothing. Furthermore, one of us (DHB) tried
running the experiment in a way that ignored his visual perception and was instead
contrived to conform with his best guess of what RMS contrast might be. The results were
noisy and conformed to none of the metrics under study (though were closest to the linear
sum model). Details of this are now provided in supplementary material and cross
referenced from the main paper (Results). We also acknowledge that although our interest
was in global contrast perception, we expect that observers would be able to make local
contrast judgements as well.
Finally, I feel obligated to convey some dissatisfaction regarding the way this study was motivated.
In the very first paragraph, the authors contend that we are able to make a judgment about global
image contrast (whatever that means), and cite Figure 1 as evidence. This evidence is very
unconvincing. Since the contrast in every local region of panel (a) exceeds the contrast in the
corresponding region of panel (b), no "global" processing is necessary. NB: The fact that panels (a)
and (b) show the same image is immaterial. Had they shown different images, then it still could be the
case that any single, randomly selected region of panel (a) would have greater contrast than most
regions in panel (b).
Surely, the real question is whether (and if so, how) global statistics, like the average apparent
contrast or the variance of greylevels, can be computed within the visual system.
The analysis above is not completely correct. With respect to our Fig 1, the local RMS
contrast in region Y is higher than in region X, hence a local analysis cannot be used to infer
the global analysis. We are now clearer about this in both the main text and the figure
caption and we acknowledge the question of whether global image contrast is computed in
the first sentence of the second paragraph.
Reviewer 2
Most importantly, there were only three observers and all of them were authors. Not only were these
authors aware of the research hypotheses, but they also have a very specific understanding of image
contrast. This is especially concerning given that the methods are subjective matches (not 2IFC, as
the authors state on P6 L54). For the results to have a general impact, the authors need to collect
data on a group of naïve observers.
We have done this (as reported above) and the results were the same as for the practised
observers. We have also removed the incorrect use of the 2IFC terminology from our
methods (thanks for spotting that).
There are a number of key omission from the literature cited. Several previous authors have examined
contrast in complex images. Most notably Peli (1990) and Bex et al (2009) both argued that a single
metric for an image with variable contrast may fail to capture contrast perception. Both groups
introduced alternative spatial contrast metrics that should be discussed: Peli (1990) introduced band-
limited contrast and Bex et al (2009) introduced local RMS contrast.
We have now cited this work.
The authors reject various models without ever applying model selection criteria, such as Bayes Factor
or Akaike information criteria.
We now provide a more thorough presentation of the analysis of our results an appendix.
This does not change our conclusions. However, since our models have no free parameters,
analyses that are designed to assess the merit of additional parameters in one model over
another (e.g. Akaike) are not appropriate here.
Eyeballing the data in figure 3, Michelson contrast (or equivalently Max contrast) does extremely well
with no free parameters. The authors’ favored model is no more successful in the Dual Component
conditions at low contrasts, where j>=4. It is important to apply these measures of model quality
before rejecting or accepting any particular model.
As our analysis in the appendix shows, the M&S model wins out over the max model in
nearly every case. There are two data sets (for the practised observers where j = 4 and j
= 8) where this is not so. However, this is presumably due to a nuance of our results
(considered in the Discussion in the section: Implications of dual component matching
for j = 4 and j = 8, which leads to a small vertical offset. When this is taken into account,
the M&S model/metric wins out again. This is because it is the only model that predicts
the paradoxical effect that is evident in every data set (including the naïve observers).
Reviewer 3.
1. I'm not 100% certain how the filter version of the model works. Is it like this: Filter the image
with odd and even filters, and then apply the pixel-by-pixel version of the model to the entire set of
pixels from the two filtered images? It would be helpful to have some clarification about this in the
paper.
More or less—it doesn’t matter whether you go with a quadrature pair, or a single sine
or cosine filter. We have clarified this in the Further model developments subsection.
2. I didn't fully understand the section that is potentially the most interesting (headed "Matched
spatial filtering?"). In this section, the authors tackle the fact that the model is most successful
when applied directly to the unfiltered image. The authors argue that, above threshold, the visual
system constructs a matched filter, so that the filtering characteristics become transparent and the
filter has no apparent effect. Firstly, what is the proposed filter matched to? Secondly, why would
this make the filter have no effect? The identity kernel for convolution is the delta function, not
the matched filter. So, if you want a filter model that behaves identically to a model without a
filter, the appropriate filter kernel is the delta function. I'm genuinely struggling to understand
why the authors have proposed a matched filter, so I think it's essential that they provide some
further justification for their conclusions about matched filtering, especially as this features
prominently in the title and abstract.
Presumably, the filter version of the model would fit the data if the filter kernel were smaller than
an individual element, so that summation across stimulus elements was negligible? Are the authors
proposing that the matched filter kernel has the profile an individual element of the Battenberg
stimulus? If so, how can they be sure that this is sufficiently small to avoid behaviour similar to
the linear sum model due to summation across elements?
Thank you for raising this point, our writing was not as clear as it might have been. We
have revised this in the abstract and the discussion and also the title. What we had in
mind is that at each point in the image, the system synthesises a filter that is essentially
a Dirac/delta pulse (an approximation would do) from its basis filters. These are then
summed over area. Now, our experiments do not examine the finer detail of this, but if
those Dirac pulses were weighted by the local image contrast, then that would be a
template that is matched to the stimulus. (To call this a filter, as we did before, we agree
is incorrect, because that implies the application of the matched filter (matched to the
entire stimulus) across the entire image – i.e convolution – which is not what we had in
mind. Furthermore, it is not even necessary to weight the delta functions across the
image. Thus, we end with a simple strategy in which the system synthesises a filter with
the impulse response of a delta function (by a weighted sum of its basis filters) and then
also sums those delta filter elements over space to derive global contrast. We are now
much clearer about this, and we have acknowledged your well-received nudge on this at
the end of the paper.
3. In the Legge-Foley and M&S models, the saturation constant, z is arbitrarily set to 1. What is the
justification for this? The authors say that this is not critical for their conclusions, but have
they tried varying the value of z? What difference does it make?
This z parameter in the Legge-Foley model is there to transition the model from
threshold to suprathreshold. The parameter choice here was not critical: it just needs to
be low enough to ensure that the model is operating in its suprathreshold regimen, as is
appropriate for the stimuli here. We tried other low values and it made no difference.
Obviously, if it were set very high, then that would change the behaviour of the model,
but that would be inconsistent with its use in contrast discrimination experiments. We
are now more explicit about this in the Modelling section.
4. The finding that the model requires a front-end filter to explain the detection thresholds, but
requires no such filter when dealing with suprathreshold contrast matching reminds me of Georgeson &
Sullivan's (1975) finding that one needs to apply filtering with the MTF to explain contrast
thresholds but not suprathreshold contrast matching (contrast constancy). I wonder if this would be
worth discussing in the current manuscript?
This is an interesting point but in the interests of brevity we were reluctant to go down
this path. For example, we don’t know anything in the contrast constancy work that
requires that the cortical filtering stage be omitted – for example, much of the issue
there has to do with the high frequency attenuating effects of the optical pointspread
function. A deep discussion of these issues would take us away from our main thread.
MINOR SUGGESTIONS
1. The final sentence of the abstract sensibly flags up the fact that this study proposes a new metric
for global image contrast, but I don't think the authors are as explicit as they should be: "The
global contrast statistic from our model is as easily derived as the RMS contrast of an image; and
since it more closely relates to human perception, we suggest it be used instead." This last sentence
could be interpreted as the authors merely suggesting that their model should be used instead of RMS
contrast as a model of human vision; they have not explicitly stated that it should be used as an
image contrast metric in practical image processing applications. It might be beneficial to be more
explicit about this. Even in the Discussion, this important point in buried in a section headed "Key
model rejections"
Thanks for encouraging us to emphasise this. We now do so in the abstract and also in a
new Conclusions section at the end of the paper.
2. I very much like Figure 1, but perhaps the gaps between the panels could be enlarged slightly, for
clarity?
Thanks. Gaps now included.
3. p. 7 "Note that in the example stimuli in Figure 2, the phase of the global checks is fixed,
whereas in the experiments this was randomised across trials and intervals, such that over the
duration of the experiment, A and B components were presented evenly across the display."
This is not completely clear. Do you mean that the phase of each square-wave contrast envelope was
set to n/(2*j) periods, where n is a random integer from 0 to (2*j - 1), and j is the cluster size?
We mean that the A and B component assignments were spatially switched at random
from trial to trial. This is now clearer in Methods. (We have avoided the word ‘phase’.)
4. p. 8. "The experiment was blocked by target contrast,"
This is the only time that the word "target" is used to describe the stimuli in this study, so it's
not immediately clear what the word "target" refers to - maybe, for consistency, the authors should
say "The experiment was blocked by the contrast of the 'A' pattern of the test stimulus" (if that is
what they mean)?
Fixed as suggested.
5. p. 8 "We fitted a cumulative log-Gaussian to the psychometric data from each repetition"
Did this include lapse rate parameters; if so, how was the PSE defined?
We now say that there were no lapse parameters.
6. p.13, line 19: "because it's footprint"
Remove the apostrophe!
Oops – done!
Appendix B
Dear Editor
Meese and colleagues have complied with the referees’ requests for data from naïve
observers. Before I comment on these new data, I would like to revisit one of my
previous comments. I wrote,
In the very first paragraph, the authors contend that we are able to make a judgment
about global image contrast (whatever that means), and cite Figure 1 as evidence.
This evidence is very unconvincing. Since the contrast in every local region of panel
(a) exceeds the contrast in the corresponding region of panel (b), no "global"
processing is necessary.
Meese and colleagues replied,
The analysis above is not completely correct. With respect to our Fig 1, the local
RMS contrast in region Y is higher than in region X, hence a local analysis cannot be
used to infer the global analysis. We are now clearer about this in both the main text
and the figure caption and we acknowledge the question of whether global image
contrast is computed in the first sentence of the second paragraph.
I protest. Regions X and Y are the exception, not the rule. I wrote ‘most’, not ‘all’. I
maintain that my original assessment was indeed completely correct:
[A]ny single, randomly selected region of panel (a) would have greater contrast than
most regions in panel (b). Surely, the real question is whether (and if so, how) global
statistics, like the average apparent contrast or the variance of greylevels, can be
computed within the visual system.
Consequently, the last sentence of Figure 1’s legend is false. Similarly, the authors’
claim (on p. 14) that following task instructions was, ‘the easiest thing to do’ pre-
supposes a mechanism that encodes global image contrast. I maintain that the
existence of any such mechanism remains unproven.
New data from naïve observers are welcome. I notice (in Figure 4a) these observers
consistently reported that the uniform (8%) contrast test appeared to have more
‘global image contrast’ than the ‘single-component match’, when components of the
latter had the same (8%) contrast. None of the models considered by Meese and
colleagues are consistent with this discrepancy.
As noted by the authors, this discrepancy is also apparent in a subset of the original
data. Therefore, I do not understand how it can be ‘suggesting individual differences.’
I would like to suggest that this discrepancy reflects a non-perceptual bias. The
authors too hastily reject such biases on the basis of DHB’s inability to reliably
calculate RMS contrast. That isn’t a good argument. I bet a naïve observer could
produce data just like those in Figure 4 with these instructions: ‘Select the stimulus
(test or match) having the greatest maximum contrast. When in doubt, select the test.’
Morgan et al (Atten Percept Psychophys, 2012, 74:185–193) have shown that
instructions of this nature can shift psychometric functions without decreasing
reliability (i.e slope). Of course, a global mechanism would be required for the most
reliable estimates of maximum contrast, but a few randomly selected local
measurements could still support fairly reliable decisions regarding which of two
images has the greatest maximum.
pendix C
r Essi/Alice
nk you for your response and the reviewer’s comments. We note that further objections arise
y from Reviewer 1, and we address those here.
first issue relates to the correspondence rather than the paper, and regards whether our
tement that the reviewer’s analysis was not completely correct, was correct. We shan’t dwell
this since it is not material to the paper, but our original statement was prompted by the
iewer’s statement that: “The fact that panels (a) and (b) show the same image is immaterial.” Perhaps
as not entirely clear to us how that statement should be interpreted following the previous
arks, but we took it to mean that the word ‘corresponding region’ was not important, in which
e, our objection was correct, because as we pointed out (and as the reviewer concedes, in the
t review too) one can find some regions in the low contrast image that are of higher contrast
n in the lower contrast image. So, as far as we can see, there is no material disagreement here.
pe we can set that aside.
reviewer then says this:
sequently, the last sentence of Figure 1’s legend is false.
last sentence of that legend (in the previous draft) read thus:
e also that the RMS contrast (a widely used metric for image contrast, applicable to both local and global
sures) in region Y (in (b)) is higher than in region X (in (a)), indicating that (this measure, at least) of local contrast
not be used to infer the global image contrast, since the overall contrast of image (a) looks higher than image (b).
re is a problem with that sentence regarding the misplacement of an opening parenthesis
ch mangled the English. We have corrected it thus, and also changed ‘cannot’ to ‘should not’:
e also that the RMS contrast (a widely used metric for image contrast, applicable to both local and global
sures) in region Y (in (b)) is higher than in region X (in (a)), indicating that this measure of local contrast should not
sed to infer the global image contrast, since the overall contrast of image (a) looks higher than image (b).
ther to this, we have also performed some more general analysis of static pink noise which we
w include in Part 1 of the supplementary material. This makes the point of Fig 1 more formally:
eneral, if one is asked about global contrast, then using measures of local contrast as a proxy
be error prone. The reader is referred to this new supplementary material in what is now the
sentence of the figure caption.
ilarly, the authors’
m (on p. 14) that following task instructions was, ‘the easiest thing to do’ presupposes
echanism that encodes global image contrast. I maintain that the
tence of any such mechanism remains unproven.
are a bit puzzled by this. We presupposed nothing—that is why we did the experiment;
wever, we did find that it was fairly straight forward to follow the instruction as we posed it,
just allow our visual perceptions to drive proceedings without engaging thought. What
chanisms were involved in those behavioural responses is always the challenge. Pursuing this,
have rejected some models and found that another model (the M&S) does rather well (that
e model also outperforms other models in various other tasks and with other stimuli). We do
go as far as to say that we have proven that a global contrast mechanism exists. (Though
trast discrimination experiments by Meese & Summers (2007) show that this does exist over at
st several stimulus cycles). However, a mechanism that aggregates contrast over the image
s do a better job on our data than anything else, but, of course, one can never rule out that a
erent, possibly more complex mechanism/strategy that we have not considered might underlie
results (and we come back to that below). Indeed, we use the phrase ‘whatever the process’,
ilar to the reviewer’s phrase ‘whatever that is’, in the paragraph above Fig 3. Anyway, with
ard to the reviewer’s objection of our sentence above, we have deleted that part and made a
all change at the end (and rewritten a potentially misleading bit in the middle) so that the
tion now reads: Notwithstanding the result above, we wondered whether an experienced
erver might be able to systematically ‘throw’ the results, should they choose to; our expectation
s not high, since all of our observers were given a rapid sequence of randomly interleaved trial
rs (with two different matching stimuli, blocked across 8 different “A” component contrasts),
h the task of deciding which image in each pair had the higher overall contrast; we found this
k to be perceptual, not cognitive, whatever the details of the underlying strategy.
have also changed the last sentence of the introduction so that it now reads: we assessed
man perception of global image contrast and considered the method it might use by comparing
results to mathematical predictions from the competing models/metrics. This further lessens
potential for misinterpreting the strength of our claim. Nonetheless, we have not changed the
e: the task given to our participants was a judgement of global contrast. Experiments on global
ge appearance cannot do better than to ask participants to judge the entire image.
data from naïve observers are welcome. I notice (in Figure 4a) these observers
sistently reported that the uniform (8%) contrast test appeared to have more
bal image contrast’ than the ‘single-component match’, when components of the
r had the same (8%) contrast. None of the models considered by Meese and
agues are consistent with this discrepancy.
t is correct. This discrepancy was noted by us (and discussed) in the naïve data, and also in the
ert data (for j = 4 and j = 8). We suggested a fairly simple modification to the model that could
ount for this (one broadly consistent with the literature concerning surround suppression) and
also explained why we thought it unwise to pursue that in detail. We see no reason to change
position on that.
oted by the authors, this discrepancy is also apparent in a subset of the original
. Therefore, I do not understand how it can be ‘suggesting individual differences.’
are puzzled by this. The discrepant effect is there for j = 2 in the naives, but not until j = 4 in
practised observers. That suggests differences between those individuals – though whether
ctice and experience might influence those differences, we do not know. We have changed the
vant part of the text to include the following parenthetical remark to clarify what we meant by
ividual differences: (i.e. different ranges of j over which observers show the discrepant result).
uld like to suggest that this discrepancy reflects a non-perceptual bias. The
ors too hastily reject such biases on the basis of DHB’s inability to reliably
ulate RMS contrast. That isn’t a good argument. I bet a naïve observer could
uce data just like those in Figure 4 with these instructions: ‘Select the stimulus
or match) having the greatest maximum contrast. When in doubt, select the test.’
gan et al (Atten Percept Psychophys, 2012, 74:185–193) have shown that
uctions of this nature can shift psychometric functions without decreasing
bility (i.e slope). Of course, a global mechanism would be required for the most
ble estimates of maximum contrast, but a few randomly selected local
surements could still support fairly reliable decisions regarding which of two
ges has the greatest maximum.
we mentioned above, it is possible that other models/strategies might account for our data.
wever, we see problems with the one proposed by the reviewer. As we have shown, a max
rator fails (that is the black curve). The reviewer offers a modification to this which is to select
‘test’ image if they are uncertain. Why the proposed bias should be towards the test rather
n the match is not clear; keep in mind that the single and dual match conditions were
rleaved, so the proposed bias is not specific to the number of elements in the display, but
at the experimenter calls the ‘test’; a nominal label that was not divulged to the naïve
ticipants since they had no need to know. Anyway, that would shift the black matching
ction upwards, but not at the A = 8% point for the dual match, because there, the test and
tch stimuli are identical, so a bias is not possible. And perhaps that would help for panels f and
Fig 3. But why does that not happen for the single match condition? And how does this
lain the paradoxical dip in the matching functions, so clear in Fig 4? (That cannot be a
babilistic issue, if the reviewer has a stochastic noise process in mind [not a part of our own
x model implementation], since that would favour the test stimulus in the single match
dition, which should then sit up above the knee point). More critically, if the model function
ts upwards, as proposed, why do the data drop down (not up) in the middle of the upper part
he limb, where A = 16%? It might be possible to work this model/strategy up to do this,
haps with a strategy that varies (for some reason) across the conditions, and perhaps the
erver forgets which the test is and so is biased to the match in some parts of the function. We
no reason to pursue that idea ourselves, but offer the following as a more general alternative:
ose the max, but if you are uncertain, then choose the one that has the lower contrast in the
er contrast sub regions. That’s a pretty weird rule (the instruction is ‘higher’, but the operation
a ‘lower’ clause), but let’s work that through. So for single match (red symbols), the stimuli are
ntical at the far left—so should equate on any model—, but as the contrast of the A component
he test increases, the observer gets puzzled (uncertain) and biases towards the other stimulus
cause the contrast in those regions is zero)—that pulls the matching function down, including
=8% (because the match still has zero contrast in those other regions). Now we get to A = 16%,
perhaps still we bias towards the match stimulus (for the same reasons), but when we get to
32%, perhaps the uncertainty diminishes, and we revert to an unbiased max. So that works
h the red function, with a convenient assumption about the kicking in and out of the bias
ger. Now let’s do the dual match (green symbols). At the far left of the function, we have the
ct same situation as the A=8% point in the red function. But since our bias rule does not use
mes like ‘test’ and ‘match’ we get the exact same result, but in this case, the function shifts
wards. By the time we get to A=8%, the stimuli are identical, and so all models must predict a
idical match (as we find). As we move up the function, perhaps uncertainty kicks in again, and
observer loses track of what is what, and tends to the uniform image, for some reason. Then,
the time A=32%, uncertainty is lost, and maxing rules once more. So, the strategy works for the
l function too, with a bit of post hoc rationalisation. Thus, we cannot rule out the possibility
t when we told our observers to match the overall contrast, they took that to mean the max
trast (whether they knew it or not), but also to bias themselves away from the stimulus with
interdigitated contrast that was greater than the interdigitated contrast in the other stimulus,
only when there was a slight difference in the contrasts in those regions within the same
ulus (e.g = a factor of 2). That is possible, but the strategy is so bizarre that we think it is of
e or no value to discuss it in the paper. More generally, we see this strategy more as a
cription of the data, the behavioural implementation of which needs to be understood. The
S model (subject to the refinements concerning mismatched areas of integration and
pression, discussed in the ms) is the simple candidate we offer.
urally though, we welcome others to model our data themselves (the data are publically
ilable, and the doi can be find in the ms), but we do suggest that the entire set should be
sidered.
ally, on the reviewer’s last remark (above), yes, a spatial max operator is, of course, a global
chanism of sorts: it must inspect some proportion of the image to select the max. The question
eally about the nature of the global operation. In general, we have come to find the following
minology convenient: signal selection, vs, signal combination (replacing the misleading
bability summation and physiological summation terms of old). Our analysis favours signal
bination (the M&S model), but as we have said already, we welcome work that can rescue the
al selection idea. We have tried very hard at contrast detection threshold, and failed – e.g.
ese & Summers (2012). We have also failed in that endeavour here (see also the point below
the new Part 3 of the supplementary material).
e last thing on this point: we also considered a model in which we had a max operator (over
A and B contrasts) with mutual inhibition between them (since the combination of some
m of global assessment and mutual suppression seems to be important for the paradox).
t model failed badly, and we excluded it from the present work for simplicity and clarity.
wever, we do now include it in Part 3 of the supplementary material and add a brief
ment about this in the Discussion in the section: The paradoxical effect and contrast-
trast. We have also slightly updated this section to address the subtle differences between
rict interpretation of contrast-contrast and surround suppression. We argue that neither of
se alone can account for our results. We also include a reference to recent EEG work on
tenbergs by Baker and Wade (2017), which further makes the case for suppression
ween the A and B components and hints at the paradoxical effect.
ally, we have also made some minor changes to the ms to fix some typos and improve clarity in
ces.
do hope that you now find our paper ready for publication.
rs sincerely
Meese
Society Open
