Enhancing endorsement of scientific inquiry increases
support for pro-environment policies
Aaron Drummond, Matthew A. Palmer and James D. Sauer
Article citation details
R. Soc. open sci. 3: 160360.
http://dx.doi.org/10.1098/rsos.160360
Review timeline
Original submission: 23 May 2016 Note: Reports are unedited and appear as
Revised submission: 30 August 2016 submitted by the referee. The review history
Final acceptance: 1 September 2016 appears in chronological order.
Review History
label_version_1
RSOS-160360.R0 (Original submission)
label_author_1
Review form: Reviewer 1 (Ed Maibach)
Is the manuscript scientifically sound in its present form?
Yes
Are the interpretations and conclusions justified by the results?
Yes
Is the language acceptable?
Yes
Is it clear how to access all supporting data?
Yes
© 2016 The Authors. Published by the Royal Society under the terms of the Creative Commons
Attribution License http://creativecommons.org/licenses/by/4.0/, which permits unrestricted use,
provided the original author and source are credited
2
Do you have any ethical concerns with this paper?
No
Have you any concerns about statistical analyses in this paper?
I do not feel qualified to assess the statistics
Recommendation?
label_recommendation_1
Accept with minor revision (please list in comments)
Comments to the Author(s)
label_comment_1
This paper – through two studies: one a secondary analysis of survey data with children, and one
an experiment conducted with adults – tests the hypothesis that support for scientific inquiry (but
not necessarily scientific literacy) will be positively associated with support for pro-
environmental policies. Both studies support this hypothesis. The experimental study also
demonstrates that a brief educational statement about the logic of scientific inquiry can increase
support for scientific inquiry.
Overall, I find this paper to be insightful, well reasoned, well written, and important. That said, I
have a few concerns and/or suggestions; I am confident the authors can easily address them.
I find the analytic strategies in both studies to be explained in an overly cryptic manner. Perhaps
this is because of a page limit for the journal that I am unaware of, but I encourage the authors to
more fully explain their analytic methods, and the psychometric qualities of their measures.
(Note to the Editor: I do not consider myself sufficiently expert with the analytic methods used to
provide this paper with a proper critical review of the analysis. I urge you to ensure that you
have at least one reviewer who is adequately well versed in the analytic methods used to
properly review them.)
Given that this research is fundamentally about one construct – support for scientific inquiry – I
would like to see more attention paid to explicating the construct. Conceptually, what is it (i.e.,
how would you define it)? Operationally, how should we measure it? In study 1, the operational
decisions were made by other investigators; was their operationalization consistent with the
author’s conceptual definition? What is the author’s assessment of the operational adequacy of
these measures, and the resultant scale? Why did the authors choose to use a different set of
operational measures for Study 2? Lastly, what are the authors thoughts about the operational
adequacy of the scale in Study 2? These may seem like picky questions, especially given the
strength of the findings, but I feel strongly that solid explication is the basis of rigorous social
science. Careful explication of this construct now will greatly enhance the value of this paper.
In the Discussion (page 18, paragraph 2) the authors note one means of counteracting the cultural
meaning associated with climate change information – i.e., highlighting geo-engineering
approach – but there are additional means that are worth noting: teaching people “how global
warming works” (see the work of Michael Ranney and colleagues); stating the degree of the
scientific consensus (see, for example, papers by Sander van der Linder and colleagues, and
Teresa Myers and colleague in PLoS ONE); and invoking different forms of moral reasoning (e.g.,
Irina Feygina and colleagues, 2010; and A.C. Wolsko and colleagues, 2016).
Placing this new mechanism in the context of those known mechanisms will be helpful.
There is no consideration of the limitations of this research. I would appreciate a critical analysis
of limitations by the authors.
3
Lastly, it is worthy of note that your hypothesized mechanism appears to be robust across the age
span (although perhaps you should clarify the nature of the adult sample in Study 2 so that we
can better understand who participated).
Additional smaller points:
Abstract
I suggest deleting or moving the sentence (“We show that enhancing…) on lines 17 to 19, as this
statement reads like a conclusion, but you have not yet described what you did.
Consider noting that study 1 was with children, and study 2 with adults.
Page 3
Line 23: Please clarify exactly how the Leiserowitz et al (2013) report supports the claim that
public support for pro-environmental policies remains low. I interpret those findings to show at
least moderate -- and in some cases high -- support for a range of climate and clean energy
policies.
Page 4
Line 3: Do citations 12, 13 and 14 provide evidence to support the claim – or merely make the
argument? It would be helpful to clarify.
Pages 8 and 9
Please clarify if the analytic method a multi-level structural equation model (or its) such that
latent variables are being measured. If not, please describe how the variables were combined to
form your three measures, and their psychometric properties.
Page 15
The analytic strategy must be more fully described.
In real terms (i.e., on average), how much did scientific endorsement increase in response to the
scientific inquiry fact sheet?
label_author_2
Review form: Reviewer 2
Is the manuscript scientifically sound in its present form?
Yes
Are the interpretations and conclusions justified by the results?
Yes
Is the language acceptable?
Yes
Is it clear how to access all supporting data?
Yes
4
Do you have any ethical concerns with this paper?
No
Have you any concerns about statistical analyses in this paper?
No
Recommendation?
label_recommendation_2
Accept with minor revision (please list in comments)
Comments to the Author(s)
label_comment_2
This is a very well-written and argued paper with persuasive empirical analyses to back up its
claims. I endorse publication. The paper is also quite important to the literature -- and public
debate -- over climate change which, in my view, is too pessimistic about the potential for a range
of interventions that may improve public reasoning about the issue. This undue pessimism
appears to be due to the popularity of cultural cognition and related theories of motivated
cognition. (While there is merit to these theories, they seem to have led to the conclusion that
there is nothing to be done -- that motivated cognition is a factor that just cannot be overcome by
competing social and psychological inputs. The various evidence I've seen, not all published,
suggests this conclusion is unwarranted.)
I would, however, request a few minor revisions. They all relate to clearer explanation of the
empirical portion so that it is well-understood by a broad audience.
For Study 1: I would suggest that the authors explain why they have made the specific data
transformation (m 500, sd 100), and say explicitly that the betas reported are standardized betas. I
would suggest they interpret one beta for the reader to make sure we're all on the same page. (In
my field, we almost never use standardized betas, so their use sometimes trips me up unless they
are explained.)
It seems as though the authors should acknowledge that one weakness of Study 1 is that there are
no control variables? Most social scientists who employ cross-sectional data use basic
demographic controls, at least. (This does not worry me much though considering the
tremendous quality and reach of the data, as well as the obvious relevance of the key variables
and the fact that an experiment follows.)
The multi-level model appears to be extremely well done and unusually well explained, by the
way.
Regarding Study 2: Another advantage of this study that can be noted is that now the authors are
interviewing adults. If we're interested in individuals who can influence policy decisions, mainly
we'll be interested in adults.
I am not familiar with the method used to correct for skewness. And, in my experience,
regression-based analyses are pretty robust to skewed data. I'd be interested in knowing whether
the results are roughly similar without the correction employed. This will help readers like me
(who don't quite understand the correction) trust the findings.
Also, I understand well mediation tests, but have only passing familiarity with Hayes' particular
method. Could the authors give a quick explanation for those in a similar situation re: what
they've done (bootstrapping/iterations) and why?
5
The very last sentence of the Study 2 write-up: I didn't understand what was being
communicated. The direct effect of the fact sheet on policy support? Also, please discuss why the
direct effect may have been negative. It might also be helpful to readers to clarify that the direct
effect is not the same thing as the total effect.
label_end_comment
Decision letter (RSOS-160360)
16th August 2016
Dear Dr Drummond
On behalf of the Editors, I am pleased to inform you that your Manuscript RSOS-160360 entitled
"Enhancing endorsement of scientific inquiry increases support for pro-environment policies" has
been accepted for publication in Royal Society Open Science subject to minor revision in
accordance with the referee suggestions. Please find the referees' comments at the end of this
email.
The reviewers and handling editors have recommended publication, but also suggest some minor
revisions to your manuscript. Therefore, I invite you to respond to the comments and revise your
manuscript.
• Ethics statement
If your study uses humans or animals please include details of the ethical approval received,
including the name of the committee that granted approval. For human studies please also detail
whether informed consent was obtained. For field studies on animals please include details of all
permissions, licences and/or approvals granted to carry out the fieldwork.
• Data accessibility
It is a condition of publication that all supporting data are made available either as
supplementary information or preferably in a suitable permanent repository. The data
accessibility section should state where the article's supporting data can be accessed. This section
should also include details, where possible of where to access other relevant research materials
such as statistical tools, protocols, software etc can be accessed. If the data has been deposited in
an external repository this section should list the database, accession number and link to the DOI
for all data from the article that has been made publicly available. Data sets that have been
deposited in an external repository and have a DOI should also be appropriately cited in the
manuscript and included in the reference list.
If you wish to submit your supporting data or code to Dryad (http://datadryad.org/), or modify
your current submission to dryad, please use the following link:
http://datadryad.org/submit?journalID=RSOS&manu=RSOS-160360
• Competing interests
Please declare any financial or non-financial competing interests, or state that you have no
competing interests.
• Authors’ contributions
All submissions, other than those with a single author, must include an Authors’ Contributions
section which individually lists the specific contribution of each author. The list of Authors
should meet all of the following criteria; 1) substantial contributions to conception and design, or
acquisition of data, or analysis and interpretation of data; 2) drafting the article or revising it
critically for important intellectual content; and 3) final approval of the version to be published.
6
All contributors who do not meet all of these criteria should be included in the
acknowledgements.
We suggest the following format:
AB carried out the molecular lab work, participated in data analysis, carried out sequence
alignments, participated in the design of the study and drafted the manuscript; CD carried out
the statistical analyses; EF collected field data; GH conceived of the study, designed the study,
coordinated the study and helped draft the manuscript. All authors gave final approval for
publication.
• Acknowledgements
Please acknowledge anyone who contributed to the study but did not meet the authorship
criteria.
• Funding statement
Please list the source of funding for each author.
Because the schedule for publication is very tight, it is a condition of publication that you submit
the revised version of your manuscript within 7 days (i.e. by the 26-Aug-2016). If you do not
think you will be able to meet this date please let me know immediately.
To revise your manuscript, log into https://mc.manuscriptcentral.com/rsos and enter your
Author Centre, where you will find your manuscript title listed under "Manuscripts with
Decisions". Under "Actions," click on "Create a Revision." You will be unable to make your
revisions on the originally submitted version of the manuscript. Instead, revise your manuscript
and upload a new version through your Author Centre.
When submitting your revised manuscript, you will be able to respond to the comments made by
the referees and upload a file "Response to Referees" in "Section 6 - File Upload". You can use this
to document any changes you make to the original manuscript. In order to expedite the
processing of the revised manuscript, please be as specific as possible in your response to the
referees.
When uploading your revised files please make sure that you have:
1) A text file of the manuscript (tex, txt, rtf, docx or doc), references, tables (including captions)
and figure captions. Do not upload a PDF as your "Main Document".
2) A separate electronic file of each figure (EPS or print-quality PDF preferred (either format
should be produced directly from original creation package), or original software format)
3) Included a 100 word media summary of your paper when requested at submission. Please
ensure you have entered correct contact details (email, institution and telephone) in your user
account
4) Included the raw data to support the claims made in your paper. You can either include your
data as electronic supplementary material or upload to a repository and include the relevant doi
within your manuscript
5) Included your supplementary files in a format you are happy with (no line numbers,
vancouver referencing, track changes removed etc) as these files will NOT be edited in
production
Once again, thank you for submitting your manuscript to Royal Society Open Science and I look
forward to receiving your revision. If you have any questions at all, please do not hesitate to get
in touch.
7
Kind regards,
Alice Power
Editorial Coordinator, Royal Society Open Science
openscience@royalsociety.org
on behalf of Essi Viding
Subject Editor, Royal Society Open Science
openscience@royalsociety.org
Associate Editor Comments to Author:
Associate Editor: 1
Comments to the Author:
This is a nice paper and will be improved by taking into account the reviewers helpful comments.
Reviewer comments to Author:
Reviewer: 1
Comments to the Author(s)
This paper – through two studies: one a secondary analysis of survey data with children, and one
an experiment conducted with adults – tests the hypothesis that support for scientific inquiry (but
not necessarily scientific literacy) will be positively associated with support for pro-
environmental policies. Both studies support this hypothesis. The experimental study also
demonstrates that a brief educational statement about the logic of scientific inquiry can increase
support for scientific inquiry.
Overall, I find this paper to be insightful, well reasoned, well written, and important. That said, I
have a few concerns and/or suggestions; I am confident the authors can easily address them.
I find the analytic strategies in both studies to be explained in an overly cryptic manner. Perhaps
this is because of a page limit for the journal that I am unaware of, but I encourage the authors to
more fully explain their analytic methods, and the psychometric qualities of their measures.
(Note to the Editor: I do not consider myself sufficiently expert with the analytic methods used to
provide this paper with a proper critical review of the analysis. I urge you to ensure that you
have at least one reviewer who is adequately well versed in the analytic methods used to
properly review them.)
Given that this research is fundamentally about one construct – support for scientific inquiry – I
would like to see more attention paid to explicating the construct. Conceptually, what is it (i.e.,
how would you define it)? Operationally, how should we measure it? In study 1, the operational
decisions were made by other investigators; was their operationalization consistent with the
author’s conceptual definition? What is the author’s assessment of the operational adequacy of
these measures, and the resultant scale? Why did the authors choose to use a different set of
operational measures for Study 2? Lastly, what are the authors thoughts about the operational
adequacy of the scale in Study 2? These may seem like picky questions, especially given the
strength of the findings, but I feel strongly that solid explication is the basis of rigorous social
science. Careful explication of this construct now will greatly enhance the value of this paper.
In the Discussion (page 18, paragraph 2) the authors note one means of counteracting the cultural
meaning associated with climate change information – i.e., highlighting geo-engineering
approach – but there are additional means that are worth noting: teaching people “how global
8
warming works” (see the work of Michael Ranney and colleagues); stating the degree of the
scientific consensus (see, for example, papers by Sander van der Linder and colleagues, and
Teresa Myers and colleague in PLoS ONE); and invoking different forms of moral reasoning (e.g.,
Irina Feygina and colleagues, 2010; and A.C. Wolsko and colleagues, 2016).
Placing this new mechanism in the context of those known mechanisms will be helpful.
There is no consideration of the limitations of this research. I would appreciate a critical analysis
of limitations by the authors.
Lastly, it is worthy of note that your hypothesized mechanism appears to be robust across the age
span (although perhaps you should clarify the nature of the adult sample in Study 2 so that we
can better understand who participated).
Additional smaller points:
Abstract
I suggest deleting or moving the sentence (“We show that enhancing…) on lines 17 to 19, as this
statement reads like a conclusion, but you have not yet described what you did.
Consider noting that study 1 was with children, and study 2 with adults.
Page 3
Line 23: Please clarify exactly how the Leiserowitz et al (2013) report supports the claim that
public support for pro-environmental policies remains low. I interpret those findings to show at
least moderate -- and in some cases high -- support for a range of climate and clean energy
policies.
Page 4
Line 3: Do citations 12, 13 and 14 provide evidence to support the claim – or merely make the
argument? It would be helpful to clarify.
Pages 8 and 9
Please clarify if the analytic method a multi-level structural equation model (or its) such that
latent variables are being measured. If not, please describe how the variables were combined to
form your three measures, and their psychometric properties.
Page 15
The analytic strategy must be more fully described.
In real terms (i.e., on average), how much did scientific endorsement increase in response to the
scientific inquiry fact sheet?
Reviewer: 2
Comments to the Author(s)
This is a very well-written and argued paper with persuasive empirical analyses to back up its
claims. I endorse publication. The paper is also quite important to the literature -- and public
9
debate -- over climate change which, in my view, is too pessimistic about the potential for a range
of interventions that may improve public reasoning about the issue. This undue pessimism
appears to be due to the popularity of cultural cognition and related theories of motivated
cognition. (While there is merit to these theories, they seem to have led to the conclusion that
there is nothing to be done -- that motivated cognition is a factor that just cannot be overcome by
competing social and psychological inputs. The various evidence I've seen, not all published,
suggests this conclusion is unwarranted.)
I would, however, request a few minor revisions. They all relate to clearer explanation of the
empirical portion so that it is well-understood by a broad audience.
For Study 1: I would suggest that the authors explain why they have made the specific data
transformation (m 500, sd 100), and say explicitly that the betas reported are standardized betas. I
would suggest they interpret one beta for the reader to make sure we're all on the same page. (In
my field, we almost never use standardized betas, so their use sometimes trips me up unless they
are explained.)
It seems as though the authors should acknowledge that one weakness of Study 1 is that there are
no control variables? Most social scientists who employ cross-sectional data use basic
demographic controls, at least. (This does not worry me much though considering the
tremendous quality and reach of the data, as well as the obvious relevance of the key variables
and the fact that an experiment follows.)
The multi-level model appears to be extremely well done and unusually well explained, by the
way.
Regarding Study 2: Another advantage of this study that can be noted is that now the authors are
interviewing adults. If we're interested in individuals who can influence policy decisions, mainly
we'll be interested in adults.
I am not familiar with the method used to correct for skewness. And, in my experience,
regression-based analyses are pretty robust to skewed data. I'd be interested in knowing whether
the results are roughly similar without the correction employed. This will help readers like me
(who don't quite understand the correction) trust the findings.
Also, I understand well mediation tests, but have only passing familiarity with Hayes' particular
method. Could the authors give a quick explanation for those in a similar situation re: what
they've done (bootstrapping/iterations) and why?
The very last sentence of the Study 2 write-up: I didn't understand what was being
communicated. The direct effect of the fact sheet on policy support? Also, please discuss why the
direct effect may have been negative. It might also be helpful to readers to clarify that the direct
effect is not the same thing as the total effect.
Author's Response to Decision Letter for (RSOS-160360)
See Appendix A.
Dear Professor Viding & the editorial team,
Thank you for the recent reviews of our manuscript “Enhancing endorsement of scientific
inquiry increases support for pro-environment policies”. We thank the editor and reviewers
for their extremely supportive and helpful comments. We address the reviewer’s specific
comments below (in italics).
Reviewer comments to Author:
Reviewer: 1
Comments to the Author(s)
This paper – through two studies: one a secondary analysis of survey data with children, and
one an experiment conducted with adults – tests the hypothesis that support for scientific
inquiry (but not necessarily scientific literacy) will be positively associated with support for
pro-environmental policies. Both studies support this hypothesis. The experimental study also
demonstrates that a brief educational statement about the logic of scientific inquiry can
increase support for scientific inquiry.
Overall, I find this paper to be insightful, well reasoned, well written, and important. That
said, I have a few concerns and/or suggestions; I am confident the authors can easily address
them.
I find the analytic strategies in both studies to be explained in an overly cryptic manner.
Perhaps this is because of a page limit for the journal that I am unaware of, but I encourage
the authors to more fully explain their analytic methods, and the psychometric qualities of
their measures.
(Note to the Editor: I do not consider myself sufficiently expert with the analytic methods
used to provide this paper with a proper critical review of the analysis. I urge you to ensure
that you have at least one reviewer who is adequately well versed in the analytic methods
used to properly review them.)
Given that this research is fundamentally about one construct – support for scientific inquiry
– I would like to see more attention paid to explicating the construct. Conceptually, what is it
(i.e., how would you define it)? Operationally, how should we measure it? In study 1, the
operational decisions were made by other investigators; was their operationalization
consistent with the author’s conceptual definition? What is the author’s assessment of the
operational adequacy of these measures, and the resultant scale? Why did the authors choose
to use a different set of operational measures for Study 2? Lastly, what are the authors
thoughts about the operational adequacy of the scale in Study 2? These may seem like picky
questions, especially given the strength of the findings, but I feel strongly that solid
explication is the basis of rigorous social science. Careful explication of this construct now
will greatly enhance the value of this paper.
We have added a substantial amount of detail about the construct in line with
Reviewer #1’s request. Specifically: “We investigated the relationship between scientific
literacy and support for pro-environment policy from a different viewpoint. A critical factor
affecting support for pro-environment policies might be the attitude that people hold about
the role of scientific research in acquiring knowledge and developing policy. We term this
concept endorsement of scientific inquiry, defined as the extent to which a person (a)
endorses the process of scientific inquiry as a valuable way of accumulating knowledge, and
(b) endorses the results of relevant scientific research as a valid basis for making decisions
and taking action to achieve societal goals. This construct overlaps to some extent with
several other constructs that have been investigated in relation to scientific literacy [9,19]
but it is nevertheless distinct from them. For example, knowledge of scientific facts and
understanding of the scientific method are important aspects of scientific literacy [8,9], but
they are not necessary for endorsement of scientific inquiry; someone with little knowledge of
scientific facts can still accept that scientific research is the best way to develop knowledge in
a range of areas. Endorsement of scientific inquiry is also distinct from interest in science—
either in terms of one’s own participation in scientific research or in learning about new
scientific discoveries [8,9]—because having an interest in science does not necessarily imply
that one believes scientific research should guide decision making or policy development.
Conversely, believing that scientific research should guide policy does not necessarily imply
that one has a personal interest in science.
Perhaps the construct that is most closely aligned with endorsement of scientific
inquiry is attitude regarding the overall impact of science on society [7,9]. This has been
measured, for example, by asking questions about benefits of science for society (e.g.,
whether science makes the world better or worse off; whether science makes lives healthier,
easier, and more comfortable) and reservations about science (e.g., whether science makes
our way of life change too fast). We would expect such attitudes to co-vary to some extent
with endorsement of scientific inquiry. In particular, the degree to which one thinks science
improves the world should be linked to one’s attitudes towards basing decisions on scientific
findings (i.e., if a person thinks science improves our quality of life, he or she should be
inclined to support basing decision-making and policy on scientific findings). However, these
two constructs are distinct because attitudes toward the impact of science on society do not
capture views about science as a valid means of accumulating knowledge, which we propose
is an important component of endorsement of scientific inquiry.
We also distinguish between endorsement of scientific inquiry and support for
government funding of science [9]. Although we would expect these constructs to co-vary in
many situations, there are circumstances under which they will diverge. For example,
variations in economic conditions might affect attitudes toward spending government money
on scientific research, but should have no effect on endorsement of scientific inquiry as a
means of accumulating knowledge. Moreover, it is possible to simultaneously endorse
scientific inquiry while believing that greater funding for science should come from industry
partnerships and non-governmental sources. Finally, we note that endorsement of scientific
inquiry differs from the ethical endorsement of scientific research in specific, controversial
domains [20]. For example, one can agree that science enables the accumulation of valid
knowledge, without supporting the use of scientific research to advance the development of
nuclear weapons or human cloning.” (pp 4-6).
In the Discussion (page 18, paragraph 2) the authors note one means of counteracting the
cultural meaning associated with climate change information – i.e., highlighting geo-
engineering approach – but there are additional means that are worth noting: teaching people
“how global warming works” (see the work of Michael Ranney and colleagues); stating the
degree of the scientific consensus (see, for example, papers by Sander van der Linder and
colleagues, and Teresa Myers and colleague in PLoS ONE); and invoking different forms of
moral reasoning (e.g., Irina Feygina and colleagues, 2010; and A.C. Wolsko and colleagues,
2016).
Placing this new mechanism in the context of those known mechanisms will be helpful.
We now include these mechanisms as suggested to place our research in a broader context.
Specifically: “effectively communicating the scientific consensus on the issue increases
climate change belief across socio-political ideologies [38,39,40] and framing climate
change action as patriotic [41. 42] or as obeying authority or defending natural purity
increases support for such policies [42].” (page 18).
There is no consideration of the limitations of this research. I would appreciate a critical
analysis of limitations by the authors.
We have also included some discussion of limitations in the general discussion: “The present
findings, while promising, are subject to limitations which are important to note. First, we
note that there is scope to further develop the construct of endorsement of scientific inquiry
and the scales used to measure it. We have provided a working definition of this construct
and a description of how it differs from related but distinct constructs that reflect aspects of
scientific literacy and attitudes to scientific research. However, this definition may be refined
through future research. Second, it is important to further investigate the effects of
interventions designed to increase endorsement of scientific inquiry. Although our study
shows that a brief—and therefore cost effective—intervention can increase endorsement of
scientific inquiry and, hence, support for pro-environment policy, it is unclear whether a
more comprehensive intervention will produce more substantial changes, whether these are
likely to persist over time. Future research should investigate the long-term effects of
interventions on endorsement for scientific inquiry and support for pro-environment policy,
and also any additional effects that such interventions might have (other than affecting
endorsement of scientific inquiry). Finally, in the real world it not often the case that
information is delivered by sources that are perceived to be politically neutral. One question
is whether the effects we demonstrate would occur if delivered by a message source perceived
to be politically biased.”(p.19-20).
We have also included some specific limitations for Study 1 raised by Reviewer #2.
Specifically: “Several limitations of Study 1 were addressed in Study 2. Firstly, Study 1 was
correlational in nature, and therefore does not illuminate whether endorsement for scientific
inquiry affects support for pro-environmental policies. Second, Study 1 contained limited
demographic controls. Finally, the study investigated the attitudes of adolescents, and
therefore it would be helpful, from an applied perspective, to understand the relationship in
adults. To address these issues, we conducted an experiment.”(pp10-11)
Lastly, it is worthy of note that your hypothesized mechanism appears to be robust across the
age span (although perhaps you should clarify the nature of the adult sample in Study 2 so
that we can better understand who participated).
“These studies demonstrate that the results are consistent across adolescent and adult
populations.”(p.16).
Additional smaller points:
Abstract
I suggest deleting or moving the sentence (“We show that enhancing…) on lines 17 to 19, as
this statement reads like a conclusion, but you have not yet described what you did.
We have altered the sentence such that it now reads: “We distinguish between scientific
literacy (basic scientific knowledge) and endorsement of scientific inquiry (perceiving science
as a valuable way of accumulating knowledge), and examine the relationship between
people’s endorsement of scientific inquiry and their support for pro-environment policy”(p.2)
Consider noting that study 1 was with children, and study 2 with adults.
We have added these details to the abstract as suggested. (p.2.)
Page 3
Line 23: Please clarify exactly how the Leiserowitz et al (2013) report supports the claim that
public support for pro-environmental policies remains low. I interpret those findings to show
at least moderate -- and in some cases high -- support for a range of climate and clean energy
policies.
We have altered the sentence thus: However, in countries such as the U.S., public support for
pro-environment policies is well below consensus levels [5]. (p.3).
Page 4
Line 3: Do citations 12, 13 and 14 provide evidence to support the claim – or merely make
the argument? It would be helpful to clarify.
We have clarified the point as follows: “For example, given the overwhelming consensus
among scientists that climate change is occurring [10,11] researchers have acknowledged
that it might be tempting to think that lower acceptance of the evidence for climate change
among the public might be attributable to poor scientific literacy [12-14]” (p.4).
Pages 8 and 9
Please clarify if the analytic method a multi-level structural equation model (or its) such that
latent variables are being measured. If not, please describe how the variables were combined
to form your three measures, and their psychometric properties.
We have clarified the questions about the measures and their psychometric properties in
three places. Specifically: “The scientific literacy scale is calculated by PISA, has been
extensively validated [29], and has a Cronbach’s alpha of .86, representing excellent internal
reliability.”
“The endorsement scale is calculated and validated by PISA [29], and has a high reliability,
a = .73.”
“The support for pro-environment policies scale has a high internal consistency, a = .73, and
has been validated against similar constructs by PISA [29]. ” (pp8-9).
Page 15
The analytic strategy must be more fully described.
In response to Reviewer #2 we have included some additional detail about the purpose of,
and method for, the bootstrapped analysis. “In accordance with current recommendations of
best practice, bootstrapped mediational analyses using 2000 iterations [34] were adopted.
Bootstrapped analyses draw n (in this case 2000) random samples (termed an iteration) from
the data averaging the analysis across each of these samples, thereby increasing the
accuracy of the point estimates. These analyses are more appropriate than earlier stepped
regression procedures for estimating mediational effects [34]. For a detailed discussion of
this method, see [34]. (p 18). We also now include a mediational diagram detailing the
direct and indirect pathways “Graphically, this analysis is represented by Figure 1.” (p.14)
In real terms (i.e., on average), how much did scientific endorsement increase in response to
the scientific inquiry fact sheet?
“with participants who read the scientific inquiry fact sheet scoring higher on the measure
(M = 47.31, SD = 7.88) than participants in the control (M = 44.96, SD = 8.05)” (p.15)
Reviewer: 2
Comments to the Author(s)
This is a very well-written and argued paper with persuasive empirical analyses to back up its
claims. I endorse publication. The paper is also quite important to the literature -- and public
debate -- over climate change which, in my view, is too pessimistic about the potential for a
range of interventions that may improve public reasoning about the issue. This undue
pessimism appears to be due to the popularity of cultural cognition and related theories of
motivated cognition. (While there is merit to these theories, they seem to have led to the
conclusion that there is nothing to be done -- that motivated cognition is a factor that just
cannot be overcome by competing social and psychological inputs. The various evidence I've
seen, not all published, suggests this conclusion is unwarranted.)
I would, however, request a few minor revisions. They all relate to clearer explanation of the
empirical portion so that it is well-understood by a broad audience.
For Study 1: I would suggest that the authors explain why they have made the specific data
transformation (m 500, sd 100), and say explicitly that the betas reported are standardized
betas. I would suggest they interpret one beta for the reader to make sure we're all on the
same page. (In my field, we almost never use standardized betas, so their use sometimes trips
me up unless they are explained.)
We have clarified this point: “Scientific literacy and endorsement of scientific inquiry are
supplied by PISA on a scale with an international average of approximately 500 and a
standard deviation of approximately 100. To ensure consistency, we also transformed
support for pro-environment policy scores to a scale with an international average of
approximately 500 and a standard deviation of approximately 100.”(p.9).
Technically we are not using standardized betas – but because our scales are all transformed
to have identical means and standard deviations, they are very close to the standardized
scores. We have clarified as the reviewer requests by interpreting the critical relationship as
follows. “The B indicates that for every point endorsement of scientific inquiry rose, support
for pro-environment policies rose by 0.43 points on average.”(p.10).
It seems as though the authors should acknowledge that one weakness of Study 1 is that there
are no control variables? Most social scientists who employ cross-sectional data use basic
demographic controls, at least. (This does not worry me much though considering the
tremendous quality and reach of the data, as well as the obvious relevance of the key
variables and the fact that an experiment follows.)
We now acknowledge this weakness at the end of Study 1, and indicate how Study 2
addresses this issue. Specifically: “Several limitations of Study 1 were addressed in Study 2.
Firstly, Study 1 was correlational in nature, and therefore does not illuminate whether
endorsement for scientific inquiry affects support for pro-environmental policies. Second,
Study 1 contained limited demographic controls. Finally, the study investigated the attitudes
of adolescents, and therefore it would be helpful, from an applied perspective, to understand
the relationship in adults. To address these issues, we conducted an experiment to test the
relationship between endorsement for scientific inquiry and support for pro-environment
policy.” (p11).
The multi-level model appears to be extremely well done and unusually well explained, by
the way.
We thank the reviewer for their positive feedback.
Regarding Study 2: Another advantage of this study that can be noted is that now the authors
are interviewing adults. If we're interested in individuals who can influence policy decisions,
mainly we'll be interested in adults.
We agree and now explicitly mention this strength. Specifically: “Moreover, Study 2 extends
our findings to an adult sample, which is critical for building policy support as in most cases
adults will be the population most likely to influence policy decisions”(p.11).
I am not familiar with the method used to correct for skewness. And, in my experience,
regression-based analyses are pretty robust to skewed data. I'd be interested in knowing
whether the results are roughly similar without the correction employed. This will help
readers like me (who don't quite understand the correction) trust the findings.
We address this issue in footnote 1: “Analysis using the raw scores rather than the square
root transformed data were similar, with the indirect effect being slightly larger k2 = .09 [.02,
.17].”(p15).
Also, I understand well mediation tests, but have only passing familiarity with Hayes'
particular method. Could the authors give a quick explanation for those in a similar situation
re: what they've done (bootstrapping/iterations) and why?
We now discuss the reasons for bootstrapping on pages 18. Specifically:“Bootstrapped
analyses draw n (in this case 2000) random samples (termed an iteration) from the data
averaging the analysis across each of these samples, thereby increasing the accuracy of the
point estimates. These analyses are more appropriate than earlier stepped regression
procedures for estimating mediational effects [34]. For a detailed discussion of this method,
see [34].”(p.14).
The very last sentence of the Study 2 write-up: I didn't understand what was being
communicated. The direct effect of the fact sheet on policy support? Also, please discuss why
the direct effect may have been negative. It might also be helpful to readers to clarify that the
direct effect is not the same thing as the total effect.
We have expanded on this point: “Our data showed a clear indirect effect consistent with our
hypothesis. This indicates that to the extent to which the manipulation increased endorsement
of scientific inquiry, this translated to an increase in support for pro-environment policy.
However, another aspect of the results must be considered when evaluating our findings.
Specifically, the coefficient for the direct effect (i.e., the effect of the fact sheet on support for
pro-environmental policies when the indirect effect is statistically controlled) was B = -0.26,
[-0.62, 0.09]. The confidence intervals around this coefficient overlap zero, indicating that
we cannot assume the effect is meaningfully different from zero. However, the direction of
this effect was negative, suggesting that we cannot rule out the possibility that our fact sheet
manipulation may have triggered some unanticipated mechanism (other than increased
endorsement of scientific inquiry) that suppressed an increase in support for pro-environment
policy. Regardless, the indirect effect is the most relevant to our hypothesis and provides
clear evidence that, to the extent that the manipulation increased endorsement, this translated
to an increase in support for pro-environment policy. Moreover, this result was produced by
a manipulation that involved presentation of a brief fact sheet; future research may show that
a more comprehensive intervention is more effective.” (p15-16).
Society Open
