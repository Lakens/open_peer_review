An investigation of the false discovery rate and the
misinterpretation of p-values
David Colquhoun
Article citation details
R. Soc. open sci. 1: 140216.
http://dx.doi.org/10.1098/rsos.140216
Review timeline
Original submission: 12 August 2014 Note: Reports are unedited and appear as
Revised submission: 17 October 2014 submitted by the referee. The review history
Final acceptance: 20 October 2014 appears in chronological order.
Review History
label_version_1
RSOS-140216.R0 (Original submission)
label_author_1
Review form: Reviewer 1 (Marcus Munafo)
Is the manuscript scientifically sound in its present form?
Yes
Are the interpretations and conclusions justified by the results?
Yes
Is the language acceptable?
Yes
Is it clear how to access all supporting data?
Not applicable.
Do you have any ethical concerns with this paper?
No
Have you any concerns about statistical analyses in this paper?
No
Recommendation
Accept with minor revision (please list in comments).
© 2014 The Authors. Published by the Royal Society under the terms of the Creative Commons
Attribution License http://creativecommons.org/licenses/by/4.0/, which permits unrestricted use,
provided the original author and source are credited
2
Comments to the Author(s)
I enjoyed reading this manuscript. The concepts and issues discussed are not in themselves novel,
but they continue to be under-appreciated and they are presented in an engaging and readily
understandable way. This alone renders the manuscript a valuable contribution. The inclusion of
a script to enable readers to perform their own simulations is a very useful addition. I have only
minor suggestions as to how the manuscript might be improved.
1. Increasing the stringency of alpha is suggested as part of the solution to the problems
described. This is a fair point, certainly in a climate where false positives are almost certainly a
larger problem than false negatives. Nevertheless, some discussion of how best to balance both
alpha and beta would be helpful. In other words, in my opinion, increasing statistical power is
also part of the solution.
2. As a related point, it might be worthwhile to discuss examples of fields that have modified
their practices and enjoyed a dramatic increase in the ratio of robust findings as a result. The
example in my mind is genome wide association studies, where the combination of a stringent
alpha (p &lt; 10^-8), large sample sizes, replication reported alongside discovery in the same
manuscript etc. is now the norm.
3. One reference that I was expecting to see was Sifting the Evidence by Sterne and Davey Smith
published in the BMJ in 2001. It includes some of the same arguments as here, albeit with a
narrower focus, but also includes a discussion of how the hybrid of Fisher and Neyman-Pearson
that became NHST came about. This might be worth referring readers to.
label_author_2
Review form: Reviewer 2 (Matthew Hankins)
Is the manuscript scientifically sound in its present form?
Yes
Are the interpretations and conclusions justified by the results?
Yes
Is the language acceptable?
Yes
Is it clear how to access all supporting data?
Yes
Do you have any ethical concerns with this paper?
No
Have you any concerns about statistical analyses in this paper?
No
Recommendation
Accept with minor revision (please list in comments).
Comments to the Author(s)
The author sets out a very clear argument that p values do not, of themselves, inform us of the
false discovery rate (FDR) and that the true FDR is likely to be uncomfortably high in many cases.
The argument is constructed by analogy to the (perhaps more widely understood) problem of test
sensitivity/specificity and their relationship to PPV/NPV: the tree diagrams are reminiscent of
those provided by Gigerenzer in his treatment of this problem. Although alarmingly self-evident
3
when presented in this way, the results are further supported by a set of simulations i.e. empirical
results as well as a more formal treatment in the appendix.
As a result the paper elegantly illustrates an enormous problem in studies using significance
testing. But while the logic of the author's position is irrefutable, some may quibble that it has not
been demonstrated (i.e. evidence is not presented) that the FDR of significance testing has been
widely misunderstood and that this is responsible for the current 'replication crisis' in science.
Similarly, some of the conclusions link e.g. the 'publish or perish culture', 'altmetrics' and a
number of other questionable practices, to the topic at hand without much in the way of
supporting evidence. I think this would be quibbling, however, since the problems are obvious
and widespread and any interested reader should be able to find such evidence for him/herself.
Some minor corrections/comments:
p1L32 'is used' appears twice
p2 Eliot quote: no comma after stomach; "but not the less valuable"
p2l34 "In 1970" but citation is 1971
p2c2l1 this jumps the gun slightly as PPV is not usually defined in the context of significance
p4l4 title format looks wrong
p4l42 Not sure what this sentence relates to or means
p5l58 'observations'
Figures 3,4,5 have no 3a, 3b etc. labelled
Figure 4 - should these not show histograms? smooth distribution implied but N=16 in 4b
p7l54 can't really compare social psychology in 1960s and neurosciences in 2013
p7c2l25 'tests' is plural 'it says on the tin' is singular, not sure if metaphor can be preserved
p10l31 is this a straw man argument, in that the impossibility of imagining a non-heliocentric
solar system derives from our post hoc knowledge of the truth? Extending the analogy to the
following paragraph would mean that we would have similar difficulty imaging a universe in
which drug don't work, given that we already know that the drugs work
p10c2l21 "the blame" is placed on a number of (deserving) usual suspects but it is a bit of a leap of
faith. However, after constructed such a sturdy soapbox it would be a shame not to let the author
speak from it.
label_end_comment
Decision letter
14-Oct-2014
Dear Dr Colquhoun
On behalf of the Editor, I am pleased to inform you that your Manuscript RSOS-140216 entitled
"An investigation of the false discovery rate and the misinterpretation of P values" has been
accepted for publication in Royal Society Open Science subject to minor revision in accordance
with the referee suggestions. Please find the referees' comments below. The reviewers and Subject
4
Editor have recommended publication, but also suggest some minor revisions to your
manuscript. Therefore, I invite you to respond to the comments and revise your manuscript.
Because the schedule for publication is very tight, it is a condition of publication that you submit
the revised version of your manuscript within 7 days. If you do not think you will be able to meet
this date please let me know immediately.
To revise your manuscript, log into http://mc.manuscriptcentral.com/rsos and enter your
Author Centre, where you will find your manuscript title listed under "Manuscripts with
Decisions". Under "Actions," click on "Create a Revision." You will be unable to make your
revisions on the originally submitted version of the manuscript. Instead, revise your manuscript
and upload a new version through your Author Centre. When submitting your revised
manuscript, you will be able to respond to the comments made by the referees and upload a file
"Response to Referees" in "Section 6 - File Upload". You can use this to document any changes
you make to the original manuscript. In order to expedite the processing of the revised
manuscript, please be as specific as possible in your response to the referees. When uploading
your revised files please make sure that you have:
1) A text file of the manuscript (tex, txt, rtf, docx or doc), references, tables (including captions)
and figure captions. Do not upload a PDF as your "Main Document"
2) A separate electronic file of each figure (EPS or print-quality PDF preferred (either format
should be produced directly from original creation package), or original software format)
3) Included a 100 word media summary of your paper when requested at submission. Please
ensure you have entered correct contact details (email, institution and telephone) in your user
account
4) Included the raw data to support the claims made in your paper. You can either include your
data as electronic supplementary material or upload to a repository and include the relevant doi
within your manuscript
5) Included your supplementary files in a format you are happy with (no line numbers,
vancouver referencing, track changes removed etc) as these files will NOT be edited in
production
Once again, thank you for submitting your manuscript to Royal Society Open Science and I look
forward to receiving your revision. If you have any questions at all, please do not hesitate to get
in touch.
Best wishes
Charlotte Wray
Senior Publishing Editor
openscience@royalsociety.org
Author's Response to Decision Letter for (RSOS-140216)
Referee 1 1. A note about power has been added as penultimate bullet point in discussion p11 2.
GWAS has been mentioned in an addition to the penultimate paragraph of the conclusions, with
a reference to Bush & Moore (2012). 3. A reference has been added to Sterne & Davey Smith
(2001) and also to Valen Johnson (2013) at end of conclusions Referee 2 p1L32 'is used' appears
twice Corrected p2 Eliot quote: no comma after stomach; "but not the less valuable" Fixed (very
impressed by the referee’s literary knowledge!) p2l34 "In 1970" but citation is 1971 Fixed (in 2
places) p2c2l1 this jumps the gun slightly as PPV is not usually defined in the context of
significance This part of the introduction has been re-worded and re-ordered to make it clearer
p4l4 title format looks wrong Subtitle removed and incorporated in the paragraph that followed
it p4l42 Not sure what this sentence relates to or means I can’t see anything wrong with this
sentence, so I’ve left it as it is p5l58 'observations' Fixed –replaced with “simulated ‘observations’
“ Figures 3,4,5 have no 3a, 3b etc. labelled Fixed Figure 4 - should these not show histograms?
smooth distribution implied but N=16 in 4b I don’t think so, The legend says “Simulated t tests
are based on samples from the postulated true distributions shown”. They are the true
5
underlying pdfs for observations and for means of 16 observations, from which random samples
are drawn for the simulations. p7l54 can't really compare social psychology in 1960s and
neurosciences in 2013 True, but since nobody has investigated the power of neuroscience studies
in the 1960s, it’s the best that can be done. p7c2l25 'tests' is plural 'it says on the tin' is singular,
not sure if metaphor can be preserved I don’t see that there is a real problem here. All
conventional (Fisherian tests of H0) make the same assumptions and do exactly what’s claimed
for them. p10l31 is this a straw man argument, in that the impossibility of imagining a non-
heliocentric solar system derives from our post hoc knowledge of the truth? Extending the
analogy to the following paragraph would mean that we would have similar difficulty imaging a
universe in which drug don't work, given that we already know that the drugs work I see your
point, of course. People have been wrangling over that problem for centuries. I’ve reworded the
whole paragraph, in the hope that I’ve demonstrated that there is no need for subjective
probabilities in my argument, just as there is no need for them in the case of screening tests.
p10c2l21 "the blame" is placed on a number of (deserving) usual suspects but it is a bit of a leap of
faith. However, after constructed such a sturdy soapbox it would be a shame not to let the author
speak from it. Thank you for allowing a bit of preaching at the end
Society Open
