Social learning solves the problem of narrow-peaked search
landscapes: experimental evidence in humans
Alberto Acerbi, Claudio Tennie and Alex Mesoudi
Article citation details
R. Soc. open sci. 3: 160215.
http://dx.doi.org/10.1098/rsos.160215
Review timeline
Original submission: 24 March 2016 Note: Reports are unedited and appear as
Revised submission: 2 June 2016 submitted by the referee. The review history
Final acceptance: 4 August 2016 appears in chronological order.
Review History
label_version_1
RSOS-160215.R0 (Original submission)
label_author_1
Review form: Reviewer 1
Is the manuscript scientifically sound in its present form?
Yes
Are the interpretations and conclusions justified by the results?
Yes
Is the language acceptable?
Yes
Is it clear how to access all supporting data?
Yes
Do you have any ethical concerns with this paper?
No
© 2016 The Authors. Published by the Royal Society under the terms of the Creative Commons
Attribution License http://creativecommons.org/licenses/by/4.0/, which permits unrestricted use,
provided the original author and source are credited
2
Have you any concerns about statistical analyses in this paper?
No
Recommendation?
label_recommendation_1
Accept with minor revision (please list in comments)
Comments to the Author(s)
label_comment_1
This a clear and straightforward paper raising an important point about the structure of search
spaces for cultural evolution.
However, the normalization procedure used in testing the second hypothesis worries me.
The analyses show quite clearly that the answer to the question "Do social learners perform
equally well in the wide and narrow conditions?" is simply that they do not. The narrow task is
more difficult, and the difficulty of this task is not fully alleviated by the addition of social
learning. Instead of leaving it at this the scores are normalized, dividing by the score of the
highest scoring demonstrator. The original question is then conflated with the slightly different
question "Do social learners perform equally well in the wide and narrow conditions, when we
control for demonstrator performance which is a proxy for task difficulty."
However, controlling for the relative difficulty of the conditions completely misses the point of
the original hypothesis. Namely that social learning would "solve" this problem so well that social
learners would have similar payoffs in spite of the difference in difficulty between the conditions.
The analyses suggest that instead social learning provides only a partial "solution" to this learning
problem.
The authors go on to present analyses showing that social learning does indeed help more in the
more difficult narrow condition than in the wide condition. These analyses illustrate the more
nuanced story I hope the authors will try to tell.
1. Narrow is harder than wide,
2. Social learning helps in both,
3. Social learning helps more in the more difficult task,
4. But not so much that performance is at ceiling and the social learners perform equally well in
both tasks.
5. This may be because, as is often the case in lab studies of social learning, participants are
utilizing social learning at a sub-optimal rate for the specific learning problem.
Everything else about the paper is good.
label_author_2
Review form: Reviewer 2
Is the manuscript scientifically sound in its present form?
No
Are the interpretations and conclusions justified by the results?
Yes
Is the language acceptable?
Yes
Is it clear how to access all supporting data?
Yes
3
Do you have any ethical concerns with this paper?
No
Have you any concerns about statistical analyses in this paper?
No
Recommendation?
label_recommendation_2
Major revision is needed (please make suggestions in comments)
Comments to the Author(s)
label_comment_2
This empirical paper tests hypotheses derived from models of social learning, which suggest that
a narrow-peaked fitness landscape increases the benefit of social learning over individual
learning when compared with a wide-peaked fitness landscape. The authors generate three
hypotheses, which they test using an established empirical paradigm. I have some comments
regarding the specifics of the experimental design as applied in this case (see below). I can
recommend acceptance if these are resolved.
Major comments
Hypothesis H2. It seems that this hypothesis relies on the authors’ manipulation of the
demonstrator pool. In a real-world scenario, if H1 is true and individual learning is harder in a
narrow-peaked fitness landscape, then the social learners in this condition should, in turn, be less
likely to find a demonstrator who has landed on the global optimum (at least in a finite
population). By manipulating the demonstrator pool the authors have ensured that this is not the
case and stacked the odds somewhat in favour of H2. Can the authors provide a more thorough
justification for this than that provided on page 5, and a more detailed discussion of the
implications for H2 and H3?
Hypothesis H3. Again this hypothesis makes sense only where the authors have ensured that the
pool of demonstrators contains individuals that have reached the global maximum. Were that not
the case, would this hypothesis be valid?
It may be interesting to discuss the outcome for H3 in terms of the work on uncertainly and the
likelihood of using social information (e.g. Morgan et al 2012). This work showed that
uncertainty, which would be generated by the flat payoffs across much of the narrow fitness
landscape should mean more social learning might be used.
Minor comments
Page 2. Line 6. Cite Heyes (1994) or her sources as the origin of your definition of social learning.
Note also that this definition refers to ‘learning’ and not specifically to ‘changes in behaviour’.
Page 2. Line 31 and Page 3 Line 16. ‘One of us’, ‘two of us’ is very informal. The convention
would be to cite these papers as one would cite any others. This should be observed here,
especially as other authors were involved in the cited papers and the work cannot be ascribed to
the authors of this paper alone.
Page 10. Lines 36-44. The terminology here changes from that of optimality and local minima and
maxima to that of ‘correct solutions’. This is a bit jarring as the paper mostly addresses complex
fitness landscapes without one ‘correct solution’. This should be standardised.
label_end_comment
Decision letter (RSOS-160215)
26th May 2016
4
Dear Dr Acerbi,
The editors assigned to your paper ("Social learning solves the problem of narrow-peaked search
landscapes: experimental evidence in humans") has now received comments from reviewers. We
would like you to revise your paper in accordance with the referee and Subject Editor
suggestions which can be found below (not including confidential reports to the Editor). Please
note this decision does not guarantee eventual acceptance.
Please submit a copy of your revised paper within three weeks (i.e. by the 17th June 2016). If we
do not hear from you within this time then it will be assumed that the paper has been withdrawn.
In exceptional circumstances, extensions may be possible if agreed with the Editorial Office in
advance.We do not allow multiple rounds of revision so we urge you to make every effort to
fully address all of the comments at this stage. If deemed necessary by the Editors, your
manuscript will be sent back to one or more of the original reviewers for assessment. If the
original reviewers are not available we may invite new reviewers.
To revise your manuscript, log into http://mc.manuscriptcentral.com/rsos and enter your
Author Centre, where you will find your manuscript title listed under "Manuscripts with
Decisions." Under "Actions," click on "Create a Revision." Your manuscript number has been
appended to denote a revision. Revise your manuscript and upload a new version through your
Author Centre.
When submitting your revised manuscript, you must respond to the comments made by the
referees and upload a file "Response to Referees" in "Section 6 - File Upload". Please use this to
document how you have responded to the comments, and the adjustments you have made. In
order to expedite the processing of the revised manuscript, please be as specific as possible in
your response.
In addition to addressing all of the reviewers' and editor's comments please also ensure that your
revised manuscript contains the following sections as appropriate before the reference list:
• Ethics statement (if applicable)
If your study uses humans or animals please include details of the ethical approval received,
including the name of the committee that granted approval. For human studies please also detail
whether informed consent was obtained. For field studies on animals please include details of all
permissions, licences and/or approvals granted to carry out the fieldwork.
• Data accessibility
It is a condition of publication that all supporting data are made available either as
supplementary information or preferably in a suitable permanent repository. The data
accessibility section should state where the article's supporting data can be accessed. This section
should also include details, where possible of where to access other relevant research materials
such as statistical tools, protocols, software etc can be accessed. If the data has been deposited in
an external repository this section should list the database, accession number and link to the DOI
for all data from the article that has been made publicly available. Data sets that have been
deposited in an external repository and have a DOI should also be appropriately cited in the
manuscript and included in the reference list.
If you wish to submit your supporting data or code to Dryad (http://datadryad.org/), or modify
your current submission to dryad, please use the following link:
http://datadryad.org/submit?journalID=RSOS&manu=RSOS-160215
5
• Competing interests
Please declare any financial or non-financial competing interests, or state that you have no
competing interests.
• Authors’ contributions
All submissions, other than those with a single author, must include an Authors’ Contributions
section which individually lists the specific contribution of each author. The list of Authors
should meet all of the following criteria; 1) substantial contributions to conception and design, or
acquisition of data, or analysis and interpretation of data; 2) drafting the article or revising it
critically for important intellectual content; and 3) final approval of the version to be published.
All contributors who do not meet all of these criteria should be included in the
acknowledgements.
We suggest the following format:
AB carried out the molecular lab work, participated in data analysis, carried out sequence
alignments, participated in the design of the study and drafted the manuscript; CD carried out
the statistical analyses; EF collected field data; GH conceived of the study, designed the study,
coordinated the study and helped draft the manuscript. All authors gave final approval for
publication.
• Acknowledgements
Please acknowledge anyone who contributed to the study but did not meet the authorship
criteria.
• Funding statement
Please list the source of funding for each author.
Once again, thank you for submitting your manuscript to Royal Society Open Science and I look
forward to receiving your revision. If you have any questions at all, please do not hesitate to get
in touch.
Yours sincerely,
Matthew Allinson,
Editorial Coordinator, Royal Society Open Science
on behalf of Essi Viding
Subject Editor, Royal Society Open Science
openscience@royalsociety.org
Comments to Author:
Reviewers' Comments to Author:
Reviewer: 1
Comments to the Author(s)
This a clear and straightforward paper raising an important point about the structure of search
spaces for cultural evolution.
However, the normalization procedure used in testing the second hypothesis worries me.
6
The analyses show quite clearly that the answer to the question "Do social learners perform
equally well in the wide and narrow conditions?" is simply that they do not. The narrow task is
more difficult, and the difficulty of this task is not fully alleviated by the addition of social
learning. Instead of leaving it at this the scores are normalized, dividing by the score of the
highest scoring demonstrator. The original question is then conflated with the slightly different
question "Do social learners perform equally well in the wide and narrow conditions, when we
control for demonstrator performance which is a proxy for task difficulty."
However, controlling for the relative difficulty of the conditions completely misses the point of
the original hypothesis. Namely that social learning would "solve" this problem so well that social
learners would have similar payoffs in spite of the difference in difficulty between the conditions.
The analyses suggest that instead social learning provides only a partial "solution" to this learning
problem.
The authors go on to present analyses showing that social learning does indeed help more in the
more difficult narrow condition than in the wide condition. These analyses illustrate the more
nuanced story I hope the authors will try to tell.
1. Narrow is harder than wide,
2. Social learning helps in both,
3. Social learning helps more in the more difficult task,
4. But not so much that performance is at ceiling and the social learners perform equally well in
both tasks.
5. This may be because, as is often the case in lab studies of social learning, participants are
utilizing social learning at a sub-optimal rate for the specific learning problem.
Everything else about the paper is good.
Reviewer: 2
Comments to the Author(s)
This empirical paper tests hypotheses derived from models of social learning, which suggest that
a narrow-peaked fitness landscape increases the benefit of social learning over individual
learning when compared with a wide-peaked fitness landscape. The authors generate three
hypotheses, which they test using an established empirical paradigm. I have some comments
regarding the specifics of the experimental design as applied in this case (see below). I can
recommend acceptance if these are resolved.
Major comments
Hypothesis H2. It seems that this hypothesis relies on the authors’ manipulation of the
demonstrator pool. In a real-world scenario, if H1 is true and individual learning is harder in a
narrow-peaked fitness landscape, then the social learners in this condition should, in turn, be less
likely to find a demonstrator who has landed on the global optimum (at least in a finite
population). By manipulating the demonstrator pool the authors have ensured that this is not the
case and stacked the odds somewhat in favour of H2. Can the authors provide a more thorough
justification for this than that provided on page 5, and a more detailed discussion of the
implications for H2 and H3?
Hypothesis H3. Again this hypothesis makes sense only where the authors have ensured that the
pool of demonstrators contains individuals that have reached the global maximum. Were that not
the case, would this hypothesis be valid?
7
It may be interesting to discuss the outcome for H3 in terms of the work on uncertainly and the
likelihood of using social information (e.g. Morgan et al 2012). This work showed that
uncertainty, which would be generated by the flat payoffs across much of the narrow fitness
landscape should mean more social learning might be used.
Minor comments
Page 2. Line 6. Cite Heyes (1994) or her sources as the origin of your definition of social learning.
Note also that this definition refers to ‘learning’ and not specifically to ‘changes in behaviour’.
Page 2. Line 31 and Page 3 Line 16. ‘One of us’, ‘two of us’ is very informal. The convention
would be to cite these papers as one would cite any others. This should be observed here,
especially as other authors were involved in the cited papers and the work cannot be ascribed to
the authors of this paper alone.
Page 10. Lines 36-44. The terminology here changes from that of optimality and local minima and
maxima to that of ‘correct solutions’. This is a bit jarring as the paper mostly addresses complex
fitness landscapes without one ‘correct solution’. This should be standardised.
Author's Response to Decision Letter for (RSOS-160215)
See Appendix A.
label_version_2
RSOS-160215.R1 (Revision)
label_author_3
Review form: Reviewer 2
Is the manuscript scientifically sound in its present form?
Yes
Are the interpretations and conclusions justified by the results?
Yes
Is the language acceptable?
Yes
Is it clear how to access all supporting data?
Yes
Do you have any ethical concerns with this paper?
No
Have you any concerns about statistical analyses in this paper?
No
Recommendation?
label_recommendation_3
Accept as is
8
Comments to the Author(s)
label_comment_3
The authors have addressed most concerns. However, I remain unconvinced about the logic of
divorcing social and individual learning by manipulating the pool of demonstrators in this way.
In their response the authors say ‘wide social learners would have been able to copy higher-
scoring demonstrators than narrow social learners, as well as experience easier individual
learning themselves ’ This is of course true, and would indeed be true in any natural wide fitness
peak environment. Therefore, the fact that the pool of demonstrators would be different in a wide
vs. a narrow peaked environment is of importance to understanding the effects of social learning
in those environments.
The authors state in their response that ‘scoring higher because of better demonstrators is
interesting but not explicitly tied to our research question about landscape smoothness’. Is this
really the case? It seems that there is (or would be in natural settings) a direct causal relationship
between fitness peak width and demonstrator quality. Can the authors envisage a natural
situation in which social learners in a wide peaked fitness landscape would not experience
differences in demonstrator quality compared to a narrow landscape?
Despite remaining unconvinced about the gains of constructing the analysis in this way, the
additional paragraph does make the assumptions clear and I see no barrier to publication.
label_end_comment
Decision letter (RSOS-160215.R1)
3rd August 2016
Dear Dr Acerbi,
I am pleased to inform you that your manuscript entitled "Social learning solves the problem of
narrow-peaked search landscapes: experimental evidence in humans" is now accepted for
publication in Royal Society Open Science.
You can expect to receive a proof of your article within approximately 10 working days. Please
contact the production office (openscience_proofs@royalsociety.org) to let us know if you are
likely to be away from e-mail contact during that period. Due to rapid publication and an
extremely tight schedule, if comments are not received, your paper may experience a delay in
publication.
Royal Society Open Science operates under a continuous publication model
(http://bit.ly/cpFAQ). Your article will be published straight into the next open issue and this
will be the final version of the paper. As such, it can be cited immediately by other researchers.
As the issue version of your paper will be the only version to be published I would advise you to
check your proofs thoroughly as changes cannot be made once the paper is published.
In order to raise the profile of your paper once it is published, we can send through a PDF of your
paper to selected colleagues. If you wish to take advantage of this, please reply to this email with
the name and email addresses of up to 10 people who you feel would wish to read your article.
On behalf of the Editors of Royal Society Open Science, we look forward to your continued
contributions to the Journal.
Best wishes,
Andrew Dunn
9
Senior Publishing Editor
http://rsos.royalsocietypublishing.org/
Reviewer(s)' Comments to Author:
Reviewer: 2
Comments to the Author(s)
The authors have addressed most concerns. However, I remain unconvinced about the logic of
divorcing social and individual learning by manipulating the pool of demonstrators in this way.
In their response the authors say ‘wide social learners would have been able to copy higher-
scoring demonstrators than narrow social learners, as well as experience easier individual
learning themselves ’ This is of course true, and would indeed be true in any natural wide fitness
peak environment. Therefore, the fact that the pool of demonstrators would be different in a wide
vs. a narrow peaked environment is of importance to understanding the effects of social learning
in those environments.
The authors state in their response that ‘scoring higher because of better demonstrators is
interesting but not explicitly tied to our research question about landscape smoothness’. Is this
really the case? It seems that there is (or would be in natural settings) a direct causal relationship
between fitness peak width and demonstrator quality. Can the authors envisage a natural
situation in which social learners in a wide peaked fitness landscape would not experience
differences in demonstrator quality compared to a narrow landscape?
Despite remaining unconvinced about the gains of constructing the analysis in this way, the
additional paragraph does make the assumptions clear and I see no barrier to publication.
pendix A
iewer: 1
mments to the Author(s)
s a clear and straightforward paper raising an important point about the structure of search
ces for cultural evolution.
wever, the normalization procedure used in testing the second hypothesis worries me.
analyses show quite clearly that the answer to the question "Do social learners perform equally
l in the wide and narrow conditions?" is simply that they do not. The narrow task is more difficult,
the difficulty of this task is not fully alleviated by the addition of social learning. Instead of
ving it at this the scores are normalized, dividing by the score of the highest scoring
onstrator. The original question is then conflated with the slightly different question "Do social
ners perform equally well in the wide and narrow conditions, when we control for demonstrator
formance which is a proxy for task difficulty."
wever, controlling for the relative difficulty of the conditions completely misses the point of the
inal hypothesis. Namely that social learning would "solve" this problem so well that social
ners would have similar payoffs in spite of the difference in difficulty between the conditions. The
lyses suggest that instead social learning provides only a partial "solution" to this learning
blem.
authors go on to present analyses showing that social learning does indeed help more in the
re difficult narrow condition than in the wide condition. These analyses illustrate the more
nced story I hope the authors will try to tell.
arrow is harder than wide,
ocial learning helps in both,
ocial learning helps more in the more difficult task,
ut not so much that performance is at ceiling and the social learners perform equally well in both
ks.
his may be because, as is often the case in lab studies of social learning, participants are utilizing
ial learning at a sub-optimal rate for the specific learning problem.
rything else about the paper is good.
thank the reviewer for their positive assessment, and useful recommendations. We have now altered the
ults and Discussion sections to reflect this more nuanced story. Specifically, we now:
resent both un-normalised and normalised score in Figure 3, rather than just the normalised as before, to
light the results pre-normalisation
e-written Results section (b) regarding Hypothesis H2, explicitly acknowledging the differing findings
ending on whether scores are normalised, including the following key text:
“On the basis of this comparison, we must reject H2, and conclude that while social learning is
of great help such that the difference between narrow and wide conditions is much smaller for
social learners than individual learners (compare Figure 3, left and middle panels), social
learning does not allow social learners in the narrow condition to fully match the performance
of social learners in the wide condition.”
e-written the second paragraph of the Discussion explicitly stating that H2 was only partially supported:
“Hypothesis H2, that social learners should perform equally well in both conditions, was
partially supported. Looking at the raw scores (Figure 3, middle), social learners in the narrow
condition performed much better relative to individual learners in the narrow condition, but still
not quite at the level of social learners in the wide condition. This shows that social learning
greatly ameliorates the difficulty of individual learning in narrow-peaked environments, but not
perfectly. Some of this shortcoming, however, was due to unavoidable differences in
demonstrator quality; when correcting for this, the difference in score between narrow and
wide social learners virtually disappeared (Figure 3, right).”
Changed the abstract to reflect the more nuanced conclusion:
“We show that individual learning is more difficult in the former condition, but that social
learners perform almost equally well in both narrow- and wide-peaked search spaces.”
iewer: 2
mments to the Author(s)
s empirical paper tests hypotheses derived from models of social learning, which suggest that a
row-peaked fitness landscape increases the benefit of social learning over individual learning
en compared with a wide-peaked fitness landscape. The authors generate three hypotheses,
ch they test using an established empirical paradigm. I have some comments regarding the
cifics of the experimental design as applied in this case (see below). I can recommend
eptance if these are resolved.
or comments
othesis H2. It seems that this hypothesis relies on the authors’ manipulation of the demonstrator
l. In a real-world scenario, if H1 is true and individual learning is harder in a narrow-peaked
ess landscape, then the social learners in this condition should, in turn, be less likely to find a
onstrator who has landed on the global optimum (at least in a finite population). By manipulating
demonstrator pool the authors have ensured that this is not the case and stacked the odds
ewhat in favour of H2. Can the authors provide a more thorough justification for this than that
vided on page 5, and a more detailed discussion of the implications for H2 and H3?
s correct that our hypothesis relies on our manipulation of the demonstrator pool, but we disagree that
stacks the odds in favour of H2. Given the importance of this point, we have added a new paragraph of
ification for this decision at the end of the Introduction immediately following the hypotheses, to make
as clear as possible.
hort, our justification is that a proper test of H2 requires that only the difficulty of individual learning is
ipulated across the two conditions. Hence our decision to use matched demonstrators. If we had used
al individual learners, then wide social learners would have been able to copy higher-scoring
onstrators than narrow social learners, as well as experience easier individual learning themselves.
sequently, if wide social learners had scored higher than narrow social learners, we would not know
ther this was because individual learning was easier or whether they simply had better demonstrators to
y. The latter - scoring higher because of better demonstrators - is interesting but not explicitly tied to our
arch question about landscape smoothness (some demonstrators might be better or worse simply by
nce, or individual differences). Hence our decision to use artificially-matched demonstrators, such that
difference could be solely attributed to the differences in individual learning caused by the landscapes.
t turned out, there were minor differences between the artificial demonstrators that were unavoidable,
these were corrected for, for the same reason.
is explained in the paper at the end of the Introduction:
“Note that in order to test H2 properly, we need to ensure that demonstrator performance
is matched across the two conditions (narrow and wide peaks), such that in both
conditions participants could potentially copy similarly high-scoring demonstrators.
Otherwise, differences in performance could simply arise from participants in the wide
condition having higher-scoring demonstrators to copy than participants in the narrow
condition. This would confound our intended manipulation: the landscape-generated
difficulty of individual learning experienced by social learners. We therefore used artificially-
generated demonstrators in both conditions such that demonstrator performance was
roughly matched (see Demonstrators section below). This ensured that the only difference
between the two conditions was the difficulty of individual learning (more difficult in the
narrow-peaked condition, assuming H1 is supported), and not differences in demonstrator
quality.”
othesis H3. Again this hypothesis makes sense only where the authors have ensured that the
l of demonstrators contains individuals that have reached the global maximum. Were that not the
e, would this hypothesis be valid?
hout running additional experiments we cannot answer this for sure, however as explained above with
ect to performance, we think that any differences in copying frequency that arise as a result of
erences in demonstrator quality are secondary compared to differences in copying arising from
erences in landscape-generated differences in individual learning difficulty.
ay be interesting to discuss the outcome for H3 in terms of the work on uncertainly and the
lihood of using social information (e.g. Morgan et al 2012). This work showed that uncertainty,
ch would be generated by the flat payoffs across much of the narrow fitness landscape should
an more social learning might be used.
is now added in the Introduction, as an alternative explanation of H2:
“A similar prediction can be derived from previous experimental work linking social
learning to the proximate factor of uncertainty [Morgan et al. 2012]: narrow
landscapes that provide little feedback in flat areas are likely to provoke uncertainty,
and therefore increase reliance on social learning.”
or comments
e 2. Line 6. Cite Heyes (1994) or her sources as the origin of your definition of social learning.
e also that this definition refers to ‘learning’ and not specifically to ‘changes in behaviour’.
es (1993) and Hoppitt & Laland (2013) are now cited as sources of our social learning definition.
e 2. Line 31 and Page 3 Line 16. ‘One of us’, ‘two of us’ is very informal. The convention would be
ite these papers as one would cite any others. This should be observed here, especially as other
hors were involved in the cited papers and the work cannot be ascribed to the authors of this
er alone.
rected.
e 10. Lines 36-44. The terminology here changes from that of optimality and local minima and
xima to that of ‘correct solutions’. This is a bit jarring as the paper mostly addresses complex
ess landscapes without one ‘correct solution’. This should be standardised.
rected one misleading use of ‘solution’, although we did not (and do not) stipulate that there can only be
solution: we use ‘solution’ as interchangeable with ‘optimum’ and ‘peak’.
itional changes
have also revised figures 2-5 to better illustrate the data, now showing boxplots and data points rather
n bar charts and error bars, and made various minor edits to the text for clarity.
Society Open
