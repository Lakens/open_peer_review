Big data integration shows Australian bush-fire frequency is
increasing significantly
Ritaban Dutta, Aruneema Das and Jagannath Aryal
Article citation details
R. Soc. open sci. 3: 150241.
http://dx.doi.org/10.1098/rsos.150241
Review timeline
Original submission: 2 June 2015 Note: Reports are unedited and appear as
Revised submission: 23 November 2015 submitted by the referee. The review history
Final acceptance: 12 January 2016 appears in chronological order.
Review History
label_version_1
RSOS-150241.R0 (Original submission)
label_author_1
Review form: Reviewer 1 (Arnab Chaudhuri)
Is the manuscript scientifically sound in its present form?
Yes
Are the interpretations and conclusions justified by the results?
Yes
Is the language acceptable?
Yes
Is it clear how to access all supporting data?
Yes Authors made supporting data available.
Yes supplementary material is adequate and clear to me.
Do you have any ethical concerns with this paper?
No
© 2016 The Authors. Published by the Royal Society under the terms of the Creative Commons
Attribution License http://creativecommons.org/licenses/by/4.0/, which permits unrestricted use,
provided the original author and source are credited
2
Have you any concerns about statistical analyses in this paper?
No
Recommendation?
label_recommendation_1
Accept with minor revision (please list in comments)
Comments to the Author(s)
label_comment_1
In this work, authors presented a reliable methodology for the prediction of bush fire incidence
on weekly temporal scale and on continental spatial scale. The manuscript is well organized and
substantiated with validations and interesting results. The ensemble method is well described
together with the exploitation of the climate data integration and the bush fire incidence data.
The manuscript presents a great way of summarizing the historical account of Australian major
bush fires in last decade, which has been used as ground truth data to validate the results.
Quantification of accuracy, specificity, sensitivity, false discovery rate and the graphical
presentation of weekly prediction error depict the capability of the new ensemble methodology.
Integrated data related to this study has been made public, which is a strong justification of the
paper being acceptable by the community. I recommend acceptance of the manuscript with few
minor revisions (see remarks below).
1. In caption of Figure 1, “of the fire intensity or severity level (as defined in Figure 1)” should be
revised. The classification of fire event is defined in Figure S2 rather than Figure 1.
2. “AWAP” first appeared in Method section with out giving the full form (which is given later in
Climatic Data Integration section).
3. C1, C2, C3 and C4 are introduced without defining it in Method section. Authors can redirect
readers to the relevant section for definition.
4. In Method section, what is “stage 2 in figure 3” ?
5. In caption of Figure 3, Table 1 and Table 2 should be Table S1 and Table S2.
label_author_2
Review form: Reviewer 2
Is the manuscript scientifically sound in its present form?
Yes
Are the interpretations and conclusions justified by the results?
No
Is the language acceptable?
No
Is it clear how to access all supporting data?
Yes
Do you have any ethical concerns with this paper?
No
Have you any concerns about statistical analyses in this paper?
No
Recommendation?
label_recommendation_2
Major revision is needed (please make suggestions in comments)
3
Comments to the Author(s)
label_comment_2
Manuscript ID: RSOS-150241
Journal: Royal Society Open Science
Title: Big data integration shows Australian bush-fire frequency is increasing significantly
Manuscript Type: Article
Comments:
By applying an ensemble method, the authors were able to predict the bush-fire frequency based
on the climate data. I think this is a very interesting topic and the research itself is quite strong.
My reading experience of this submission, however, was not very pleasant. I suggest the authors
make some more effort to polish the story line as well as the writing.
I also have the following a few concerns:
(1) I am not so sure whether you can make a claim of climatic change based on 5 years of
increasing bush-fire frequency, although I agree climate change is in action. Five active fire years
may still be a random event throughout the history, e.g. it could be the effect of some climatic
indices.
(2) Some terms used in the manuscripts were not properly defined, which may confuse the
readers (please see the comments I made on the attached file).
(3) Results were not properly introduced in the Methods section.
(4) I think the writing needs some major work before it is acceptable.
(5) I am not sure whether this study is qualified for “big data” analysis…
label_author_3
Review form: Reviewer 3 (Ben Bond-Lamberty)
Is the manuscript scientifically sound in its present form?
No
Are the interpretations and conclusions justified by the results?
No
Is the language acceptable?
No
Is it clear how to access all supporting data?
Yes.
Do you have any ethical concerns with this paper?
No
Have you any concerns about statistical analyses in this paper?
Yes
Recommendation?
label_recommendation_3
Major revision is needed (please make suggestions in comments)
Comments to the Author(s)
label_comment_3
General comments
This manuscript discusses an effort to train machine-learning algorithms for the prediction of
Australian bush fires, based on a wide suite of input data: climate, fuel, soil moisture, wind
speed, etc. Such data-driven approaches have proven their worth in a wide variety of fields
4
(Jordan and Mitchell 2015), and the enormous effects of such fires make their prediction, and a
better understanding of their drivers, quite important.
There are many problems here, though. First, the ms is difficult to read: confusingly structured,
formatted unhelpfully; and while I appreciate the difficulties of writing in a foreign language, the
current manuscript has generally minor but distracting grammatical errors throughout.
Second, the ms needs to better set the context (in the introduction) and discuss the implications of
the results (in fact, there is no discussion at all). Give the readers more information about
Australian bush fires–their drivers, and importance–as well as data-driven machine learning
algorithms. Right now this ms reads like a poorly written technical report.
Side note: I’m not sure this qualifies as “big data” – none of these data sources seems particularly
large – do the authors feel this is the correct term to use in the title?
The methods section is, again, poorly and confusingly structured. See comments below.
Finally, the model evaluation seems to me quite inadequate. The authors have a particular
definition of performance they’re using, but it would be really useful to see e.g.
observed:predicted plots, assessment of model biases, etc. The maps of Figure 4 aren’t
particularly useful, and not a good way to assess performance. I don’t think the ms, as currently
written, can support its title (“increasing significantly”).
In summary, there are points of interest here, but every part of this ms needs extensive and
fundamental revisions for clarity, language, and better evaluation of model performance.
Reference: Jordan, M. I. and T. M. Mitchell (2015). "Machine learning: Trends, perspectives, and
prospects." Science 349: 255-260.
Specific comments
1. Please double-space and number lines. Line numbers below refer to those added to PDF
by the journal
2. Page 1, lines 13, 24, and throughout: odd English grammar, confusing terminology
3. P. 1, L. 41: this (“The main motivation of this research…”) should start a new paragraph
at the end of the introduction
4. P. 1: introduction needs some basic material on machine learning algorithms, data-
driven studies, etc.
5. P. 2: the Methods section starts very oddly–this first paragraph is really out of place. The
second, more general, paragraph would be a better way to introduce readers to methodology
6. P. 2, l. 47-54: please provide citation(s) for this method for assessing model accuracy. It
seems very minimal; what about bias?
7. P. 3, l. 12: what does “integrated” mean in this paragraph? Mathematical integration?
Collected together? Clarify
8. P. 4, l. 1-2: unclear. How do major fire events make your data more valuable?
9. P. 4, l. 17: unclear. Why can’t is be “synchronized”? (And what does this term mean
here?)
10. P. 5: “Technical Validation” should perhaps be “Results”?
11. P. 5, l. 40: “fold”. This is confusing; here you say a 10-fold cross-validation, while on p. 2
you say 50% training, 50% validation. I assume these apply to the two different layers of the
analysis, but would be helpful to clarify
12. Supplementary info is well done. Figshare data is present (although I did not download
it).
5
label_author_4
Review form: Reviewer 4
Is the manuscript scientifically sound in its present form?
No
Are the interpretations and conclusions justified by the results?
No
Is the language acceptable?
No
Is it clear how to access all supporting data?
Yes.
Do you have any ethical concerns with this paper?
No
Have you any concerns about statistical analyses in this paper?
Yes
Recommendation?
label_recommendation_4
Major revision is needed (please make suggestions in comments)
Comments to the Author(s)
label_comment_4
A note about the reviewing questions above: in the current exposition, the paper is lacking clear,
technical explanations that would allow this reviewer to conclude favorably on the following
questions. It is possible that with a major revision, these could be improved.
- Is the manuscript scientifically sound in its present form?
- Are the interpretations and conclusions justified by the results?
- Does the manuscript provide a useful contribution to the literature?
- Have you any concerns about statistical analyses in this paper?
------
Main comments:
On the positive side, a significant amount of work clearly went into this research project, and
there might be some interesting findings here; machine learning approaches to such important
problems are worth pursuing.
Unfortunately, the present submission is not ready for a journal publication. The submission does
not read like a journal paper, making it very difficult to review, and assess the significance of the
contribution. It instead reads as a disorganized compilation of exhaustive details, figures, and
tables.
Extensive care should be taken to revise this into a strong narrative, which presents and justifies
the work in a logical order. A revamping of the exposition would give the authors the ability to
explain and justify the significance of their contribution. In the current form, it seems like a raw
manuscript that is unlikely to attract the interest of readers.
6
The paper also suffers from some major technical concerns raised below. Perhaps they will
become resolved and clarified in the major revision of the exposition. However it is also likely
that the experimental framework needs to be significantly robustified.
Technical concerns:
The reported data sets seem to be too small for applying deep learning, especially using the size
of the network that was stated (100 layers of 100 nodes each). Therefore, it is likely that there was
overfitting in the stated results. Further justification and explanation must be added, e.g. did you
augment your data size beyond 704, and if so, how? If not, the experimental framework likely
needs to be redesigned.
What does the following mean: is this an input parameter, or the output?
"Reconstruction error from the RBMs WAS VARIED between 5%-12%.”
Please describe how you used bagging on this time-series data. This is a non-trivial problem.
Please be more specific about your validation, i.e. provide formulas for sensitivity, specificity, etc.
Earlier in the paper you said you did validation using a long list of supervised learning methods.
How were those methods tuned?
How do you justify your title quantitatively? These results are not currently clear from the
figures. E.g. what period are you comparing to, for your statement of “increasing”?
Comments about exposition:
The paper is not well-written. In addition to the concerns raised above, the language does not
read smoothly and should be carefully edited. Grammatical errors are prevalent. Throughout the
paper, long blocks of text should be broken up into more reasonably-sized paragraphs.
label_end_comment
Decision letter (RSOS-150241)
26-Oct-2015
Dear Dr Dutta,
The editors assigned to your paper ("Big data integration shows Australian bush-fire frequency is
increasing significantly") has now received comments from reviewers. We would like you to
revise your paper in accordance with the referee and Subject Editor suggestions which can be
found below (not including confidential reports to the Editor). Please note this decision does not
guarantee eventual acceptance.
Please submit a copy of your revised paper within three weeks (i.e. by the 18-Nov-2015). If we do
not hear from you within this time then it will be assumed that the paper has been withdrawn. In
exceptional circumstances, extensions may be possible if agreed with the Editorial Office in
advance.We do not allow multiple rounds of revision so we urge you to make every effort to
fully address all of the comments at this stage. If deemed necessary by the Editors, your
manuscript will be sent back to one or more of the original reviewers for assessment. If the
original reviewers are not available we may invite new reviewers.
To revise your manuscript, log into http://mc.manuscriptcentral.com/rsos and enter your
Author Centre, where you will find your manuscript title listed under "Manuscripts with
7
Decisions." Under "Actions," click on "Create a Revision." Your manuscript number has been
appended to denote a revision. Revise your manuscript and upload a new version through your
Author Centre.
When submitting your revised manuscript, you must respond to the comments made by the
referees and upload a file "Response to Referees" in "Section 6 - File Upload". Please use this to
document how you have responded to the comments, and the adjustments you have made. In
order to expedite the processing of the revised manuscript, please be as specific as possible in
your response.
In addition to addressing all of the reviewers' and editor's comments please also ensure that your
revised manuscript contains the following sections as appropriate before the reference list:
• Ethics statement (if applicable)
If your study uses humans or animals please include details of the ethical approval received,
including the name of the committee that granted approval. For human studies please also detail
whether informed consent was obtained. For field studies on animals please include details of all
permissions, licences and/or approvals granted to carry out the fieldwork.
• Data accessibility
It is a condition of publication that all supporting data are made available either as
supplementary information or preferably in a suitable permanent repository. The data
accessibility section should state where the article's supporting data can be accessed. This section
should also include details, where possible of where to access other relevant research materials
such as statistical tools, protocols, software etc can be accessed. If the data has been deposited in
an external repository this section should list the database, accession number and link to the DOI
for all data from the article that has been made publicly available. Data sets that have been
deposited in an external repository and have a DOI should also be appropriately cited in the
manuscript and included in the reference list.
If you wish to submit your supporting data or code to Dryad (http://datadryad.org/), or modify
your current submission to dryad, please use the following link:
http://datadryad.org/submit?journalID=RSOS&manu=RSOS-150241
• Competing interests
Please declare any financial or non-financial competing interests, or state that you have no
competing interests.
• Authors’ contributions
All submissions, other than those with a single author, must include an Authors’ Contributions
section which individually lists the specific contribution of each author. The list of Authors
should meet all of the following criteria; 1) substantial contributions to conception and design, or
acquisition of data, or analysis and interpretation of data; 2) drafting the article or revising it
critically for important intellectual content; and 3) final approval of the version to be published.
All contributors who do not meet all of these criteria should be included in the
acknowledgements.
We suggest the following format:
AB carried out the molecular lab work, participated in data analysis, carried out sequence
alignments, participated in the design of the study and drafted the manuscript; CD carried out
the statistical analyses; EF collected field data; GH conceived of the study, designed the study,
8
coordinated the study and helped draft the manuscript. All authors gave final approval for
publication.
• Acknowledgements
Please acknowledge anyone who contributed to the study but did not meet the authorship
criteria.
• Funding statement
Please list the source of funding for each author.
Once again, thank you for submitting your manuscript to Royal Society Open Science and I look
forward to receiving your revision. If you have any questions at all, please do not hesitate to get
in touch.
Yours sincerely,
Emilie Aime
Senior Publishing Editor, Royal Society Open Science
on behalf of Jon Blundy
Subject Editor, Royal Society Open Science
openscience@royalsociety.org
Author's Response to Decision Letter for (RSOS-150241)
See Appendix A.
Reviewer: 1
Comments to the Author(s)
In this work, authors presented a reliable methodology for the prediction of bush fire
incidence on weekly temporal scale and on continental spatial scale. The manuscript
is well organized and substantiated with validations and interesting results. The
ensemble method is well described together with the exploitation of the climate data
integration and the bush fire incidence data. The manuscript presents a great way of
summarizing the historical account of Australian major bush fires in last decade,
which has been used as ground truth data to validate the results. Quantification of
accuracy, specificity, sensitivity, false discovery rate and the graphical presentation of
weekly prediction error depict the capability of the new ensemble methodology.
Integrated data related to this study has been made public, which is a strong
justification of the paper being acceptable by the community. I recommend
acceptance of the manuscript with few minor revisions (see remarks below).
Response: Thanks for positive comments and suggestions; we’ve now corrected our
manuscript according to the following recommendations.
1. In caption of Figure 1, “of the fire intensity or severity level (as defined in Figure
1)” should be revised. The classification of fire event is defined in Figure S2 rather
than Figure 1.
Response: This has now been corrected to Figure S2-S17.
2. “AWAP” first appeared in Method section with out giving the full form (which is
given later in Climatic Data Integration section).
Response: Full name of AWAP has now been provided in Method section.
3. C1, C2, C3 and C4 are introduced without defining it in Method section. Authors
can redirect readers to the relevant section for definition.
Response: We have now added reference to the section called Observations on Bush-
Fire Frequency Increment
in the Method section to redirect reader for the definitions of C1-C4.
4. In Method section, what is “stage 2 in figure 3” ?
Response: It has now been corrected to “stage 2 in Figure 1”.
5. In caption of Figure 3, Table 1 and Table 2 should be Table S1 and Table S2.
Response: It has now been corrected to Table S1 and Table S2, to redirect readers
towards the supplementary information.
Reviewer: 2
Comments:
By applying an ensemble method, the authors were able to predict the bush-fire
frequency based on the climate data. I think this is a very interesting topic and the
research itself is quite strong. My reading experience of this submission, however,
was not very pleasant. I suggest the authors make some more effort to polish the story
line as well as the writing.
Response: Thanks for the positive comments and recommendations. Overall writing
of the manuscript has now been modified and improved to highlight the essence of the
very interesting topic stronger.
I also have the following a few concerns:
(1) I am not so sure whether you can make a claim of climatic change based on 5
years of increasing bush-fire frequency, although I agree climate change is in action.
Five active fire years may still be a random event throughout the history, e.g. it could
be the effect of some climatic indices.
Response: It’s a much-debated topic, but in this study we intended to showcase a
novel application of machine learning for a very interesting topic. Thanks for agreeing
that climate change is in action, more severely in recent times than before, and that
should be reported in journal like Royal Society Open Science. In our case we have
used 336 weeks of data (spread over last 8 years anyway) to develop a weekly
prediction model, hence temporal resolution was significantly higher, supported and
represented by available data. Moreover the sudden change in bush-fire frequency is a
unique observation from this study, which was not present in the past, e.g. 10 years
ago. So studying older data than 2007, in our case was not really appropriate. New
observations can be reported from a small amount of climatic data, as there is no
evidence that only decade long studies are suitable to highlight global climate changes
of recent time.
(2) Some terms used in the manuscripts were not properly defined, which may
confuse the readers (please see the comments I made on the attached file).
Response: Thanks for pointing this, we have worked on this and believe that all
terminologies are rectified now.
(3) Results were not properly introduced in the Methods section.
Response: It has now been fully restructured and rewritten.
(4) I think the writing needs some major work before it is acceptable.
Response: Thanks for the positive comments and recommendations. Overall writing
of the manuscript has now been modified and improved to highlight the essence of the
very interesting topic stronger.
Response: It’s a much-debated topic again, and we’d like to call this a big data
analytics work, as processed data (which we’ve made available) volume might not be
in the TB range, but original data that we handled on our cloud system was in the
range of 10TB, as we needed 7 years data from MODIS and LANDAT products. Also
we’d like mention that in our view data could also be called ‘Big’ if it represents
‘Big’ knowledge, context or topic of bigger socio-economic need.
Reviewer: 3
Comments to the Author(s)
General comments
This manuscript discusses an effort to train machine-learning algorithms for the
prediction of Australian bush fires, based on a wide suite of input data: climate, fuel,
soil moisture, wind speed, etc. Such data-driven approaches have proven their worth
in a wide variety of fields (Jordan and Mitchell 2015), and the enormous effects of
such fires make their prediction, and a better understanding of their drivers, quite
important.
There are many problems here, though. First, the ms is difficult to read: confusingly
structured, formatted unhelpfully; and while I appreciate the difficulties of writing in
a foreign language, the current manuscript has generally minor but distracting
grammatical errors throughout.
Response: Thanks for the positive comments and recommendations. Overall writing
of the manuscript has now been modified and improved to highlight the essence of the
very interesting topic stronger.
Second, the ms needs to better set the context (in the introduction) and discuss the
implications of the results (in fact, there is no discussion at all). Give the readers more
information about Australian bush fires–their drivers, and importance–as well as data-
driven machine learning algorithms. Right now this ms reads like a poorly written
technical report.
Response: Two new paragraphs are now added to this background section to
introduce readers to machine learning etc. We have also rewritten parts of all sections
to link the story lined better. A new discussion paragraph has now been added in the
Method section to highlight the potential application of this study in the context of
Australian bush-fire.
Side note: I’m not sure this qualifies as “big data” – none of these data sources seems
particularly large – do the authors feel this is the correct term to use in the title?
Response: It’s a much-debated topic again, and we’d like to call this a big data
analytics work, as processed data (which we’ve made available) volume might not be
in the TB range, but original data that we handled on our cloud system was in the
range of 10TB, as we needed 7 years data from MODIS and LANDAT products. Also
we’d like mention that in our view data could also be called ‘Big’ if it represents
Response: It has now been fully restructured and rewritten.
Finally, the model evaluation seems to me quite inadequate. The authors have a
particular definition of performance they’re using, but it would be really useful to see
e.g. observed:predicted plots, assessment of model biases, etc. The maps of Figure 4
aren’t particularly useful, and not a good way to assess performance. I don’t think the
ms, as currently written, can support its title (“increasing significantly”).
Response: our contribution was designed to be used to more accurately develop fire
incidence outcomes for climate scenarios. For example, if we assume particular
climate changes for 2030, we can adjust our climate surfaces and estimate their
implications for patterns of fire incidence. If we assume a late monsoon incidence, we
can estimate its likely influence on the patterning of fire in northern Australia. We
thought that we had made this aim highly explicit when we wrote: ‘Our major aim in
undertaking the work reported in the present paper was to develop an accurate system
for predicting weekly wildfire incidence from readily available monthly average
climatic conditions, in order to be able to refine our understanding of the implications
of climate change for fire regimes.’ We obviously had not made our aim clear
enough. We have therefore substituted the word ‘hot-spot estimation’ for the word
‘prediction’ throughout the text.
As described in the sub section ‘Observations on Bush-Fire Frequency Increment’,
Figure 3, and supported by Figure 4 and Figure S2-S17, quantification of increment of
bush-fire frequency was on average 40% over last 7 years, hence we believe
justification of title (“increasing significantly”). It could be debated in the community
as in general climate change is a topic some take seriously, but other tend to avoid
completely.
In summary, there are points of interest here, but every part of this ms needs extensive
and fundamental revisions for clarity, language, and better evaluation of model
performance.
Reference: Jordan, M. I. and T. M. Mitchell (2015). "Machine learning: Trends,
perspectives, and prospects." Science 349: 255-260.
Response: Thanks for the positive comments and recommendations. We have
improved the manuscript significantly and the manuscript above has now been added
to our reference list with reference (no. 17) in the introduction section.
Specific comments
1. Please double-space and number lines. Line numbers below refer to those added
to PDF by the journal
Response: We believe this will be rectified and edited in the final manuscript proof
upon acceptance.
Response: This has now been rectified.
3. P. 1, L. 41: this (“The main motivation of this research…”) should start a new
paragraph at the end of the introduction
Response: This is now a new paragraph with a fresh start as suggested.
4. P. 1: introduction needs some basic material on machine learning algorithms,
data-driven studies, etc.
Response: Two new paragraphs are now added to this background section to
introduce readers to machine learning etc.
5. P. 2: the Methods section starts very oddly–this first paragraph is really out of
place. The second, more general, paragraph would be a better way to introduce
readers to methodology
Response: The whole methodology section is now completely restructured and
rewritten to improve the story line, with new titles and redirection of the textual flow.
6. P. 2, l. 47-54: please provide citation(s) for this method for assessing model
accuracy. It seems very minimal; what about bias?
Response: citation and reference to the technical validity section has been added,
which is also part of the methodology section.
7. P. 3, l. 12: what does “integrated” mean in this paragraph? Mathematical
integration? Collected together? Clarify
Response: This “integrated” means collected together before the machine learning
experiments. We have restructured the method section accordingly.
8. P. 4, l. 1-2: unclear. How do major fire events make your data more valuable?
Response: This sub section has now been renamed as ground truths; major fire events
were used to benchmark the data as well recorded ground truth point on long history.
Historical accountability was essential to highlight the success of prediction /
estimation from a model derived from the study.
We have also added “...Idea behind highlighting of these major fire events within our
data set was primarily to show that we are not just working on any data but a cross-
validated data according to the real historical facts. It was aimed that if the newly
developed ensemble of deep learning mechanism could predict the major events with
higher generalization and repeatability, confidence on such a predictive system would
be significant. From the historical event records, climatic conditions around the major
Australian bush-fire were critical in our study, to capture as ground truth and model
that information for future hot-spot estimations.”
9. P. 4, l. 17: unclear. Why can’t is be “synchronized”? (And what does this term
mean here?)
Response: Although this is the main results section, but based on Royal Society Open
Science journal regulations, this has to be called as “Technical Validation” section.
11. P. 5, l. 40: “fold”. This is confusing; here you say a 10-fold cross-validation,
while on p. 2 you say 50% training, 50% validation. I assume these apply to the two
different layers of the analysis, but would be helpful to clarify
Response: Thanks for this; yes it was written in a confusing manner. We have
removed the 10-fold statement, as major validation was done based on randomization
of the whole data set and then a 50%-50% split for training and testing, as described.
12. Supplementary info is well done. Figshare data is present (although I did not
download it).
Response: Thanks.
Reviewer: 4
Comments to the Author(s)
A note about the reviewing questions above: in the current exposition, the paper is
lacking clear, technical explanations that would allow this reviewer to conclude
favorably on the following questions. It is possible that with a major revision, these
could be improved.
- Is the manuscript scientifically sound in its present form?
- Are the interpretations and conclusions justified by the results?
- Does the manuscript provide a useful contribution to the literature?
- Have you any concerns about statistical analyses in this paper?
------
Main comments:
On the positive side, a significant amount of work clearly went into this research
project, and there might be some interesting findings here; machine learning
approaches to such important problems are worth pursuing.
Unfortunately, the present submission is not ready for a journal publication. The
submission does not read like a journal paper, making it very difficult to review, and
assess the significance of the contribution. It instead reads as a disorganized
compilation of exhaustive details, figures, and tables.
Extensive care should be taken to revise this into a strong narrative, which presents
and justifies the work in a logical order. A revamping of the exposition would give
Response: Thanks for the positive comments and recommendations. Overall writing
of the manuscript has now been modified and improved to highlight the essence of the
very interesting topic stronger. The whole methodology section is now completely
restructured and rewritten to improve the story line, with new titles and redirection of
the textual flow. Two new paragraphs are now added to this background section to
introduce readers to machine learning etc. We have also rewritten parts of all sections
to link the story lined better. A new discussion paragraph has now been added in the
Method section to highlight the potential application of this study in the context of
Australian bush-fire.
The paper also suffers from some major technical concerns raised below. Perhaps
they will become resolved and clarified in the major revision of the exposition.
However it is also likely that the experimental framework needs to be significantly
robustified.
Response: Thanks. We presume that the statement about scientific defensibility was
made in the context of the misperception of our aims. The statement about data
uncertainties relates to inaccuracies at the spatiotemporal scale of collection which we
have overcome through generalisation, as indicated by the high levels of prediction /
estimation accuracy of our models, which in our revised version were NOT overfitted,
as has been accepted by the other reviewers.
Our contribution was designed to be used to more accurately develop fire incidence
outcomes for climate scenarios. For example, if we assume particular climate changes
for 2030, we can adjust our climate surfaces and estimate their implications for
patterns of fire incidence. If we assume a late monsoon incidence, we can estimate its
likely influence on the patterning of fire in northern Australia. We thought that we
had made this aim highly explicit when we wrote: ‘Our major aim in undertaking the
work reported in the present paper was to develop an accurate system for predicting
weekly wildfire incidence from readily available monthly average climatic conditions,
in order to be able to refine our understanding of the implications of climate change
for fire regimes.’ We obviously had not made our aim clear enough. We have
therefore substituted the word ‘hot-spot estimation’ for the word ‘prediction’
throughout the text.
Technical concerns:
The reported data sets seem to be too small for applying deep learning, especially
using the size of the network that was stated (100 layers of 100 nodes each).
Therefore, it is likely that there was overfitting in the stated results. Further
justification and explanation must be added, e.g. did you augment your data size
beyond 704, and if so, how? If not, the experimental framework likely needs to be
redesigned.
Response: It’s a much-debated topic again, and we’d like to call this a big data
analytics work, as processed data (which we’ve made available) volume might not be
in the TB range, but original data that we handled on our cloud system was in the
range of 10TB, as we needed 7 years data from MODIS and LANDAT products. Also
we’d like mention that in our view data could also be called ‘Big’ if it represents
but to showcase a novel application of machine learning for a greater cause, e.g. bush-
fire hot-spot prediction.
We have also added the following text in the new ‘Machine Learning Experiments’
sub section regarding concern on overfitting issue, “...Our use of independent data
sets for training and testing is the most widely used means of overcoming potential
problems with overfitting. These strategies overcame the problem of the many
imperfections of the MODIS fire incidence observations at the spatiotemporal scale of
their collection.”
What does the following mean: is this an input parameter, or the output?
"Reconstruction error from the RBMs WAS VARIED between 5%-12%.”
Response: Not sure about this comment or confusion, as we have clearly described in
the newly restructured ‘Machine Learning Experiments’ section that,
“We used a gridded matrix of 704 rows and 817 columns for all input data sources.
Six data segmentation regions were used for training and testing the network (Figure
S1). The segments S1, S2, S4 and S5 have 335 rows and 300 columns. The segments
S3 and S6 have 335 rows and 213 columns. The map-based image data (training
inputs, testing inputs and training targets) were segmented into six smaller regions to
maximize the learning speed while training and optimizing the computational
memory usage. Six dedicated Deep Belief Networks (of size 100 X 100 hidden nodes
using Restricted Boltzmann Machines (RBM)) for each of these segments (S1-S6 in
Figure S1) were trained and weights were extracted individually.” In our knowledge
reconstruction error is a widely accepted performance indicator for RBMs.
Please describe how you used bagging on this time-series data. This is a non-trivial
problem.
Response: Not sure about this comment or confusion, as we have clearly described in
the newly restructured ‘Machine Learning Experiments’ section that, input and target
output, all were image data, surface maps, hence we had no time series data!
Ensemble bagging was used as a supervised learner and classifier in the second stage
of the framework, without any particular emphasis on particular tuning aspects of the
bagging process.
Please be more specific about your validation, i.e. provide formulas for sensitivity,
specificity, etc. Earlier in the paper you said you did validation using a long list of
supervised learning methods. How were those methods tuned?
Response: Not sure about this comment or confusion, as we have clearly described
provided all equations that were used to calculate sensitivity, specificity, F1 scoring
and False Discovery, in the newly restructured ‘Machine Learning Experiments’
section.
We have now also added, “...Methods were tuned using an independent optimization
process based on individual methods’ estimation performances. Summery of the
results are listed in the table S2 in the supplementary information document.”, to
redirect readers to the best results in an obvious manner.
We have also stated in the Method section that, “...Extracted weights from this
unsupervised training stage were used to form an integrated and dimensionally
reduced representation of the climatic data. These integrated weights were also used
to tune the supervised learning phase, as described in the methods section of the
the figures. E.g. what period are you comparing to, for your statement of
“increasing”?
Response: As described in the sub section ‘Observations on Bush-Fire Frequency
Increment’, Figure 3, and supported by Figure 4 and Figure S2-S17, quantification of
increment of bush-fire frequency was on average 40% over last 7 years, hence we
believe justification of title (“increasing significantly”). It could be debated in the
community, as in general climate change is a topic some take seriously, but other
tends to avoid completely.
We have also added “...Estimated average bush-fire event frequency over the whole
continent of Australia was 3284 per week in 2007, in comparison to the frequency of
5484 events per week in 2013. This shows that weekly bush-fire frequencies for the
Australian major climatic zones have increased by 40% since 2007.”
Comments about exposition:
The paper is not well-written. In addition to the concerns raised above, the language
does not read smoothly and should be carefully edited. Grammatical errors are
prevalent. Throughout the paper, long blocks of text should be broken up into more
reasonably-sized paragraphs.
Response: Thanks for the recommendations. Overall writing of the manuscript has
now been modified and improved to highlight the essence of the very interesting topic
stronger. The whole methodology section is now completely restructured and
rewritten to improve the story line, with new titles and redirection of the textual flow.
Two new paragraphs are now added to this background section to introduce readers to
machine learning etc. We have also rewritten parts of all sections to link the story
lined better. A new discussion paragraph has now been added in the Method section
to highlight the potential application of this study in the context of Australian bush-
fire.
Society Open
