Error rate on the director’s task is influenced by the need to
take another’s perspective but not the type of perspective
Edward W. Legg, Laure Olivier, Steven Samuel, Robert Lurz and Nicola S. Clayton
Article citation details
R. Soc. open sci. 4: 170284.
http://dx.doi.org/10.1098/rsos.170284
Review timeline
Original submission: 28 March 2017 Note: Reports are unedited and appear as
Revised submission: 14 July 2017 submitted by the referee. The review history
Final acceptance: 17 July 2017 appears in chronological order.
Review History
label_version_1
RSOS-170284.R0 (Original submission)
label_author_1
Review form: Reviewer 1
Is the manuscript scientifically sound in its present form?
Yes
Are the interpretations and conclusions justified by the results?
Yes
Is the language acceptable?
Yes
Is it clear how to access all supporting data?
Yes
Do you have any ethical concerns with this paper?
No
Have you any concerns about statistical analyses in this paper?
No
© 2017 The Authors. Published by the Royal Society under the terms of the Creative Commons
Attribution License http://creativecommons.org/licenses/by/4.0/, which permits unrestricted use,
provided the original author and source are credited
2
Recommendation?
label_recommendation_1
Accept with minor revision (please list in comments)
Comments to the Author(s)
label_comment_1
File attached. (Appendix A)
label_author_2
Review form: Reviewer 2
Is the manuscript scientifically sound in its present form?
Yes
Are the interpretations and conclusions justified by the results?
Yes
Is the language acceptable?
Yes
Is it clear how to access all supporting data?
Yes
Do you have any ethical concerns with this paper?
No
Have you any concerns about statistical analyses in this paper?
No
Recommendation?
label_recommendation_2
Accept with minor revision (please list in comments)
Comments to the Author(s)
label_comment_2
This manuscript describes an online study, which employs a well-known perspective taking
paradigm, the Director task. In a between-subjects study, adult participants are required to
complete one out of three versions of the task. The first one is referred to as a level 1 perspective
taking task (L1 task), a second which purports to measure level 2 perspective taking (L2 task) and
a third one is a control task that requires participants to follow a rule (i.e., ignore the opaque
barriers, Rule task). The study replicates previous findings that participants make more errors in
the version of the task when there is a ‘director’ present behind the grid compared to following a
rule when the director figure is removed. However, they found no differences in error rates
between L1 (judging whether an object is seen or not by another person) and L2 (judging how an
object appears to some else). The manuscript is well-written, with clear and concise language.
However, I have a few comments below that the authors could address.
1. Although it is encouraging that the key findings from previous studies are replicated
(i.e., larger error rates in the L1 version of the task compared to the rule version of the task), the
online nature of the study poses some issues that deserve to be considered by the authors. For
example, how can the researchers ensure participants fully understood what was required of
them when performing the task. If participants were unclear, the researcher was not there with
them to answer questions or clarify what participants were required to do. Related to this, the
authors mention that 9 participants were excluded from the analysis for failing to understand the
effect of the barriers used in the task, but don’t provide any further information. Can the authors
3
provide further information about what was the manipulation check at the end of the
experiment?
2. I commend the authors in the use of non-parametric tests to analyse their data. However,
can the authors specify if the post-hoc comparisons are Bonferroni corrected?
3. In the analysis of the ambiguous trials the authors say that error rates were similar across
the L1 and L2 task. However, what the analysis revealed is a trend towards significance (p.08),
with L1 error rates at 10.4 and in L2 at 3.5. Therefore, perhaps the authors could tone down the
claim that these error rates are similar and acknowledge a significant trend.
4. Since Masangkay et al. (1974) and Flavell et al. (1981)’s work distinguishing between
level 1 and level 2 perspective taking, it is widely accepted that level 1 abilities emerge earlier in
development than level 2. Therefore, the findings from this study that the error rates between the
two versions of the task in both ambiguous and relational trials, are numerically larger in the L1
task, although not significantly so, than in L2 is intriguing. Would the authors consider the
possibility that perhaps performance on this task might not be driven by inferences about what
the other person (the director) can see or how they see it and instead the colour of the transparent
covers in L2 are more salient than those in L1, making the former less prone to errors? This seems
to be the only visible difference between the stimuli in the 2 tasks. Could the authors provide an
example of the images of the shelves from the Director’s perspective (for both opaque and
translucent barriers? Perhaps these images could be added as supplementary material?
5. Related to the above, in the Discussion, the authors claim that their results support
previous findings that in the director task, participants are less prone to errors when following
rules than when required to adopt another’s perspective. In my opinion, this is a strong claim to
make in a between-subjects study, carried out online. Under such conditions, the experimenters
cannot even be sure if, for example, the participant was receiving any help from another person
while performing either of the tasks.
6. When this task has been administered to adults in previous studies, participants are
frequently asked not just to select the object (as they do here) but also to move it to another slot.
Although sometimes only object selection (rather than selection and movement) is included in the
analysis. Asking participants to just click on the object makes the task easier than previous
versions. One of the authors argument in the discussion is that ceiling effects could have
influenced the results because the error rates tend to be extremely low. I would have agreed with
the ‘ceiling effect’ comment based on how easy the task was, as participants only had to click on
the correct slot. However, I disagree with the reasoning that the error rates were extremely low.
For example, in relational trials, the error rate in L1 was 21.25% and 16.50% in L2, these are
hardly ‘extremely low’ error rates.
7. Finally, the interpretation of the findings in the discussion is rather confusing. On one
the hand the authors say that their results provide support to the previous findings that error
rates in this task are linked to the need to infer another’s perspective and on the other hand (in
the same – final – sentence) they propose that these errors do not come about because participants
have difficulty to infer another’s perspective. Perhaps the authors could explain this? If the error
rates are related but not caused by the requirement to make inferences, then what could be
causing such error rates in the L1 and L2 tasks? If it is something other than making inferences,
then is this task an appropriate measure of perspective taking?
4
label_end_comment
Decision letter (RSOS-170284)
27-Jun-2017
Dear Dr Legg
On behalf of the Editors, I am pleased to inform you that your Manuscript RSOS-170284 entitled
"Error rate on the director’s task is influenced by the need to take another’s perspective but not
the type of perspective" has been accepted for publication in Royal Society Open Science subject
to minor revision in accordance with the referee suggestions. Please find the referees' comments
at the end of this email.
The reviewers and handling editors have recommended publication, but also suggest some minor
revisions to your manuscript. Therefore, I invite you to respond to the comments and revise your
manuscript.
• Ethics statement
If your study uses humans or animals please include details of the ethical approval received,
including the name of the committee that granted approval. For human studies please also detail
whether informed consent was obtained. For field studies on animals please include details of all
permissions, licences and/or approvals granted to carry out the fieldwork.
• Data accessibility
It is a condition of publication that all supporting data are made available either as
supplementary information or preferably in a suitable permanent repository. The data
accessibility section should state where the article's supporting data can be accessed. This section
should also include details, where possible of where to access other relevant research materials
such as statistical tools, protocols, software etc can be accessed. If the data has been deposited in
an external repository this section should list the database, accession number and link to the DOI
for all data from the article that has been made publicly available. Data sets that have been
deposited in an external repository and have a DOI should also be appropriately cited in the
manuscript and included in the reference list.
If you wish to submit your supporting data or code to Dryad (http://datadryad.org/), or modify
your current submission to dryad, please use the following link:
http://datadryad.org/submit?journalID=RSOS&manu=RSOS-170284
• Competing interests
Please declare any financial or non-financial competing interests, or state that you have no
competing interests.
• Authors’ contributions
All submissions, other than those with a single author, must include an Authors’ Contributions
section which individually lists the specific contribution of each author. The list of Authors
should meet all of the following criteria; 1) substantial contributions to conception and design, or
acquisition of data, or analysis and interpretation of data; 2) drafting the article or revising it
critically for important intellectual content; and 3) final approval of the version to be published.
All contributors who do not meet all of these criteria should be included in the
acknowledgements.
We suggest the following format:
AB carried out the molecular lab work, participated in data analysis, carried out sequence
alignments, participated in the design of the study and drafted the manuscript; CD carried out
the statistical analyses; EF collected field data; GH conceived of the study, designed the study,
5
coordinated the study and helped draft the manuscript. All authors gave final approval for
publication.
• Acknowledgements
Please acknowledge anyone who contributed to the study but did not meet the authorship
criteria.
• Funding statement
Please list the source of funding for each author.
Please note that we cannot publish your manuscript without these end statements included. We
have included a screenshot example of the end statements for reference. If you feel that a given
heading is not relevant to your paper, please nevertheless include the heading and explicitly state
that it is not relevant to your work.
Because the schedule for publication is very tight, it is a condition of publication that you submit
the revised version of your manuscript within 7 days (i.e. by the 06-Jul-2017). If you do not think
you will be able to meet this date please let me know immediately.
To revise your manuscript, log into https://mc.manuscriptcentral.com/rsos and enter your
Author Centre, where you will find your manuscript title listed under "Manuscripts with
Decisions". Under "Actions," click on "Create a Revision." You will be unable to make your
revisions on the originally submitted version of the manuscript. Instead, revise your manuscript
and upload a new version through your Author Centre.
When submitting your revised manuscript, you will be able to respond to the comments made by
the referees and upload a file "Response to Referees" in "Section 6 - File Upload". You can use this
to document any changes you make to the original manuscript. In order to expedite the
processing of the revised manuscript, please be as specific as possible in your response to the
referees.
When uploading your revised files please make sure that you have:
1) A text file of the manuscript (tex, txt, rtf, docx or doc), references, tables (including captions)
and figure captions. Do not upload a PDF as your "Main Document".
2) A separate electronic file of each figure (EPS or print-quality PDF preferred (either format
should be produced directly from original creation package), or original software format)
3) Included a 100 word media summary of your paper when requested at submission. Please
ensure you have entered correct contact details (email, institution and telephone) in your user
account
4) Included the raw data to support the claims made in your paper. You can either include your
data as electronic supplementary material or upload to a repository and include the relevant doi
within your manuscript
5) All supplementary materials accompanying an accepted article will be treated as in their final
form. Note that the Royal Society will neither edit nor typeset supplementary material and it will
be hosted as provided. Please ensure that the supplementary material includes the paper details
where possible (authors, article title, journal name).
Supplementary files will be published alongside the paper on the journal website and posted on
the online figshare repository (https://figshare.com). The heading and legend provided for each
supplementary file during the submission process will be used to create the figshare page, so
please ensure these are accurate and informative so that your files can be found in searches. Files
on figshare will be made available approximately one week before the accompanying article so
that the supplementary material can be attributed a unique DOI.
6
Once again, thank you for submitting your manuscript to Royal Society Open Science and I look
forward to receiving your revision. If you have any questions at all, please do not hesitate to get
in touch.
Kind regards,
Andrew Dunn
Royal Society Open Science
openscience@royalsociety.org
on behalf of Essi Viding
Subject Editor, Royal Society Open Science
openscience@royalsociety.org
Reviewer comments to Author:
Reviewer: 1
Comments to the Author(s)
File attached.
Reviewer: 2
Comments to the Author(s)
This manuscript describes an online study, which employs a well-known perspective taking
paradigm, the Director task. In a between-subjects study, adult participants are required to
complete one out of three versions of the task. The first one is referred to as a level 1 perspective
taking task (L1 task), a second which purports to measure level 2 perspective taking (L2 task) and
a third one is a control task that requires participants to follow a rule (i.e., ignore the opaque
barriers, Rule task). The study replicates previous findings that participants make more errors in
the version of the task when there is a ‘director’ present behind the grid compared to following a
rule when the director figure is removed. However, they found no differences in error rates
between L1 (judging whether an object is seen or not by another person) and L2 (judging how an
object appears to some else). The manuscript is well-written, with clear and concise language.
However, I have a few comments below that the authors could address.
1. Although it is encouraging that the key findings from previous studies are replicated
(i.e., larger error rates in the L1 version of the task compared to the rule version of the task), the
online nature of the study poses some issues that deserve to be considered by the authors. For
example, how can the researchers ensure participants fully understood what was required of
them when performing the task. If participants were unclear, the researcher was not there with
them to answer questions or clarify what participants were required to do. Related to this, the
authors mention that 9 participants were excluded from the analysis for failing to understand the
effect of the barriers used in the task, but don’t provide any further information. Can the authors
provide further information about what was the manipulation check at the end of the
experiment?
2. I commend the authors in the use of non-parametric tests to analyse their data. However,
can the authors specify if the post-hoc comparisons are Bonferroni corrected?
3. In the analysis of the ambiguous trials the authors say that error rates were similar across
the L1 and L2 task. However, what the analysis revealed is a trend towards significance (p.08),
with L1 error rates at 10.4 and in L2 at 3.5. Therefore, perhaps the authors could tone down the
claim that these error rates are similar and acknowledge a significant trend.
7
4. Since Masangkay et al. (1974) and Flavell et al. (1981)’s work distinguishing between
level 1 and level 2 perspective taking, it is widely accepted that level 1 abilities emerge earlier in
development than level 2. Therefore, the findings from this study that the error rates between the
two versions of the task in both ambiguous and relational trials, are numerically larger in the L1
task, although not significantly so, than in L2 is intriguing. Would the authors consider the
possibility that perhaps performance on this task might not be driven by inferences about what
the other person (the director) can see or how they see it and instead the colour of the transparent
covers in L2 are more salient than those in L1, making the former less prone to errors? This seems
to be the only visible difference between the stimuli in the 2 tasks. Could the authors provide an
example of the images of the shelves from the Director’s perspective (for both opaque and
translucent barriers? Perhaps these images could be added as supplementary material?
5. Related to the above, in the Discussion, the authors claim that their results support
previous findings that in the director task, participants are less prone to errors when following
rules than when required to adopt another’s perspective. In my opinion, this is a strong claim to
make in a between-subjects study, carried out online. Under such conditions, the experimenters
cannot even be sure if, for example, the participant was receiving any help from another person
while performing either of the tasks.
6. When this task has been administered to adults in previous studies, participants are
frequently asked not just to select the object (as they do here) but also to move it to another slot.
Although sometimes only object selection (rather than selection and movement) is included in the
analysis. Asking participants to just click on the object makes the task easier than previous
versions. One of the authors argument in the discussion is that ceiling effects could have
influenced the results because the error rates tend to be extremely low. I would have agreed with
the ‘ceiling effect’ comment based on how easy the task was, as participants only had to click on
the correct slot. However, I disagree with the reasoning that the error rates were extremely low.
For example, in relational trials, the error rate in L1 was 21.25% and 16.50% in L2, these are
hardly ‘extremely low’ error rates.
7. Finally, the interpretation of the findings in the discussion is rather confusing. On one
the hand the authors say that their results provide support to the previous findings that error
rates in this task are linked to the need to infer another’s perspective and on the other hand (in
the same – final – sentence) they propose that these errors do not come about because participants
have difficulty to infer another’s perspective. Perhaps the authors could explain this? If the error
rates are related but not caused by the requirement to make inferences, then what could be
causing such error rates in the L1 and L2 tasks? If it is something other than making inferences,
then is this task an appropriate measure of perspective taking?
Author's Response to Decision Letter for (RSOS-170284)
See Appendix B.
8
label_end_comment
Decision letter (RSOS-170284.R1)
17-Jul-2017
Dear Dr Legg,
I am pleased to inform you that your manuscript entitled "Error rate on the director’s task is
influenced by the need to take another’s perspective but not the type of perspective" is now
accepted for publication in Royal Society Open Science.
You can expect to receive a proof of your article in the near future. Please contact the editorial
office (openscience_proofs@royalsociety.org and openscience@royalsociety.org) to let us know if
you are likely to be away from e-mail contact. Due to rapid publication and an extremely tight
schedule, if comments are not received, your paper may experience a delay in publication.
Royal Society Open Science operates under a continuous publication model
(http://bit.ly/cpFAQ). Your article will be published straight into the next open issue and this
will be the final version of the paper. As such, it can be cited immediately by other researchers.
As the issue version of your paper will be the only version to be published I would advise you to
check your proofs thoroughly as changes cannot be made once the paper is published.
In order to raise the profile of your paper once it is published, we can send through a PDF of your
paper to selected colleagues. If you wish to take advantage of this, please reply to this email with
the name and email addresses of up to 10 people who you feel would wish to read your article.
On behalf of the Editors of Royal Society Open Science, we look forward to your continued
contributions to the Journal.
Best wishes,
Alice Power
Editorial Coordinator
Royal Society Open Science
openscience@royalsociety.org
Appendix A
Comments to the Authors: RSOS-170284
The current study aimed to examine what underpins error rates on the ‘Director’s
Task’, a measure of perspective taking in which participants tend to make egocentric
errors. In a between-subjects design, they compared a Level 1 Perspective Taking vs
Level 2 Perspective Taking vs Rule Following version of the task. In support of their
predictions and replicating previous studies, they found participants made more
errors in the Perspective Taking tasks compared to the Rule Following task
(depending partly on Instruction Type), but found no differences between Level 1
and Level 2 Perspective Taking performance. They conclude that errors in the
Director’s Task do not result from errors in inferring another’s perspective.
This is an interesting well-written paper; its key contribution to the literature is in
the comparison between Level 1 and Level 2 Perspective Taking in the Director’s
Task. My comments and suggestions are outlined below:
1. The authors suggest three explanations for perspective taking errors (page 4,
line 10) and state that the current study tests the first hypothesis only (p.4
l.26; p.12 l.3), yet predictions are also made for the other two hypotheses
(p.5 l.23-31), specifically for interpretations in the event of finding no
difference between Level 1 and Level 2 error rates (as the results indeed
show). Clarifying this would be helpful, for instance, having made the
predictions and found data to support them (although null effects) it would
be useful to include this in the discussion with respect to the tripartite model
of perspective taking processes introduced earlier (p.3, l.20). It would also be
helpful to make explicit the link between this tripartite model and the three
explanations for perspective taking errors, certainly the first two components
seem to be related but the third one differs (failure to use information vs
extraneous cognitive demands).
2. Could the authors confirm whether the participants in the L2 task and Rule
task are the same? The mean age and range, gender, and exclusion details
are remarkably similar. If they are indeed the same participants, then how
long was the duration between tasks? I think it is concerning if the same
participants took part in both tasks as if this were the case the tasks would
need to be counterbalanced, it would become a within rather than between
subjects design and further complicate comparisons with the L1 task group. I
would also be concerned about practice effects and carry-over effects, e.g. if
participants continue to use the rule in the subsequent L2 perspective taking
task and vice-versa.
3. It would be helpful when referring to Apperly et al. (2010) to mention the
specific experiment (3). There are a number of design differences between
the Director’s Task in the current study and that used in Apperly et al., and a
1
list of such deviations would be useful in light of the replication attempt.
Namely, that participants’ task was to ‘click on’ rather than ‘move’ objects,
and the differences between the ambiguous and relational instructions. In
Apperly et al. (2010), ambiguous instructions referred to a noun that
described two different objects (e.g. ‘mouse’ signifying either a cartoon
animal or a computer mouse) whereas in the current study the objects were
the same (e.g. ‘the yellow ball’) but one of the two was behind an occluder.
Regarding the relational instructions, Apperly et al. used an adjective (e.g.
small) whereas the current study used the superlative (‘the smallest blue
ball’). I find this problematic as, in this case, the director sees only two balls
while the participant sees three. Why would the director use the superlative
for only two objects? It implies to the participant that the director is aware
of the third object.
4. Although it is implied, it would be helpful to explicitly state that the red
barriers used in the L2 task changed the colour of objects for the director so
that they appeared red to him yet appeared as their original colour to
participants, and how this constitutes L2 perspective taking (i.e. please
explain what ‘how it appears’ means).
5. I was surprised that only 16 of 96 trials per participant were used in the
analysis, and comprised two sets of 8 trials analysed separately. Although I
note that this number is similar to Apperly et al. (2010), it would be useful to
know why the authors included 64 filler trials and a further 16 control trials.
6. It would be helpful if the authors could further explain why they used non-
parametric tests rather than ANOVA, as this is a significant change from
previous studies using the Director Task and is relevant for making
comparisons (especially for within-subject variable Instruction Type). The
authors claim error data are categorical, while this may be the case on a
single trial, I think it is less clear when the total possible errors is 8. Given that
one of the findings of the current study is a replication of Apperly et al., it
would be helpful to show, perhaps in supplementary materials, data analysed
using the same methods as that of Apperly et al. .
7. The main hypothesis of the current study was that if errors on the Director
Task are due to perspective inference then errors should increase as a
function of perspective complexity, specifically that more errors would be
observed for L2 than L1 perspective taking. The mean error rates were in fact
higher in the L1 task than the L2 task (and this difference is marginally
significant in the ambiguous condition, p=.08). Although the statistical
evidence doesn’t support a difference between L1 and L2, it would be
interesting for the authors to comment further on why L1 might have been as
difficult as L2.
8. Abstract p. 2, l. 31-35; The final line of the abstract is confusing, the
suggestion that the results show that ‘having to represent another’s
2
perspective induces errors in interpreting instructions’ is unclear. The results
show a difference in error rates between perspective taking and rule
following conditions, with no difference between type of perspective
represented, I am unsure how this relates to problems interpreting
instructions. I do not think the data can show that errors were due to how
participants interpreted instructions. It would be very helpful if the authors
could elaborate on their meaning of this point.
9. Although the authors acknowledge that there is a literature on whether
‘mental states’ or perspectives are actually represented in the Director Task
and other similar perspective taking tasks, this is mentioned in a footnote or
not fully explored with reference to the current study. For instance, the
authors make little reference to possible cognitive mechanisms involved, and
how they might differ between their three tasks. The Santiesteban et al.
study the authors reference includes the suggestion of object-centered
spatial coding as a cognitive mechanism underpinning performance on the
Director’s Task. The authors could consider how this mechanism might not be
the relevant cognitive strategy for the rule version of their task, as there is no
need for such spatial reasoning when one must only ignore the red boxes
from one’s own perspective. The authors could expand on how the different
cognitive demands of their three tasks may explain the differences in
performance, and go into further detail, situating the current study in the
wider literature, about what cognitive mechanisms are relevant to the
‘perspective taking’ in their Director’s Tasks.
10. P.7, l.24, says ‘one instruction per trial’, which I think should read ‘one
instruction per array’.
11. P.8, l.43, please give the p-value to two decimal places (as per APA 6th
Edition Style).
12. P.8, l.45, I was confused by this sentence: ‘…the L1 Task, L2 Task data were
analysed…’, which I think should read: ‘…the L1 Task and L2 Task, data were
analysed…’.
3
Appendix B
To the Editor,
We thank you and the two reviewers for the constructive comments on the manuscript. We have now
addressed the comments and made relevant alterations to the manuscript. These alterations are listed below,
in red, underneath each comment from a reviewer.
Yours Sincerely,
Edward Legg
Reviewer 1:
1. The authors suggest three explanations for perspective taking errors (page 4, line 10) and state that
the current study tests the first hypothesis only (p.4 l.26; p.12 l.3), yet predictions are also made for
the other two hypotheses (p.5 l.23-31), specifically for interpretations in the event of finding no
difference between Level 1 and Level 2 error rates (as the results indeed show). Clarifying this
would be helpful, for instance, having made the predictions and found data to support them
(although null effects) it would be useful to include this in the discussion with respect to the
tripartite model of perspective taking processes introduced earlier (p.3, l.20). It would also be
helpful to make explicit the link between this tripartite model and the three explanations for
perspective taking errors, certainly the first two components seem to be related but the third one
differs (failure to use information vs extraneous cognitive demands).
We have now clarified how the three hypotheses relate to the tripartite model on page 3 lines 4-7. In the
discussion we have elaborated the two hypotheses supported by the null effect and more explicitly indicated
that taken with previous studies it appears that there is stronger support for the third hypothesis.
2. Could the authors confirm whether the participants in the L2 task and Rule task are the same? The
mean age and range, gender, and exclusion details are remarkably similar. If they are indeed the
same participants, then how long was the duration between tasks? I think it is concerning if the
same participants took part in both tasks as if this were the case the tasks would need to be
counterbalanced, it would become a within rather than between subjects design and further
complicate comparisons with the L1 task group. I would also be concerned about practice effects
and carry-over effects, e.g. if participants continue to use the rule in the subsequent L2 perspective
taking task and vice-versa.
The participants in the two tasks were different and between subjects comparisons were made (it just
happens that the two groups have similar demographic information). We have now clarified that ‘no
individual took part in more than one task’ on page 5 lines 11-12
3. It would be helpful when referring to Apperly et al. (2010) to mention the specific experiment (3).
There are a number of design differences between the Director’s Task in the current study and that
used in Apperly et al., and a list of such deviations would be useful in light of the replication
attempt. Namely, that participants’ task was to ‘click on’ rather than ‘move’ objects, and the
differences between the ambiguous and relational instructions. In 2 Apperly et al. (2010),
ambiguous instructions referred to a noun that described two different objects (e.g. ‘mouse’
signifying either a cartoon animal or a computer mouse) whereas in the current study the objects
were the same (e.g. ‘the yellow ball’) but one of the two was behind an occluder. Regarding the
relational instructions, Apperly et al. used an adjective (e.g. small) whereas the current study used
the superlative (‘the smallest blue ball’). I find this problematic as, in this case, the director sees
only two balls while the participant sees three. Why would the director use the superlative for only
two objects? It implies to the participant that the director is aware of the third object.
We have now included a footnote (footnote 3, page 7 that explains the differences between Apperly 2010
and the current task and our reasons for these differences.
4. Although it is implied, it would be helpful to explicitly state that the red barriers used in the L2
task changed the colour of objects for the director so that they appeared red to him yet
appeared as their original colour to participants, and how this constitutes L2 perspective taking
(i.e. please explain what ‘how it appears’ means).
We thank the reviewer for pointing out this oversight and have now explicitly explained the effects of the
red translucent barriers on page 5 lines 22-24.
5. I was surprised that only 16 of 96 trials per participant were used in the analysis, and comprised
two sets of 8 trials analysed separately. Although I note that this number is similar to Apperly et al.
(2010), it would be useful to know why the authors included 64 filler trials and a further 16 control
trials.
The proportion of filler and control trials is similar to Apperly et al (2010). Please note that Apperly (2010)
did not use a fixed number of trials per array (with a range of 3 – 5 trials per array one of which was an
experimental or a control trial). Every array in our task had three trials one of which was either an
experimental or control trial. These filler and control trials are important because otherwise the participants
always have a different perspective to the director’s perspective and the repetitive nature of always
answering based on a different perspective would make it easier for participants to respond without actively
taking the director’s perspective.
6. It would be helpful if the authors could further explain why they used nonparametric tests rather
than ANOVA, as this is a significant change from previous studies using the Director Task and is
relevant for making comparisons (especially for within-subject variable Instruction Type). The
authors claim error data are categorical, while this may be the case on a single trial, I think it is less
clear when the total possible errors is 8. Given that one of the findings of the current study is a
replication of Apperly et al., it would be helpful to show, perhaps in supplementary materials, data
analysed using the same methods as that of Apperly et al.
The reviewer is correct to point out that our use of ‘categorical’ is not correct. The data are counts of errors
and it is incorrect to perform an ANOVA on these data for the reasons we have described in the text –
which reviewer 2 has commended us for. We have corrected this in the text.
Please note that the results would not be different had we run an ANOVA and that the raw data is available
in the supplementary material which will allow readers to perform alternative analyses.
7. The main hypothesis of the current study was that if errors on the Director Task are due to
perspective inference then errors should increase as a function of perspective complexity,
specifically that more errors would be observed for L2 than L1 perspective taking. The mean
error rates were in fact higher in the L1 task than the L2 task (and this difference is marginally
significant in the ambiguous condition, p=.08). Although the statistical evidence doesn’t
support a difference between L1 and L2, it would be interesting for the authors to comment
further on why L1 might have been as difficult as L2.
We agree that an increased discussion of why L1 and L2 produce similar error rates would be helpful and
have added in an extra paragraph on page 12 to address this.
8. Abstract p. 2, l. 31-35; The final line of the abstract is confusing, the suggestion that the results
show that ‘having to represent another’s perspective induces errors in interpreting instructions’ is
unclear. The results show a difference in error rates between perspective taking and rule following
conditions, with no difference between type of perspective 3 represented, I am unsure how this
relates to problems interpreting instructions. I do not think the data can show that errors were due
to how participants interpreted instructions. It would be very helpful if the authors could elaborate
on their meaning of this point.
We thank the reviewer for pointing this out. What we meant is that ‘representing another’s perspective
induces errors when following their instructions….’. We have now amended this in the text.
9. Although the authors acknowledge that there is a literature on whether ‘mental states’ or
perspectives are actually represented in the Director Task and other similar perspective taking
tasks, this is mentioned in a footnote or not fully explored with reference to the current study.
For instance, the authors make little reference to possible cognitive mechanisms involved, and
how they might differ between their three tasks. The Santiesteban et al. study the authors
reference includes the suggestion of object-centered spatial coding as a cognitive mechanism
underpinning performance on the Director’s Task. The authors could consider how this
mechanism might not be the relevant cognitive strategy for the rule version of their task, as
there is no need for such spatial reasoning when one must only ignore the red boxes from
one’s own perspective. The authors could expand on how the different cognitive demands of
their three tasks may explain the differences in performance, and go into further detail,
situating the current study in the wider literature, about what cognitive mechanisms are
relevant to the ‘perspective taking’ in their Director’s Tasks.
We agree that we could discuss the literature on whether the director’s task requires perspective taking at
all in more detail and have now added a paragraph at page 13 line 24. This paragraph discusses how the
model supported by our results relates to the patterns of results that are argued to support each side of the
debate.
10. P.7, l.24, says ‘one instruction per trial’, which I think should read ‘one instruction per
array’.
We thank the reviewer for pointing out this mistake and have now corrected this.
11. P.8, l.43, please give the p-value to two decimal places (as per APA 6th Edition Style).
We thank the reviewer for pointing this out. This analysis was in fact incorrectly located here and we have
now put in the correct Wilcoxon-signed rank results in its place.
12. P.8, l.45, I was confused by this sentence: ‘…the L1 Task, L2 Task data were analysed…’, which I think
should read: ‘…the L1 Task and L2 Task, data were analysed…’.
We apologise for this mistake. The sentence has been corrected and now reads ‘… the L1 Task, L2 Task
and rule task data were analysed…’. Page 8 line 18.
Reviewer: 2
Comments to the Author(s)
This manuscript describes an online study, which employs a well-known perspective taking paradigm, the
Director task. In a between-subjects study, adult participants are required to complete one out of three
versions of the task. The first one is referred to as a level 1 perspective taking task (L1 task), a second which
purports to measure level 2 perspective taking (L2 task) and a third one is a control task that requires
participants to follow a rule (i.e., ignore the opaque barriers, Rule task). The study replicates previous
findings that participants make more errors in the version of the task when there is a ‘director’ present
behind the grid compared to following a rule when the director figure is removed. However, they found no
differences in error rates between L1 (judging whether an object is seen or not by another person) and L2
(judging how an object appears to some else). The manuscript is well-written, with clear and concise
language. However, I have a few comments below that the authors could address.
1. Although it is encouraging that the key findings from previous studies are replicated (i.e., larger
error rates in the L1 version of the task compared to the rule version of the task), the online
nature of the study poses some issues that deserve to be considered by the authors. For
example, how can the researchers ensure participants fully understood what was required of
them when performing the task. If participants were unclear, the researcher was not there
with them to answer questions or clarify what participants were required to do. Related to
this, the authors mention that 9 participants were excluded from the analysis for failing to
understand the effect of the barriers used in the task, but don’t provide any further
information. Can the authors provide further information about what was the manipulation
check at the end of the experiment?
We have now included a section at page 7 line 16 in the Procedure about the manipulation check and
included images of this in the supplemental material.
2. I commend the authors in the use of non-parametric tests to analyse their data. However, can
the authors specify if the post-hoc comparisons are Bonferroni corrected?
Our analyses were planned comparisons as there were clear predictions that there could be differences
between each of the three types of task. Applying Bonferroni corrections would only have one major effect
– the p-value in the Mann-Whitney test comparing the Rule and L1 task would no longer be significant (a
result that is inline with previous studies). This would in no way alter our interpretation of the results.
3. In the analysis of the ambiguous trials the authors say that error rates were similar across the L1
and L2 task. However, what the analysis revealed is a trend towards significance (p.08), with
L1 error rates at 10.4 and in L2 at 3.5. Therefore, perhaps the authors could tone down the
claim that these error rates are similar and acknowledge a significant trend.
Please see response to Reviewer 1 point 7 who raises the same issue.
4. Since Masangkay et al. (1974) and Flavell et al. (1981)’s work distinguishing between lev el 1 and
level 2 perspective taking, it is widely accepted that level 1 abilities emerge earlier in
development than level 2. Therefore, the findings from this study that the error rates
between the two versions of the task in both ambiguous and relational trials, are numerically
larger in the L1 task, although not significantly so, than in L2 is intriguing. Would the
authors consider the possibility that perhaps performance on this task might not be driven
by inferences about what the other person (the director) can see or how they see it and
instead the colour of the transparent covers in L2 are more salient than those in L1, making
the former less prone to errors? This seems to be the only visible difference between the
stimuli in the 2 tasks. Could the authors provide an example of the images of the shelves
from the Director’s perspective (for both opaque and translucent barriers? Perhaps these
images could be added as supplementary material?
We agree that the data are surprising given the developmental literature on the subject. As the reviewer
points out one explanation for the subtle difference in the mean error rate between the L1 and the L2 task
could be because of differences in the visual properties and salience the barriers between the two tasks. We
discuss this possibility in the paragraph we have added at page 12 line 13
5. Related to the above, in the Discussion, the authors claim that their results support previous
findings that in the director task, participants are less prone to errors when following rules
than when required to adopt another’s perspective. In my opinion, this is a strong claim to
make in a between-subjects study, carried out online. Under such conditions, the
experimenters cannot even be sure if, for example, the participant was receiving any help
from another person while performing either of the tasks.
The comparison of the Rule task and L1 task suggest that with the current online participant pool we are
able to conceptually replicate the results of offline between-subjects comparisons.
6. When this task has been administered to adults in previous studies, participants are frequently
asked not just to select the object (as they do here) but also to move it to another slot.
Although sometimes only object selection (rather than selection and movement) is included
in the analysis. Asking participants to just click on the object makes the task easier than
previous versions. One of the authors argument in the discussion is that ceiling effects could
have influenced the results because the error rates tend to be extremely low. I would have
agreed with the ‘ceiling effect’ comment based on how easy the task was, as participants only
had to click on the correct slot. However, I disagree with the reasoning that the error rates
were extremely low. For example, in relational trials, the error rate in L1 was 21.25% and
16.50% in L2, these are hardly ‘extremely low’ error rates.
The reviewer is correct that we did not ask the subjects to ‘move’ the objects like in previous studies. One
reason for this is because this may have inadvertently led to a form of Level 2 perspective taking (as
participants could respond to an instruction to move an object left based on which location was on their
own left (director’s right) or the director’s left (their right). We have now clarified this in the text at page 8
line 15.
The reviewer is also correct to warn us about our use of ceiling effects. The reviewer mentions error rates
in the relational trial types, however, we refer to ceiling effects in the context of ambiguous trials (page 11,
line 12) to explain why there is no difference in performance between performance in ambiguous trials on
the L1 task and Rule task. Here error rates are low on the rule task (e.g. 1.56%) and we have now clarified
that we are referring to a ceiling effect in the ambiguous trials of the rule task.
7. Finally, the interpretation of the findings in the discussion is rather confusing. On one the hand
the authors say that their results provide support to the previous findings that error rates in
this task are linked to the need to infer another’s perspective and on the other hand (in the
same – final – sentence) they propose that these errors do not come about because
participants have difficulty to infer another’s perspective. Perhaps the authors could explain
this? If the error rates are related but not caused by the requirement to make inferences,
then what could be causing such error rates in the L1 and L2 tasks? If it is something other
than making inferences, then is this task an appropriate measure of perspective taking?
We believe we have addressed this issue in our penultimate paragraph where we discuss how higher error
rates in perspective taking variants of the task (versus rule versions) could be influenced by differences in
the cognitive demands.
To clarify this matter in the penultimate paragraph we have emphasised the ‘indirect’ contribution that
inferring another’s perspective may have on error rates. Furthermore, we have altered the final two
sentences of the concluding paragraphs to highlight our interpretation. These sentences now state:
Thus, our findings lend support to the suggestion that although error rates on these tasks are linked to the need to infer another’s
perspective the errors are unlikely to be because participants’ inferences about the other’s perspective are incorrect. Instead these
errors may occur because inferring another’s perspective places extra cognitive demands on participants which makes them more
error prone than when they do not need to infer another’s perspective.
Society Open
