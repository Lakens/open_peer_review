Emotion appraisal dimensions inferred from vocal
expressions are consistent across cultures: a comparison
between Australia and India
Henrik Nordström, Petri Laukka, Nutankumar S. Thingujam, Emery Schubert and Hillary
Anger Elfenbein
Article citation details
R. Soc. open sci. 4: 170912.
http://dx.doi.org/10.1098/rsos.170912
Review timeline
Original submission: 15 July 2017 Note: Reports are unedited and appear as
Revised submission: 13 September 2017 submitted by the referee. The review history
Final acceptance: 17 October 2017 appears in chronological order.
Review History
label_version_1
RSOS-170912.R0 (Original submission)
label_author_1
Review form: Reviewer 1
Is the manuscript scientifically sound in its present form?
Yes
Are the interpretations and conclusions justified by the results?
No
Is the language acceptable?
Yes
Is it clear how to access all supporting data?
Yes
Do you have any ethical concerns with this paper?
No
© 2017 The Authors. Published by the Royal Society under the terms of the Creative Commons
Attribution License http://creativecommons.org/licenses/by/4.0/, which permits unrestricted use,
provided the original author and source are credited
2
Have you any concerns about statistical analyses in this paper?
Yes
Recommendation?
label_recommendation_1
Major revision is needed (please make suggestions in comments)
Comments to the Author(s)
label_comment_1
The article by Nordström et al. provided a study on the perceptual and acoustic correlates of
nonverbal vocal expressions in Australia and India culture. Eight emotions were elicited by actors
from these cultures were judged on six emotion appraisal dimensions (or aspects of emotion-
eliciting situations) by listeners from each of the two cultural groups. With Bayesian analysis,
they showed that the appraisal ratings were generally consistent with the predictions from
appraisal theories. Appraisal ratings were no different between ingroup and outgroup, and
Australian and Indian raters were different only in the ratings for norm compatibility. The
acoustic correlates of appraisal ratings also showed cultural similarity. The authors argued for the
independence of appraisal inferences from the cultural group.
This experimental report well extends the existing cross-cultural study by looking at the
emotional appraisal. The findings are straightforward and the analysis is appropriate. I have
some points I encourage the authors to take into account.
Page 2 Line 28 What is the motivation for examining the acoustic correlates of appraisal
dimensions beside the emotion? Not clear.
Page 2 Line 40 Since the authors mentioned about the Australian participants were from
multicultural university and all Indian participants spoke English, did they evaluate their
exposure to each other's culture? What was the English proficiency in Indian group? How did the
cultural familiarity affect the participant's ability to process emotion from the other group? Any
type of analysis linking language profile with the rating would be very helpful.
Page 3 Line 54 Please specify what analytic platform was used for running the Bayesian analysis.
Page 4 Line 20 Please clarify how Bayesian statistics can reveal the ingroup vs. outgroup
difference.
In particular, I was wondering how counting the number of supported predictions by in-and out-
group combinations could reflect the difference. The consistent ranking between emotional
categories in certain appraisal dimensions solely is not sufficient for me to argue for a between-
group similarity since the magnitude difference was not directly compared between group status
(and the same applied to the cultural differences). Perhaps some additional analysis would be
needed?
Page 4 Line 49 One compelling analysis would be to show how emotions were rated differently
on each appraisal dimensions regardless of culture. A table or figure showing the rating values
collapsing four groups for each dimension would be clear.
Page 5 Line 12 Judging by Figure 1, the listener cultural difference mainly lied in Australian
speaker judged by Australian vs. Indian listener (but not in Indian speaker) and was mainly
found in happiness, pride, serenity. Did author have any interpretation for these observations?
Page 5 Line 20 Did the authors control for other acoustic cues or appraisal dimensions when they
explored each acoustic cue in relation to a particular appraisal dimension?
Page Line 20 I was wondering to what extent the results were potentially affected by the
recognition accuracy of target emotions. Any data collected for this study?
3
Page Line 22 The authors proposed at the beginning of the article that the Australian and Indian
culture are different greatly in cultural orientation. I was curious how they would interpret their
findings regarding emotional appraisal in the context of Hofstedes' cultural dimension.
Page 7 Line 53 I would like to see some discussions on how the Bayesian analysis can benefit the
understanding the emotional appraisal theory.
label_author_2
Review form: Reviewer 2 (Cesar Lima)
Is the manuscript scientifically sound in its present form?
Yes
Are the interpretations and conclusions justified by the results?
Yes
Is the language acceptable?
Yes
Is it clear how to access all supporting data?
Yes
Do you have any ethical concerns with this paper?
No
Have you any concerns about statistical analyses in this paper?
No
Recommendation?
label_recommendation_2
Major revision is needed (please make suggestions in comments)
Comments to the Author(s)
label_comment_2
Nordström and colleagues present a cross-cultural study examining how Australian and Indian
listeners infer emotion appraisal dimensions from emotional speech produced by Australian and
Indian speakers. Using a simple but effective design, they asked participants to rate the stimuli
across six dimensions, namely novelty, intrinsic pleasantness, goal conduciveness, urgency,
power, and norm compatibility. Through a set of Bayesian analyses, they show that (1) the
profiles of ratings generally confirm the predictions of appraisal theories, both for Australian and
for Indian participants; and that (2) the ratings of Australian and Indian participants were similar
in most cases (64% of the comparisons), suggesting that appraisal inferences are universal to an
important extent. An exploratory analysis of the relationship between acoustic features and
appraisal ratings is also included.
I really enjoyed reading this paper – the focus on appraisal dimensions in a cross-cultural setting
makes this a novel and compelling contribution, that will be of interest to many researchers on
vocal communication and on emotion more broadly. The paper is well-written, the research
questions and hypotheses are clear and well-motivated, and the methods are generally sound.
I have a few comments/suggestions, though, that I would encourage the authors to address
before publication in Royal Society Open Science:
1. It is not clear before the Materials and Methods section that the focus is on emotional speech
prosody, and not on purely nonverbal vocalizations such as screams or laughter. I suggest this is
4
made explicit in the title and/or abstract, and it would also be useful to make the distinction
between the two types of vocal cues in the Introduction.
2. The authors appropriately refer to (and cite) appraisal theories, but it is somewhat unclear why
this particular set of dimensions was selected for the current study. Can they briefly discuss this?
Including additional details about the dimensions could also be helpful, particularly for readers
not familiarized with appraisal theories.
3. It would also be useful to include more details about the cultural differences between Australia
and India (e.g., Hofstede’s dimensions), and to discuss previous findings on acoustic/perceptual
differences in emotional prosody across these countries.
4. Details about the stimuli: the VENEC database (from which the current recordings were
selected) includes 20 actors per culture, but it is not said how many of these speakers are
represented in the subset of recordings used here. Was the number of speakers (and the number
of stimuli produced by men and women) matched across the Australian and Indian sets?
5. There were some differences in how the experiment was conducted in Australia and in India
(e.g., time vs. untimed format), but I believe this is unlikely to have affected results in important
ways. One small point, though: was the number of times each stimulus was played registered,
and have the authors checked if this was similar across conditions? If there were differences (e.g.,
between countries), can these differences account for how the stimuli were rated?
6. I wonder if the authors considered including an emotion recognition measure as well. This
would have been interesting to directly compare the magnitude of culture effects across domains
(e.g., is emotion recognition more strongly shaped by culture than emotion appraisal inferences?).
Additionally, and related to a possibility mentioned on p. 6: if participants first make a
categorical judgment, and base their appraisal evaluations on that judgment, would it be more
appropriate to only consider appraisal evaluations for stimuli that participants could correctly
categorize (i.e., are appraisal evaluations for stimuli that participants might not be able to
recognize meaningful)?
7. On a related note, I would be interested in hearing the authors’ thoughts about what would be
the equivalent of an in-group advantage in the context of emotion appraisal inferences. Would
we expect to see more extreme ratings – in the direction of the theoretical predictions – when the
speakers and perceivers come from the same culture; more consistent evaluations (with less
variation between listeners/speakers of the same culture); or just different ratings? Do the
authors consider the reported group differences conceptually comparable to the in-group
advantage reported in previous cross-cultural work in the categorical tradition?
8. In the Results section, I would encourage the authors to include a measure of rater consistency,
to confirm that the listeners were able to rate all the appraisal dimensions in a consistent way,
and that reliability coefficients were similar across countries.
9. A point about the stimuli: was it the case that the verbal content of all the stimuli (including
Australian and Indian recordings) consisted of emotionally neutral English sentences? If so,
Australian participants produced and rated stimuli expressed in their native language, while
Indian participants did not (they reported being fluent in English, but their native languages
were Nepali, Assamese, Indi, and Tibetan). I agree that this improves consistency across
portrayals, and might prevent language-related confounds, but I wonder if it might also mask
potential effects of culture. Can we exclude the possibility that the actors would express emotions
slightly differently in their native language, and that the listeners would evaluate appraisal
dimensions differently in these stimuli? It would be important to see this discussed, particularly
because cross-cultural similarities are central for the argument of the paper.
Reviewed by César Lima, University of Porto and University College London
5
label_end_comment
Decision letter (RSOS-170912)
21-Aug-2017
Dear Mr Nordström,
The editors assigned to your paper ("Emotion appraisal dimensions inferred from vocal
expressions are consistent across cultures: A comparison between Australia and India") have now
received comments from reviewers. We would like you to revise your paper in accordance with
the referee and Associate Editor suggestions which can be found below (not including
confidential reports to the Editor). Please note this decision does not guarantee eventual
acceptance.
Please submit a copy of your revised paper within three weeks (i.e. by the 13-Sep-2017). If we do
not hear from you within this time then it will be assumed that the paper has been withdrawn. In
exceptional circumstances, extensions may be possible if agreed with the Editorial Office in
advance.We do not allow multiple rounds of revision so we urge you to make every effort to
fully address all of the comments at this stage. If deemed necessary by the Editors, your
manuscript will be sent back to one or more of the original reviewers for assessment. If the
original reviewers are not available we may invite new reviewers.
To revise your manuscript, log into http://mc.manuscriptcentral.com/rsos and enter your
Author Centre, where you will find your manuscript title listed under "Manuscripts with
Decisions." Under "Actions," click on "Create a Revision." Your manuscript number has been
appended to denote a revision. Revise your manuscript and upload a new version through your
Author Centre.
When submitting your revised manuscript, you must respond to the comments made by the
referees and upload a file "Response to Referees" in "Section 6 - File Upload". Please use this to
document how you have responded to the comments, and the adjustments you have made. In
order to expedite the processing of the revised manuscript, please be as specific as possible in
your response.
In addition to addressing all of the reviewers' and editor's comments please also ensure that your
revised manuscript contains the following sections as appropriate before the reference list:
• Ethics statement (if applicable)
If your study uses humans or animals please include details of the ethical approval received,
including the name of the committee that granted approval. For human studies please also detail
whether informed consent was obtained. For field studies on animals please include details of all
permissions, licences and/or approvals granted to carry out the fieldwork.
• Data accessibility
It is a condition of publication that all supporting data are made available either as
supplementary information or preferably in a suitable permanent repository. The data
accessibility section should state where the article's supporting data can be accessed. This section
should also include details, where possible of where to access other relevant research materials
such as statistical tools, protocols, software etc can be accessed. If the data have been deposited in
an external repository this section should list the database, accession number and link to the DOI
for all data from the article that have been made publicly available. Data sets that have been
deposited in an external repository and have a DOI should also be appropriately cited in the
manuscript and included in the reference list.
If you wish to submit your supporting data or code to Dryad (http://datadryad.org/), or modify
your current submission to dryad, please use the following link:
6
http://datadryad.org/submit?journalID=RSOS&manu=RSOS-170912
• Competing interests
Please declare any financial or non-financial competing interests, or state that you have no
competing interests.
• Authors’ contributions
All submissions, other than those with a single author, must include an Authors’ Contributions
section which individually lists the specific contribution of each author. The list of Authors
should meet all of the following criteria; 1) substantial contributions to conception and design, or
acquisition of data, or analysis and interpretation of data; 2) drafting the article or revising it
critically for important intellectual content; and 3) final approval of the version to be published.
All contributors who do not meet all of these criteria should be included in the
acknowledgements.
We suggest the following format:
AB carried out the molecular lab work, participated in data analysis, carried out sequence
alignments, participated in the design of the study and drafted the manuscript; CD carried out
the statistical analyses; EF collected field data; GH conceived of the study, designed the study,
coordinated the study and helped draft the manuscript. All authors gave final approval for
publication.
• Acknowledgements
Please acknowledge anyone who contributed to the study but did not meet the authorship
criteria.
• Funding statement
Please list the source of funding for each author.
Once again, thank you for submitting your manuscript to Royal Society Open Science and I look
forward to receiving your revision. If you have any questions at all, please do not hesitate to get
in touch.
Yours sincerely,
Alice Power
Editorial Coordinator
Royal Society Open Science
on behalf of Essi Viding
Subject Editor, Royal Society Open Science
openscience@royalsociety.org
Comments to Author:
Reviewers' Comments to Author:
Reviewer: 1
Comments to the Author(s)
The article by Nordström et al. provided a study on the perceptual and acoustic correlates of
nonverbal vocal expressions in Australia and India culture. Eight emotions were elicited by actors
from these cultures were judged on six emotion appraisal dimensions (or aspects of emotion-
eliciting situations) by listeners from each of the two cultural groups. With Bayesian analysis,
they showed that the appraisal ratings were generally consistent with the predictions from
appraisal theories. Appraisal ratings were no different between ingroup and outgroup, and
Australian and Indian raters were different only in the ratings for norm compatibility. The
7
acoustic correlates of appraisal ratings also showed cultural similarity. The authors argued for the
independence of appraisal inferences from the cultural group.
This experimental report well extends the existing cross-cultural study by looking at the
emotional appraisal. The findings are straightforward and the analysis is appropriate. I have
some points I encourage the authors to take into account.
Page 2 Line 28 What is the motivation for examining the acoustic correlates of appraisal
dimensions beside the emotion? Not clear.
Page 2 Line 40 Since the authors mentioned about the Australian participants were from
multicultural university and all Indian participants spoke English, did they evaluate their
exposure to each other's culture? What was the English proficiency in Indian group? How did the
cultural familiarity affect the participant's ability to process emotion from the other group? Any
type of analysis linking language profile with the rating would be very helpful.
Page 3 Line 54 Please specify what analytic platform was used for running the Bayesian analysis.
Page 4 Line 20 Please clarify how Bayesian statistics can reveal the ingroup vs. outgroup
difference.
In particular, I was wondering how counting the number of supported predictions by in-and out-
group combinations could reflect the difference. The consistent ranking between emotional
categories in certain appraisal dimensions solely is not sufficient for me to argue for a between-
group similarity since the magnitude difference was not directly compared between group status
(and the same applied to the cultural differences). Perhaps some additional analysis would be
needed?
Page 4 Line 49 One compelling analysis would be to show how emotions were rated differently
on each appraisal dimensions regardless of culture. A table or figure showing the rating values
collapsing four groups for each dimension would be clear.
Page 5 Line 12 Judging by Figure 1, the listener cultural difference mainly lied in Australian
speaker judged by Australian vs. Indian listener (but not in Indian speaker) and was mainly
found in happiness, pride, serenity. Did author have any interpretation for these observations?
Page 5 Line 20 Did the authors control for other acoustic cues or appraisal dimensions when they
explored each acoustic cue in relation to a particular appraisal dimension?
Page Line 20 I was wondering to what extent the results were potentially affected by the
recognition accuracy of target emotions. Any data collected for this study?
Page Line 22 The authors proposed at the beginning of the article that the Australian and Indian
culture are different greatly in cultural orientation. I was curious how they would interpret their
findings regarding emotional appraisal in the context of Hofstedes' cultural dimension.
Page 7 Line 53 I would like to see some discussions on how the Bayesian analysis can benefit the
understanding the emotional appraisal theory.
Reviewer: 2
Comments to the Author(s)
Nordström and colleagues present a cross-cultural study examining how Australian and Indian
listeners infer emotion appraisal dimensions from emotional speech produced by Australian and
Indian speakers. Using a simple but effective design, they asked participants to rate the stimuli
across six dimensions, namely novelty, intrinsic pleasantness, goal conduciveness, urgency,
8
power, and norm compatibility. Through a set of Bayesian analyses, they show that (1) the
profiles of ratings generally confirm the predictions of appraisal theories, both for Australian and
for Indian participants; and that (2) the ratings of Australian and Indian participants were similar
in most cases (64% of the comparisons), suggesting that appraisal inferences are universal to an
important extent. An exploratory analysis of the relationship between acoustic features and
appraisal ratings is also included.
I really enjoyed reading this paper – the focus on appraisal dimensions in a cross-cultural setting
makes this a novel and compelling contribution, that will be of interest to many researchers on
vocal communication and on emotion more broadly. The paper is well-written, the research
questions and hypotheses are clear and well-motivated, and the methods are generally sound.
I have a few comments/suggestions, though, that I would encourage the authors to address
before publication in Royal Society Open Science:
1. It is not clear before the Materials and Methods section that the focus is on emotional speech
prosody, and not on purely nonverbal vocalizations such as screams or laughter. I suggest this is
made explicit in the title and/or abstract, and it would also be useful to make the distinction
between the two types of vocal cues in the Introduction.
2. The authors appropriately refer to (and cite) appraisal theories, but it is somewhat unclear why
this particular set of dimensions was selected for the current study. Can they briefly discuss this?
Including additional details about the dimensions could also be helpful, particularly for readers
not familiarized with appraisal theories.
3. It would also be useful to include more details about the cultural differences between Australia
and India (e.g., Hofstede’s dimensions), and to discuss previous findings on acoustic/perceptual
differences in emotional prosody across these countries.
4. Details about the stimuli: the VENEC database (from which the current recordings were
selected) includes 20 actors per culture, but it is not said how many of these speakers are
represented in the subset of recordings used here. Was the number of speakers (and the number
of stimuli produced by men and women) matched across the Australian and Indian sets?
5. There were some differences in how the experiment was conducted in Australia and in India
(e.g., time vs. untimed format), but I believe this is unlikely to have affected results in important
ways. One small point, though: was the number of times each stimulus was played registered,
and have the authors checked if this was similar across conditions? If there were differences (e.g.,
between countries), can these differences account for how the stimuli were rated?
6. I wonder if the authors considered including an emotion recognition measure as well. This
would have been interesting to directly compare the magnitude of culture effects across domains
(e.g., is emotion recognition more strongly shaped by culture than emotion appraisal inferences?).
Additionally, and related to a possibility mentioned on p. 6: if participants first make a
categorical judgment, and base their appraisal evaluations on that judgment, would it be more
appropriate to only consider appraisal evaluations for stimuli that participants could correctly
categorize (i.e., are appraisal evaluations for stimuli that participants might not be able to
recognize meaningful)?
7. On a related note, I would be interested in hearing the authors’ thoughts about what would be
the equivalent of an in-group advantage in the context of emotion appraisal inferences. Would
we expect to see more extreme ratings – in the direction of the theoretical predictions – when the
speakers and perceivers come from the same culture; more consistent evaluations (with less
variation between listeners/speakers of the same culture); or just different ratings? Do the
authors consider the reported group differences conceptually comparable to the in-group
advantage reported in previous cross-cultural work in the categorical tradition?
8. In the Results section, I would encourage the authors to include a measure of rater consistency,
to confirm that the listeners were able to rate all the appraisal dimensions in a consistent way,
and that reliability coefficients were similar across countries.
9. A point about the stimuli: was it the case that the verbal content of all the stimuli (including
Australian and Indian recordings) consisted of emotionally neutral English sentences? If so,
Australian participants produced and rated stimuli expressed in their native language, while
Indian participants did not (they reported being fluent in English, but their native languages
9
were Nepali, Assamese, Indi, and Tibetan). I agree that this improves consistency across
portrayals, and might prevent language-related confounds, but I wonder if it might also mask
potential effects of culture. Can we exclude the possibility that the actors would express emotions
slightly differently in their native language, and that the listeners would evaluate appraisal
dimensions differently in these stimuli? It would be important to see this discussed, particularly
because cross-cultural similarities are central for the argument of the paper.
Reviewed by César Lima, University of Porto and University College London
Author's Response to Decision Letter for (RSOS-170912)
See Appendix A.
label_version_2
RSOS-170912.R1 (Revision)
label_author_3
Review form: Reviewer 1
Is the manuscript scientifically sound in its present form?
Yes
Are the interpretations and conclusions justified by the results?
Yes
Is the language acceptable?
Yes
Is it clear how to access all supporting data?
Yes
Do you have any ethical concerns with this paper?
No
Have you any concerns about statistical analyses in this paper?
No
Recommendation?
label_recommendation_3
Accept as is
Comments to the Author(s)
label_comment_3
The authors have addressed all my comments carefully in their revised manuscript. I will
recommend its publication.
10
label_author_4
Review form: Reviewer 2 (Cesar Lima)
Is the manuscript scientifically sound in its present form?
Yes
Are the interpretations and conclusions justified by the results?
Yes
Is the language acceptable?
Yes
Is it clear how to access all supporting data?
Yes
Do you have any ethical concerns with this paper?
No
Have you any concerns about statistical analyses in this paper?
No
Recommendation?
label_recommendation_4
Accept as is
Comments to the Author(s)
label_comment_4
The authors have satisfactorily addressed my concerns.
label_end_comment
Decision letter (RSOS-170912.R1)
17-Oct-2017
Dear Mr Nordström,
I am pleased to inform you that your manuscript entitled "Emotion appraisal dimensions inferred
from vocal expressions are consistent across cultures: A comparison between Australia and India"
is now accepted for publication in Royal Society Open Science.
You can expect to receive a proof of your article in the near future. Please contact the editorial
office (openscience_proofs@royalsociety.org and openscience@royalsociety.org) to let us know if
you are likely to be away from e-mail contact. Due to rapid publication and an extremely tight
schedule, if comments are not received, your paper may experience a delay in publication.
Royal Society Open Science operates under a continuous publication model
(http://bit.ly/cpFAQ). Your article will be published straight into the next open issue and this
will be the final version of the paper. As such, it can be cited immediately by other researchers.
As the issue version of your paper will be the only version to be published I would advise you to
check your proofs thoroughly as changes cannot be made once the paper is published.
In order to raise the profile of your paper once it is published, we can send through a PDF of your
paper to selected colleagues. If you wish to take advantage of this, please reply to this email with
the name and email addresses of up to 10 people who you feel would wish to read your article.
11
On behalf of the Editors of Royal Society Open Science, we look forward to your continued
contributions to the Journal.
Kind regards,
Alice Power
Editorial Coordinator
Royal Society Open Science
openscience@royalsociety.org
http://rsos.royalsocietypublishing.org/
Associate Editor Comments to Author:
I am pleased to inform you that your revised paper satisfactorily addressed the reviewer's
concerns, and is now suitable for publication.
Reviewer(s)' Comments to Author:
Reviewer: 2
Comments to the Author(s)
The authors have satisfactorily addressed my concerns.
Reviewer: 1
Comments to the Author(s)
The authors have addressed all my comments carefully in their revised manuscript. I will
recommend its publication.
Appendix A
September 12, 2017
Dear Editors,
Enclosed with this letter is a revised version of our manuscript “Emotion appraisal
dimensions inferred from vocal expressions are consistent across cultures: A comparison
between Australia and India” (RSOS-170912).
We appreciate greatly the time and care that you and the reviewers took to provide us with
detailed feedback that has allowed us to improve the work. We have done our best to
address all of the reviewers’ comments and hope that the manuscript now meets the high
standards of Royal Society Open Science. All changes that have been made are marked in
red in the revised version.
Cordially yours,
Henrik Nordström
Petri Laukka
Nutankumar Thingujam
Emery Schubert
Hillary Anger Elfenbein
----------------
Below we provide detail on these changes. For reference, we include the original comments
in italic typescript
Reviewer: 1
Comments to the Author(s)
- The article by Nordström et al. provided a study on the perceptual and acoustic correlates
of nonverbal vocal expressions in Australia and India culture. Eight emotions were elicited by
actors from these cultures were judged on six emotion appraisal dimensions (or aspects of
emotion-eliciting situations) by listeners from each of the two cultural groups. With Bayesian
analysis, they showed that the appraisal ratings were generally consistent with the
predictions from appraisal theories. Appraisal ratings were no different between ingroup and
outgroup, and Australian and Indian raters were different only in the ratings for norm
compatibility. The acoustic correlates of appraisal ratings also showed cultural similarity. The
authors argued for the independence of appraisal inferences from the cultural group.
This experimental report well extends the existing cross-cultural study by looking at the
emotional appraisal. The findings are straightforward and the analysis is appropriate. I have
some points I encourage the authors to take into account.
*We thank you for this positive evaluation of our work.
- Page 2 Line 28 What is the motivation for examining the acoustic correlates of appraisal
dimensions beside the emotion? Not clear.
* We now provide a motivation for these analyses in a rewritten part of the introduction
section on page 2, line 30:
“… we investigated the extent to which listeners’ appraisal ratings were associated with
various acoustic parameters in exploratory analyses. Laukka and Elfenbein [1] reported
correlations between appraisal ratings and acoustic parameters in a within-cultural setting,
but no previous study has investigated such correlations in a cross-cultural setting. These
analyses thus provide initial clues about cultural similarities and differences in the degree to
which various acoustic parameters are used by listeners to infer appraisal information from
emotional speech prosody.”
- Page 2 Line 40 Since the authors mentioned about the Australian participants were from
multicultural university and all Indian participants spoke English, did they evaluate their
exposure to each other's culture? How did the cultural familiarity affect the participant's
ability to process emotion from the other group?
* Unfortunately we did not ask the participants about aspects of cultural exposure, and
therefore cannot assess if cultural familiarity had an effect on appraisal ratings. We tried to
make sure that participants were exposed mainly to their native culture by only including
those born and raised in their respective country.
-What was the English proficiency in Indian group?
* The Indian participants were all students at a university that used English as the medium
for instruction. This means that they were accustomed to reading and communicating (both
orally and in writing) in English in an academic setting. We have added this information on
page 2, line 47:
“None of the Indian participants had English as their primary language, but all reported
being fluent in English and regularly used the language as students at a university where the
medium of instruction is English.”
-Any type of analysis linking language profile with the rating would be very helpful.
*All participants reported that they were fluent in English, but we did not ask for a more
detailed report of language proficiency. Therefore we cannot analyze if English proficiency
had an effect on appraisal ratings. The Indian participants reported various native languages,
but the number of participants for each specific language is too small for a between-group
analysis of possible differences in appraisal ratings.
To summarize, we agree that it would be interesting to investigate effects of cultural
exposure and language profiles on emotion perception, but our study was not designed for
this purpose and these questions are best addressed by future studies. For what it’s worth,
we note that our previous (categorical) studies suggest that greater cultural distance is
associated with lower emotion recognition rates (e.g., [10]), whereas results regarding the
effects of language proficiency on emotion recognition are mixed (e.g., Bhatara, et al., 2016,
Second language ability and emotional prosody perception. PLoS ONE, 11, e0156855).
- Page 3 Line 54 Please specify what analytic platform was used for running the Bayesian
analysis.
*All statistical analyses, including the Bayesian analyses, were built using preinstalled
functions in R (“base R”). The only exceptions to this were the PCA analysis (which was
conducted using the ´paran´ package [26, 27]) and the calculation of intra-class correlations
(which was done using the ‘psych’ package [37]). This has now been clarified on page 4 line
1:
“All statistical analyses were conducted using R [30] and all data and analysis code is
available in the supplementary material.”
The file “00_func.R” found in the online supplementary material contains the code that
performs the Bayesian analysis. See also references [31, 32, 33] for the rationale of this
code.
- Page 4 Line 20 Please clarify how Bayesian statistics can reveal the ingroup vs. outgroup
difference. In particular, I was wondering how counting the number of supported predictions
by in-and out-group combinations could reflect the difference. The consistent ranking
between emotional categories in certain appraisal dimensions solely is not sufficient for me
to argue for a between-group similarity since the magnitude difference was not directly
compared between group status (and the same applied to the cultural differences). Perhaps
some additional analysis would be needed?
* Our first research question was to investigate whether appraisal ratings for the different
emotions were consistent with predictions based on appraisal theory. These analyses are
reported in Section 3.1, and results showed that 113 out of 144 (78%) mean ratings were in
the predicted direction. The aim of these analyses was not primarily to investigate group
differences between Australian and Indian participants, but for the sake of completeness we
do report that the proportions of supported predictions were similar across conditions.
About one half (28 + 27) of the correct predictions were from participants in in-group
conditions, and the other half (27 + 31) were from participants in out-group conditions.
Our second research question was, however, to directly investigate if there were differences
between appraisal ratings from Australian and Indian participants. These analyses are
reported in Section 3.2. We calculated the Bayes factors (BFs) for each comparison between
Australian and Indian participants, and these analyses are based on the “magnitude
difference” between groups. Our conclusion that there were few differences between
Australian and Indian listeners is based on the generally small BFs that were obtained in
these analyses (all BFs are presented in Table S1). Out of the 96 comparisons, only 17
comparisons yielded BFs that were large enough to give support for a difference between
groups, whereas 61 comparisons yielded BFs that gave support for no difference.
We hope that this explanation clarifies that our conclusions about cultural consistency in
appraisal ratings are indeed based on direct tests of the “magnitude difference” between
Australian and Indian ratings. We agree that there are also other ways to analyze the data,
but we have opted for Bayesian analysis, because this allowed us to interpret both
similarities and differences found across cultures. We have added a brief motivation for our
choice of Bayesian analysis on page 4, line 5:
“Bayesian analysis is one of many statistical tools, each with its benefits and drawbacks. In
the current study, we have used Bayesian analyses because we believe that it gives the most
accurate and informative description of our data. For example, its ability to differentiate
between a small effect and low power [31] allowed us to interpret both similarities and
differences found across cultures.”
- Page 4 Line 49 One compelling analysis would be to show how emotions were rated
differently on each appraisal dimensions regardless of culture. A table or figure showing the
rating values collapsing four groups for each dimension would be clear.
* We agree that such a figure would be informative and have added a new figure (online
supplemental Figure S2) which shows appraisal ratings for each emotion collapsed across
speaker and listener cultures. The results are almost identical to Figure 1, but it may be
easier to see the general appraisal patterns for each emotion in Figure S2.
- Page 5 Line 12 Judging by Figure 1, the listener cultural difference mainly lied in Australian
speaker judged by Australian vs. Indian listener (but not in Indian speaker) and was mainly
found in happiness, pride, serenity. Did author have any interpretation for these
observations?
* We interpreted cultural differences mainly at the level of individual appraisal dimensions.
For norm compatibility, we observed that 7 out of 16 cross-cultural comparisons supported
a difference (3 for Australian speakers and 4 for Indian speakers). Consequently we
concluded that cultural differences were observed in particular for norm compatibility (see
Figure S3).
If we instead look at cultural differences at the level of individual emotions, we get the
following numbers. For Australian speakers, differences were observed for happiness (4),
pride (3), fear (2), sadness (2) and serenity (2), whereas for Indian speakers differences were
observed for anger (1), fear (1), pride (1), and serenity (1). While there could be some
underlying pattern to these results, we hesitate to interpret the results at the level of
individual emotions. We only have 6 cross-cultural comparisons for each emotion, and we
believe this makes our estimates for individual emotions too uncertain.
- Page 5 Line 20 Did the authors control for other acoustic cues or appraisal dimensions when
they explored each acoustic cue in relation to a particular appraisal dimension?
* For the sake of comparison with previous within-cultural research on the acoustical
correlates of appraisal ratings, we used the same method as described in [1] and calculated
bivariate Pearson correlations between acoustic parameters and mean listener ratings. The
suggestion to control for acoustic cues and appraisal dimensions in these analyses is
interesting. However, our study was not designed for this purpose, and we would probably
have problems with multicollinearity if we tried to use, for example, a regression analysis to
determine the unique contribution of individual acoustic cues/appraisal dimensions. Ideally,
studies that focus on the unique contribution of various acoustic cues should create stimuli
where acoustic characteristics are manipulated in a systematic way, and this would be an
excellent topic for future studies on appraisal perception.
- Page Line 20 I was wondering to what extent the results were potentially affected by the
recognition accuracy of target emotions. Any data collected for this study?
* We unfortunately did not collect recognition rates for specific emotion categories in the
current study. In hindsight, we wish we would have done this, and we have added a note
regarding the need for studies that directly compare perception of appraisal dimensions and
emotion categories in the discussion section (page 7, line 1):
“Future cross-cultural studies could explicitly compare traditional categorical judgments and
appraisal ratings of emotion expressions. Studies that aim to link effects of culture on the
perception of specific appraisal dimensions to effects of culture on the recognition rates for
specific emotions would be especially valuable.”
Because we did not collect emotion recognition rates from our current listener sample, it
was not possible for us to directly explore how our results were affected by “the recognition
of target emotions”. However, we selected our stimuli based on emotion recognition data
from a previous study [10]. Based on data from that previous study, the target emotions in
our stimulus sample were on average recognized with accuracy around 4.5 times higher
than chance – which compares favorably to the recognition rates usually reported in the
speech prosody literature (e.g., [4]). We have added this information in the methods section
(page 3, line 4):
“Stimulus selection was based on own-culture emotion recognition rates obtained in [10],
using an 11-alternative forced-choice paradigm conducted separately for positive and
negative emotions. The average recognition rate for the selected portrayals was around 4.5
times higher than chance agreement (mean recognition accuracy = 41%; Australia = 35%,
India = 47%).”
- Page Line 22 The authors proposed at the beginning of the article that the Australian and
Indian culture are different greatly in cultural orientation. I was curious how they would
interpret their findings regarding emotional appraisal in the context of Hofstedes' cultural
dimension.
* We believe that Hofstede’s cultural dimensions provide one useful way to operationalize
differences between cultures, and have added more details about how Australia and India
differ in this regard in the Introduction (page 2, line 15):
“We chose to compare Australia and India because these two nations exhibit different
profiles on Hofstede’s [19] cultural dimensions. Australia scores low on power distance and
high on individualism, whereas the opposite pattern is reported for India.”
In the section about study limitations, we now also refer back to Hofstede’s dimensions
(page 7, line 30):
“For example, our study is limited because it only compared two cultures. Australia and
India have different cultural profiles in terms of Hofstede’s [19] dimensions, but it remains a
possibility that comparisons of other nations – with other cultural profiles – might reveal
additional effects of culture.”
In other words, we believe that an investigation of the effects of cultural distance on
appraisal perception would require a larger selection of nations/cultures with varying
Hofstede profiles. For what it’s worth, we again note that in a previous study we did observe
that greater overall cultural distance predicted lower recognition of emotion categories [10].
- Page 7 Line 53 I would like to see some discussions on how the Bayesian analysis can
benefit the understanding the emotional appraisal theory.
* Bayesian analysis is a statistical tool that, if used correctly, can help researchers in all fields
to get a better understanding of the questions they seek to answer. We have added a brief
motivation for our choice of Bayesian analysis on page 4, line 5:
“Bayesian analysis is one of many statistical tools, each with its benefits and drawbacks. In
the current study, we have used Bayesian analyses because we believe that it gives the most
accurate and informative description of our data. For example, its ability to differentiate
between a small effect and low power [31] allowed us to interpret both similarities and
differences found across cultures.”
Reviewer: 2
Comments to the Author(s)
- Nordström and colleagues present a cross-cultural study examining how Australian and
Indian listeners infer emotion appraisal dimensions from emotional speech produced by
Australian and Indian speakers. Using a simple but effective design, they asked participants
to rate the stimuli across six dimensions, namely novelty, intrinsic pleasantness, goal
conduciveness, urgency, power, and norm compatibility. Through a set of Bayesian analyses,
they show that (1) the profiles of ratings generally confirm the predictions of appraisal
theories, both for Australian and for Indian participants; and that (2) the ratings of
Australian and Indian participants were similar in most cases (64% of the comparisons),
suggesting that appraisal inferences are universal to an important extent. An exploratory
analysis of the relationship between acoustic features and appraisal ratings is also included.
I really enjoyed reading this paper – the focus on appraisal dimensions in a cross-cultural
setting makes this a novel and compelling contribution, that will be of interest to many
researchers on vocal communication and on emotion more broadly. The paper is well-
written, the research questions and hypotheses are clear and well-motivated, and the
methods are generally sound.
* We thank you for this positive evaluation of our research.
- I have a few comments/suggestions, though, that I would encourage the authors to address
before publication in Royal Society Open Science:
1. It is not clear before the Materials and Methods section that the focus is on emotional
speech prosody, and not on purely nonverbal vocalizations such as screams or laughter. I
suggest this is made explicit in the title and/or abstract, and it would also be useful to make
the distinction between the two types of vocal cues in the Introduction.
* We have added information, both in the abstract and in the Introduction, clarifying that
the focus of our study was on emotional speech prosody.
Abstract (page 1, line 27):
“This study explored the perception of emotion appraisal dimensions on the basis of speech
prosody in a cross-cultural setting.”
Introduction (page 1, line 49):
“The current article presents the first study of cross-cultural similarities and differences with
regard to judgments of emotion-eliciting situations, described in terms of appraisal
dimensions, from emotional speech prosody.”
- 2. The authors appropriately refer to (and cite) appraisal theories, but it is somewhat
unclear why this particular set of dimensions was selected for the current study. Can they
briefly discuss this? Including additional details about the dimensions could also be helpful,
particularly for readers not familiarized with appraisal theories.
* We now clarify that the particular set of appraisal dimensions included in our study
consisted of those appraisal dimensions that received acceptable inter-rater reliability in the
previous within-cultural study by Laukka and Elfenbein [1]. This selection in turn was based
on readings of the appraisal literature (e.g., [13, 29]) and contained a representative, but not
exhaustive, sample of the major appraisal dimensions that have been proposed in the
literature. See page 3, line 47:
“Following Laukka and Elfenbein [1], and based on the literature on emotion appraisal (e.g.,
13, 29), we set up the following predictions about the expected outcome of the participants’
appraisal ratings. All appraisal dimensions that received acceptable inter-rater reliability in
[1] were also included in the current study. Note that it was not possible to make predictions
for all appraisal dimensions and all emotions based on the literature.”
- 3. It would also be useful to include more details about the cultural differences between
Australia and India (e.g., Hofstede’s dimensions), and to discuss previous findings on
acoustic/perceptual differences in emotional prosody across these countries.
* We have provided additional details about how Australia and India differ with regard to
Hofstede’s dimensions (page 2, line 15):
“We chose to compare Australia and India because these two nations exhibit different
profiles on Hofstede’s [19] cultural dimensions. Australia scores low on power distance and
high on individualism, whereas the opposite pattern is reported for India.”
Although there are many studies comparing Western and Eastern nations, we are only
aware of one previous study that has specifically compared Australia and India – in that
study we observed a clear example of in-group advantage between these two nations [10].
We now briefly mention the main findings from that study (page 2, line 17):
“In a previous study, using a categorical approach, we also observed a clear bi-directional in-
group advantage, with more accurate emotion recognition accuracy in in-group vs. out-
group conditions, between these two nations [10].”
- 4. Details about the stimuli: the VENEC database (from which the current recordings were
selected) includes 20 actors per culture, but it is not said how many of these speakers are
represented in the subset of recordings used here. Was the number of speakers (and the
number of stimuli produced by men and women) matched across the Australian and Indian
sets?
* We have added a paragraph which describes the speakers who contributed stimuli to the
current study. The number of speakers was the same for both groups, but Indian stimuli
contained a slightly higher proportion of female vs. male speakers (page 3, line 2):
“We selected 8 recordings from each of the 8 emotion categories/scenarios from both the
Australian and Indian recordings for the current study, which resulted in a total of 128 vocal
expressions. The selected portrayals contained stimuli from 19 Australian (9 female) and 19
Indian (10 female) actors, with the following numbers of female (Australia, N = 32; India, N =
37) and male (Australia, N = 32; India, N = 27) stimuli. Stimulus selection was based on own-
culture emotion recognition rates obtained in [10], using an 11-alternative forced-choice
paradigm conducted separately for positive and negative emotions.”
- 5. There were some differences in how the experiment was conducted in Australia and in
India (e.g., time vs. untimed format), but I believe this is unlikely to have affected results in
important ways. One small point, though: was the number of times each stimulus was played
registered, and have the authors checked if this was similar across conditions? If there were
differences (e.g., between countries), can these differences account for how the stimuli were
rated?
* The difference in format was a consequence of the fact that we only had access to 30 min
sessions (albeit with a large number of participants) in Australia, whereas we had a limited
number of participants (albeit with less strict time limits) in India. The chosen procedures
allowed us to obtain at least 40 ratings from both Australian and Indian listeners for each of
the included 128 vocal stimuli. Unfortunately, we did not record response times or the
number of times that each stimulus was played. However, based on the average length of
the whole session in India, and the average number of stimuli rated per 30 min in Australia,
we have no reason to expect any major differences in response time between listener
groups.
- 6. I wonder if the authors considered including an emotion recognition measure as well.
This would have been interesting to directly compare the magnitude of culture effects across
domains (e.g., is emotion recognition more strongly shaped by culture than emotion
appraisal inferences?).
* As discussed above, we did not collect recognition rates for specific emotion categories in
the current study. In hindsight, we wish we would have done this, and we have added a note
regarding the need for studies that directly compare perception of appraisal dimensions and
emotion categories in the discussion section (page 7, line 1):
“Future cross-cultural studies could explicitly compare traditional categorical judgments and
appraisal ratings of emotion expressions. Studies that aim to link effects of culture on the
perception of specific appraisal dimensions to effects of culture on the recognition rates for
specific emotions would be especially valuable.”
- Additionally, and related to a possibility mentioned on p. 6: if participants first make a
categorical judgment, and base their appraisal evaluations on that judgment, would it be
more appropriate to only consider appraisal evaluations for stimuli that participants could
correctly categorize (i.e., are appraisal evaluations for stimuli that participants might not be
able to recognize meaningful)?
* We believe that the comparison of categorical and dimensional/appraisal accounts of
emotion perception represents an important empirical question for future research. We
have added a brief note to our discussion of this topic, about possible ways to distinguish
between categorical and dimensional accounts (page 7, line 44):
“Conceptually, one important avenue for future research is to investigate if listeners directly
infer the appraisal dimensions from vocal stimuli, or if they first make a categorical
judgment and then infer the appraisal based on their categorical judgment through a
process of reverse engineering (e.g., [16]) … Studies that directly compare the time courses
of emotion category perception and appraisal perception could be helpful for further
investigations of this issue.”
In addition, we note that we have reason to believe that the target emotions of our stimuli
were relatively well recognized. Although we did not collect recognition rates for the current
sample of listeners, the stimuli were selected based on emotion recognition rates in a
previous study, and we have added information about the selection procedure (and previous
recognition rates) on page 3, line 4:
“Stimulus selection was based on own-culture emotion recognition rates obtained in [10],
using an 11-alternative forced-choice paradigm conducted separately for positive and
negative emotions. The average recognition rate for the selected portrayals was around 4.5
times higher than chance agreement (mean recognition accuracy = 41%; Australia = 35%,
India = 47%).”
- 7. On a related note, I would be interested in hearing the authors’ thoughts about what
would be the equivalent of an in-group advantage in the context of emotion appraisal
inferences. Would we expect to see more extreme ratings – in the direction of the theoretical
predictions – when the speakers and perceivers come from the same culture; more consistent
evaluations (with less variation between listeners/speakers of the same culture); or just
different ratings? Do the authors consider the reported group differences conceptually
comparable to the in-group advantage reported in previous cross-cultural work in the
categorical tradition?
* At this initial stage of cross-cultural research on appraisal perception, we believe that an
in-group advantage could look like any of the alternatives that you describe. More extreme
ratings (indicating that listeners feel more secure in their ratings) or ratings more often in
line with the predictions (indicating that listeners can infer more aspects of the emotion-
eliciting situation) would obviously be examples of in-group advantage. However, any
difference in appraisal ratings between groups could be related to differences in emotion
category perception. It thus remains a possibility that the cultural differences that we
observed for (mainly) norm compatibility could be related to group differences in emotion
perception (and possibly in-group advantage). We therefore believe that our results are
conceptually comparable to previous findings from categorical studies (which have reported
minimal universality accompanied by in-group advantage). We devote a whole section of the
Discussion to this issue (page 6, line 54). (It is the section starting with: ”Previous cross-
cultural studies in the categorical tradition have reported evidence for minimal universality
… “)
- 8. In the Results section, I would encourage the authors to include a measure of rater
consistency, to confirm that the listeners were able to rate all the appraisal dimensions in a
consistent way, and that reliability coefficients were similar across countries.
* We have added measures of rater consistency, as requested.
Methods section, page 4, line 59:
“Consistency among raters was assessed separately for each appraisal dimension and rater
group (Australia and India). Raters were randomly split into halves and 10 000 randomly
selected split-half correlations were calculated. The means of these correlations were then
standardized using the Spearman-Brown prophecy formula [36]. As a validation of this
procedure, we also calculated intra-class correlations, ICC(2,k), for the Indian raters using
the ‘psych’ package in R [37]. Both procedures yielded almost (to the second decimal point)
identical results. Because a majority of the Australian listeners did not rate all stimuli, it was
not possible to calculate intra-class correlations for the Australian listeners. Therefore, the
Spearman-Brown standardized mean split-half correlations were used as a measure of inter-
rater reliability for both rater groups.”
Results section, page 5, line 14:
“Inter-rater reliability (average split-half correlations) was good for all appraisal dimensions
across cultural conditions. For Australian and Indian listeners, respectively, the inter-rater
reliability for each dimension was: Novelty (.93, .95), Intrinsic Pleasantness (.97, .98), Goal
Conduciveness (.88, .92), Urgency (.94, .96), Power (.82, .88), and Norm Compatibility (.83,
.93).”
- 9. A point about the stimuli: was it the case that the verbal content of all the stimuli
(including Australian and Indian recordings) consisted of emotionally neutral English
sentences? If so, Australian participants produced and rated stimuli expressed in their native
language, while Indian participants did not (they reported being fluent in English, but their
native languages were Nepali, Assamese, Indi, and Tibetan). I agree that this improves
consistency across portrayals, and might prevent language-related confounds, but I wonder
if it might also mask potential effects of culture. Can we exclude the possibility that the
actors would express emotions slightly differently in their native language, and that the
listeners would evaluate appraisal dimensions differently in these stimuli? It would be
important to see this discussed, particularly because cross-cultural similarities are central for
the argument of the paper.
*We now clarify that all stimuli were indeed in English, and that this was done to improve
the consistency of stimuli across conditions. Such consistency is especially important for
acoustic analyses, where the vocal content needs to be kept controlled (otherwise it could
influence acoustic parameters in systematic ways), see page 2, line 60:
“For consistency across portrayals, in each case the verbal content consisted of brief
emotionally neutral sentences in English (“Let me tell you something”, “That is exactly what
happened”). See Laukka et al. [10] for a full description of the recording procedure including
descriptions of the emotion scenarios.”
We have also added a discussion about possible limitations of using only English-language
stimuli on page 7, line 33:
“The verbal content of our stimuli further consisted of neutral sentences spoken in English,
in order to increase consistency across portrayals (see [10]). However, it remains a
possibility that effects of culture might be more salient when vocal stimuli from different
cultures are portrayed using different languages. More research is thus needed to
investigate if the results of the current study can be generalized to other speaker and
listener cultures and languages, preferably also using a wider selection of emotions,
appraisal dimensions, and acoustic parameters.”
Society Open
