Scientific risk communication about controversial issues
influences public perceptions of scientists' political
orientations and credibility
Emily Vraga, Teresa Myers, John Kotcher, Lindsey Beall and Ed Maibach
Article citation details
R. Soc. open sci. 5: 170505.
http://dx.doi.org/10.1098/rsos.170505
Review timeline
Original submission: 16 May 2017 Note: Reports are unedited and appear as
1st revised submission: 5 October 2017 submitted by the referee. The review history
2nd revised submission: 21 November 2017 appears in chronological order.
Final acceptance: 19 January 2018
Review History
label_version_1
RSOS-170505.R0 (Original submission)
label_author_1
Review form: Reviewer 1
Is the manuscript scientifically sound in its present form?
Yes
Are the interpretations and conclusions justified by the results?
No
Is the language acceptable?
Yes
Is it clear how to access all supporting data?
Yes
Do you have any ethical concerns with this paper?
No
© 2018 The Authors. Published by the Royal Society under the terms of the Creative Commons
Attribution License http://creativecommons.org/licenses/by/4.0/, which permits unrestricted use,
provided the original author and source are credited
2
Have you any concerns about statistical analyses in this paper?
No
Recommendation?
label_recommendation_1
Major revision is needed (please make suggestions in comments)
Comments to the Author(s)
label_comment_1
This manuscript explores how scientists engaging with the public in risk communication on a
politically contested issue can influence an individual’s perception about the political orientation
of the scientist, as well as the political orientation of the broader scientific community. It posits
that when a scientist highlights risks associated with an issue primarily of concern to
conservatives (e.g., marijuana use) this will increase estimates of the scientist and scientific
community as conservative, and vice versa when the scientist highlights the risk of a perceived
liberal issue (e.g., climate change) – i.e., relative to perceptions of the scientist when they engage
the public on a non-controversial issue in which there is no clear partisan divide (see H1 and H2).
This expectation is based on research demonstrating that perceptions of scientists are often
consistent with “pop-culture depictions”, low levels of factual science knowledge, and research
on heuristic processing of information demonstrating that “relatively superficial cues influence
perceptions” (p. 5). This process is labeled the “contextual effects model” in which perceptions of
scientists’ political orientations depend both on the nature of the political issue (is there
ideological / partisan conflict or not) and an individual’s own partisan / ideological
identification. Another mechanism, labeled the “main effects” model, by which ideology may
influence perceptions of a scientist (and the science community) more generally is if ideology
(conservatism) directly increases perception that scientists and the scientific community are
driven by a liberal / Democratic agenda. This is not a focus of the proposed experiment or the
hypotheses listed on pages 9-10. In addition to exploring how motivated reasoning may
influence reported perceptions of scientists’ political orientation among partisans, the manuscript
also explores how political moderates react to risk communication across experimental contexts.
The manuscript includes hypotheses about how the information will influence perceptions of the
scientific community more broadly in addition to perceptions about the political orientation of
the individual scientist taking a position on an issue; however, the predictions that different
ideological subgroups will respond to a greater extent when the issue is out-group focused are
not clearly grounded in any theory. I suggest either simplifying / cutting those hypotheses or
developing additional theory to motivate the expectations. The hypotheses about how the
information will influence perceptions of the broader scientific community based on exposure to
the risk communication of a single scientist are not grounded in any theory – the explanation
offered on page 8 with the discussion of the scientist’s communication serving as a “salient
exemplar of scientific risk communication” is not overly compelling. The paper cites the work of
Kahan et al. 2011 that demonstrates motivated reasoning clearly drives perceptions of scientific
expertise based on whether risk communication is congruent / incongruent with an individual’s
worldview (evidence of directional motivated reasoning), but it then motivates the hypotheses it
tests by making an argument that in this instance perceptions are driven by “heuristic
processing” and “susceptibility” to such information processing shortcuts that produce opinion
change / “biases”, especially when forming judgments about “politicized political issues” (p. 7).
The manuscript addresses an important and interesting research topic, and it cites relevant
literatures that motivate some of the hypotheses (H1 & H2). However, the manuscript needs
additional theoretical development to support its predictions about perceptions of the broader
scientific community would be influenced by a single (hypothetical) scientist’s statement about
risk associated with an issue that is more closely connected to the concerns of a particular
subgroup of partisans / ideologues.
These hypotheses are tested with an experiment conducted in the US in 2015 via an online survey
(> 2,000 participants) through Qualtrics that recruited a nationally representative sample. It
3
wasn’t completely clear how many participants were in each of the four conditions that are the
focus of the present study (more below on this).
The survey included a fictional scientist taking a position about risk on two low controversy
issues (severe weather & flu) and two high controversy issues (climate change & marijuana use).
The results demonstrate that the fictional scientist is seen as more conservative and Republican
when communicating about marijuana risks relative to the other three issues, and more liberal /
Democratic when taking a position on climate change. The manuscript also finds limited support
for H2b regarding evaluations of the scientific community being perceived as more liberal
following information about climate change relative to marijuana or the flu issue (but not when
severe weather is the baseline). What is the relevant baseline condition for evaluating the
hypotheses? If comparing for significance between conditions that received different information
(i.e., not relative to a “pure control” condition) then how can one be sure whether the significance
is being driven by the “climate change” treatment, the “marijuana treatment” or some
combination of movement produced by each stimuli? The issue of defining / justifying what the
relevant baseline is for assessing statistical significance is also relevant for the analyses reporting
the tests on political moderates’ views across conditions. There are “mixed findings” with
respect to the additional hypothesis tests that are conducted, depending on both the issue and
what condition is used as the relevant comparison / baseline.
I was confused by the discussion of the “No Solution”, Non-Controversial solution, Controversial
solution conditions (p. 10) and which conditions were excluded and included from the original
design. I believe the focus in the present paper is exclusively on participants that were in the “no
solution conditions” of the original experiment, correct? If so, what is the exact N of the
participants in each condition in the experiment reported in this manuscript, and what is the total
N for this particular paper not counting the conditions that are excluded? I do not following the
discussion regarding “other results are reported elsewhere”. The discussion of what conditions
were collapsed from the original experiment, and why, at the bottom of pg. 10 is unclear and
needs additional explanation.
I don’t follow the information in footnote 7. Was random assignment unsuccessful or is it simply
that the marijuana issue was seen as less threatening and less meriting of government action
compared to the other conditions? If the latter, then it doesn’t seem necessary to retain the
control variables.
label_author_2
Review form: Reviewer 2 (Dan Kahan)
Is the manuscript scientifically sound in its present form?
Yes
Are the interpretations and conclusions justified by the results?
Yes
Is the language acceptable?
Yes
Is it clear how to access all supporting data?
Yes
Do you have any ethical concerns with this paper?
No
4
Have you any concerns about statistical analyses in this paper?
No
Recommendation?
label_recommendation_2
Major revision is needed (please make suggestions in comments)
Comments to the Author(s)
label_comment_2
The authors present the results of an experiment in which they assessed study subjects’
impressions of the political outlooks and affiliations of scientists who reported research findings
on topics that divide the public on political grounds. Although the scientist presenting the
information did not take any position on the policy implications of the research (see
Supplemental Information, App. 1), the subjects inferred that the scientist and in some instances
scientists as a group had partisan affiliations that matched the apparent policy significance of the
reported research. On this basis, the authors advise that “Scientists need to carefully consider
public perceptions of the issues they choose to engage with in communicating about scientific
risk” (p. 23).
I think the article might well be suitable for publication. But before the journal makes such a
determination, I believe the authors should be requested to resubmit a revised draft that
addresses issues related to the internal validity of the study. They should also be asked to supply
a more detailed account of how the authors’ conclusions in this paper can be reconciled (if they
can be) with those of other studies their research group has conducted.
1. A premise of the study is that the perception that a scientist who reaches results congenial to
his or her political outlooks and affiliations is less credible than one who reaches results unrelated
or contrary to his or her political outlooks and affiliations (see p. 8, e.g.). But in fact, the authors
do not report any data relating to the perceived trustworthiness and expertise of the scientist (or
scientists generally) in the various conditions or relative to a genuinely neutral control. Nor do
they report whether subjects’ own perceptions of the risks being addressed were affected by
exposure to the scientist’s finding.
No variables relating to these basic questions appear in the supplied data file. However, the
authors expressly state that they have included only a subset of the data collected, the remainder
of which “are reported elsewhere” (p. 10).
Accordingly, I think the authors should state expressly whether they collected any data that bear
on the subjects’ perceptions of the credibility or trustworthiness of the scientist in the various
conditions. If they did, they should indicate what such data show, since a finding that that such
perceptions were not adversely affected would undercut the inferences the authors make in this
paper. If they didn’t, they should explain why and acknowledge that this omission is another
limitation on the strength of the inferences that can be drawn.
I also think the authors should in any case describe the omitted data that they “report elsewhere.”
In general, it is bad research practice to publish results of a single study piecemeal across multiple
journal articles. The reviewers should have an opportunity, then, to determine whether separate
reporting of the omitted data is appropriate.
2. The authors’ research lab has published various studies on how scientist communication
influences opinion on climate change. The conclusions of at least two of them seem in deep
tension with the data reported here.
In one (van der Linden et al. 2015; co-author Maibach), they purport to find that a “scientific
consensus” treatment generated higher estimates of consensus and other pro-action perceptions
5
and attitudes among Republican as well as Democratic study subjects. This seems out of keeping
with the results presented in this paper: either the Republican subjects did not see scientific risk
information as originating in the scientists’ ideology or they did but didn’t discount its credibility
as a result.
Even more recently Kotcher et al. (2017; coauthors Myers, Maibach, and Kotcher) published a
study in which they found that simple reporting of data by scientists did not diminish the
credibility of scientists discussing recent research findings. Indeed, they found that there was no
diminution of credibility even when the climate scientist combined his report of the data with a
specific policy recommendation. So either the subjects in that study did not draw inferences
about the featured scientist’s “liberal Democratic” political outlooks and affiliations or they didn’t
see those outlooks and affiliations as grounds for discounting what the scientist said. Indeed,
Kotcher et al. go so are to say that “our results suggest that scientists who wish to engage in
certain forms of advocacy may be able to do so without directly harming their credibility, or the
credibility of the scientific community” (p. 23)—advice that is obviously in tension with that
given in the current study.
The authors must address the relationship between their studies and the diverse conclusions they
are reaching. They might have a good explanation, but one that might naturally occur to a
neutral reader is that none of the study findings in these papers is particular robust.
Last point: if the data published in Kotcher et al. (2017) also features “Dr. Wilson,” who is
depicted variously as reporting a research finding and reporting research plus taking an
advocacy stance. If the data in that study are the ones the authors omitted from the current paper
and “reported elsewhere,” then there is a really big problem, since in that case, the authors would
not only be publishing their study results piecemeal but also publishing them in a truncated
format that generates opposing results.
But whether or not the data came from the same study, the tension between this paper and
Kotcher et al (2017) must be addressed here so that readers can be apprised of all the data that
variously support and contradict the conclusions the authors reach in the current submission.
References
Kotcher, J. E., Myers, T. A., Vraga, E. K., Stenhouse, N., & Maibach, E. W. (2017). Does
Engagement in Advocacy Hurt the Credibility of Scientists? Results from a Randomized National
Survey Experiment. Environmental Communication, 11(3), 415-429.
doi:10.1080/17524032.2016.1275736
Kotcher, J. E., Myers, T. A., Vraga, E. K., Stenhouse, N., & Maibach, E. W. (2017). Does
Engagement in Advocacy Hurt the Credibility of Scientists? Results from a Randomized National
Survey Experiment. Environmental Communication, 11(3), 415-429.
doi:10.1080/17524032.2016.1275736
label_end_comment
Decision letter (RSOS-170505)
21-Aug-2017
Dear Dr Vraga,
The editors assigned to your paper ("Scientific risk communication about controversial issues
6
influences public perceptions of scientists' political orientations") have now received comments
from reviewers. We would like you to revise your paper in accordance with the referee and
Associate Editor suggestions which can be found below (not including confidential reports to the
Editor). Please note this decision does not guarantee eventual acceptance.
Please submit a copy of your revised paper within three weeks (i.e. by the 13-Sep-2017). If we do
not hear from you within this time then it will be assumed that the paper has been withdrawn. In
exceptional circumstances, extensions may be possible if agreed with the Editorial Office in
advance.We do not allow multiple rounds of revision so we urge you to make every effort to
fully address all of the comments at this stage. If deemed necessary by the Editors, your
manuscript will be sent back to one or more of the original reviewers for assessment. If the
original reviewers are not available we may invite new reviewers.
To revise your manuscript, log into http://mc.manuscriptcentral.com/rsos and enter your
Author Centre, where you will find your manuscript title listed under "Manuscripts with
Decisions." Under "Actions," click on "Create a Revision." Your manuscript number has been
appended to denote a revision. Revise your manuscript and upload a new version through your
Author Centre.
When submitting your revised manuscript, you must respond to the comments made by the
referees and upload a file "Response to Referees" in "Section 6 - File Upload". Please use this to
document how you have responded to the comments, and the adjustments you have made. In
order to expedite the processing of the revised manuscript, please be as specific as possible in
your response.
In addition to addressing all of the reviewers' and editor's comments please also ensure that your
revised manuscript contains the following sections as appropriate before the reference list:
• Ethics statement (if applicable)
If your study uses humans or animals please include details of the ethical approval received,
including the name of the committee that granted approval. For human studies please also detail
whether informed consent was obtained. For field studies on animals please include details of all
permissions, licences and/or approvals granted to carry out the fieldwork.
• Data accessibility
It is a condition of publication that all supporting data are made available either as
supplementary information or preferably in a suitable permanent repository. The data
accessibility section should state where the article's supporting data can be accessed. This section
should also include details, where possible of where to access other relevant research materials
such as statistical tools, protocols, software etc can be accessed. If the data have been deposited in
an external repository this section should list the database, accession number and link to the DOI
for all data from the article that have been made publicly available. Data sets that have been
deposited in an external repository and have a DOI should also be appropriately cited in the
manuscript and included in the reference list.
If you wish to submit your supporting data or code to Dryad (http://datadryad.org/), or modify
your current submission to dryad, please use the following link:
http://datadryad.org/submit?journalID=RSOS&manu=RSOS-170505
• Competing interests
Please declare any financial or non-financial competing interests, or state that you have no
competing interests.
7
• Authors’ contributions
All submissions, other than those with a single author, must include an Authors’ Contributions
section which individually lists the specific contribution of each author. The list of Authors
should meet all of the following criteria; 1) substantial contributions to conception and design, or
acquisition of data, or analysis and interpretation of data; 2) drafting the article or revising it
critically for important intellectual content; and 3) final approval of the version to be published.
All contributors who do not meet all of these criteria should be included in the
acknowledgements.
We suggest the following format:
AB carried out the molecular lab work, participated in data analysis, carried out sequence
alignments, participated in the design of the study and drafted the manuscript; CD carried out
the statistical analyses; EF collected field data; GH conceived of the study, designed the study,
coordinated the study and helped draft the manuscript. All authors gave final approval for
publication.
• Acknowledgements
Please acknowledge anyone who contributed to the study but did not meet the authorship
criteria.
• Funding statement
Please list the source of funding for each author.
Once again, thank you for submitting your manuscript to Royal Society Open Science and I look
forward to receiving your revision. If you have any questions at all, please do not hesitate to get
in touch.
Yours sincerely,
Alice Power
Editorial Coordinator
Royal Society Open Science
on behalf of Essi Viding
Subject Editor, Royal Society Open Science
openscience@royalsociety.org
Comments to Author:
Reviewers' Comments to Author:
Reviewer: 1
Comments to the Author(s)
This manuscript explores how scientists engaging with the public in risk communication on a
politically contested issue can influence an individual’s perception about the political orientation
of the scientist, as well as the political orientation of the broader scientific community. It posits
that when a scientist highlights risks associated with an issue primarily of concern to
conservatives (e.g., marijuana use) this will increase estimates of the scientist and scientific
community as conservative, and vice versa when the scientist highlights the risk of a perceived
liberal issue (e.g., climate change) – i.e., relative to perceptions of the scientist when they engage
the public on a non-controversial issue in which there is no clear partisan divide (see H1 and H2).
8
This expectation is based on research demonstrating that perceptions of scientists are often
consistent with “pop-culture depictions”, low levels of factual science knowledge, and research
on heuristic processing of information demonstrating that “relatively superficial cues influence
perceptions” (p. 5). This process is labeled the “contextual effects model” in which perceptions of
scientists’ political orientations depend both on the nature of the political issue (is there
ideological / partisan conflict or not) and an individual’s own partisan / ideological
identification. Another mechanism, labeled the “main effects” model, by which ideology may
influence perceptions of a scientist (and the science community) more generally is if ideology
(conservatism) directly increases perception that scientists and the scientific community are
driven by a liberal / Democratic agenda. This is not a focus of the proposed experiment or the
hypotheses listed on pages 9-10. In addition to exploring how motivated reasoning may
influence reported perceptions of scientists’ political orientation among partisans, the manuscript
also explores how political moderates react to risk communication across experimental contexts.
The manuscript includes hypotheses about how the information will influence perceptions of the
scientific community more broadly in addition to perceptions about the political orientation of
the individual scientist taking a position on an issue; however, the predictions that different
ideological subgroups will respond to a greater extent when the issue is out-group focused are
not clearly grounded in any theory. I suggest either simplifying / cutting those hypotheses or
developing additional theory to motivate the expectations. The hypotheses about how the
information will influence perceptions of the broader scientific community based on exposure to
the risk communication of a single scientist are not grounded in any theory – the explanation
offered on page 8 with the discussion of the scientist’s communication serving as a “salient
exemplar of scientific risk communication” is not overly compelling. The paper cites the work of
Kahan et al. 2011 that demonstrates motivated reasoning clearly drives perceptions of scientific
expertise based on whether risk communication is congruent / incongruent with an individual’s
worldview (evidence of directional motivated reasoning), but it then motivates the hypotheses it
tests by making an argument that in this instance perceptions are driven by “heuristic
processing” and “susceptibility” to such information processing shortcuts that produce opinion
change / “biases”, especially when forming judgments about “politicized political issues” (p. 7).
The manuscript addresses an important and interesting research topic, and it cites relevant
literatures that motivate some of the hypotheses (H1 & H2). However, the manuscript needs
additional theoretical development to support its predictions about perceptions of the broader
scientific community would be influenced by a single (hypothetical) scientist’s statement about
risk associated with an issue that is more closely connected to the concerns of a particular
subgroup of partisans / ideologues.
These hypotheses are tested with an experiment conducted in the US in 2015 via an online survey
(> 2,000 participants) through Qualtrics that recruited a nationally representative sample. It
wasn’t completely clear how many participants were in each of the four conditions that are the
focus of the present study (more below on this).
The survey included a fictional scientist taking a position about risk on two low controversy
issues (severe weather & flu) and two high controversy issues (climate change & marijuana use).
The results demonstrate that the fictional scientist is seen as more conservative and Republican
when communicating about marijuana risks relative to the other three issues, and more liberal /
Democratic when taking a position on climate change. The manuscript also finds limited support
for H2b regarding evaluations of the scientific community being perceived as more liberal
following information about climate change relative to marijuana or the flu issue (but not when
severe weather is the baseline). What is the relevant baseline condition for evaluating the
hypotheses? If comparing for significance between conditions that received different information
(i.e., not relative to a “pure control” condition) then how can one be sure whether the significance
is being driven by the “climate change” treatment, the “marijuana treatment” or some
combination of movement produced by each stimuli? The issue of defining / justifying what the
9
relevant baseline is for assessing statistical significance is also relevant for the analyses reporting
the tests on political moderates’ views across conditions. There are “mixed findings” with
respect to the additional hypothesis tests that are conducted, depending on both the issue and
what condition is used as the relevant comparison / baseline.
I was confused by the discussion of the “No Solution”, Non-Controversial solution, Controversial
solution conditions (p. 10) and which conditions were excluded and included from the original
design. I believe the focus in the present paper is exclusively on participants that were in the “no
solution conditions” of the original experiment, correct? If so, what is the exact N of the
participants in each condition in the experiment reported in this manuscript, and what is the total
N for this particular paper not counting the conditions that are excluded? I do not following the
discussion regarding “other results are reported elsewhere”. The discussion of what conditions
were collapsed from the original experiment, and why, at the bottom of pg. 10 is unclear and
needs additional explanation.
I don’t follow the information in footnote 7. Was random assignment unsuccessful or is it simply
that the marijuana issue was seen as less threatening and less meriting of government action
compared to the other conditions? If the latter, then it doesn’t seem necessary to retain the
control variables.
Reviewer: 2
Comments to the Author(s)
The authors present the results of an experiment in which they assessed study subjects’
impressions of the political outlooks and affiliations of scientists who reported research findings
on topics that divide the public on political grounds. Although the scientist presenting the
information did not take any position on the policy implications of the research (see
Supplemental Information, App. 1), the subjects inferred that the scientist and in some instances
scientists as a group had partisan affiliations that matched the apparent policy significance of the
reported research. On this basis, the authors advise that “Scientists need to carefully consider
public perceptions of the issues they choose to engage with in communicating about scientific
risk” (p. 23).
I think the article might well be suitable for publication. But before the journal makes such a
determination, I believe the authors should be requested to resubmit a revised draft that
addresses issues related to the internal validity of the study. They should also be asked to supply
a more detailed account of how the authors’ conclusions in this paper can be reconciled (if they
can be) with those of other studies their research group has conducted.
1. A premise of the study is that the perception that a scientist who reaches results congenial to
his or her political outlooks and affiliations is less credible than one who reaches results unrelated
or contrary to his or her political outlooks and affiliations (see p. 8, e.g.). But in fact, the authors
do not report any data relating to the perceived trustworthiness and expertise of the scientist (or
scientists generally) in the various conditions or relative to a genuinely neutral control. Nor do
they report whether subjects’ own perceptions of the risks being addressed were affected by
exposure to the scientist’s finding.
No variables relating to these basic questions appear in the supplied data file. However, the
authors expressly state that they have included only a subset of the data collected, the remainder
of which “are reported elsewhere” (p. 10).
Accordingly, I think the authors should state expressly whether they collected any data that bear
10
on the subjects’ perceptions of the credibility or trustworthiness of the scientist in the various
conditions. If they did, they should indicate what such data show, since a finding that that such
perceptions were not adversely affected would undercut the inferences the authors make in this
paper. If they didn’t, they should explain why and acknowledge that this omission is another
limitation on the strength of the inferences that can be drawn.
I also think the authors should in any case describe the omitted data that they “report elsewhere.”
In general, it is bad research practice to publish results of a single study piecemeal across multiple
journal articles. The reviewers should have an opportunity, then, to determine whether separate
reporting of the omitted data is appropriate.
2. The authors’ research lab has published various studies on how scientist communication
influences opinion on climate change. The conclusions of at least two of them seem in deep
tension with the data reported here.
In one (van der Linden et al. 2015; co-author Maibach), they purport to find that a “scientific
consensus” treatment generated higher estimates of consensus and other pro-action perceptions
and attitudes among Republican as well as Democratic study subjects. This seems out of keeping
with the results presented in this paper: either the Republican subjects did not see scientific risk
information as originating in the scientists’ ideology or they did but didn’t discount its credibility
as a result.
Even more recently Kotcher et al. (2017; coauthors Myers, Maibach, and Kotcher) published a
study in which they found that simple reporting of data by scientists did not diminish the
credibility of scientists discussing recent research findings. Indeed, they found that there was no
diminution of credibility even when the climate scientist combined his report of the data with a
specific policy recommendation. So either the subjects in that study did not draw inferences
about the featured scientist’s “liberal Democratic” political outlooks and affiliations or they didn’t
see those outlooks and affiliations as grounds for discounting what the scientist said. Indeed,
Kotcher et al. go so are to say that “our results suggest that scientists who wish to engage in
certain forms of advocacy may be able to do so without directly harming their credibility, or the
credibility of the scientific community” (p. 23)—advice that is obviously in tension with that
given in the current study.
The authors must address the relationship between their studies and the diverse conclusions they
are reaching. They might have a good explanation, but one that might naturally occur to a
neutral reader is that none of the study findings in these papers is particular robust.
Last point: if the data published in Kotcher et al. (2017) also features “Dr. Wilson,” who is
depicted variously as reporting a research finding and reporting research plus taking an
advocacy stance. If the data in that study are the ones the authors omitted from the current paper
and “reported elsewhere,” then there is a really big problem, since in that case, the authors would
not only be publishing their study results piecemeal but also publishing them in a truncated
format that generates opposing results.
But whether or not the data came from the same study, the tension between this paper and
Kotcher et al (2017) must be addressed here so that readers can be apprised of all the data that
variously support and contradict the conclusions the authors reach in the current submission.
References
Kotcher, J. E., Myers, T. A., Vraga, E. K., Stenhouse, N., & Maibach, E. W. (2017). Does
Engagement in Advocacy Hurt the Credibility of Scientists? Results from a Randomized National
11
Survey Experiment. Environmental Communication, 11(3), 415-429.
doi:10.1080/17524032.2016.1275736
Kotcher, J. E., Myers, T. A., Vraga, E. K., Stenhouse, N., & Maibach, E. W. (2017). Does
Engagement in Advocacy Hurt the Credibility of Scientists? Results from a Randomized National
Survey Experiment. Environmental Communication, 11(3), 415-429. doi:10.1080/17524032.2016.
Author's Response to Decision Letter for (RSOS-170505)
See Appendix A.
label_version_2
RSOS-170505.R1 (Revision)
label_author_3
Review form: Reviewer 1
Is the manuscript scientifically sound in its present form?
Yes
Are the interpretations and conclusions justified by the results?
Yes
Is the language acceptable?
Yes
Is it clear how to access all supporting data?
Yes
Do you have any ethical concerns with this paper?
No
Have you any concerns about statistical analyses in this paper?
No
Recommendation?
label_recommendation_3
Accept as is
Comments to the Author(s)
label_comment_3
The authors have done a very thorough job responding to the recommendations from in the
initial review. I believe the manuscript is greatly improved as a result of the revisions, and I now
strongly endorse its publication. I agree with the decision to move the results about general
perceptions of science to the Appendix and add the mediation hypotheses about perceived
credibility of Dr. Wilson as a function of his risk communication on different topics, and how this
might be moderated by political ideology. While there is no support for H2a and H2b, the
finding that talking about any controversial issue (relative to talking about a non-controversial
issue) reduces the scientist's perceived credibility is interesting to me. The description of the
study design and the key conditions for this paper is much clearer and easier to follow. The
footnote making the case for separating this study from the additional conditions in the larger
12
study focused on communicating policy solutions is convincing and makes sense. I noticed that
Figure 1 is missing a legend that identifies the color with the experimental condition, and I
recommend adding that as it appears in the other Figures.
label_author_4
Review form: Reviewer 2 (Dan Kahan)
Is the manuscript scientifically sound in its present form?
No
Are the interpretations and conclusions justified by the results?
No
Is the language acceptable?
Yes
Is it clear how to access all supporting data?
Yes
Do you have any ethical concerns with this paper?
No
Have you any concerns about statistical analyses in this paper?
No
Recommendation?
label_recommendation_4
Major revision is needed (please make suggestions in comments)
Comments to the Author(s)
label_comment_4
The authors failed meaningfully to address my two central reactions to their earlier draft.
One of these was that there was a contradiction between the conclusion of this study and the ones
reached in earlier papers authored by at least one of the co-authors of the current paper. In
Kotcher et al. (2017), the authors conclude that their "results suggest that climate scientists who
wish to engage in certain forms of advocacy have considerable latitude to do so without risking
harm to their credibility, or the credibility of the scientific community." In this paper, in contrast,
the authors warn that "Scientists should carefully consider public perceptions of the issues they
choose to engage with in communicating about scientific risk" because of the impact that such
communication has on public impressions of scientists' ideology, an effect that induces the public
to apply "political labels to the scientific community more broadly, [thereby] creating a potential
reinforcing cycle of perceptions of scientists as political actors."
The authors' response to my observation of this tension is, w/ due respect, a nonresponse-- a
hand-waiving account about about why we should expect R's to be generally more skeptical of
scientists than D's. The current paper does not add "nuance" to the Kotcher et al. (2017); it simply
contradicts that earlier study. The authors also ignored the tension between this paper and the
van der Linden et al. study on the effects of "consensus messaging"-- a study that also took the
position that members of the public, including Repubs, trust scientists on climate change (see also
Leiserowitz, Myers & Maibach 2014).
The authors should be asked again to address these tensions, which readers could reasonably
13
understand to indicate that the authors have a weak grasp of what they are actually measuring in
the various studies in question.
I also suggested that the authors should be directed to discuss the nature of the work they have
submitted "elsewhere" on the impact that scientist advocacy has on public perceptions (p. 11 fn 2).
Readers deserve to know whether those data, which apparently derive from the same study,
support conclusions consistent with the one that the authors reach here. Again, my point was
ignored by the authors.
I believe the authors should be asked for a resubmission that addresses these issues.
Refs
Kotcher, J.E., Myers, T.A., Vraga, E.K., Stenhouse, N. & Maibach, E.W. Does Engagement in
Advocacy Hurt the Credibility of Scientists? Results from a Randomized National Survey
Experiment. Environmental Communication 11, 415-429 (2017).
Maibach, E., Myers, T. & Leiserowitz, A. Climate scientists need to set the record straight: There
is a scientific consensus that human-caused climate change is happening. Earth's Future 2, 295-
298 (2014).
van der Linden, S.L., Leiserowitz, A.A., Feinberg, G.D. & Maibach, E.W. The Scientific Consensus
on Climate Change as a Gateway Belief: Experimental Evidence. PLoS ONE 10 (2015).
label_end_comment
Decision letter (RSOS-170505.R1)
08-Nov-2017
Dear Dr Vraga:
Manuscript ID RSOS-170505.R1 entitled "Scientific risk communication about controversial issues
influences public perceptions of scientists' political orientations" which you submitted to Royal
Society Open Science, has been reviewed. The comments of the reviewer(s) are included at the
bottom of this letter.
Please submit a copy of your revised paper within three weeks (i.e. by the 01-Dec-2017). If we do
not hear from you within this time then it will be assumed that the paper has been withdrawn. In
exceptional circumstances, extensions may be possible if agreed with the Editorial Office in
advance. We do not allow multiple rounds of revision so we urge you to make every effort to
fully address all of the comments at this stage. If deemed necessary by the Editors, your
manuscript will be sent back to one or more of the original reviewers for assessment. If the
original reviewers are not available we may invite new reviewers.
To revise your manuscript, log into http://mc.manuscriptcentral.com/rsos and enter your
Author Centre, where you will find your manuscript title listed under "Manuscripts with
Decisions." Under "Actions," click on "Create a Revision." Your manuscript number has been
appended to denote a revision. Revise your manuscript and upload a new version through your
Author Centre.
When submitting your revised manuscript, you must respond to the comments made by the
14
referees and upload a file "Response to Referees" in "Section 6 - File Upload". Please use this to
document how you have responded to the comments, and the adjustments you have made. In
order to expedite the processing of the revised manuscript, please be as specific as possible in
your response.
In addition to addressing all of the reviewers' and editor's comments please also ensure that your
revised manuscript contains the following sections before the reference list:
• Ethics statement
If your study uses humans or animals please include details of the ethical approval received,
including the name of the committee that granted approval. For human studies please also detail
whether informed consent was obtained. For field studies on animals please include details of all
permissions, licences and/or approvals granted to carry out the fieldwork.
• Data accessibility
It is a condition of publication that all supporting data are made available either as
supplementary information or preferably in a suitable permanent repository. The data
accessibility section should state where the article's supporting data can be accessed. This section
should also include details, where possible of where to access other relevant research materials
such as statistical tools, protocols, software etc can be accessed. If the data have been deposited in
an external repository this section should list the database, accession number and link to the DOI
for all data from the article that have been made publicly available. Data sets that have been
deposited in an external repository and have a DOI should also be appropriately cited in the
manuscript and included in the reference list.
• Competing interests
Please declare any financial or non-financial competing interests, or state that you have no
competing interests.
• Authors’ contributions
All submissions, other than those with a single author, must include an Authors’ Contributions
section which individually lists the specific contribution of each author. The list of Authors
should meet all of the following criteria; 1) substantial contributions to conception and design, or
acquisition of data, or analysis and interpretation of data; 2) drafting the article or revising it
critically for important intellectual content; and 3) final approval of the version to be published.
All contributors who do not meet all of these criteria should be included in the
acknowledgements.
We suggest the following format:
AB carried out the molecular lab work, participated in data analysis, carried out sequence
alignments, participated in the design of the study and drafted the manuscript; CD carried out
the statistical analyses; EF collected field data; GH conceived of the study, designed the study,
coordinated the study and helped draft the manuscript. All authors gave final approval for
publication.
• Acknowledgements
Please acknowledge anyone who contributed to the study but did not meet the authorship
criteria.
• Funding statement
Please list the source of funding for each author.
15
Once again, thank you for submitting your manuscript to Royal Society Open Science and I look
forward to receiving your revision. If you have any questions at all, please do not hesitate to get
in touch.
Sincerely,
Alice Power
Royal Society Open Science
openscience@royalsociety.org
on behalf of Antonia Hamilton
Subject Editor, Royal Society Open Science
openscience@royalsociety.org
Associate Editor Comments to Author (Dr Molly Crockett):
Associate Editor: 1
Comments to the Author:
Comments to Author:
Reviewer: 1
Comments to the Author(s)
The authors have done a very thorough job responding to the recommendations from in the
initial review. I believe the manuscript is greatly improved as a result of the revisions, and I now
strongly endorse its publication. I agree with the decision to move the results about general
perceptions of science to the Appendix and add the mediation hypotheses about perceived
credibility of Dr. Wilson as a function of his risk communication on different topics, and how this
might be moderated by political ideology. While there is no support for H2a and H2b, the
finding that talking about any controversial issue (relative to talking about a non-controversial
issue) reduces the scientist's perceived credibility is interesting to me. The description of the
study design and the key conditions for this paper is much clearer and easier to follow. The
footnote making the case for separating this study from the additional conditions in the larger
study focused on communicating policy solutions is convincing and makes sense. I noticed that
Figure 1 is missing a legend that identifies the color with the experimental condition, and I
recommend adding that as it appears in the other Figures.
Reviewer: 2
Comments to the Author(s)
The authors failed meaningfully to address my two central reactions to their earlier draft.
One of these was that there was a contradiction between the conclusion of this study and the ones
reached in earlier papers authored by at least one of the co-authors of the current paper. In
Kotcher et al. (2017), the authors conclude that their "results suggest that climate scientists who
wish to engage in certain forms of advocacy have considerable latitude to do so without risking
harm to their credibility, or the credibility of the scientific community." In this paper, in contrast,
the authors warn that "Scientists should carefully consider public perceptions of the issues they
choose to engage with in communicating about scientific risk" because of the impact that such
communication has on public impressions of scientists' ideology, an effect that induces the public
16
to apply "political labels to the scientific community more broadly, [thereby] creating a potential
reinforcing cycle of perceptions of scientists as political actors."
The authors' response to my observation of this tension is, w/ due respect, a nonresponse-- a
hand-waiving account about about why we should expect R's to be generally more skeptical of
scientists than D's. The current paper does not add "nuance" to the Kotcher et al. (2017); it simply
contradicts that earlier study. The authors also ignored the tension between this paper and the
van der Linden et al. study on the effects of "consensus messaging"-- a study that also took the
position that members of the public, including Repubs, trust scientists on climate change (see also
Leiserowitz, Myers & Maibach 2014).
The authors should be asked again to address these tensions, which readers could reasonably
understand to indicate that the authors have a weak grasp of what they are actually measuring in
the various studies in question.
I also suggested that the authors should be directed to discuss the nature of the work they have
submitted "elsewhere" on the impact that scientist advocacy has on public perceptions (p. 11 fn 2).
Readers deserve to know whether those data, which apparently derive from the same study,
support conclusions consistent with the one that the authors reach here. Again, my point was
ignored by the authors.
I believe the authors should be asked for a resubmission that addresses these issues.
Refs
Kotcher, J.E., Myers, T.A., Vraga, E.K., Stenhouse, N. & Maibach, E.W. Does Engagement in
Advocacy Hurt the Credibility of Scientists? Results from a Randomized National Survey
Experiment. Environmental Communication 11, 415-429 (2017).
Maibach, E., Myers, T. & Leiserowitz, A. Climate scientists need to set the record straight: There
is a scientific consensus that human-caused climate change is happening. Earth's Future 2, 295-
298 (2014).
van der Linden, S.L., Leiserowitz, A.A., Feinberg, G.D. & Maibach, E.W. The Scientific Consensus
on Climate Change as a Gateway Belief: Experimental Evidence. PLoS ONE 10 (2015).
Author's Response to Decision Letter for (RSOS-170505.R1)
See Appendix B.
label_version_3
RSOS-170505.R2 (Revision)
label_author_5
Review form: Reviewer 2 (Dan Kahan)
Is the manuscript scientifically sound in its present form?
Yes
17
Are the interpretations and conclusions justified by the results?
Yes
Is the language acceptable?
Yes
Is it clear how to access all supporting data?
Yes
Do you have any ethical concerns with this paper?
No
Have you any concerns about statistical analyses in this paper?
No
Recommendation?
label_recommendation_5
Accept as is
Comments to the Author(s)
label_comment_5
I remain unconvinced that the pattern of results across the authors' studies generate opposing
inferences about the impact of "scientist advocacy" (let's call it). Indeed, I think there is no result
-- backlash against scientists' views or embracing of them-- that the papers will not be able to
"explain" by invoking one or another of the authors' papers to fit the result at hand. But I have
had my say and have seen the authors' response, and now believe that the issues I've raised are
appropriately assessed by reflective readers, whose opinions constitute the sort of peer review
that matters most.
label_end_comment
Decision letter (RSOS-170505.R2)
19-Jan-2018
Dear Dr Vraga,
I am pleased to inform you that your manuscript entitled "Scientific risk communication about
controversial issues influences public perceptions of scientists' political orientations and
credibility" is now accepted for publication in Royal Society Open Science.
You can expect to receive a proof of your article in the near future. Please contact the editorial
office (openscience_proofs@royalsociety.org and openscience@royalsociety.org) to let us know if
you are likely to be away from e-mail contact. Due to rapid publication and an extremely tight
schedule, if comments are not received, your paper may experience a delay in publication.
Royal Society Open Science operates under a continuous publication model
(http://bit.ly/cpFAQ). Your article will be published straight into the next open issue and this
will be the final version of the paper. As such, it can be cited immediately by other researchers.
As the issue version of your paper will be the only version to be published I would advise you to
check your proofs thoroughly as changes cannot be made once the paper is published.
In order to raise the profile of your paper once it is published, we can send through a PDF of your
paper to selected colleagues. If you wish to take advantage of this, please reply to this email with
the name and email addresses of up to 10 people who you feel would wish to read your article.
18
Please note that Royal Society Open Science will introduce article processing charges for all new
submissions received from 1 January 2018. Charges will also apply to papers transferred to Royal
Society Open Science from other Royal Society Publishing journals, as well as papers submitted
as part of our collaboration with the Royal Society of Chemistry
(http://rsos.royalsocietypublishing.org/chemistry). If your manuscript is submitted and
accepted for publication after 1 Jan 2018, you will be asked to pay the article processing charge,
unless you request a waiver and this is approved by Royal Society Publishing. You can find out
more about the charges at http://rsos.royalsocietypublishing.org/page/charges. Should you
have any queries, please contact openscience@royalsociety.org.
On behalf of the Editors of Royal Society Open Science, we look forward to your continued
contributions to the Journal.
Kind regards,
Alice Power
Editorial Coordinator
Royal Society Open Science
openscience@royalsociety.org
on behalf of Dr Molly Crockett (Associate Editor) and Antonia Hamilton (Subject Editor)
openscience@royalsociety.org
Reviewer comments to Author:
Reviewer: 2
Comments to the Author(s)
I remain unconvinced that the pattern of results across the authors' studies generate opposing
inferences about the impact of "scientist advocacy" (let's call it). Indeed, I think there is no result
-- backlash against scientists' views or embracing of them-- that the papers will not be able to
"explain" by invoking one or another of the authors' papers to fit the result at hand. But I have
had my say and have seen the authors' response, and now believe that the issues I've raised are
appropriately assessed by reflective readers, whose opinions constitute the sort of peer review
that matters most.
pendix A
Notes to Reviewers
thank the reviewers for their insightful comments. We have made a number of substantive
nges throughout the manuscript to address the concerns raised in the review process and
erwise clarified the rationale behind our decisions regarding our research design and
roach. We address these changes in the order in which they appear in the manuscript.
1. Based on comments from both reviewers and the editors, we have made a substantial
change to the focus of our manuscript and our analyses. Specifically, we draw upon
Reviewer #2’s suggestion that our manuscript would be improved by drawing
connections between our previous findings regarding perceptions of Dr. Wilson’s
political orientations to evaluations of Dr. Wilson’s credibility. We have maintained H1
and H3 from our previous manuscript, which test the effects of issue context (H1) and the
conditional role of participants’ political ideology (H3) on perceptions of Dr. Wilson’s
political orientations. However, we have added two new hypotheses looking at a
mediated pathway between issue context, perceptions of Dr. Wilson’s political
orientations, and Dr. Wilson’s credibility (H2), and the role of participants’ political
ideology in further moderating this mediated relationship (H4).
This revision also addresses Reviewer #1’s concern that we had insufficient motivation to
explain why communication by a single scientist would impact perceptions of the
scientific community. These analyses are no longer the focus of our manuscript. Instead,
we moved these previous analyses looking at effects on the perceived political
orientations of the scientific community to a supplemental appendix, as well as extending
that model to test its mediated relationship with trust in the scientific community overall.
We report briefly on these findings in footnote 10 on page 18 of the manuscript; we
believe this revision better situates our paper to contribute to the literature on scientific
communication regarding controversial issues.
2. Based on this change, we have revised our introduction and literature review to provide
support for our expectations that perceptions of a scientist’s political orientations will
mediate the impact of issue context on perceptions of that scientist’s credibility. We
introduce this literature on page 3 of the manuscript, and expand on these relationships on
pages 5-6 of the manuscript.
3. Per Reviewer #1’s suggestion, we have also expanded our literature addressing why we
expect ideological subgroups to respond more strongly to an outgroup-focused issue
context. Specifically, we draw on the motivated reasoning literature and the contextual
effects model for response to science communication initially on page 6 of the
manuscript and then in more detail to explain why we expect these effects to be stronger
for incongruent issues on page 8 of the manuscript. We conclude our argument on page 8
by saying:
The motivated reasoning literature suggests people respond strongly to protect their
beliefs when seeing information that disagrees with their worldview (9, 37, 43). This
process should lead political ideology to condition an individual’s response to scientific
communication on controversial issues – both in shaping perceptions of the scientist’s
ideology and in translating those perceptions of that ideology into credibility perceptions
– especially when seeing a scientist adopting an incongruent position in order to protect
a cherished identity.
4. Reviewer #1 and Reviewer #2 raised several questions about the methodological design
of our manuscript, which were echoed by the editor. We have addressed these concerns
both in the paper and in this response to reviewers.
We believe the structure of our paper added unnecessary confusion regarding the
experimental conditions examined in our paper. In our methods section, we now describe
the four cell design used in this study – specifically examining the issue context for a
conservative issue (Marijuana), a liberal issue (Climate Change), and two non-
controversial issues (Flu and Severe Weather). We have moved our description of the full
experimental design to footnotes 3 and 4 on pages 10-11 of the manuscript. Specifically,
these footnotes confirm that:
These conditions are extracted from a larger experimental design, wherein we also
manipulated whether the scientist offered a non-controversial or a controversial policy
solution for each of the four issues examined here. In this paper, we are primarily
interested in the effects of issue context and its relationship to perceptions of scientific
political orientations and credibility, rather than the effects of scientific advocacy, which
we believe is a different but related question. Analyses from a paper explicitly exploring
scientific advocacy are reported elsewhere.
Our original design divided the four issues using a 2 (Polarizing Scientific Issue:
Controversial vs. Non-Controversial) x 2 (Issue Domain: Health vs. Earth Science), and
counter-balanced the “lean” of the polarized issues (one conservative and one liberal).
However, with this analysis, perceptions of scientists’ political leaning is hypothesized to
depend on the partisan direction – and thus, separating the two polarized issues from one
another is necessary. In this analysis, we do not focus on differences between the earth
and health science contexts.
In doing so, we clarify that all descriptive statistics reported in the paper are only for the
four experimental conditions examined in the paper.
We would like to further elaborate on these footnotes in this response to reviewers. We
chose to focus on four experimental designs in this paper for two reasons. First, we are
interested in the question of how the selection of an issue context for scientific
communication –absent any overt forms of advocacy – influences perceptions of the
communicating scientist. We believe it is meaningful that – as our results indicate –even
absent a clear effort to persuade, simply informing the public of the risks on a
controversial science topic does in fact shape how the public thinks about that scientist.
As such, this addresses a broader implication for scientific communication, beyond the
narrower (although related) question of advocacy. Therefore, we excluded those
conditions that focused on scientific advocacy to focus on pure risk communication
efforts.
Second, there is also the question of scope. This paper already represents an ambitious
design. Our paper reports on the results of a series of moderated-mediation models
including four independent variables, two mediators, one dependent variable, and one
moderator. We believe attempting to add an additional eight independent variables to this
design would be unnecessarily confusing and would obscure the main theoretical and
practical contributions of this paper. While we agree with Reviewer #2’s fundamental
point that data collections should not be arbitrarily divided across journal articles for the
sake of increasing publications, we also believe that it is important to present a clear and
coherent narrative bounded appropriately by theoretical and practical questions. We have
attempted to do so here. We are happy to share with the reviewers the related manuscript
under preparation, at their request or the request of the editors.
5. Reviewer #1 also questions why we included controls in our model for issue threat and
government action. Originally, the purpose of including these controls was to account for
any differences in perceptions of these issues that could contribute to the experimental
effects perceived here. For these variables, it is not that random assignment failed, but
instead that – both according to the pre-test and to the current data collection – that there
were differences between these issues in terms of issue threat and governmental action. In
selecting issues that varied systematically in terms of their controversy, we could not
perfectly control that these issues were identical on all other characteristics.
However, we also agree with the reviewer that this footnote is unnecessarily confusing.
Moreover, we tested our analyses having removed these controls and found they were not
substantively different. Therefore, we have removed these controls from our analyses and
have removed this footnote from the paper.
6. Reviewer #1 raises the question of whether the flu or severe weather serves as a more
appropriate baseline for our hypotheses. Both of these issues were originally selected as
non-controversial reference groups. By including comparison to both flu and severe
weather for our conservative (marijuana) and liberal (climate change) issues, we have a
better sense of the strength of the effects and limit the potential that the effects are
idiosyncratic to our chosen non-controversial issue.
However, in some limited circumstances, there are differences between the effects of our
manipulated issues compared to our baseline issues. We explore the possible reasons for
these differences on page 21 of the discussion. Specifically, we highlight that it is
possible that differences in the issue domain of these topics (earth science versus health)
may account for some of the differences observed in these analyses. However, without a
priori expectations about differences between these two issues, we must leave this an
open question, which we note as a limitation.
7. As noted in our first point in this response to reviewers, the results section has been
entirely re-written to reflect our new analyses, focusing on perceptions of Dr. Wilson’s
political orientations, their mediating role for Dr. Wilson’s credibility, and the
moderating influence of participant ideology for these relationships. We have moved the
analyses examining scientists’ political orientations and trustworthiness to the
supplemental appendix. We also include the previous analyses looking at the effects of
these models among moderates to the supplemental appendix.
8. Reviewer #2 questions how the results of this paper can be reconciled with the results of
previous papers by van der Linden et al. (2015) or Kotcher et al. (2017). We thank the
reviewer for this feedback, but we do not believe that the results of van der Linden et al.
(2015) or Kotcher et al. (2017) are inconsistent with the results reported in this
manuscript. Several key differences between these studies are important for
consideration. In the present study, we examined differences in perceived political
orientation (and now also credibility) across issue contexts (e.g., climate change versus
flu), rather than differences in perceived credibility across levels of advocacy within a
single issue context like Kotcher et al. (2017). Similarly, van der Linden et al. (2015)
examined how attitudes toward climate change (not perceived credibility of a single
communicating scientist) are influenced by information about the scientific consensus on
climate change (compared to receiving no consensus information). In sum, the present
experiment is testing a different independent variable than these two previous studies
and, in the case of van der Linden et al. (2015), a different set of dependent variables.
As they note in the discussion of their study, the scientific consensus message in Van der
Linden et al. (2015) may have generated more attitude change among Republicans
(relative to Democrats) due to a ceiling effect among Democrats. In other words,
Democrats already had relatively high levels of perceived consensus and pro-action
attitudes such that the impact of consensus information was relatively small compared to
the effect that it had on Republicans. Although Republicans on average tend to view
climate scientists as less credible than Democrats, this does not mean that all Republicans
automatically reject any information about climate change.
Kotcher et al. (2017) did find a main effect of political ideology on perceived credibility
such that conservatives viewed the communicating climate scientist as less credible
compared to moderates and liberals. This effect of ideology was consistent across all
levels of advocacy tested in Kotcher et al. (2017) such that ideological differences in
perceived credibility were not dependent upon the specific level of advocacy adopted by
the communicating scientist. In the present manuscript, we find that when Dr. Wilson
talks about the risks of climate change, conservatives view him as more liberal and less
credible compared to when Dr. Wilson talks about less politically polarized topics like
the risks of severe weather or the seasonal flu. In contrast, liberal participants did not
view Dr. Wilson as any more liberal or less credible when he talked about the risks of
climate change versus flu or versus severe weather. This overall pattern of results is
consistent with the general finding in Kotcher et al. (2017) that conservatives on average
tend to view climate scientists as less credible relative to liberals.
We address this debate, especially with regards to the differences between the Kotcher et
al. (2017) study and the current study on page 20 of the manuscript. Specifically, we say:
These findings provide additional nuance to those examined by Kotcher et al. (2017).
Kotcher et al. (2017) found that different levels of advocacy for particular solutions on
climate change may not influence perceptions of the scientist’s credibility, nor was this
effect different between liberals and conservatives (55). However, that study found that
conservatives systematically rated the scientist’s credibility lower than liberals,
regardless of his position. This study provides a mechanism for this effect – in choosing
to talk about climate change, rather than another issue, the scientist provided a signal
about his political beliefs, which were used to inform credibility perceptions.
9. The data reported in the present manuscript are not from the same study reported in
Kotcher et al. (2017).
pendix B
Notes to Reviewers
thank the reviewers for their response to our revisions. We address remaining concerns
arately for Reviewer #1 and Reviewer #2.
1. As suggested by Reviewer #1, we have updated Figure 1 to include the missing legend
for our results. We thank them for pointing out this oversight and their thoughtful
response to our revisions to the analytical approach of this manuscript. We agree with the
reviewer that this new model represents a greatly improved approach, and thank them for
encouraging us to consider the implications of our findings for scientific credibility.
2. Reviewer #2 expresses two ongoing concerns with regards to this manuscript. First, they
remain concerned about the relationships between this study and previous research
regarding scientific advocacy.
Specifically, the reviewer notes that Kotcher et al. (2017) argue that their "results suggest
that climate scientists who wish to engage in certain forms of advocacy have
considerable latitude to do so without risking harm to their credibility, or the credibility
of the scientific community." While this is one of the conclusions from Kotcher et al.
(2017), we think it important to note that their overall message was that caution still
needed to be applied when scientists make decisions about engaging in public advocacy.
For example, Kotcher et al. (2017) say on page 11 of their manuscript: “The fact that
conservatives responded more negatively to Dr. Wilson regardless of the substance of his
communication raises an important caution for climate scientists doing public
engagement.” We believe that the current study is able to speak to a potential reason why
conservatives responded less positively to the communicating scientist across all of the
advocacy conditions examined by Kotcher et al. (2017) – by communicating about the
risks of climate change (which is a politically controversial issue), the scientist is seen as
more liberal/Democratic, and thus less credible. Our study tests this proposition by
examining risk communication absent advocacy across a range of controversial and non-
controversial issues, rather than looking at advocacy within one inherently controversial
issue (i.e., climate change) that is associated with liberal ideology.
Likewise, on page 12 in discussing the limitations of their study, Kotcher et al. (2017)
highlight that “First, reactions to advocacy by scientists may differ not simply on the
basis of the specific policy endorsed as noted above, but may also vary according to the
wider issue domain. Some have speculated that scientific advocacy may be more widely
accepted on public health issues relative to earth science issues, but to our knowledge, no
research has tested this assumption (Corner & Groves, 2014).” We address the latter
question in our manuscript: examining whether risk communication efforts across a range
of issues – rather than whether advocacy on the particular issue of climate change –
influences credibility perceptions of the communicating scientist. Our manuscript also
tests a potential mechanism for this effect: perceptions of the political orientations of the
communicating scientist.
Ultimately, we do not believe our conclusion differs from that of Kotcher et al. (2017)
who say on page 10 of their manuscript “Therefore, it may be the case that scientists
should be aware that what they advocate for may lead to negative credibility perceptions,
rather than ruling out advocacy altogether.” We agree and have added a similar
prescription at the end of our paper on page 23 of the manuscript: “Ultimately, we think
the take-away for scientists across a range of studies is that they must be cognizant of the
potential consequences of engaging in public risk communication on contentious
scientific issues, not that they need to avoid it entirely.” We have also adjusted our
language to urge scientists to be aware of the potential for scientific risk communication
to shape perceptions of political orientations and credibility, rather than suggesting
caution.
Reviewer #2 also raises a possible contradiction between the current manuscript and
work by van der Linden et al. (2015). The van der Linden study posited that exposure to a
message communicating the scientific consensus regarding climate change, attributed to
the American Association for the Advancement of Science (AAAS), would change
viewer’s perceptions of the scientific consensus, and that increases in perceived scientific
consensus, in turn, would lead to changes in other climate change beliefs. The authors’
hypothesis was supported, as they found the effect of consensus messages was larger
among Republicans than Democrats (partially due to a ceiling effect among Democrats).
Again, we do not think our manuscript is necessarily at odds with their findings. There
are several critical differences between the two manuscripts that limit comparability.
First, the van der Linden manuscript is looking at messaging within the context of climate
change specifically, rather than comparing across a range of issues, as we do in the
current manuscript. Second, their key outcome variables are perceptions of scientific
consensus and related perceptions about climate change, rather than perceptions of an
individual communicating scientist or the scientific community. Their finding that
consensus messaging for the climate change issue was successful in shifting perceptions
for Republicans even more so than Democrats does not necessarily mean that
Republicans believed that scientists were neutral on the issue – and indeed, believing
more scientists think climate change is occurring may reinforce perceptions of scientists
as a liberal community. This remains an open question that future research should
explore.
To address these concerns, we have incorporated a broader discussion of how we believe
our work fits into the broader debate about scientific advocacy and communication on
controversial issues on pages 22-23 of the manuscript. We include these paragraphs
below in italics to facilitate review.
This study addresses an ongoing debate about the appropriate role for scientists in
engaging in public commentary. For example, Kotcher et al. (2017) suggested that
different levels of scientific advocacy on the issue of climate change may not alter
perceptions of the scientist’s credibility (56), while van der Linden et al. (2015) found
that communicating the scientific consensus on climate change was effective in producing
more accurate climate change beliefs among both Republicans and Democrats (57).
These studies could be interpreted as supporting efforts for scientists to communicate
publicly on the issue of climate change. However, both of those studies examine scientific
communication within the issue of climate change, whereas the current study examines
risk communication across a range of scientific issues. Our related work suggests that the
effects of advocacy on perceptions of scientists can differ depending on the issue context
in which the scientist is communicating (58), which may result from the differing
perceptions of the political context surrounding the issues that this study investigates.
Moreover, Kotcher et al. (2017) found that conservatives viewed the scientist who was
communicating about climate change to be less credible than did liberals, regardless of
the level of advocacy in the scientist’s message. This current study suggests a mechanism
for this effect – in choosing to talk about climate change, rather than another issue, the
scientist provided a signal about his political beliefs, which was used to inform credibility
perceptions.
Ultimately, we think the take-away for scientists across a range of studies is that they
must be cognizant of the potential consequences of engaging in public risk
communication on contentious scientific issues, not that they need to avoid it entirely.
This study suggests that when a scientist only speaks to the potential risks and
consequences of an issue – avoiding any recommendation of specific policy solutions –
the public can make assumptions about their political orientations based on this
information. Even more problematic, after seeing a single scientist engaging in such
communication, the public sometimes attributes these political labels to the scientific
community more broadly, creating a potential reinforcing cycle of perceptions of
scientists as political actors. Future research should test these links between assumptions
about scientists’ political orientations and other outcomes such as willingness to
consider scientists’ recommendations. Additionally, it may be that scientists who explain
their positive motivations for conducting research in such polarized issue contexts (e.g.
serving the public good; 59) may negate the effects found here, a possibility that future
research should examine. Furthermore, reframing the issue in a way that resonates with
an audience’s political views could help attenuate the attributions some individuals might
make about scientists based solely on the issue under consideration (60). Scientists
should be aware that audience members may make inferences about the communicating
scientist’s political orientations when they engage in risk communication about
controversial issues.
3. Reviewer #2 also expresses concern about the potential for discrepancies between the
current manuscript and our related manuscript produced from this dataset. One
manuscript from the current dataset has been accepted for publication at another journal;
it examines how levels of advocacy – non-controversial policy solutions and
controversial policy solutions versus purely informational statements – affect perceptions
of the scientist’s motives (i.e., why the scientist chose to share information) and the
scientist’s credibility. Therefore, we believe the second manuscript addresses a
fundamentally different, albeit related question. The current manuscript focuses on the
effects of risk communication on perceptions of scientists’ political orientations and
credibility absent advocacy across a range of issue contexts. The other manuscript
focuses on the effects of different forms of advocacy, and compares whether the effects
of advocacy differ depending on issue context. We reference the related manuscript in the
current manuscript on page 23, where we say: “Our related work suggests that the effects
of advocacy on perceptions of scientists can differ depending on the issue context in
which the scientist is communicating (58), which may result from the differing
perceptions of the political context surrounding the issues that this study investigates.”
In this related study, we again tested participant political ideology as a moderator of the
relationship between solution position (i.e., risk communication without a proposed
solution, proposed non-controversial policy solutions, and proposed controversial policy
solutions), perceived motivations, and perceptions of credibility separately for the same
four issues examined in the current manuscript. The overall conclusion from that study is
that participant ideology largely did not explain differences in response to advocacy
within a topic, stating “Few of the omnibus interactions were significant and the results
did not explain the disparate findings between topics.” Of most direct relevance to the
current manuscript, the related manuscript investigated the perception that the
communicating scientist’s statement was motivated by their personal “political views”.
The related study did not find that discussing a controversial or non-controversial
solution (as compared to providing risk information only) changed perceptions of a
scientist’s political motivation within any of the four issues studied, nor was this
relationship different for conservatives versus liberals. However, we again do not believe
that this is at odds with the current manuscript nor other existing work. The effects of
advocacy within an issue domain is a fundamentally different process (as examined in the
related study) than risk communication across different issue contexts (as examined in
the current study).
In addition, the results demonstrated that liberal participants viewed Dr. Wilson as less
credible when viewing the controversial policy solution for the marijuana condition (i.e.,
stricter regulations on the legalization of medical and commercially sold marijuana).
These findings are consistent with the present study’s results that Dr. Wilson’s credibility
decreased among liberal participants when he discussed the risks of marijuana.
We are including the final version of the related manuscript as a supplemental file,
accepted for publication at PLoS ONE, so the reviewer can evaluate the differences for
themselves.
Society Open
