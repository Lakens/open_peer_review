Glyph guessing for “oo and “ee”: spatial frequency
information in sound symbolic matching for ancient and
unfamiliar scripts
Nora Turoman and Suzy J. Styles
Article citation details
R. Soc. open sci. 4: 170882.
http://dx.doi.org/10.1098/rsos.170882
Review timeline
Original submission: 11 July 2017 Note: Reports are unedited and appear as
Revised submission: 12 August 2017 submitted by the referee. The review history
Final acceptance: 14 August 2017 appears in chronological order.
Review History
label_version_1
RSOS-170882.R0 (Original submission)
label_author_1
Review form: Reviewer 1 (Alan Nielsen)
Is the manuscript scientifically sound in its present form?
Yes
Are the interpretations and conclusions justified by the results?
Yes
Is the language acceptable?
Yes
Is it clear how to access all supporting data?
Yes
Do you have any ethical concerns with this paper?
No
© 2017 The Authors. Published by the Royal Society under the terms of the Creative Commons
Attribution License http://creativecommons.org/licenses/by/4.0/, which permits unrestricted use,
provided the original author and source are credited
2
Have you any concerns about statistical analyses in this paper?
No
Recommendation?
label_recommendation_1
Accept with minor revision (please list in comments)
Comments to the Author(s)
label_comment_1
Comments can be found in the attached file (Appendix A).
label_author_2
Review form: Reviewer 2
Is the manuscript scientifically sound in its present form?
Yes
Are the interpretations and conclusions justified by the results?
Yes
Is the language acceptable?
Yes
Is it clear how to access all supporting data?
Yes
Do you have any ethical concerns with this paper?
No
Have you any concerns about statistical analyses in this paper?
No
Recommendation?
label_recommendation_2
Accept with minor revision (please list in comments)
Comments to the Author(s)
label_comment_2
This paper was a delight to read. The logic was clear and elegant. The studies were reported in a
straightforward manner and the writing is excellent.
I have three main comments:
(1) At a number of points in the paper it is claimed that diverse groups of people use similar
strategies for mapping speech to visual forms. This claim rests in 2 parts: (a) the different writing
systems that have evolved, (b) the results of Experiment 2. Both of these points have limitations.
(a) Not all writing systems have evolved independently. There are clear chains of transmission
from writing system to writing system. It would be wrong to treat the 56 letter pairs considered
here as independent datapoints with respect to the hypothesis. This point should be explicitly
acknowledged in the discussion (and ideally also dealt with in terms of the statistical analyses).
(b) It is stated that participants from Experiment 2 were diverse because they came from "a
variety of countries and spoke a variety of languages". I could not access the data from OSF so
cannot verify this. The body of the paper should provide more detailed information since this
point is critical to one of the key arguments of the paper. In particular, it would be important to
note the limitations (if any) of the sample diversity, especially as it impacts the conclusions of the
paper.
(2) The authors claim on p.12 that infants cannot pitch and size until 30-36 months, but Dolscheid
et al (2014; Psychological Science) showed that 4 month olds can match pitch to size. The authors
3
also fail to acknowledge the fact that cross-modal correspondences as culturally shaped too
(Dolscheid et al, 2013, Psychological Science; Shayan et al, 2014, Developmental Science). This
does not detract from the main point of this paper. Nevertheless, it is clear that there is cultural
shaping of associations too, and this needs to be reconciled with these fascinating biases the
authors uncover. A short discussion of this would be warranted.
(3) Finally, I urge the reviewers to revise Figures 3 and 4 to also include the 2nd most guessable
scripts into the visualization.
Overall, this is a fascinating paper and should be published.
label_end_comment
Decision letter (RSOS-170882)
04-Aug-2017
Dear Ms Turoman
On behalf of the Editors, I am pleased to inform you that your Manuscript RSOS-170882 entitled
"Telling “oo” from “ee” in Cherokee: Spatial frequency information drives sound symbolic
matching in ancient and unfamiliar scripts" has been accepted for publication in Royal Society
Open Science subject to minor revision in accordance with the referee suggestions. Please find the
referees' comments at the end of this email.
The reviewers and handling editors have recommended publication, but also suggest some minor
revisions to your manuscript. Therefore, I invite you to respond to the comments and revise your
manuscript.
• Ethics statement
If your study uses humans or animals please include details of the ethical approval received,
including the name of the committee that granted approval. For human studies please also detail
whether informed consent was obtained. For field studies on animals please include details of all
permissions, licences and/or approvals granted to carry out the fieldwork.
• Data accessibility
It is a condition of publication that all supporting data are made available either as
supplementary information or preferably in a suitable permanent repository. The data
accessibility section should state where the article's supporting data can be accessed. This section
should also include details, where possible of where to access other relevant research materials
such as statistical tools, protocols, software etc can be accessed. If the data has been deposited in
an external repository this section should list the database, accession number and link to the DOI
for all data from the article that has been made publicly available. Data sets that have been
deposited in an external repository and have a DOI should also be appropriately cited in the
manuscript and included in the reference list.
If you wish to submit your supporting data or code to Dryad (http://datadryad.org/), or modify
your current submission to dryad, please use the following link:
http://datadryad.org/submit?journalID=RSOS&manu=RSOS-170882
• Competing interests
Please declare any financial or non-financial competing interests, or state that you have no
competing interests.
4
• Authors’ contributions
All submissions, other than those with a single author, must include an Authors’ Contributions
section which individually lists the specific contribution of each author. The list of Authors
should meet all of the following criteria; 1) substantial contributions to conception and design, or
acquisition of data, or analysis and interpretation of data; 2) drafting the article or revising it
critically for important intellectual content; and 3) final approval of the version to be published.
All contributors who do not meet all of these criteria should be included in the
acknowledgements.
We suggest the following format:
AB carried out the molecular lab work, participated in data analysis, carried out sequence
alignments, participated in the design of the study and drafted the manuscript; CD carried out
the statistical analyses; EF collected field data; GH conceived of the study, designed the study,
coordinated the study and helped draft the manuscript. All authors gave final approval for
publication.
• Acknowledgements
Please acknowledge anyone who contributed to the study but did not meet the authorship
criteria.
• Funding statement
Please list the source of funding for each author.
Please note that we cannot publish your manuscript without these end statements included. We
have included a screenshot example of the end statements for reference. If you feel that a given
heading is not relevant to your paper, please nevertheless include the heading and explicitly state
that it is not relevant to your work.
Because the schedule for publication is very tight, it is a condition of publication that you submit
the revised version of your manuscript within 7 days (i.e. by the 13-Aug-2017). If you do not
think you will be able to meet this date please let me know immediately.
To revise your manuscript, log into https://mc.manuscriptcentral.com/rsos and enter your
Author Centre, where you will find your manuscript title listed under "Manuscripts with
Decisions". Under "Actions," click on "Create a Revision." You will be unable to make your
revisions on the originally submitted version of the manuscript. Instead, revise your manuscript
and upload a new version through your Author Centre.
When submitting your revised manuscript, you will be able to respond to the comments made by
the referees and upload a file "Response to Referees" in "Section 6 - File Upload". You can use this
to document any changes you make to the original manuscript. In order to expedite the
processing of the revised manuscript, please be as specific as possible in your response to the
referees.
When uploading your revised files please make sure that you have:
1) A text file of the manuscript (tex, txt, rtf, docx or doc), references, tables (including captions)
and figure captions. Do not upload a PDF as your "Main Document".
2) A separate electronic file of each figure (EPS or print-quality PDF preferred (either format
should be produced directly from original creation package), or original software format)
3) Included a 100 word media summary of your paper when requested at submission. Please
ensure you have entered correct contact details (email, institution and telephone) in your user
account
5
4) Included the raw data to support the claims made in your paper. You can either include your
data as electronic supplementary material or upload to a repository and include the relevant doi
within your manuscript
5) All supplementary materials accompanying an accepted article will be treated as in their final
form. Note that the Royal Society will neither edit nor typeset supplementary material and it will
be hosted as provided. Please ensure that the supplementary material includes the paper details
where possible (authors, article title, journal name).
Supplementary files will be published alongside the paper on the journal website and posted on
the online figshare repository (https://figshare.com). The heading and legend provided for each
supplementary file during the submission process will be used to create the figshare page, so
please ensure these are accurate and informative so that your files can be found in searches. Files
on figshare will be made available approximately one week before the accompanying article so
that the supplementary material can be attributed a unique DOI.
Once again, thank you for submitting your manuscript to Royal Society Open Science and I look
forward to receiving your revision. If you have any questions at all, please do not hesitate to get
in touch.
Kind regards,
Alice Power
Editorial Coordinator
Royal Society Open Science
openscience@royalsociety.org
on behalf of Essi Viding
Subject Editor, Royal Society Open Science
openscience@royalsociety.org
Reviewer comments to Author:
Reviewer: 1
Comments to the Author(s)
Comments can be found in the attached file
Reviewer: 2
Comments to the Author(s)
This paper was a delight to read. The logic was clear and elegant. The studies were reported in a
straightforward manner and the writing is excellent.
I have three main comments:
(1) At a number of points in the paper it is claimed that diverse groups of people use similar
strategies for mapping speech to visual forms. This claim rests in 2 parts: (a) the different writing
systems that have evolved, (b) the results of Experiment 2. Both of these points have limitations.
(a) Not all writing systems have evolved independently. There are clear chains of transmission
from writing system to writing system. It would be wrong to treat the 56 letter pairs considered
here as independent datapoints with respect to the hypothesis. This point should be explicitly
acknowledged in the discussion (and ideally also dealt with in terms of the statistical analyses).
(b) It is stated that participants from Experiment 2 were diverse because they came from "a
variety of countries and spoke a variety of languages". I could not access the data from OSF so
cannot verify this. The body of the paper should provide more detailed information since this
point is critical to one of the key arguments of the paper. In particular, it would be important to
note the limitations (if any) of the sample diversity, especially as it impacts the conclusions of the
paper.
6
(2) The authors claim on p.12 that infants cannot pitch and size until 30-36 months, but Dolscheid
et al (2014; Psychological Science) showed that 4 month olds can match pitch to size. The authors
also fail to acknowledge the fact that cross-modal correspondences as culturally shaped too
(Dolscheid et al, 2013, Psychological Science; Shayan et al, 2014, Developmental Science). This
does not detract from the main point of this paper. Nevertheless, it is clear that there is cultural
shaping of associations too, and this needs to be reconciled with these fascinating biases the
authors uncover. A short discussion of this would be warranted.
(3) Finally, I urge the reviewers to revise Figures 3 and 4 to also include the 2nd most guessable
scripts into the visualization.
Overall, this is a fascinating paper and should be published.
Author's Response to Decision Letter for (RSOS-170882)
See Appendix B.
label_end_comment
Decision letter (RSOS-170882.R1)
14-Aug-2017
Dear Ms Turoman,
I am pleased to inform you that your manuscript entitled "Glyph guessing for “oo” and “ee”:
Spatial frequency information in sound symbolic matching for ancient and unfamiliar scripts" is
now accepted for publication in Royal Society Open Science.
You can expect to receive a proof of your article in the near future. Please contact the editorial
office (openscience_proofs@royalsociety.org and openscience@royalsociety.org) to let us know if
you are likely to be away from e-mail contact. Due to rapid publication and an extremely tight
schedule, if comments are not received, your paper may experience a delay in publication.
Royal Society Open Science operates under a continuous publication model
(http://bit.ly/cpFAQ). Your article will be published straight into the next open issue and this
will be the final version of the paper. As such, it can be cited immediately by other researchers.
As the issue version of your paper will be the only version to be published I would advise you to
check your proofs thoroughly as changes cannot be made once the paper is published.
In order to raise the profile of your paper once it is published, we can send through a PDF of your
paper to selected colleagues. If you wish to take advantage of this, please reply to this email with
the name and email addresses of up to 10 people who you feel would wish to read your article.
On behalf of the Editors of Royal Society Open Science, we look forward to your continued
contributions to the Journal.
Best wishes,
Andrew Dunn
Senior Publishing Editor
Royal Society Open Science
openscience@royalsociety.org
Appendix A
Response to: Telling ‘oo’ from ‘ee’ in Cherokee: Spatial frequency information drives sound-
symbolic matching in ancient and unfamiliar scripts
This is a very well-written and interesting bit of research that I think makes a substantial
contribution to the study of sound symbolism/iconicity. Using a series of experiments, the
authors find that experimental participants from a range of linguistic backgrounds were
able to guess whether orthographic letter forms from unfamiliar languages represented
the sound /u/ or the sound /i/. Although the observed results are not particularly strong-
i.e. the difference from chance is not very large - the studies are well powered and the
results are consistent with similarly motivated word-guessing experiments (e.g. Lockwood
et al., 2016). I suggest that the paper should be accepted for publication with minor
(minimal) revisions.
Comments (roughly in order of importance/reverse order of pedantry):
a- I think that this paper is very well situated in the literature, and addresses a
problem that is basically never considered- some critics (e.g. Cuskley et al.) suggest
that the bouba-kiki effect can be traced to orthography, rather than
phonology/acoustics, without considering that orthography and phonology might
themselves be entangled- this paper is the first modern on that I’m aware of that
attempts to do so.
There have, of course, been several attempts to minimize or control for
orthographic effects, as the authors acknowledge. Additionally, other authors have
acknowledged the entanglement of orthography and phonology and proposed
similar work- notably Nielsen (2011) states:
“Of course, even in the best of situations it may not be possible to fully control
for orthographic effects- insofar as experimenters are correct that sound symbolic
relationships between objects and their tokens exist, it is possible that this sort of
representation might have leaked over into the creation of letters themselves.
Thus, the letter /k/ might have the form that it does precisely because of the way
it sounds- given multiple candidates for the form of a letter used to represent a
strident, broadband sound with certain acoustic characteristics, it is perhaps be
unsurprising that a specific visual polymorphism of a chaotic nature was chosen
to represent it. The idea that orthographic characteristics of letters might be
confounding thus ignores the question of why there might be systematic
confounds in the first place.” – pp.35
Additionally, there is at least one case of previous research into this idea (though
more related to acoustics) that the authors are remiss to not cite:
Koriat, A., & Levy, I. (1977). The symbolic implications of vowels and of
their orthographic representations in two natural languages. Journal of
Psycholinguistic Research, 6, 93-104.
b- Methodologically, I’m somewhat concerned about the influence of the user’s own
language on their response patterns- in all studies graphemes that the participants
are actually familiar with are excluded, but this only excludes response for which
they *know* the mapping between grapheme and phoneme.
The participants in Experiment 1 are listed as speaking English, Mandarin, Malay,
Tamil, Korean, and French - notably, they all speak English and are familiar with
English graphemes (that much is hard to get around, I’ll admit!), but French and
Malay both use the Latin alphabet, Mandarin is logographic (not confounded),
and both Tamil (i = <U+0B87> or <U+0B88> ; u = <U+0B89> or <U+0B8A>) and Korean (i = <U+3163>; u = <U+315C>)
arguably follow the same pattern as the Latin alphabet.
I recognize that it would be too big of an ask to try to do this study with speakers
of a language that does *not* have the property in question, both i) because it
would be very difficult in general to find experimental participants not familiar
with English orthography, and ii) because that would be a follow-up study, for
further proof of theory, rather than something that I’d request as a revision to a
single manuscript. Nonetheless, I suggest that the authors should acknowledge
this point- it ultimately relates to the arguments made in Taylor & Taylor (1965)
re: objective vs. subjective sound symbolism- the responses of experimental
participants to manipulations are hard to disentangle from their own language- do
English speakers respond to scripts that are isomorphic with respect to this
phenomenon because it’s a cognitive bias shared by humans generally (subjective
sound symbolism), or because it’s a feature of their own language (objective sound
symbolism).
The results of these experiments suggest that it’s the former of the two above,
rather than the latter, but it would be good scientific practice to acknowledge the
possible confound, and propose ways forward from it. I have dealt with a similar
issue in differentiating between learning biases and learned biases in Nielsen &
Rendall, 2012.
c- Spatial frequency distributions- I’m very much in support of this type of
simplified explanation, and going against original eyeballed interpretations (i.e.
notions of ‘curviness’ mentioned for the pilot) to attempt to arrive at a more
objective value like spatial frequency distribution that can be analysed
statistically- there is nothing worse than an ad hoc description that folks are
trying to link to a pet theory, so I appreciate this.
I do, however, think that the discussion of its use as a metric could be more
nuanced- spatial frequency differences work as *a* predictor of differences
between grapheme:phoneme mappings, but they are unlikely to be *the*
predictor- it’s certainly beyond the purview of this study to fully categorise what
might be going on perceptually- what features make a grapheme *good* for a
given phoneme- it’s impressive that something simple like spatial frequency can
capture anything, but disingenuous not to acknowledge that it’s a pretty crude
metric, especially when taking into account multiple iconicities- languages could
encode the phonetic contrasts differently in any number of ways, only some of
which might be captured by spatial frequency. On this note, there could be more
discussion about why spatial frequency is used as the metric.
d- Task Demands? I wonder somewhat about the influence of having participants
make judgements across so many scripts in a single experiment. On the one hand,
this might enhance the ability of participants to make these sort of judgements-
this wouldn’t be a problem unless indeed the distribution of scripts chosen was
skewed- i.e. if the distribution of languages that have differences in spatial
frequency between u/i in the predicted direction is sufficiently similar to the
distribution of responses, then it becomes difficult to tell whether participants are
responding the way they are because of iconicity (leaving aside whether it is
objective or subjective- see above), or because they have picked up on some
regularity of the stimulus set and are responding systematically (see both
Dingemanse et al., and Nielsen, 2016 for discussions of these differences).
On the other hand, the process of making multiple comparisons might lead to
attenuation of the effect- as mentioned above, if different writing systems have
iconic phoneme:grapheme mappings that make use of competing iconicities, they
might effectively obscure each other.
In total, I think it’s great that this study is comprehensive in its use of writing
systems, but these possibilities might bear mentioning.
e- Transparency and writing systems- Similarly to above, I wonder what the authors
might be able to say about full writing systems (at least alphabets, abugidas, and
abjads)- choosing /i/ vs /u/ is a sensible starting point, but what would happen if
you were to look at entire alphabets?
One suggestion might be that this effect can only be produced experimentally
because it’s the best possible comparison- much like the case that Lockwood and
Dingemanse make for ideophone-guessing tasks- when you’re presented with
antonym pairs it’s pretty easy to guess the meaning of words, but not so much if
you have to choose from multiple foils or the foil isn’t an antonym.
At the same time, if grapheme:phoneme mappings in writing systems are
systematic, in addition to being iconic, they might be even more obvious, both to
users of a writing system and to naive experimental participants- this is a point
made in Bouba-kiki studies- t and k are both jagged graphemes for voiceless
plosives, m and n are both curvy graphemes for voiced sonorants – perhaps some
writing systems are systematically sound-symbolic in this relative sense, rather
than having individual grapheme:phoneme mappings that are iconic.
This is of course not something that you have data for, but it’s likely the direction
that further research of this type needs to head in, so I think it bears discussion
f- I find some of the discussion a bit too far afield and theoretical for a research paper
of this type- although I generally agree with the authors and think that
synesthesia, dyslexia, and their possible links to crossmodal perception more
generally are fascinating topics, I don’t think the data presented in this
manuscript have much material to say about those topics, so I’m not sure if they
add anything to the paper. I’d rather see the issues above discussed more fully-
pointing concretely towards where this kind of research can go in the future, rather
than too much outside speculation. That is my own opinion though, and I
recognize that different journals have different views about how much leeway
authors are given to theorise.
g- The title irks me. It’s nice that the first portion rhymes, but readers might skip
over it- even as a reviewer I started reading thinking “wait... isn’t this paper about
cherokee?”
Appendix B
Response to Reviewers’ comments
We would like to thank our reviewers for their careful attention and thoughtful
responses. It is a pleasure to revise when the comments are so constructive and
insightful.
Reviewer 1
This is a very well-written and interesting bit of research that I think makes a
substantial contribution to the study of sound symbolism/iconicity. Using a series of
experiments, the authors find that experimental participants from a range of linguistic
backgrounds were able to guess whether orthographic letter forms from unfamiliar
languages represented the sound /u/ or the sound /i/. Although the observed results are
not particularly strong- i.e. the difference from chance is not very large - the studies
are well powered and the results are consistent with similarly motivated word-
guessing experiments (e.g. Lockwood et al., 2016). I suggest that the paper should be
accepted for publication with minor (minimal) revisions.
We thank the reviewer for such a positive overview of our study’s objectives, and for
the endorsement of our work expressed here and in other parts of the comments. We
will deal with individual points below. Changes in accordance with reviewer
suggestions have been coloured blue in the manuscript, as in response letter.
a-
I think that this paper is very well situated in the literature, and addresses a problem
that is basically never considered- some critics (e.g. Cuskley et al.) suggest that the
bouba-kiki effect can be traced to orthography, rather than phonology/acoustics,
without considering that orthography and phonology might themselves be entangled-
this paper is the first modern on that I’m aware of that attempts to do so. There have,
of course, been several attempts to minimize or control for orthographic effects, as the
authors acknowledge. Additionally, other authors have acknowledged the
entanglement of orthography and phonology and proposed similar work- notably
Nielsen (2011) states:
“Of course, even in the best of situations it may not be possible to fully control for
orthographic effects- insofar as experimenters are correct that sound symbolic
relationships between objects and their tokens exist, it is possible that this sort of
representation might have leaked over into the creation of letters themselves. Thus,
the letter /k/ might have the form that it does precisely because of the way it sounds-
given multiple candidates for the form of a letter used to represent a strident,
broadband sound with certain acoustic characteristics, it is perhaps be unsurprising
that a specific visual polymorphism of a chaotic nature was chosen to represent it. The
idea that orthographic characteristics of letters might be confounding thus ignores the
question of why there might be systematic confounds in the first place.” – pp.35
Additionally, there is at least one case of previous research into this idea (though
more related to acoustics) that the authors are remiss to not cite:
Koriat, A., & Levy, I. (1977). The symbolic implications of vowels and of their
orthographic representations in two natural languages. Journal of Psycholinguistic
Research, 6, 93-104.
We thank the reviewer for pointing us in the direction of these two interesting
sources, and have acknowledged them in the introduction (p.4):
The ‘entanglement’ of the visual forms of letters with the sounds they
represent has been noted previously (29, 30). Koriat & Levy (29) asked
participants to rate vowel glyphs on the sensory dimensions of magnitude,
brightness, hardness, and length. The glyphs were from unrelated script-
families (Japanese Katakana and Devanagari), that were unfamiliar to the
participants (Hebrew speakers). In their study, the glyphs were ranked across
each visual dimension in the same order as had previously been documented
for participants familiar with the Latin alphabet –the sequence /i, e, a, u, o/
represented increasing size, and decreasing brightness and hardness in all three
scripts. This finding suggested a common cross-modal core for the visual
representations of speech sounds in three scripts. To date, no studies have
investigated whether a broader sample of writing systems of the world encode
this kind of sensory information systematically – in a way that might allow
naïve participants to guess letter identity – nor what visual properties might
drive the effect.
b-
Methodologically, I’m somewhat concerned about the influence of the user’s own
language on their response patterns- in all studies graphemes that the participants are
actually familiar with are excluded, but this only excludes response for which they
*know* the mapping between grapheme and phoneme.
It seems reviewer 1 may have slightly misunderstood our exclusion process: We did
not excluded those scripts where people could correctly identify which was /i/ and
which was /u/, rather, we excluded any scripts that participants judged as familiar and
named correctly. That is to say, if a participant said the Japanese script was familiar
and named it as Chinese, their response was NOT excluded, since they were clearly
not familiar with the script. However, we interpreted the question quite generously,
such that if a participant said the Khmer script was familiar and named it as Thai, we
accepted this as a correct response, since the writing systems are closely related
(Khmer is the parent script for modern Thai), which could give a participant insights
into the match between glyph and phoneme.
In the original submission we described this exclusion process as follows:
Original text:
Experiment 1 (p. 5): “Since the goal of the study was to investigate responses
to unfamiliar writing systems, we excluded any scripts that were marked as
familiar and correctly named, at the level of the individual.”
Experiment 2 (p 6) Following exclusion of correctly identified familiar scripts
(1.1%)…
Following Reviewer 1’s comments, we have updated the wording in the description of
Experiment 2 for greater clarity. If the editor thinks there is still ambiguity in the text,
we are happy to provide further details in the Methods section.
Updated text:
Experiment 2 (p 6) Following exclusion of familiar, correctly-named scripts
for each individual (1.1%)…
We understand that these comments refer only to the portion of the text about
exclusions, and continue to address the rest of the comment below.
The participants in Experiment 1 are listed as speaking English, Mandarin, Malay,
Tamil, Korean, and French - notably, they all speak English and are familiar with
English graphemes (that much is hard to get around, I’ll admit!), but French and
Malay both use the Latin alphabet, Mandarin is logographic (not confounded), and
both Tamil and Korean arguably follow the same pattern as the Latin alphabet. I
recognize that it would be too big of an ask to try to do this study with speakers of a
language that does *not* have the property in question, both i) because it would be
very difficult in general to find experimental participants not familiar with English
orthography, and ii) because that would be a follow-up study, for further proof of
theory, rather than something that I’d request as a revision to a single manuscript.
Firstly, we would like to acknowledge that all of our participants are familiar with
English, and this may have been a confound in the pattern of responding. We have
added sections to address how this might have affected participants responding in
several sections of the paper to address this concern, including comments about their
familiarity with the Latin script and other possible linguistic/cultural factors.
P14 para 3 (i.e., all participants took the test in English, and are therefore
familiar with the visual properties of the letters “i” and “u”).
P15 para 1 Alternatively, they could have settled on this response strategy by
analogy to Latin letters.
P15 para 2 Previous research has begun to document cross-cultural differences
in linguistic sound symbolism (28, 56), as well as in audio-visual crossmodal
mappings related to linguistic metaphor (46, 57, 58). For instance, in at least
two cases, the well known matches between pseudoword pairs like bouba/kiki
and maluma/takete do not show the expected pattern of audio-visual
correspondence in languages where the test items do not match the sound
structure of the language (see 56 for extended discussion). Also, in crossmodal
matching between pitch and the visual dimensions of height or thickness
(German: ‘high’ versus ‘low’ pitch; Farsi and Turkish: ‘thin’ versus ‘thick’
pitch), prelinguistic infants show sensitivity to mapping strategies that are
used by a variety of cultures (46), while adults tend to prefer to match
according to the dominant linguistic metaphor in their culture (57). These
adaptations of the linkages between auditory and visual processing represent a
kind of multisensory perceptual narrowing analogous to the ‘tuning’ processes
well-known to occur in the speech perception of young infants (59-61). This
experience-dependent developmental trajectory from general to culture-
specific audio-visual matching may help to account for differences between
universal patterns of sound symbolism, and conventionalized, culturally bound
ones. A similar chain of reasoning exists in the feedback theory of Taylor and
Taylor (62, 63), whereby shared subjective experiences of sound symbolic
matching (subjective sound symbolism) may become conventionalised in a
speech community over time (objective sound symbolism).
P15 para 3 In the context of the present study, although our participants report
culturally and linguistically diverse backgrounds (especially in Experiment 2),
all were familiar with the conventions of the English language, and thus
shared some elements of cultural background. The observed pattern of
responses could represent more-or-less WEIRD responding (i.e., responses
from Western, Educated, Industrialized, Rich and Democratic nations 64) due
to elements of shared culture (although note that participants in Experiment 1
were from South East Asia). Importantly, Latin letters canonically used to
represent the target vowels in English also show an observed spatial frequency
difference in the same direction as was found for highly guessable scripts in
the current study. It is therefore not possible to disentangle whether the spatial
frequency metric was a driver of sound symbolic matching due to a low-level
sensory bias, or due to the participants’ experience with the English language
visual contrast. Such confounds between general patterns of sensory matching
and culturally mediated patterns of sound symbolism have been noted
elsewhere (e.g., 16, 19, 21, 65, 66, 67). One way to concretely untangle these
possibilities in the future will be to investigate whether participants without
English script knowledge show the same matching biases (e.g., illiterate
populations / literate participants with no knowledge of the Latin script script /
infants).
Secondly, we acknowledge that the difference in the structure of the writing systems
may have consequences for our participants. To make this clearer for our readers’
interpretation of the data, we have added a note about these structural differences in
the Participants section of the Methods on page 18:
Typical of the Singapore language environment, most participants were
bilingual speakers of English and Mandarin Chinese (83.7%), along with
bilingual speakers of English and Malay (8.3%), English and Tamil (2%),
English and Korean (2%), English and French (2%), and monolingual English
speakers (2%). It should be noted that bilingual speakers of Chinese have
experience with an ideographic writing system, while speakers of Korean and
Tamil have experience with syllabic writing systems, while speakers of Malay
and French use only the Latin alphabet.
And on page 20 we have included an additional note about writing system structure,
in the extended section on participants’ language backgrounds.
All participants were speakers of English, and in addition reported that they
were from a variety of countries (Singapore (22.4%), Germany (21.3%),
United States (19.7%), Serbia (12.6%), United Kingdom (4.4%), Austria and
Australia (both 3.8%), The Netherlands (2.2%), Switzerland, Canada and
Hungary (all 1.6%), France (1.1%), Malaysia, Italy, Japan, Finland, New
Zealand, Mexico, Ireland (all 0.5%). and spoke a variety of languages.
Languages that received the highest self-report rating included English
(52.7%), German (19.4%), Serbian (8.1%), Mandarin Chinese (3.7%),
Croatian, Spanish and French (all 1.8%), Hungarian, Bosnian and Dutch (all
1.1%), Malay, Austrian German and Italian (all 0.7%), Cantonese, Russian,
Hindi, Hebrew, Greek, Portuguese, Singlish (Singaporean English Creole),
Czech, Finnish, Arabic, Bulgarian, Sinhala, Esperanto, Montenegrin (all
0.4%), as well as other languages (<.04% each). It should be noted that some
of the participants spoke languages which use only the Latin alphabet, while
others reported speaking languages with a more diverse range of scripts. Full
data are available in the Open Science repository for this project
(https://osf.io/xufmd).
Nonetheless, I suggest that the authors should acknowledge this point- it ultimately
relates to the arguments made in Taylor & Taylor (1965) re: objective vs. subjective
sound symbolism- the responses of experimental participants to manipulations are
hard to disentangle from their own language- do English speakers respond to scripts
that are isomorphic with respect to this phenomenon because it’s a cognitive bias
shared by humans generally (subjective sound symbolism), or because it’s a feature of
their own language (objective sound symbolism).
The results of these experiments suggest that it’s the former of the two above, rather
than the latter, but it would be good scientific practice to acknowledge the possible
confound, and propose ways forward from it. I have dealt with a similar issue in
differentiating between learning biases and learned biases in Nielsen & Rendall, 2012.
Finally, we incorporate the very relevant point of Taylor & Taylor (1965) into a
broader discussion acknowledging the entanglement of objective vs. subjective sound
symbolism in the context of our study (p.15, in paragraphs 2 and 3 – see text above).
That is, given the current participant pool, it is impossible to know for certain whether
our participants’ responses were driven by low-level sensory biases or cultural
experience with English language/orthography. We also propose an empirical
solution, inspired by Reviewer 1’s comment, which would be to conduct comparative
research with participants without such biases. We are thankful that this issue was
raised here, and believe such considerations should be incorporated into future study
designs in the field.
c-
Spatial frequency distributions- I’m very much in support of this type of simplified
explanation, and going against original eyeballed interpretations (i.e. notions of
‘curviness’ mentioned for the pilot) to attempt to arrive at a more objective value like
spatial frequency distribution that can be analysed statistically- there is nothing worse
than an ad hoc description that folks are trying to link to a pet theory, so I appreciate
this.
I do, however, think that the discussion of its use as a metric could be more nuanced-
spatial frequency differences work as *a* predictor of differences between
grapheme:phoneme mappings, but they are unlikely to be *the* predictor- it’s
certainly beyond the purview of this study to fully categorise what might be going on
perceptually- what features make a grapheme *good* for a given phoneme- it’s
impressive that something simple like spatial frequency can capture anything, but
disingenuous not to acknowledge that it’s a pretty crude metric, especially when
taking into account multiple iconicities- languages could encode the phonetic
contrasts differently in any number of ways, only some of which might be captured by
spatial frequency. […]
We appreciate the reviewer’s word of support for our method. We agree that spatial
frequency is likely to be one-of-many iconic strategies that can trigger links between
audio and visual stimuli. We regret that this plurality didn't through in our previous
version, and have added some sections to make this clearer.
[…] On this note, there could be more discussion about why spatial frequency is used
as the metric.
As we described briefly in the original manuscript, our choice of spatial frequency as
a metric was based on prior research (notably the logical links arising from Evans &
Treisman, 2010; and Ohala, 1994). To support our original reasoning, we have
substantially expanded our discussion on these points in three sections:
Discussion of Experiment 2 Page 7
In the crossmodal matching work of Evans & Triesman (40), high-pitched
sounds generate reaction time facilitation for small visual objects – an effect
which has also been observed in young children (41). Since a small visual
object activates a small area in the receptive field of the retina, it therefore
represents high spatial frequency information. Evans & Triesman further
demonstrated that pitch had the same facilitatory effect on high-spatial
frequency stimuli as on small sized stimuli, confirming a low-level crossmodal
link between visual spatial frequency and acoustic fundamental frequency
(pitch). Ohala’s (37) proposal that small body size is signalled by the higher
spectral frequencies of formants in lip-retracted vowels (e.g., /i/) as compared
to lip protruded vowels (e.g., /u/), suggests that size may be similarly mapped
to not only to fundamental frequency information (pitch), but also to spectral
frequency information (vowel formants). Hence for the visual analysis that
follows, we investigated whether the selection of which glyph was /i/ and
which was /u/ could be driven by the spatial frequency information in the
letters. We therefore investigated if scripts that maximised spatial frequency
distribution differences were the ones that attracted the highest proportion of
correct guesses.
Discussion: p13 para 2 In our study, the correspondence between spatial
frequency cycles (line length/complexity), and lower frequency components in
an auditory signal (lower F2, and F3 for /u/ as compared to /i/) is consistent
with environmental regularities such large body size/low pitch, as proposed by
Ohala (37). Furthermore, in the work of Evans & Triesman (40), high-pitched
sounds generate reaction time facilitation for visual objects with high-spatial
frequency, further confirming a low-level crossmodal link between visual
spatial frequency and acoustic frequency (in this case pitch). We therefore
propose that this effect is an extension of the congruence patterns exhibited by
the general sensory processing system – an effect that may not need to be
acquired through exposure to written language.
We hope that this better explains the chain of reasoning that lead us to investigate
spatial frequency profiles of the scripts. We should note that this research was
conducted before preregistration was widely advocated, so we aren’t in a position to
demonstrate that this was out only hypothesized visual dimension of interest, but we
feel it remains the best theoretically grounded in genuinely low-level sensory
processing.
We are happy to acknowledge that visual spatial frequency is therefore an extremely
simple property of visual stimulation (as Rev 1 puts it, a ‘crude metric’), however, our
attempt throughout this research has been to look for the properties of the sensory
system that could be doing the heavy lifting in our subjective experience of sensory
matching. Visual spatial frequency is about as low level as one can get. To
acknowledge Reviewer 1’s point, we have noted that this is a very simple metric, and
that it is by no means the only visual factor at play.
(P13-14) It should be noted that the simple measurement of spatial frequency
cycles may be picking up low-level sensory information from a variety of
iconic strategies (e.g., small versus large; simple versus complex), and this
visual feature may be just one of many that are contrasted in glyphs in
different writing systems. For example, some glyph pairs may exhibit more
contrast for curved versus angular forms, high-versus low positioning, or
vertical versus horizontal elements, without any attendant difference in
observed visual spatial frequency. Indeed the wide spread of responses across
this glyph set, and the spread of the data in the critical comparison (Fig 4)
suggests that multiple factors may be at play in judgments about individual
glyph-pairs. However, having uncovered a novel link between visual spatial
frequency and representation of speech sounds provides a new dimension for
future investigations into iconicity in human communication systems. The
straightforward measurement properties of spatial frequency can also be used
to create new generations of stimuli for future investigations into cross-modal
linkages both within, and outside the domain of language.
d-
Task Demands? I wonder somewhat about the influence of having participants make
judgements across so many scripts in a single experiment. On the one hand, this might
enhance the ability of participants to make these sort of judgements- this wouldn’t be
a problem unless indeed the distribution of scripts chosen was skewed- i.e. if the
distribution of languages that have differences in spatial frequency between u/i in the
predicted direction is sufficiently similar to the distribution of responses, then it
becomes difficult to tell whether participants are responding the way they are because
of iconicity (leaving aside whether it is objective or subjective- see above), or because
they have picked up on some regularity of the stimulus set and are responding
systematically (see both Dingemanse et al., and Nielsen, 2016 for discussions of these
differences).
On the other hand, the process of making multiple comparisons might lead to
attenuation of the effect- as mentioned above, if different writing systems have iconic
phoneme:grapheme mappings that make use of competing iconicities, they might
effectively obscure each other.
In total, I think it’s great that this study is comprehensive in its use of writing systems,
but these possibilities might bear mentioning.
We thank the reviewer for raising this important issue, which we acknowledge and
discuss further in the Discussion, on p14 para 3:
One further caveat on the interpretation of the findings is that the response
pattern we observe may not reflect an iconic strategy in glyph generation, but
may instead be driven by the task demands of making massed decisions about
a large number of visual stimuli in a single testing setting, for participants with
a particular language/script background (i.e., all participants took the test in
English, and are therefore familiar with the visual properties of the letters “i”
and “u”). It has been pointed out previously that massed testing of this kind
could induce task-specific decision strategies that may be driven by the
structure of the items in the test set. For example, if different letters pairs used
different iconic strategies, these effects may be attenuated by conflicting
response strategies (30). In our case, letters differ substantially across the full
set on a number of visual dimensions (including peak visual spatial frequency,
size, curvature, angularity, line width, orientation). Within a letter pair, these
differences are more-or-less controlled by the stylistics of the script, leaving
differences in observed spatial frequency (ink density), for most scripts. This
could mean that the use of multiple scripts lead participants to pay more
attention to the ink density characteristics than to other salient differences
between letter pairs. Alternatively, they could have settled on this response
strategy by analogy to Latin letters. Future iterations could use smaller subsets
of the glyph-pairs (one-shot tests), to washing out conflicting response
strategies, or test whether the visual properties identified here have a more
general role in multisensory processing to clarify the source of the observed
effects.
e-
Transparency and writing systems- Similarly to above, I wonder what the authors
might be able to say about full writing systems (at least alphabets, abugidas, and
abjads)- choosing /i/ vs /u/ is a sensible starting point, but what would happen if you
were to look at entire alphabets?
One suggestion might be that this effect can only be produced experimentally because
it’s the best possible comparison- much like the case that Lockwood and Dingemanse
make for ideophone-guessing tasks- when you’re presented with antonym pairs it’s
pretty easy to guess the meaning of words, but not so much if you have to choose
from multiple foils or the foil isn’t an antonym.
At the same time, if grapheme:phoneme mappings in writing systems are systematic,
in addition to being iconic, they might be even more obvious, both to users of a
writing system and to naive experimental participants- this is a point made in Bouba-
kiki studies- t and k are both jagged graphemes for voiceless plosives, m and n are
both curvy graphemes for voiced sonorants – perhaps some writing systems are
systematically sound-symbolic in this relative sense, rather than having individual
grapheme:phoneme mappings that are iconic.
This is of course not something that you have data for, but it’s likely the direction that
further research of this type needs to head in, so I think it bears discussion
We are delighted by the suggestion of whole alphabet comparisons, and hope to see
more research along these lines in the future. We have added section suggesting how
great this would be in the extended discussion on page 13.
The current study investigated only the single vowels /i/ and /u/, meaning that
more or less systematicity may be evident in other sounds/letters in world
writing systems. For example, it may well be the case that sound symbolic
guessing for consonant glyphs may be stronger than it is for vowel glyphs, a
finding that would be consistent with experimental pseudoword-shape
matching tasks (33, 36). As it stands, the choice of two highly contrastive
‘bare’ vowels allows the smallest unit of comparison that is utterable,
implemented using high prevalence, highly contrastive phonemes, that are
canonical for these kinds of effects (56). Despite the narrow phonological
range, this study provides proof of concept for further (e.g., whole of writing
system) investigations. For example, it may well be the case that some writing
systems are more iconic than others (at the level of the whole writing system),
rather than at the level of individual pairs. On the other hand, it may be that
some sound-pairs are uniquely iconic due to their dimensional contrastiveness,
and that most languages do more-or less well on pairs of this kind. These
details have yet to be established by future work.
f-
I find some of the discussion a bit too far afield and theoretical for a research paper of
this type- although I generally agree with the authors and think that synesthesia,
dyslexia, and their possible links to crossmodal perception more generally are
fascinating topics, I don’t think the data presented in this manuscript have much
material to say about those topics, so I’m not sure if they add anything to the paper.
I’d rather see the issues above discussed more fully- pointing concretely towards
where this kind of research can go in the future, rather than too much outside
speculation. That is my own opinion though, and I recognize that different journals
have different views about how much leeway authors are given to theorise.
The reviewer makes a fair point, and given the expanded discussion on the specifics
of the experiment and stimuli, we have reduced our comments on these topics
according. (p15-16)
Letters as multisensory objects. From an evolutionary perspective, writing is a
relatively recent technology, meaning that the links between text and speech
must be subserved by neural functions originally adapted for other purposes
(63). This mismatch between novel functions and evolved systems may make
letter representations acutely fragile to disruption from subtle differences in
multisensory processing (7), with grapheme-induced synaesthesia representing
disregulated and/or hyperactive multisensory processing (64-67), and letter
decoding difficulties well-known in dyslexia representing disregulated and/or
hypoactive multisensory processing (68-74). In the current study we provide a
measurable source of cross-modal activity linking acoustic properties of
speech sounds and visual properties of glyphs. Research into individual
differences may reveal further modulation of these effects in different subsets
of readers.
g-
The title irks me. It’s nice that the first portion rhymes, but readers might skip over it-
even as a reviewer I started reading thinking “wait... isn’t this paper about cherokee?”
We have updated the title per the reviewer’s suggestion. In the update, we have also
toned down the causal language from ‘Spatial frequency drives sound symbolic
matching…” to “Spatial frequency information in sound symbolic matching…”
Glyph guessing for “oo” and “ee”: Spatial frequency information in sound
symbolic matching for ancient and unfamiliar scripts
------------------------------------------------------------------
Reviewer: 2
Comments to the Author(s)
This paper was a delight to read. The logic was clear and elegant. The studies were
reported in a straightforward manner and the writing is excellent.
I have three main comments:
(1)
At a number of points in the paper it is claimed that diverse groups of people use
similar strategies for mapping speech to visual forms. This claim rests in 2 parts: (a)
the different writing systems that have evolved, (b) the results of Experiment 2. Both
of these points have limitations.
(a) Not all writing systems have evolved independently. There are clear chains of
transmission from writing system to writing system. It would be wrong to treat the 56
letter pairs considered here as independent datapoints with respect to the hypothesis.
This point should be explicitly acknowledged in the discussion (and ideally also dealt
with in terms of the statistical analyses).
We would like to thank Reviewer 2 for flagging this point, as we did not build these
relationships into the design of the study, or the pre-planned analysis. We have
highlighted the point that such genetic relationships between scripts may indeed be
involved in the relationship between audio and visual components of letter
representation, or indeed in individuals’ guessing strategies. We have highlighted this
in the “Further Directions” section (p. 17), as we see this as a rich potential future
direction.
One promising line of inquiry may be how script evolution interacts with the
sound-symbolic properties of scripts, and whether different lineages encode
different patterns of iconicity. Writing systems shown clear chains of
development over time, with more-closely related scripts looking more similar
to each other. To give examples from the scripts used in the study, the letters
/i/ and /u/ share some overall similarities in the scripts from the Devanagari
family: Devanagari and Bengali (IDs 17 and 36, respectively), as do scripts
from the Arabic family, including Urdu, Sindhi, Book Pahlavi, Nestorian
Syriac, Avestan and Parthian inscription (IDs 52, 24, 26, 35, 39, 37), albeit at
different degrees of visual similarity. The norms for script guessability allow
more fine-grained investigation of these relationships over historical time and
geographic space.
(b) It is stated that participants from Experiment 2 were diverse because they came
from "a variety of countries and spoke a variety of languages". I could not access the
data from OSF so cannot verify this.
We apologise that the review link may not have been clear in our original
submission, as it only appeared in the endmatter (Data Accessibility), and not
in the body of the text, where we used the Permalink not the Review link. We
apologise for any confusion this may have caused in the review process. In
preparation for publication we have made the whole Repository open access
now.
The body of the paper should provide more detailed information since this point is
critical to one of the key arguments of the paper. In particular, it would be important
to note the limitations (if any) of the sample diversity, especially as it impacts the
conclusions of the paper.
In line with the reviewer’s suggestion, we have provided more information as to the
countries and languages reported by the participants that took part in Experiment 2 (p.
19-20).
All participants were speakers of English, and in addition reported that they
were from a variety of countries [Singapore (22.4%), Germany (21.3%),
United States (19.7%), Serbia (12.6%), United Kingdom (4.4%), Austria and
Australia (both 3.8%), The Netherlands (2.2%), Switzerland, Canada and
Hungary (all 1.6%), France (1.1%), Malaysia, Italy, Japan, Finland, New
Zealand, Mexico, Ireland (all 0.5%).] and spoke a variety of languages.
Languages that received the highest self-report rating included English
(52.7%), German (19.4%), Serbian (8.1%), Mandarin Chinese (3.7%),
Croatian, Spanish and French (all 1.8%), Hungarian, Bosnian and Dutch (all
1.1%), Malay, Austrian German and Italian (all 0.7%), Cantonese, Russian,
Hindi, Hebrew, Greek, Portuguese, Singlish (Singaporean English Creole),
Czech, Finnish, Arabic, Bulgarian, Sinhala, Esperanto, Montenegrin (all
0.4%), as well as other languages (<.04% each). Full data are available in the
Open Science repository for this project (https://osf.io/xufmd)
We have also made sure to include the link to the OSF (the permanent link, now that
the manuscript has been accepted) in all places in the manuscript where the OSF data
is being referred to, to allow easier access.
In response to a similar issue raised by Reviewer 1, we acknowledged and elaborated
on our sample’s diversity in that all participants spoke English, and were familiar with
English orthography, and what the implications of this were, generally and for future
work in several places, including the following:
P15 para 2 Although our participants (especially in Experiment 2) reported
coming from a wide range of cultural and linguistic backgrounds, all were
familiar with Western culture and the conventions of the English language, so
it is possible that the pattern of responses we see in the current study could
represent more-or-less WEIRD responding (i.e., responses from Western,
Educated, Industrialized, Rich and Democratic nations 62).
P17 para 3: This study provides norms for letter-pair guessability, as well as
measured spatial frequency information for the individual letters in a variety
of writing systems that are likely to be unfamiliar to the majority of
contemporary readers in the West.
P 18 para 2 p. 19 para 2: Participants were 183 internet users who took part in
the test in English
(2)
The authors claim on p.12 that infants cannot pitch and size until 30-36 months, but
Dolscheid et al (2014; Psychological Science) showed that 4 month olds can match
pitch to size.
We have updated the wording in the section on crossmodal correspondences to
include this work (p. 13):
Such correspondences have been observed very early in life (e.g., pitch-
lightness in 30-36-month-olds: 41, loudness and brightness in 20- to 30-day-
old infants: 44, pitch and visual elevation in three- to four-month-olds: 45,
pitch and size in 4-month-olds: 46, for review see: 47)
The authors also fail to acknowledge the fact that cross-modal correspondences as
culturally shaped too (Dolscheid et al, 2013, Psychological Science; Shayan et al,
2014, Developmental Science). This does not detract from the main point of this
paper. Nevertheless, it is clear that there is cultural shaping of associations too, and
this needs to be reconciled with these fascinating biases the authors uncover. A short
discussion of this would be warranted.
This is a great point that we agree with wholeheartedly. We have added a new section
on linguistic-relativity-type differences to address this point, and the further
implications arising from this chain of reasoning (p. 15).
Previous research has begun to document cross-cultural differences in
linguistic sound symbolism (28, 56), as well as in audio-visual crossmodal
mappings related to linguistic metaphor (46, 57, 58). For instance, in at least
two cases, the well known matches between pseudoword pairs like bouba/kiki
and maluma/takete do not show the expected pattern of audio-visual
correspondence in languages where the test items do not match the sound
structure of the language (see 56 for extended discussion). Also, in crossmodal
matching between pitch and the visual dimensions of height or thickness
(German: ‘high’ versus ‘low,’ Farsi and Turkish: ‘thin’ versus ‘thick’),
prelinguistic infants show sensitivity to mapping strategies that are used by a
variety of cultures (46), while adults tend to prefer to match according to the
dominant linguistic metaphor in their culture (57). These adaptations of the
linkages between auditory and visual processing represent a kind of
multisensory perceptual narrowing analogous to the ‘tuning’ processes well-
known to occur in the speech perception of young infants (59-61). Although
our participants (especially in Experiment 2) reported coming from a wide
range of cultural and linguistic backgrounds, all were familiar with Western
culture and the conventions of the English language, so it is possible that the
pattern of responses we see in the current study could represent more-or-less
WEIRD responding (i.e., responses from Western, Educated, Industrialized,
Rich and Democratic nations 62).
(3)
Finally, I urge the reviewers to revise Figures 3 and 4 to also include the 2nd most
guessable scripts into the visualization.
We have updated the figures to accommodate this suggestion (Figure 3 on p.10, and
figure 4 on p.11). On both figures, Script 42: Mongolian, a script with a small positive
difference between /i/ and /u/ guesses, is now shown as the example for the 2nd most
guessable scripts. The figure legends were likewise changed to suit:
P10
Figure 3. Scatterplot of Median Detection Rates for /i/ and /u/ glyphs, shown for each
glyph, with the script’s guessability quartiles shown in colour. Dashed line indicates
equivalence. Above the line, scripts have higher SF Detection for /u/ than for /i/. Data
from all 56 scripts shown, with outlier (Mayan) highlighted. Examples of scripts with a
large positive difference (Uyghur), a small difference (Mongolian, Vai), and a large
negative difference (Tamil) are shown.
P11
Figure 4. Scatterplot of each script’s guessability and median of the SF Difference
wave (the difference in detection of black/white cycles at difference spatial
frequencies: /u/ minus /i/). Solid line shows linear relationship. Dashed lines show
95% Confidence Interval of Mean. Data from all 56 scripts shown. Examples of
scripts with a large positive difference (Uyghur), a small difference (Vai, Mongolian),
and a large negative difference (Tamil) are shown.
Overall, this is a fascinating paper and should be published.
Society Open
