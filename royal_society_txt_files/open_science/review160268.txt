Using network analysis to study behavioural phenotypes:
an example using domestic dogs
Conor Goold, Judit Vas, Christine Olsen and Ruth C. Newberry
Article citation details
R. Soc. open sci. 3: 160268.
http://dx.doi.org/10.1098/rsos.160268
Review timeline
Original submission: 18 April 2016 Note: Reports are unedited and appear as
Revised submission: 10 August 2016 submitted by the referee. The review history
Final acceptance: 14 September 2016 appears in chronological order.
Review History
label_version_1
RSOS-160268.R0 (Original submission)
label_author_1
Review form: Reviewer 1 (Sacha Epskamp)
Is the manuscript scientifically sound in its present form?
Yes
Are the interpretations and conclusions justified by the results?
Yes
Is the language acceptable?
Yes
Is it clear how to access all supporting data?
Data is included in the submission.
Do you have any ethical concerns with this paper?
No
© 2016 The Authors. Published by the Royal Society under the terms of the Creative Commons
Attribution License http://creativecommons.org/licenses/by/4.0/, which permits unrestricted use,
provided the original author and source are credited
2
Have you any concerns about statistical analyses in this paper?
No
Recommendation?
label_recommendation_1
Accept with minor revision (please list in comments)
Comments to the Author(s)
label_comment_1
I found the manuscript to be exceptionally well written and think it could make a strong and
timely contribution to the literature. The overview of network analysis was very clear and spot-
on, correct references were used throughout the manuscript, and the most recent methodological
advances in psychological network analysis were applied. In addition, the figures and description
of results were very clear and interpretable. I also think this paper highlights the first application
of multiple imputation in network psychometrics. I advice to accept this article for publication
pending the issues mentioned below.
I have only one major comment, which is on the emphasis on confidence intervals on centrality
indices. As explained the pre-print at https://arxiv.org/abs/1604.08462, bootstrapping
confidence intervals on centrality indices turned out to be influenced by a bias due to absolute
values used in graph estimation. As such, obtaining confidence intervals can *not* be done at the
moment and is an important topic for future research. The bootnet package provides intervals
that do show the variability of these indices, but they can not be interpreted as being exact 95%
confidence intervals (as the true parameter is not retained in 95% of such intervals). Thus, care
should be taken in the reporting of these intervals. I advice the authors to not describe these as
confidence intervals (or to make this limitation clear) and to report the person-dropping and
node-dropping stability of centrality indices as well.
In addition, the selected gamma parameter is relatively high, even though there is no problem in
using this value the authors could make clear that using such a high value optimizes specificity
(there are likely no to few falsely estimated edges, but not all true edges might be detected).
Finally I suggest panels a and b to be plotted with the same layout to make the networks more
easily comparable.
Sacha Epskamp
University of Amsterdam
label_author_2
Review form: Reviewer 2 (Jamie Fratkin)
Is the manuscript scientifically sound in its present form?
Yes
Are the interpretations and conclusions justified by the results?
Yes
Is the language acceptable?
Yes
Is it clear how to access all supporting data?
Yes
Do you have any ethical concerns with this paper?
No
3
Have you any concerns about statistical analyses in this paper?
I do not feel qualified to assess the statistics
Recommendation?
label_recommendation_2
Major revision is needed (please make suggestions in comments)
Comments to the Author(s)
label_comment_2
This paper presents a novel topic, examining how network analysis can be used to study
behavioral phenotypes on dogs. The results are interesting and provide useful information to
further important research in dogs.
1. One of my main concerns about the paper is about the survey that was used. I do not see any
evidence the behavioral descriptors were assessed for reliability or validity. In the manuscript, it
says all participants were familiar with the terminology used as descriptions of police dog
behaviour, but the descriptors are not very specific (unless the handlers were given more
description than what was given in the manuscript or supplementary material). For example,
there are some interesting results regarding play, but it looks like the only information the
handlers received for play is ‘playful’. There are many different types of domains of play (ball
play, play with humans, play with other dogs, tug play, etc.). Is there any evidence of the
consistency of their ratings?
2. Along with reliability concerns, I am wondering how some traits were designated as desirable,
while others were designated as undesirable? Was this based on the handler’s ratings of what
would be desirable or was this set up during survey development? Was there consistency in what
traits were rated as desirable vs. undesirable? To me, it seems as if some of the traits might even
be desirable for specific jobs but not others. For example, strong tendency to growl at strangers is
listed as undesirable, but it seems like that might be desirable for patrol dogs (and previous
literature does suggest certain traits related to aggression are related to police dogs success, e.g.,
Slabbert & Odendaal - 1999 - Early prediction of adult police dog efficiency—a longitudinal
study).
3. One thing I’d like to see more in the discussion is how the network analysis helps us more than
previous work. For example, on page 20 it is mentioned that the findings extend previous studies
by disentangling potential causal, mutually-reinforcing relationships between behaviours. Why is
it important to know this?
4. Is there any information on the demographics of the handlers? Were they all male handlers?
How many dogs have they handled before? Information like this would be helpful.
5. You many not have a big enough sample size to answer this, but were there any breed
differences? Maybe even between German Shepherds and other dogs or Labrador Retrievers and
other dogs?
Other minor comments
6. Page 9 – how many items remained after removal of some descriptors?
7. Page 16 – is there any way to get these models to go next to each other rather than one on top of
the other? It would be easier to compare them if they were side by side.
4
8. Page 22 – line 399 – I’m not sure I understand this point. Why does this demonstrate less
stringent behavioral selection for detection dogs compared to patrol dogs? Maybe giving an
example would help?
9. Page 20 – line 369 – playfulness has been assessed in a wide variety of ways, not just
specifically being about tug-type games, it’s probably better to say playfulness is sometimes
assessed…
label_end_comment
Decision letter (RSOS-160268)
19-Jul-2016
Dear Mr Goold,
The editors assigned to your paper ("Using network analysis to study behavioural phenotypes: an
example using domestic dogs.") has now received comments from reviewers. We would like you
to revise your paper in accordance with the referee and Subject Editor suggestions which can be
found below (not including confidential reports to the Editor). Please note this decision does not
guarantee eventual acceptance.
Please submit a copy of your revised paper within three weeks (i.e. by the 11-Aug-2016). If we do
not hear from you within this time then it will be assumed that the paper has been withdrawn. In
exceptional circumstances, extensions may be possible if agreed with the Editorial Office in
advance.We do not allow multiple rounds of revision so we urge you to make every effort to
fully address all of the comments at this stage. If deemed necessary by the Editors, your
manuscript will be sent back to one or more of the original reviewers for assessment. If the
original reviewers are not available we may invite new reviewers.
To revise your manuscript, log into http://mc.manuscriptcentral.com/rsos and enter your
Author Centre, where you will find your manuscript title listed under "Manuscripts with
Decisions." Under "Actions," click on "Create a Revision." Your manuscript number has been
appended to denote a revision. Revise your manuscript and upload a new version through your
Author Centre.
When submitting your revised manuscript, you must respond to the comments made by the
referees and upload a file "Response to Referees" in "Section 6 - File Upload". Please use this to
document how you have responded to the comments, and the adjustments you have made. In
order to expedite the processing of the revised manuscript, please be as specific as possible in
your response.
In addition to addressing all of the reviewers' and editor's comments please also ensure that your
revised manuscript contains the following sections as appropriate before the reference list:
• Ethics statement (if applicable)
If your study uses humans or animals please include details of the ethical approval received,
including the name of the committee that granted approval. For human studies please also detail
whether informed consent was obtained. For field studies on animals please include details of all
permissions, licences and/or approvals granted to carry out the fieldwork.
• Data accessibility
It is a condition of publication that all supporting data are made available either as
supplementary information or preferably in a suitable permanent repository. The data
5
accessibility section should state where the article's supporting data can be accessed. This section
should also include details, where possible of where to access other relevant research materials
such as statistical tools, protocols, software etc can be accessed. If the data has been deposited in
an external repository this section should list the database, accession number and link to the DOI
for all data from the article that has been made publicly available. Data sets that have been
deposited in an external repository and have a DOI should also be appropriately cited in the
manuscript and included in the reference list.
If you wish to submit your supporting data or code to Dryad (http://datadryad.org/), or modify
your current submission to dryad, please use the following link:
http://datadryad.org/submit?journalID=RSOS&manu=RSOS-160268
• Competing interests
Please declare any financial or non-financial competing interests, or state that you have no
competing interests.
• Authors’ contributions
All submissions, other than those with a single author, must include an Authors’ Contributions
section which individually lists the specific contribution of each author. The list of Authors
should meet all of the following criteria; 1) substantial contributions to conception and design, or
acquisition of data, or analysis and interpretation of data; 2) drafting the article or revising it
critically for important intellectual content; and 3) final approval of the version to be published.
All contributors who do not meet all of these criteria should be included in the
acknowledgements.
We suggest the following format:
AB carried out the molecular lab work, participated in data analysis, carried out sequence
alignments, participated in the design of the study and drafted the manuscript; CD carried out
the statistical analyses; EF collected field data; GH conceived of the study, designed the study,
coordinated the study and helped draft the manuscript. All authors gave final approval for
publication.
• Acknowledgements
Please acknowledge anyone who contributed to the study but did not meet the authorship
criteria.
• Funding statement
Please list the source of funding for each author.
Once again, thank you for submitting your manuscript to Royal Society Open Science and I look
forward to receiving your revision. If you have any questions at all, please do not hesitate to get
in touch.
Yours sincerely,
Andrew Dunn
Senior Publishing Editor
Royal Society Open Science
on behalf of Kevin Padian
Subject Editor, Royal Society Open Science
openscience@royalsociety.org
6
Comments to Author:
Reviewers' Comments to Author:
Reviewer: 1
Comments to the Author(s)
I found the manuscript to be exceptionally well written and think it could make a strong and
timely contribution to the literature. The overview of network analysis was very clear and spot-
on, correct references were used throughout the manuscript, and the most recent methodological
advances in psychological network analysis were applied. In addition, the figures and description
of results were very clear and interpretable. I also think this paper highlights the first application
of multiple imputation in network psychometrics. I advice to accept this article for publication
pending the issues mentioned below.
I have only one major comment, which is on the emphasis on confidence intervals on centrality
indices. As explained the pre-print at https://arxiv.org/abs/1604.08462, bootstrapping
confidence intervals on centrality indices turned out to be influenced by a bias due to absolute
values used in graph estimation. As such, obtaining confidence intervals can *not* be done at the
moment and is an important topic for future research. The bootnet package provides intervals
that do show the variability of these indices, but they can not be interpreted as being exact 95%
confidence intervals (as the true parameter is not retained in 95% of such intervals). Thus, care
should be taken in the reporting of these intervals. I advice the authors to not describe these as
confidence intervals (or to make this limitation clear) and to report the person-dropping and
node-dropping stability of centrality indices as well.
In addition, the selected gamma parameter is relatively high, even though there is no problem in
using this value the authors could make clear that using such a high value optimizes specificity
(there are likely no to few falsely estimated edges, but not all true edges might be detected).
Finally I suggest panels a and b to be plotted with the same layout to make the networks more
easily comparable.
Sacha Epskamp
University of Amsterdam
Reviewer: 2
Comments to the Author(s)
This paper presents a novel topic, examining how network analysis can be used to study
behavioral phenotypes on dogs. The results are interesting and provide useful information to
further important research in dogs.
1. One of my main concerns about the paper is about the survey that was used. I do not see any
evidence the behavioral descriptors were assessed for reliability or validity. In the manuscript, it
says all participants were familiar with the terminology used as descriptions of police dog
behaviour, but the descriptors are not very specific (unless the handlers were given more
description than what was given in the manuscript or supplementary material). For example,
there are some interesting results regarding play, but it looks like the only information the
handlers received for play is ‘playful’. There are many different types of domains of play (ball
play, play with humans, play with other dogs, tug play, etc.). Is there any evidence of the
consistency of their ratings?
2. Along with reliability concerns, I am wondering how some traits were designated as desirable,
while others were designated as undesirable? Was this based on the handler’s ratings of what
7
would be desirable or was this set up during survey development? Was there consistency in what
traits were rated as desirable vs. undesirable? To me, it seems as if some of the traits might even
be desirable for specific jobs but not others. For example, strong tendency to growl at strangers is
listed as undesirable, but it seems like that might be desirable for patrol dogs (and previous
literature does suggest certain traits related to aggression are related to police dogs success, e.g.,
Slabbert & Odendaal - 1999 - Early prediction of adult police dog efficiency—a longitudinal
study).
3. One thing I’d like to see more in the discussion is how the network analysis helps us more than
previous work. For example, on page 20 it is mentioned that the findings extend previous studies
by disentangling potential causal, mutually-reinforcing relationships between behaviours. Why is
it important to know this?
4. Is there any information on the demographics of the handlers? Were they all male handlers?
How many dogs have they handled before? Information like this would be helpful.
5. You many not have a big enough sample size to answer this, but were there any breed
differences? Maybe even between German Shepherds and other dogs or Labrador Retrievers and
other dogs?
Other minor comments
6. Page 9 – how many items remained after removal of some descriptors?
7. Page 16 – is there any way to get these models to go next to each other rather than one on top of
the other? It would be easier to compare them if they were side by side.
8. Page 22 – line 399 – I’m not sure I understand this point. Why does this demonstrate less
stringent behavioral selection for detection dogs compared to patrol dogs? Maybe giving an
example would help?
9. Page 20 – line 369 – playfulness has been assessed in a wide variety of ways, not just
specifically being about tug-type games, it’s probably better to say playfulness is sometimes
assessed…
Author's Response to Decision Letter for (RSOS-160268)
See Appendix A.
label_version_2
RSOS-160268.R1 (Revision)
label_author_3
Review form: Reviewer 2 (Jamie Fratkin)
Is the manuscript scientifically sound in its present form?
Yes
8
Are the interpretations and conclusions justified by the results?
Yes
Is the language acceptable?
Yes
Is it clear how to access all supporting data?
Yes
Do you have any ethical concerns with this paper?
No
Have you any concerns about statistical analyses in this paper?
I do not feel qualified to assess the statistics
Recommendation?
label_recommendation_3
Accept as is
Comments to the Author(s)
label_comment_3
Thank you for taking the suggestions from my last review. I think you have clarified the points I
made from the previous draft.
Jamie Fratkin
label_end_comment
Decision letter (RSOS-160268.R1)
14-Sep-2016
Dear Mr Goold,
I am pleased to inform you that your manuscript entitled "Using network analysis to study
behavioural phenotypes: an example using domestic dogs." is now accepted for publication in
Royal Society Open Science.
You can expect to receive a proof of your article within approximately 10 working days. Please
contact the production office (openscience_proofs@royalsociety.org) to let us know if you are
likely to be away from e-mail contact during that period. Due to rapid publication and an
extremely tight schedule, if comments are not received, your paper may experience a delay in
publication.
Royal Society Open Science operates under a continuous publication model
(http://bit.ly/cpFAQ). Your article will be published straight into the next open issue and this
will be the final version of the paper. As such, it can be cited immediately by other researchers.
As the issue version of your paper will be the only version to be published I would advise you to
check your proofs thoroughly as changes cannot be made once the paper is published.
In order to raise the profile of your paper once it is published, we can send through a PDF of your
paper to selected colleagues. If you wish to take advantage of this, please reply to this email with
the name and email addresses of up to 10 people who you feel would wish to read your article.
9
On behalf of the Editors of Royal Society Open Science, we look forward to your continued
contributions to the Journal.
Best wishes,
Andrew Dunn
Senior Publishing Editor
Royal Society Open Science
Reviewer(s)' Comments to Author:
Reviewer: 2
Comments to the Author(s)
Thank you for taking the suggestions from my last review. I think you have clarified the points I
made from the previous draft.
Jamie Fratkin
Appendix A
Dear Editor and Reviewers,
Thank you for the comments on our manuscript. Please find below our responses to
your suggestions and requested clarifications.
Yours sincerely,
Conor Goold
Comments to reviewer 1 (Sacha Epskamp)
Reviewer 1
I have only one major comment, which is on the emphasis on confidence intervals on
centrality indices. As explained the pre-print at https://arxiv.org/abs/1604.08462,
bootstrapping confidence intervals on centrality indices turned out to be influenced by
a bias due to absolute values used in graph estimation. As such, obtaining confidence
intervals can *not* be done at the moment and is an important topic for future
research. The bootnet package provides intervals that do show the variability of these
indices, but they can not be interpreted as being exact 95% confidence intervals (as
the true parameter is not retained in 95% of such intervals). Thus, care should be
taken in the reporting of these intervals. I advice the authors to not describe these as
confidence intervals (or to make this limitation clear) and to report the person-
dropping and node-dropping stability of centrality indices as well.
Authors’ response
We thank Sacha Epksamp for highlighting a very recent paper discussing the
biasedness of bootstrapped network ‘confidence intervals’. Due to the concerns about
bias, we have removed the calculation of confidence intervals from our analyses.
Since bootstrapping is often conducted to calculate confidence intervals, or other
measures of parameter uncertainty, we do briefly note (and cite the aforementioned
article [reference 65]) the reasons for not calculating confidence intervals in the paper
(lines 262-263) and in the R script file, as it would be of importance to potential
readers wanting to apply network analysis as we have done in our paper.
As recommended, we have retained our reporting of network stability based on node-
wise bootstrapping, and included the explanation and results of subject-wise
bootstrapping (lines 258-260 & 320-325). We have presented the results of node-wise
and subject-wise bootstrapping graphically in Figure 4 of the manuscript, and placed
additional results in Figures S1 and S2 in the Supplementary Material. We have,
furthermore, changed reference to network ‘robustness’ to network ‘stability’, to
reflect language used by Epskamp et al. [reference 65].
Reviewer 1
In addition, the selected gamma parameter is relatively high, even though there is no
problem in using this value the authors could make clear that using such a high value
optimizes specificity (there are likely no to few falsely estimated edges, but not all true
edges might be detected).
Authors’ response
We have included this point in lines 234-235.
Reviewer 1
Finally I suggest panels a and b to be plotted with the same layout to make the
networks more easily comparable.
Authors’ response
Done. Additionally, the graphs in Figure 1 have been placed alongside one another, to
address reviewer 2’s comments (see below).
Comments to reviewer 2
Reviewer 2
One of my main concerns about the paper is about the survey that was used. I do not
see any evidence the behavioral descriptors were assessed for reliability or validity.
In the manuscript, it says all participants were familiar with the terminology used as
descriptions of police dog behaviour, but the descriptors are not very specific (unless
the handlers were given more description than what was given in the manuscript or
supplementary material). For example, there are some interesting results regarding
play, but it looks like the only information the handlers received for play is ‘playful’.
There are many different types of domains of play (ball play, play with humans, play
with other dogs, tug play, etc.). Is there any evidence of the consistency of their
ratings?
Authors’ response
The police dog handlers only received the descriptions reported in Table S1, and
responses for each dog were obtained from just one handler on one occasion.
However, the police dog handlers were regarded as knowledgeable raters, all having
undertaken formal police training in dog handling and in the documentation of
behavioural information. Since handlers were asked to describe the general behaviour
of the dogs across a wide range of experiences, assessing reliability between raters
would pose considerable challenges (e.g. finding additional individuals that know the
same dogs well enough across the same range of contexts).
Research supports the reliability of lexical rating approaches, both in dogs (e.g.
Wilsson & Sinn, 2012. doi.org/10.1016/j.applanim.2012.08.012) and other animals,
such as in Qualitative Behaviour Assessment (e.g. Phythian et al., 2013.
doi:10.1016/j.applanim.2012.11.011.). We also note in our discussion section (lines
427-429) that there are advantages to such lexical rating approaches over more
quantitative measures.
Our data preparation methodology resulted in removal of 23 of the original 43
descriptors in the survey, indicating the value of these data screening procedures and
pointing to needed refinements in the survey instrument. We have emphasised in lines
429-431 that no checks of reliability were conducted, and have suggested in lines
386-389 future work to quantify networks of more specific behavioural measures (e.g.
to see how different behaviours related to the ‘Playful’ descriptor coalesce in a
network).
As we have noted in lines 433-443, validity is not yet well formulated in the network
framework (see reference [76,78]), and applying conventional methods to check the
survey's validity would be contradictory to the goal of our paper. Therefore, we
instead focussed our efforts on careful screening and conditioning of the data prior to
analysis.
Reviewer 2
Along with reliability concerns, I am wondering how some traits were designated as
desirable, while others were designated as undesirable? Was this based on the
handler’s ratings of what would be desirable or was this set up during survey
development? Was there consistency in what traits were rated as desirable vs.
undesirable? To me, it seems as if some of the traits might even be desirable for
specific jobs but not others. For example, strong tendency to growl at strangers is
listed as undesirable, but it seems like that might be desirable for patrol dogs (and
previous literature does suggest certain traits related to aggression are related to
police dogs success, e.g., Slabbert & Odendaal - 1999 - Early prediction of adult
police dog efficiency—a longitudinal study).
Authors’ response
The distinction between desirable and undesirable behaviours was made during
survey development, in accordance with senior members of the Norwegian Police
University College. We have explained this in lines 163-164. Reviewer 2 raises the
important point that the desirability of behaviour can be context specific. Indeed, this
was the case for the descriptor, ‘Bites people hard’ (desirable in patrol dogs in
restricted contexts; undesirable in detection dogs), resulting in many ‘Not relevant/I
do not know’ responses and consequent removal of this descriptor in the data
screening process (see Table S1).
‘Strong tendency to growl at strangers’ was labelled undesirable in this study as it was
considered to indicate a dog that is uncomfortable around unknown people.
Norwegian police dogs work without muzzles and are required to be calm and non-
aggressive around people in general. The article by Slabbert and Odendaal (1999;
cited by reviewer 2) reports a behavioural test labelled a test of aggression that is not
comparable to the behaviour our descriptor was intended to represent. Overall, a
dog’s response in the specific training and testing contexts described by Slabbert and
Odendaal does not imply that a dog who growls at strangers is also desirable. Other
large scale personality studies in dogs suggest that while a ‘boldness’ trait predicts
working dog performance, aggression is distinct from this trait (e.g. see Svartberg
[reference 44]).
Reviewer 2
One thing I’d like to see more in the discussion is how the network analysis helps us
more than previous work. For example, on page 20 it is mentioned that the findings
extend previous studies by disentangling potential causal, mutually-reinforcing
relationships between behaviours. Why is it important to know this?
Authors’ response
We have expanded on the value of network analysis in lines 359-364.
Reviewer 2
Is there any information on the demographics of the handlers? Were they all male
handlers? How many dogs have they handled before? Information like this would be
helpful.
Authors’ response
Information on the sex, age, years of experience and the number of previous dogs (pet
and working) has been added on lines 152-156.
Reviewer 2
You many not have a big enough sample size to answer this, but were there any breed
differences? Maybe even between German Shepherds and other dogs or Labrador
Retrievers and other dogs?
Authors’ response
We were unable to explore breed differences using network analyses due to limited
sample sizes for more than one breed (noted on lines 151-152). To do this adequately
would also require the multiple imputation procedure to be repeated with breed as a
conditioning variable, which was infeasible without larger samples of each breed. We,
thus, a priori focused on the distinction of patrol and detection dog differences. We
have alluded to the relevance of exploring breed differences in future research (e.g. on
playfulness, see lines 386-389).
Reviewer 2
Page 9 – how many items remained after removal of some descriptors?
Authors’ response
38 descriptors remained after the first 5. This has been added on line 177-178.
Reviewer 2
Page 16 – is there any way to get these models to go next to each other rather than
one on top of the other? It would be easier to compare them if they were side by side.
Authors’ response
Done. Additionally, the networks have been plotted in the same layout, in response to
reviewer 1’s suggestion (see Figure 1).
Reviewer 2
Page 22 – line 399 – I’m not sure I understand this point. Why does this demonstrate
less stringent behavioral selection for detection dogs compared to patrol dogs?
Maybe giving an example would help?
Authors’ response
We have clarified this point (lines 408-410).
Reviewer 2
Page 20 – line 369 – playfulness has been assessed in a wide variety of ways, not just
specifically being about tug-type games, it’s probably better to say playfulness is
sometimes assessed…
Authors’ response
We have changed this to ‘has been assayed…’ (line 373) to be more neutral about its
frequency in working dog assessments in general as opposed to police and military
dog assessments specifically.
Society Open
