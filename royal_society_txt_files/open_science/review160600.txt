Not Normal: the uncertainties of scientific measurements
David C. Bailey
Article citation details
R. Soc. open sci. 4: 160600.
http://dx.doi.org/10.1098/rsos.160600
Review timeline
Original submission: 18 August 2016 Note: Reports are unedited and appear as
1st revised submission: 6 October 2016 submitted by the referee. The review history
2nd revised submission: 30 November 2016 appears in chronological order.
Final acceptance: 30 November 2016
Review History
label_version_1
RSOS-160600.R0 (Original submission)
label_author_1
Review form: Reviewer 1 (Maurice Cox)
Is the manuscript scientifically sound in its present form?
No
Are the interpretations and conclusions justified by the results?
No
Is the language acceptable?
No
Is it clear how to access all supporting data?
Yes.
Do you have any ethical concerns with this paper?
No
Have you any concerns about statistical analyses in this paper?
Yes
© 2017 The Authors. Published by the Royal Society under the terms of the Creative Commons
Attribution License http://creativecommons.org/licenses/by/4.0/, which permits unrestricted use,
provided the original author and source are credited
2
Recommendation?
label_recommendation_1
Major revision is needed (please make suggestions in comments)
Comments to the Author(s)
label_comment_1
See attached file. (Appendix A)
label_author_2
Review form: Reviewer 2
Is the manuscript scientifically sound in its present form?
Yes
Are the interpretations and conclusions justified by the results?
Yes
Is the language acceptable?
Yes
Is it clear how to access all supporting data?
It is clear.
Do you have any ethical concerns with this paper?
No
Have you any concerns about statistical analyses in this paper?
I do not feel qualified to assess the statistics
Recommendation?
label_recommendation_2
Accept as is
Comments to the Author(s)
label_comment_2
Having read and re-read the manuscript I am unable to find fault with this it. The results are clear
and fairly presented. The writing is solid, for the most part, concise.
I have not checked the calculations in section (d) of the discussion and section (e) comes across a
bit speculative (or at least the connection is not made a concrete as this reviewer my like), but
these are minor concerns.
label_end_comment
Decision letter (RSOS-160600)
13-Sep-2016
Dear Professor Bailey,
The editors assigned to your paper ("Not Normal: the uncertainties of scientific measurements")
have now received comments from reviewers. We would like you to revise your paper in
accordance with the referee and Subject Editor suggestions which can be found below (not
including confidential reports to the Editor). Please note this decision does not guarantee
eventual acceptance.
Please submit a copy of your revised paper within three weeks (i.e. by the 06-Oct-2016). If we do
not hear from you within this time then it will be assumed that the paper has been withdrawn. In
3
exceptional circumstances, extensions may be possible if agreed with the Editorial Office in
advance.We do not allow multiple rounds of revision so we urge you to make every effort to
fully address all of the comments at this stage. If deemed necessary by the Editors, your
manuscript will be sent back to one or more of the original reviewers for assessment. If the
original reviewers are not available we may invite new reviewers.
To revise your manuscript, log into http://mc.manuscriptcentral.com/rsos and enter your
Author Centre, where you will find your manuscript title listed under "Manuscripts with
Decisions." Under "Actions," click on "Create a Revision." Your manuscript number has been
appended to denote a revision. Revise your manuscript and upload a new version through your
Author Centre.
When submitting your revised manuscript, you must respond to the comments made by the
referees and upload a file "Response to Referees" in "Section 6 - File Upload". Please use this to
document how you have responded to the comments, and the adjustments you have made. In
order to expedite the processing of the revised manuscript, please be as specific as possible in
your response.
In addition to addressing all of the reviewers' and editor's comments please also ensure that your
revised manuscript contains the following sections as appropriate before the reference list:
• Ethics statement (if applicable)
If your study uses humans or animals please include details of the ethical approval received,
including the name of the committee that granted approval. For human studies please also detail
whether informed consent was obtained. For field studies on animals please include details of all
permissions, licences and/or approvals granted to carry out the fieldwork.
• Data accessibility
It is a condition of publication that all supporting data are made available either as
supplementary information or preferably in a suitable permanent repository. The data
accessibility section should state where the article's supporting data can be accessed. This section
should also include details, where possible of where to access other relevant research materials
such as statistical tools, protocols, software etc can be accessed. If the data have been deposited in
an external repository this section should list the database, accession number and link to the DOI
for all data from the article that have been made publicly available. Data sets that have been
deposited in an external repository and have a DOI should also be appropriately cited in the
manuscript and included in the reference list.
If you wish to submit your supporting data or code to Dryad (http://datadryad.org/), or modify
your current submission to dryad, please use the following link:
http://datadryad.org/submit?journalID=RSOS&manu=RSOS-160600
• Competing interests
Please declare any financial or non-financial competing interests, or state that you have no
competing interests.
• Authors’ contributions
All submissions, other than those with a single author, must include an Authors’ Contributions
section which individually lists the specific contribution of each author. The list of Authors
should meet all of the following criteria; 1) substantial contributions to conception and design, or
acquisition of data, or analysis and interpretation of data; 2) drafting the article or revising it
critically for important intellectual content; and 3) final approval of the version to be published.
All contributors who do not meet all of these criteria should be included in the
acknowledgements.
4
We suggest the following format:
AB carried out the molecular lab work, participated in data analysis, carried out sequence
alignments, participated in the design of the study and drafted the manuscript; CD carried out
the statistical analyses; EF collected field data; GH conceived of the study, designed the study,
coordinated the study and helped draft the manuscript. All authors gave final approval for
publication.
• Acknowledgements
Please acknowledge anyone who contributed to the study but did not meet the authorship
criteria.
• Funding statement
Please list the source of funding for each author.
Once again, thank you for submitting your manuscript to Royal Society Open Science and I look
forward to receiving your revision. If you have any questions at all, please do not hesitate to get
in touch.
Yours sincerely,
Andrew Dunn
Senior Publishing Editor
Royal Society Open Science
on behalf of Mark Chaplain
Subject Editor, Royal Society Open Science
openscience@royalsociety.org
Comments to Author:
Reviewers' Comments to Author:
Reviewer: 1
Comments to the Author(s)
See attached file.
Reviewer: 2
Comments to the Author(s)
Having read and re-read the manuscript I am unable to find fault with this it. The results are clear
and fairly presented. The writing is solid, for the most part, concise.
I have not checked the calculations in section (d) of the discussion and section (e) comes across a
bit speculative (or at least the connection is not made a concrete as this reviewer my like), but
these are minor concerns.
Author's Response to Decision Letter for (RSOS-160600)
See Appendix B.
5
label_version_2
RSOS-160600.R1 (Revision)
label_author_3
Review form: Reviewer 1 (Maurice Cox)
Is the manuscript scientifically sound in its present form?
Yes
Are the interpretations and conclusions justified by the results?
Yes
Is the language acceptable?
Yes
Is it clear how to access all supporting data?
Yes.
Do you have any ethical concerns with this paper?
No
Have you any concerns about statistical analyses in this paper?
No
Recommendation?
label_recommendation_3
Accept with minor revision (please list in comments)
Comments to the Author(s)
label_comment_3
Please attend to the few additional comments over and above my original review. It will not be
necessary for me to see the ms again. (See Appendix C)
label_end_comment
Decision letter (RSOS-160600.R1)
23-Nov-2016
Dear Professor Bailey:
On behalf of the Editors, I am pleased to inform you that your Manuscript RSOS-160600.R1
entitled "Not Normal: the uncertainties of scientific measurements" has been accepted for
publication in Royal Society Open Science subject to minor revision in accordance with the
referee suggestions. Please find the referees' comments at the end of this email.
The reviewers and Subject Editor have recommended publication, but also suggest some minor
revisions to your manuscript. Therefore, I invite you to respond to the comments and revise your
manuscript.
• Ethics statement
If your study uses humans or animals please include details of the ethical approval received,
including the name of the committee that granted approval. For human studies please also detail
whether informed consent was obtained. For field studies on animals please include details of all
permissions, licences and/or approvals granted to carry out the fieldwork.
6
• Data accessibility
It is a condition of publication that all supporting data are made available either as
supplementary information or preferably in a suitable permanent repository. The data
accessibility section should state where the article's supporting data can be accessed. This section
should also include details, where possible of where to access other relevant research materials
such as statistical tools, protocols, software etc can be accessed. If the data has been deposited in
an external repository this section should list the database, accession number and link to the DOI
for all data from the article that has been made publicly available. Data sets that have been
deposited in an external repository and have a DOI should also be appropriately cited in the
manuscript and included in the reference list.
If you wish to submit your supporting data or code to Dryad (http://datadryad.org/), or modify
your current submission to dryad, please use the following link:
http://datadryad.org/submit?journalID=RSOS&manu=RSOS-160600.R1
• Competing interests
Please declare any financial or non-financial competing interests, or state that you have no
competing interests.
• Authors’ contributions
All submissions, other than those with a single author, must include an Authors’ Contributions
section which individually lists the specific contribution of each author. The list of Authors
should meet all of the following criteria; 1) substantial contributions to conception and design, or
acquisition of data, or analysis and interpretation of data; 2) drafting the article or revising it
critically for important intellectual content; and 3) final approval of the version to be published.
All contributors who do not meet all of these criteria should be included in the
acknowledgements.
We suggest the following format:
AB carried out the molecular lab work, participated in data analysis, carried out sequence
alignments, participated in the design of the study and drafted the manuscript; CD carried out
the statistical analyses; EF collected field data; GH conceived of the study, designed the study,
coordinated the study and helped draft the manuscript. All authors gave final approval for
publication.
• Acknowledgements
Please acknowledge anyone who contributed to the study but did not meet the authorship
criteria.
• Funding statement
Please list the source of funding for each author.
Please note that we cannot publish your manuscript without these end statements included. We
have included a screenshot example of the end statements for reference. If you feel that a given
heading is not relevant to your paper, please nevertheless include the heading and explicitly state
that it is not relevant to your work.
Because the schedule for publication is very tight, it is a condition of publication that you submit
the revised version of your manuscript within 7 days (i.e. by the 02-Dec-2016). If you do not think
you will be able to meet this date please let me know immediately.
To revise your manuscript, log into https://mc.manuscriptcentral.com/rsos and enter your
Author Centre, where you will find your manuscript title listed under "Manuscripts with
Decisions". Under "Actions," click on "Create a Revision." You will be unable to make your
7
revisions on the originally submitted version of the manuscript. Instead, revise your manuscript
and upload a new version through your Author Centre.
When submitting your revised manuscript, you will be able to respond to the comments made by
the referees and upload a file "Response to Referees" in "Section 6 - File Upload". You can use this
to document any changes you make to the original manuscript. In order to expedite the
processing of the revised manuscript, please be as specific as possible in your response to the
referees.
When uploading your revised files please make sure that you have:
1) A text file of the manuscript (tex, txt, rtf, docx or doc), references, tables (including captions)
and figure captions. Do not upload a PDF as your "Main Document".
2) A separate electronic file of each figure (EPS or print-quality PDF preferred (either format
should be produced directly from original creation package), or original software format)
3) Included a 100 word media summary of your paper when requested at submission. Please
ensure you have entered correct contact details (email, institution and telephone) in your user
account
4) Included the raw data to support the claims made in your paper. You can either include your
data as electronic supplementary material or upload to a repository and include the relevant doi
within your manuscript
5) All supplementary materials accompanying an accepted article will be treated as in their final
form. Note that the Royal Society will neither edit nor typeset supplementary material and it will
be hosted as provided. Please ensure that the supplementary material includes the paper details
where possible (authors, article title, journal name).
Supplementary files will be published alongside the paper on the journal website and posted on
the online figshare repository (https://figshare.com). The heading and legend provided for each
supplementary file during the submission process will be used to create the figshare page, so
please ensure these are accurate and informative so that your files can be found in searches. Files
on figshare will be made available approximately one week before the accompanying article so
that the supplementary material can be attributed a unique DOI.
Once again, thank you for submitting your manuscript to Royal Society Open Science and I look
forward to receiving your revision. If you have any questions at all, please do not hesitate to get
in touch.
Best wishes
Alice Power
Editorial Coordinator
Royal Society Open Science
openscience@royalsociety.org
on behalf of Mark Chaplain
Subject Editor, Royal Society Open Science
openscience@royalsociety.org
Comments to Author:
Reviewer: 1
Comments to the Author(s)
Please attend to the few additional comments over and above my original review. It will not be
necessary for me to see the ms again.
8
Author's Response to Decision Letter for (RSOS-160600.R1)
See Appendix D.
label_end_comment
Decision letter (RSOS-160600.R2)
30-Nov-2016
Dear Professor Bailey,
I am pleased to inform you that your manuscript entitled "Not Normal: the uncertainties of
scientific measurements" is now accepted for publication in Royal Society Open Science.
You can expect to receive a proof of your article in the near future. Please contact the editorial
office (openscience_proofs@royalsociety.org and openscience@royalsociety.org) to let us know if
you are likely to be away from e-mail contact. Due to rapid publication and an extremely tight
schedule, if comments are not received, your paper may experience a delay in publication.
Royal Society Open Science operates under a continuous publication model
(http://bit.ly/cpFAQ). Your article will be published straight into the next open issue and this
will be the final version of the paper. As such, it can be cited immediately by other researchers.
As the issue version of your paper will be the only version to be published I would advise you to
check your proofs thoroughly as changes cannot be made once the paper is published.
In order to raise the profile of your paper once it is published, we can send through a PDF of your
paper to selected colleagues. If you wish to take advantage of this, please reply to this email with
the name and email addresses of up to 10 people who you feel would wish to read your article.
On behalf of the Editors of Royal Society Open Science, we look forward to your continued
contributions to the Journal.
Best wishes,
Alice Power
Editorial Coordinator
Royal Society Open Science
openscience@royalsociety.org
Not Normal: the uncertainties of scientific measurements
David C. Bailey
This paper is concerned with establishing the non-normality of scientific observations. It is
an interesting paper to read, and there is certainly a case for such a paper. I have comments
on the form of presentation, which in my opinion should be attended to before publication.
Major comments
The informal style of presentation is easy for the reader, but unacceptable to the statistician
and the users of the GUM and the VIM. Adhering to the use of internationally accepted
definitions and concepts as in the GUM and the VIM are likely to make this paper much
more acceptable and understandable.
I do not doubt that the distributions of concern are heavy-tailed, but the manner in which
they have been obtained is questionable.
(page 1, line 23 et seq) “Uncertainty-normalized differences between multiple
measurements of the same quantity follow heavy-tailed Student-t distributions that are
often almost Cauchy”. It can never be stated that data follows a particular distribution, only
that there is no reason to doubt it follows some distribution. Similar statements occur
elsewhere. Perhaps here: “… much better follow a heavy-tailed Student-t distributions than
a normal distribution …”
(4, equation 2.1) There is extreme redundancy in this measure, with repercussions as
reported. Discuss in more detail (currently only one sentence) the use of a reference value,
as indicated [16], ideally independent of the data, taking $(x_i - x_{\mathrm ref})/[u_i^2
\pm u^2(x_{\rm ref})]^{1/2}$ as appropriate. The denominator in (2.1) assumes
independence, which is incorrect. As a consequence of the lack of independence,
conclusions cannot be drawn directly from the histograms. Is the statement (4, 35) ‘… if a
quantity has 10 measurements, there are 45 possible pairs, and each entry has a weight of
10/45 …’ a suggested way of overcoming this lack? If so, the statement should be
supported.
(4, 13 and elsewhere) It is incorrect to refer to $x \pm u$ as an uncertainty. It is an interval
of values.
(4, 16) It would be much better in accordance with common practice (GUM, VIM, many
publications) to refer to $u_{\mathrm S}$ as a standard uncertainty.
(4, 17) should read ‘… with k = 1 or k = 2 standard uncertainties …’.
used in the paired comparisons.’ should be explained more explicitly.
(4, 45) Please explain more explicitly: ‘Random selection of individual measurements was
not used since it generates unrealistic z=0 values due to the same measurement sometimes
being selected twice, and also because some quantities might fail the study’s selection
criterion of having at least 5 good measurements.’
(figure 1) Displacing the four data sets seems to make a nonsense of the vertical scale.
Suggest four separate plots are presented.
(5, 39) Please explain the implications of ‘This metric is not a true chi-squared since the bins
are not independent because measurements contribute to multiple bins as part of different
permutation pairs.’
(5, 45) Please explain why ‘This correction is, however, negligible for the data reported
here.‘ is the case.
(5.47) Please explain ‘Real experimental bounds may be stronger, but a careful
measurement-by-measurement estimate of the allowed range for all quantities was beyond
the scope of this study.’ What are ‘stronger’ bounds?
(7, 22-25) I do not understand the following at all: ‘This implies that the uncertainties u in
Equation 2.1 might be better combined linearly as is appropriate for Cauchy uncertainties,
not in quadrature as for Normal uncertainties, but analysing the data with linear
uncertainties simply reduces sigma by ~ 21/2 and has negligible effect on $\nu$.’ Standard
uncertainties only combine additively when the quantities concerned are fully correlated.
Please also defend the reduction and the effect on $\nu$.
Table 2. The contents of this table are insufficiently explained in the text.
(7, 52) The sentence ‘This method is not preferred since the weighting already makes
implicit assumptions about the nature of the distribution.’ Is cryptic and could benefit from
explanation.
(16, 53 and elsewhere) Uncertainty is a measure of dispersion. Unlike a random variable, it
does not have a distribution.
Other comments
A very useful reference that considers ‘unexplained uncertainty’ is
Consider making reference to it.
Many terms and concepts are used without definition, which is dangerous, particularly in a
paper such as this. I would recommend using definitions that are largely accepted by the
scientific community such as in the GUM or the VIM. Instances:
1. Outlier (1, 22)
2. power-law distribution (1, 35)
3. Massively parallel data searches (2, 7)
4. Effect size (2, 9)
5. Uncertainty tails (2, 24)
6. Accuracy of a measurement (2, 45)
7. Unknown unknowns (2, 51)
8. High-statistics subset (3, 20)
9. Heterogeneity inconsistency index (3, 52)
10. Normal in the Gaussian limit (4, 6)
11. ‘Uncertainty evaluation’ (e.g., 4, 11) or ‘uncertainty estimation’ (e.g., 1, 17) or
‘uncertainty calculation’ (4, 38). Consider using only one term. The GUM and the
VIM prefer ‘evaluation’
12. Nominal chi-squared (5, 39)
13. Monte Carlo deconvolution (8, 33)
14. Precision (9, 30, for example) has an accepted definition in the metrology literature
(GUM, VIM, etc.). I suggest this definition is adhered to throughout the paper. It
seems to be used in various ways, which will cause considerable confusion.
15. Very non-diagonal covariance matrices (12, 49)
16. Real uncertainty (16, 49)
The abstract refers to ‘s’. Which s? Further, what is calibration of uncertainty? This usage
seems very different from instrument calibration.
‘Systematic uncertainties’ (2, 36) is a misnomer. Uncertainties are neither systematic nor
random. The errors are such [GUM, VIM]. Departure from convention is very likely to cause
confusion.
statistical or systematic, but the errors. Type A and Type B are methods of evaluation of
uncertainty, and not ‘uncertainty labels’.
The distinction between Class 2 and Class 3 systematics is unclear (2, 43).
Please explain more explicitly (3, 7-11): “Observed inconsistencies are either fixed or
included in the reported uncertainty. Unknown systematics and mistakes are constrained by
such checks, with bigger unknown systematics and mistakes more likely, but not certain, to
be noticed. The power of consistency checks is, however, limited by the impossibility of
making completely independent measurements.
PTB is referred to in full in (13, 7), but earlier by ‘PTB’. Rectify.
Editorial
The RS editorial team should comment on usage such as
1. isn’t
2. labs
3. interlab
4. split infinitives [several, e.g., “to always agree” (1, 48)]
5. ending sentences with a proposition, e.g., (15, 34)
6. starting sentences with ‘This …’ when it is not clear to what ‘this’ refers, e.g., (15, 47)
Response to Referees
Manuscript: RSOS-160600
Not Normal: Not Normal: the uncertainties of scientific measurements
by
David Bailey
All the Reviewers’ comments are listed below along with notes on what has been revised in
response. The brief response to Reviewer 2 is at the end.
Reviewer 1 Comments
This paper is concerned with establishing the non-normality of scientific observations. It is an
interesting paper to read, and there is certainly a case for such a paper. I have comments on
the form of presentation, which in my opinion should be attended to before publication.
• I would like to thank the Reviewer for the careful reading, fair criticism, and
extremely helpful comments.
Major Comments
The informal style of presentation is easy for the reader, but unacceptable to the statistician
and the users of the GUM and the VIM. Adhering to the use of internationally accepted
definitions and concepts as in the GUM and the VIM are likely to make this paper much more
acceptable and understandable.
I do not doubt that the distributions of concern are heavy-tailed, but the manner in which they
have been obtained is questionable.
(page 1, line 23 et seq) “Uncertainty-normalized differences between multiple measurements of
the same quantity follow heavy-tailed Student-t distributions that are often almost Cauchy”.
It can never be stated that data follows a particular distribution, only that there is no reason
to doubt it follows some distribution. Similar statements occur elsewhere. Perhaps here: “...
much better follow a heavy-tailed Student-t distributions than a normal distribution ...”
• Good point: changed “follows” to “is consistent with” in the Abstract, and made
similar changes to three sentences in sections 4.4, 4.5, and in the Conclusions.
(4, equation 2.1) There is extreme redundancy in this measure, with repercussions as reported.
Discuss in more detail (currently only one sentence) the use of a reference value, as indicated
[16], ideally independent of the data, taking (xi - xref )/[u2i ± u2 (xref )]1/2 as appropriate. The
denominator in (2.1) assumes independence, which is incorrect. As a consequence of the lack
of independence, conclusions cannot be drawn directly from the histograms. Is the statement
(4, 35) ‘... if a quantity has 10 measurements, there are 45 possible pairs, and each entry has
a weight of 10/45 ...’ a suggested way of overcoming this lack? If so, the statement should
be supported.
• (Sec. 2.4 ) I may not completely understand all the Reviewer’s concerns, but
discussion of these issues has been significantly expanded later (Sec. 3.2, 3.3 ), and
referenced at this point.
(4, 13 and elsewhere) It is incorrect to refer to x ± u as an uncertainty. It is an interval of
values.
• “Uncertainties” replaced here by “Measurements with uncertainties”, and “uncer-
tainty intervals” in the following sentence.
(4, 16) It would be much better in accordance with common practice (GUM, VIM, many
publications) to refer to uS as a standard uncertainty.
(4, 17) should read ‘... with k = 1 or k = 2 standard uncertainties ...’.
• (Sec. 2.3 ) Done, but it has also been clarified that not all fields report “standard
uncertainties”, although their definitions are equivalent for Normal uncertainties.
(4, 21) ‘If there were asymmetric plus and minus uncertainties, the relevant side was always
used in the paired comparisons.’ should be explained more explicitly.
• (Sec. 2.4 ) Added a sentence to clarify by example.
(4, 45) Please explain more explicitly: ‘Random selection of individual measurements was not
used since it generates unrealistic z=0 values due to the same measurement sometimes being
selected twice, and also because some quantities might fail the study’s selection criterion of
having at least 5 good measurements.’
• (Sec. 2.4 ) A more detailed explanation is now given.
(figure 1) Displacing the four data sets seems to make a nonsense of the vertical scale. Suggest
four separate plots are presented.
• Done.
(5, 39) Please explain the implications of ‘This metric is not a true chi-squared since the bins
are not independent because measurements contribute to multiple bins as part of different
permutation pairs.’
• This has been moved to a more relevant location (Sec. 3.1 ) in the discussion of
Table 2, and additional discussion of the nominal <U+03C7>2 added there.
(5, 45) Please explain why ‘This correction is, however, negligible for the data reported here.’
is the case.
(5.47) Please explain ‘Real experimental bounds may be stronger, but a careful measurement-
by-measurement estimate of the allowed range for all quantities was beyond the scope of this
study.’ What are ‘stronger’ bounds?
• (Sec. 2.5 ) Both points addressed by expanding this paragraph with more expla-
nation.
(7, 22-25) I do not understand the following at all: ‘This implies that the uncertainties u in
Equation 2.1 might be better combined linearly as is appropriate for Cauchy uncertainties,
not in quadrature as for Normal uncertainties, but analysing the data with linear uncertainties
simply reduces sigma by ~ 21/2 and has negligible effect on <U+03BD>.’ Standard uncertainties only
combine additively when the quantities concerned are fully correlated. Please also defend the
reduction and the effect on <U+03BD>.
• (Sec. 3.2 ) A more detailed explanation is now given.
Table 2. The contents of this table are insufficiently explained in the text.
• All columns are now specifically referenced in the text atvrelevant locations, and
the explanations expanded if lacking, e.g. sx , sx , <U+03C7>2 /dof, 2.
(7, 52) The sentence “This method is not preferred since the weighting already makes im-
plicit assumptions about the nature of the distribution.” Is cryptic and could benefit from
explanation.
• (Sec. 3.2 ) A more detailed explanation is now given.
(16, 53 and elsewhere) Uncertainty is a measure of dispersion. Unlike a random variable, it
does not have a distribution.
• All references to “uncertainty distribution(s)” have been replaced by alternative
wording.
Other Comments
A very useful reference that considers ‘unexplained uncertainty’ is ‘Dark Uncertainty’ by
Thompson and Ellison. Consider making reference to it.
• (Sec. 4.1 ) Thanks for letting me know about this paper. A reference to it and
discussion have been added.
Many terms and concepts are used without definition, which is dangerous, particularly in a
paper such as this. I would recommend using definitions that are largely accepted by the
scientific community such as in the GUM or the VIM. Instances:
1. Outlier (1, 22)
• There is not room to define this in the Abstract, but it is now briefly explained in
the Introduction.
2. power-law distribution (1, 35)
• This has been better specified in the text in Sections 2.5 and 4.5.
3. Massively parallel data searches (2, 7)
• Reworded so term is unnecessary.
4. Effect size (2, 9)[black]
• Replaced with more generally understandable wording.
5. Uncertainty tails (2, 24)
• Reworded so term is unnecessary.
6. Accuracy of a measurement (2, 45)
• Uses obviously inconsistent with GUM definition have been removed or replaced.
In some cases I have kept a less precise usage of when I believe its meaning is clear
and alternate wording would be over-convoluted.
7. Unknown unknowns (2, 51)
• More explanation and example given. (Sec. 1.1 )
8. High-statistics subset (3, 20)
• Reworded so term is unnecessary.
9. Heterogeneity inconsistency index (3, 52)
• Now mathematically defined. (Sec. 2.2 )
10. Normal in the Gaussian limit (4, 6)
• Reworded with additional explanation. (Sec. 2.2 )
11. ‘Uncertainty evaluation’ (e.g., 4, 11) or ‘uncertainty estimation’ (e.g., 1, 17) or ‘uncer-
tainty calculation’ (4, 38). Consider using only one term. The GUM and the VIM prefer
‘evaluation’
• All ‘uncertainty calculation’ (and variants) and many ‘uncertainty estimation’ uses
have been replaced.
12. Nominal chi-squared (5, 39)
• Now defined (Eq. 2.3).
13. Monte Carlo deconvolution (8, 33)
• Now explained in more detail. (Sec. 3.1 )
14. Precision (9, 30, for example) has an accepted definition in the metrology literature
(GUM, VIM, etc.). I suggest this definition is adhered to throughout the paper. It seems to
be used in various ways, which will cause considerable confusion.
• “precision” has been replaced by “relative uncertainty” in this section (Sec. 3.5 ).
The labels in Fig. 3 and 4 have also been changed, and Fig. 4 incidentally rebinned
to reduce clutter. Other colloquial usages of “precision” have been replaced.
15. Very non-diagonal covariance matrices (12, 49)
• Replaced by easier-to-understand wording. (Sec. 4.2 )
16. Real uncertainty (16, 49)
• ‘Real’ removed.
The abstract refers to ‘s’. Which s? Further, what is calibration of uncertainty? This usage
seems very different from instrument calibration.
• Abstract now uses “well evaluated” instead of “well calibrated”. The brief mentions
in the abstract of “5s disagreements” and “5s discovery criterion”are now better
supported in the manuscript body. The former by an improved explanation of
Table 2, and the latter by explicit definition in the Introduction supplementing the
already extant mention and 4 references on the criterion’s history.
‘Systematic uncertainties’ (2, 36) is a misnomer. Uncertainties are neither systematic nor
random. The errors are such [GUM, VIM]. Departure from convention is very likely to cause
confusion.
• This usage has been removed from the text. (Many particle and nuclear physicists
would disagree that it is a misnomer, e.g. see the title of the article by Sinervo or
its use in the current Review of Particle Properties and the Table of Isotopes, but
that is a discussion for another time.)
Sentences (2, 37-43), I am afraid, compound the problem. It is not the uncertainties that
are statistical or systematic, but the errors. Type A and Type B are methods of evaluation of
uncertainty, and not “uncertainty labels”.
• Reworded to clarify that Type A and B refer to methods of evaluation. (Sec. 1.1 )
The distinction between Class 2 and Class 3 systematics is unclear (2, 43).
• Explanation expanded. (Sec. 1.1 )
Please explain more explicitly (3, 7-11): “Observed inconsistencies are either fixed or included
in the reported uncertainty. Unknown systematics and mistakes are constrained by such checks,
with bigger unknown systematics and mistakes more likely, but not certain, to be noticed. The
power of consistency checks is, however, limited by the impossibility of making completely
independent measurements.”
• Explanation expanded. (Sec. 1.1 )
PTB is referred to in full in (13, 7), but earlier by “PTB”. Rectify.
• Now refer to all the national labs by their full names and acronyms (which are
often more familiar) when first referenced in Sec. 3.4.
Editorial
The RS editorial team should comment on usage such as
isn’t
• Changed to “is not”.
Labs
• Replaced 8 “labs” with either “laboratories” or “institutes”, but kept 5 instances
to avoid over-repetitive use of “laboratories”, especially in the same sentence.
interlab
• “Interlab” kept as name of data set, but elsewhere replaced with “interlaboratory”.
split infinitives [several, e.g., ‘to always agree’ (1, 48)]
• I usually avoid split infinitives, but agree with Strunk & White in their classic Ele-
ments of Style that “Some infinitives seem to improve on being split”. I eliminated
one of the three cases I found, but kept the other two (“to always agree” and “to
never use”) as providing a desired emphasis on the adverb.
ending sentences with a proposition, e.g., (15, 34)
• Now reworded as a partial quote to make it clear that this usage comes from the
Royal Society Transactions paper cited here (Sec. 4.6 ).
starting sentences with ‘This ...’ when it is not clear to what ‘this’ refers, e.g., (15, 47)
• In this instance and several others, a noun or phase has been added for clarity so
“this” is now a demonstrative adjective instead of an ambiguous pronoun.
Reviewer 2 Comments
Having read and re-read the manuscript I am unable to find fault with this it. The results are
clear and fairly presented. The writing is solid, for the most part, concise.
• Thank you.
I have not checked the calculations in section (d) of the discussion and section (e) comes
across a bit speculative (or at least the connection is not made a concrete as this reviewer my
like), but these are minor concerns.
• Any calculation mistakes are, of course, my responsibility. To strengthen the
connection a bit, a few more details about highly optimized tolerance have been
added (Sec. 4.5 ), but the sparseness of relevant theoretical work makes it hard to
be very concrete.
Not Normal: the uncertainties of scientific measurements (revised version)
David C. Bailey
The author has attended to the great bulk of my comments on the first version of his paper.
He should attend to the outstanding points below. It will not be necessary for me to see the
ms again.
(page 11, line 26) Explain “analysis forest plot”.
(12, 17-19) I did not understand “If there were …” to “… =2.”. Please give some
explanation.
(16, 30) Explain how the factor 1/v2 is obtained.
(21, 38) Do not use ‘random uncertainties’! This point was made in the review of the first
version.
(21, 56) “Almost-Cauchy uncertainties” does not make sense. Surely this is a feature of a
distribution rather than an uncertainty.
(22, 19), (23, 28), (24, 14) Do not use “Normal uncertainties”. Again this is a feature of a
distribution. Also (26, 49) “uncertainties are often almost-Cauchy”; also see (21, 56).
(23, 45) “… true uncertainties t that have an unknown distribution …” is an abomination.
Change!
(23, 49) “2t2” should be parenthesized.
(24, 13), (24, 15) “uncertainties“ should be “standard uncertainties“.
(25, 50) “s can be made arbitrarily small by taking enough data” can only be true in the
absence of systematic errors. Please correct.
Response to Referee
Revised Manuscript: RSOS-160600.R1
Not Normal: Not Normal: the uncertainties of scientific measurements
by
David Bailey
The referee has again made many helpful and valid comments. These are listed below along
with the changes made to the manuscript in response. All issues raised have been addressed.
(page 11, line 26) Explain “analysis forest plot”.
• Use of ”forest plot” is unnecessary here, since the point is that multiple measurements
of the same effect were analysed, not that a forest plot was used to display the analysis,
so “analysis forest plot” has simply been replaced by “analysis”.
(12, 17-19) I did not understand If there were ... to ... =2.. Please give some explanation.
• Expanded explanation into its own paragraph. Added a reference for readers interested
in issues associated with combining asymmetric uncertainties. These lines now read:
“Uncertainties based on confidence intervals may not be symmetric about the reported value,
which is the case for about 13% of Particle, 6% of Medical, 0.3% of Nuclear, and 0.06% of
Interlab measurements. Following common (albeit imperfect) practice [42], if the reported
plus and minus uncertainties were asymmetric, zij was calculated from Eq. 2.1 using the
uncertainty for the side towards the other member of the comparison pair. vFor example,
if x1 = 80±32 , x2 = 5 15
v 100±4 , and x3 = 126±12 , then z12 = (100 - 80)/ 3 + 4 and
2 2
2
z23 = (126 - 100)/ 5 + 12 .” 2
v
(16, 30) Explain how the factor 1/ 2 is obtained.
v
• Have made explicit how the 1/ 2 is obtained. Relevant lines now read:
v
“... but even perfect anti-correlation could only decrease z values by at most a factor of 1/ 2
compared to the v uncorrelated case. (i.e. Changing cov(xi , xj ) from 0 to -ui uj in Eq. 3.1
reduces zij by 2 if ui = uj , and less if ui 6= uj .)”
(21, 38) Do not use random uncertainties! This point was made in the review of the first
version.
• This occurrence of ‘random uncertainties’ has been replaced by ‘random errors’. My
apologies for being slow to appreciate how confusing use of “random/Normal/Gaussian
uncertainties” as convenient (but formally incorrect) short-hand for the uncertainties
that parameterize a random/Normal/Gaussian dispersion of errors may be outside of
particle physics.
(21, 56) “Almost-Cauchy uncertainties” does not make sense. Surely this is a feature of a
distribution rather than an uncertainty.
• The phrase containing “Almost-Cauchy uncertainties” has been deleted as unnecessary.
(22, 19), (23, 28), (24, 14) Do not use “Normal uncertainties”. Again this is a feature of a
distribution. Also (26, 49) uncertainties are often almost-Cauchy; also see (21, 56).
• These occurrences of “Normal uncertainties” or “almost-Cauchy uncertainties” (and
several more the referee did not comment on) have been replaced by other wording.
(23, 45) ... true uncertainties t that have an unknown distribution ... is an abomination.
Change!
• This badly worded sentence has been exorcised and replaced by:
“One way is to assume that the measurement values are normally distributed with standard
deviation t that is unknown but which has a probability distribution f(t).”
(23, 49) 2t2 should be parenthesized.
• Done
(24, 13), (24, 15) “uncertainties” should be “standard uncertainties”.
• The first and last of the three occurrences of “uncertainties” on these lines have been
replaced by ”standard uncertainties”, and the middle one by ”reported uncertainties”.
(25, 50) “s can be made arbitrarily small by taking enough data” can only be true in the
absence of systematic errors. Please correct.
• Good point. “s” has been replaced by “statistical errors”.
Society Open
