Does truth matter to voters? The effects of correcting
political misinformation in an Australian sample
Michael J. Aird, Ullrich K. H. Ecker, Briony Swire, Adam J. Berinsky and Stephan
Lewandowsky
Article citation details
R. Soc. open sci. 5: 180593.
http://dx.doi.org/10.1098/rsos.180593
Review timeline
Original submission: 18 April 2018 Note: Reports are unedited and appear as
Revised submission: 11 October 2018 submitted by the referee. The review history
Final acceptance: 9 November 2018 appears in chronological order.
Review History
label_version_1
RSOS-180593.R0 (Original submission)
label_author_1
Review form: Reviewer 1 (Gordon Pennycook)
Is the manuscript scientifically sound in its present form?
Yes
Are the interpretations and conclusions justified by the results?
Yes
Is the language acceptable?
Yes
Is it clear how to access all supporting data?
Yes
Do you have any ethical concerns with this paper?
No
Reports © 2018 The Reviewers; Decision Letters © 2018 The Reviewers and Editors;
Responses © 2018 The Reviewers, Editors and Authors. Published by the Royal Society under the
terms of the Creative Commons Attribution License http://creativecommons.org/licenses/by/4.0/,
which permits unrestricted use, provided the original author and source are credited
2
Have you any concerns about statistical analyses in this paper?
Yes
Recommendation?
label_recommendation_1
Accept with minor revision (please list in comments)
Comments to the Author(s)
label_comment_1
The authors investigate the effect of fact-checks on both beliefs (about the myths/facts presented)
and support for politicians who have been fact-checked. This is a well-researched and obviously
very timely manuscript that I think should be published. However, I do have two concerns that I
think should be addressed. The primary concern pertains to the results and the secondary
concern pertains to the framing of the manuscript.
Results
The most important issue is that the full design is underpowered and the results section is (in my
view, needlessly) hard to follow. There are 12 between subject conditions and only 370
participants (~30 participants per cell). Moreover, even this low level of power is maintained
because of what I take to be an inappropriate split of the sample on political ideology. That is, I
don’t think it is appropriate to split the groups based on sample characteristics (into 3 equally
numerous groups). This is because if the sample skews left (as it does), there are people in the
neutral category that are left-wing and people in the right-wing category that are neutral.
Left/Neutral/Right should be determined based on where they fall on the political spectrum,
even if it means there will be fewer participants in some of the cells. This probably played a large
role in why the left-wing participants were more extreme (as per the analyses on page 17).
Moreover, the neutral group really isn’t relevant here (apart from acting as a control, although it
is hard to interpret data from such people since they could be genuine moderates or just
apathetic). So, one possibility to gain power is to make as the primary test the data recoded so
that the politician and ideology are either congruent (left-wing participant, Shorten condition/
right-wing participant, Turnbull condition) or incongruent (right-wing participant, Shorten
condition/ left-wing participant, Turnbull condition), as done on page 17 (the full ANOVA can
be reported in a supplement). For clarity, this will result in the following design: 2 (fact-check:
pre, post) x 2 (myth: 4:1, 4:4) x 2 (congruency: congruent, incongruent). This means that neutral
participants are dropped and that ideological asymmetry can’t be investigated in the full design,
but it will increase the sample to (I’m guessing) around 50 per cell. I should also note that this
analysis addresses the central issue, as elucidated in the “summary of main results” section (p.
21). It also means that a single central test can be used to test the key motivated reasoning
hypothesis: i.e., that fact-check will interact with congruency and that this interaction will be
sourced by a smaller effect in the incongruent case. The authors are free (in my view) to report
whatever additional tests they like, but I think this really should be the central analysis reported
at the beginning of the results section (for all DVs).
Regarding ideological asymmetry, it would make sense to simply correlate the political ideology
measure with a fact-check difference score (post minus pre) separately for the Shorten and
Turnbull conditions. That is, I don’t think the myth-ratio manipulation is important for the
asymmetry question. The correlation will tell you if conservatives are less responsive to the fact-
check than liberals and whether this depends on ideological congruency (Shorten v. Turnbull).
The interaction between ideology and Shorten/Turnbull condition can be tested in a regression as
well (averaging across myth-ratio condition, interacting Shorten/Turnbull condition with
conservatism). As above, this analysis retains the most power while addressing the central
question.
3
Obviously, these are just suggestions. But, regardless, the full design is underpowered and it is
not appropriate to categorize individuals as left-wing/neutral/right-wing based on sample
characteristics instead of self-identification.
Another note on the results is that the inferences are driven by interpretation of the patterns that
emerge from significant interactions, but follow-up tests weren’t apparently run (with some
exceptions). For example (p.16): “There were two further unexpected interactions: a significant
interaction of fact-check, myth:fact ratio, and political orientation, which was further qualified by
a significant fourway interaction. This result indicated that myth belief reduced more among
neutral participants in the 4:1 than the 4:4 condition, especially for Turnbull myths, while myth
belief reduced similarly regardless of the myth:fact ratio among left-wing and right-wing
participants.” It is unclear if all of the individual effects that are mentioned are significant on their
own. The significant interaction warrants the follow-ups, but it doesn’t mean that every
difference that (once added up to produce a significant interaction) is itself significant. [Note that
the authors did do this for perhaps one of the most central analyses, which is somewhat buried in
the results: last paragraph of page 19 and first paragraph of page 20]. I think my suggested
revisions to the results might simplify things a bit.
Introduction/Framing
My first comment is simple: “Attitude” is used throughout but not fully defined.
I am also a bit unclear on how different is the attitude-protection hypothesis is from the identity-
protective cognition hypothesis (as per Kahan)? One possibility, which the authors may or may
not agree with, is that the former is an important specification of the latter. Kahan’s account says
that people will engage in motivated reasoning to protect their political (or otherwise) identities.
However, this can be taken broadly to imply that any information that might conflict with one’s
identity (such as Trump’s inaccurate statements in Swire et al., 2017) will lead to motivated
reasoning. Here, the specification is that “identity” might be too broad and that motivated
reasoning occurs as a result of conflict with a specific attitude (although, as mentioned, this term
needs to be defined). At any rate, the connection between these accounts should be addressed in
the manuscript. (Although, I should add, the attitude-protection hypothesis isn’t really tested
here.)
I always sign my reviews,
Gordon Pennycook
label_end_comment
Decision letter (RSOS-180593.R0)
13-Sep-2018
Dear Dr Ecker,
The editors assigned to your paper ("Does truth matter to voters? The effects of correcting
political misinformation in an Australian sample") have now received comments from reviewers.
We would like you to revise your paper in accordance with the referee and Associate Editor
suggestions which can be found below (not including confidential reports to the Editor). Please
note this decision does not guarantee eventual acceptance.
4
Please submit a copy of your revised paper before 06-Oct-2018. Please note that the revision
deadline will expire at 00.00am on this date. If we do not hear from you within this time then it
will be assumed that the paper has been withdrawn. In exceptional circumstances, extensions
may be possible if agreed with the Editorial Office in advance. We do not allow multiple rounds
of revision so we urge you to make every effort to fully address all of the comments at this stage.
If deemed necessary by the Editors, your manuscript will be sent back to one or more of the
original reviewers for assessment. If the original reviewers are not available, we may invite new
reviewers.
To revise your manuscript, log into http://mc.manuscriptcentral.com/rsos and enter your
Author Centre, where you will find your manuscript title listed under "Manuscripts with
Decisions." Under "Actions," click on "Create a Revision." Your manuscript number has been
appended to denote a revision. Revise your manuscript and upload a new version through your
Author Centre.
When submitting your revised manuscript, you must respond to the comments made by the
referees and upload a file "Response to Referees" in "Section 6 - File Upload". Please use this to
document how you have responded to the comments, and the adjustments you have made. In
order to expedite the processing of the revised manuscript, please be as specific as possible in
your response.
In addition to addressing all of the reviewers' and editor's comments please also ensure that your
revised manuscript contains the following sections as appropriate before the reference list:
• Ethics statement (if applicable)
If your study uses humans or animals please include details of the ethical approval received,
including the name of the committee that granted approval. For human studies please also detail
whether informed consent was obtained. For field studies on animals please include details of all
permissions, licences and/or approvals granted to carry out the fieldwork.
• Data accessibility
It is a condition of publication that all supporting data are made available either as
supplementary information or preferably in a suitable permanent repository. The data
accessibility section should state where the article's supporting data can be accessed. This section
should also include details, where possible of where to access other relevant research materials
such as statistical tools, protocols, software etc can be accessed. If the data have been deposited in
an external repository this section should list the database, accession number and link to the DOI
for all data from the article that have been made publicly available. Data sets that have been
deposited in an external repository and have a DOI should also be appropriately cited in the
manuscript and included in the reference list.
If you wish to submit your supporting data or code to Dryad (http://datadryad.org/), or modify
your current submission to dryad, please use the following link:
http://datadryad.org/submit?journalID=RSOS&manu=RSOS-180593
• Competing interests
Please declare any financial or non-financial competing interests, or state that you have no
competing interests.
• Authors’ contributions
All submissions, other than those with a single author, must include an Authors’ Contributions
section which individually lists the specific contribution of each author. The list of Authors
5
should meet all of the following criteria; 1) substantial contributions to conception and design, or
acquisition of data, or analysis and interpretation of data; 2) drafting the article or revising it
critically for important intellectual content; and 3) final approval of the version to be published.
All contributors who do not meet all of these criteria should be included in the
acknowledgements.
We suggest the following format:
AB carried out the molecular lab work, participated in data analysis, carried out sequence
alignments, participated in the design of the study and drafted the manuscript; CD carried out
the statistical analyses; EF collected field data; GH conceived of the study, designed the study,
coordinated the study and helped draft the manuscript. All authors gave final approval for
publication.
• Acknowledgements
Please acknowledge anyone who contributed to the study but did not meet the authorship
criteria.
• Funding statement
Please list the source of funding for each author.
Please note that Royal Society Open Science charge article processing charges for all new
submissions that are accepted for publication. Charges will also apply to papers transferred to
Royal Society Open Science from other Royal Society Publishing journals, as well as papers
submitted as part of our collaboration with the Royal Society of Chemistry
(http://rsos.royalsocietypublishing.org/chemistry). If your manuscript is newly submitted and
subsequently accepted for publication, you will be asked to pay the article processing charge,
unless you request a waiver and this is approved by Royal Society Publishing. You can find out
more about the charges at http://rsos.royalsocietypublishing.org/page/charges. Should you
have any queries, please contact openscience@royalsociety.org.
Once again, thank you for submitting your manuscript to Royal Society Open Science and I look
forward to receiving your revision. If you have any questions at all, please do not hesitate to get
in touch.
Kind regards,
Royal Society Open Science Editorial Office
Royal Society Open Science
openscience@royalsociety.org
on behalf of Dr Molly Crockett (Associate Editor) and Prof. Antonia Hamilton (Subject Editor)
openscience@royalsociety.org
Associate Editor's comments (Dr Molly Crockett):
Associate Editor: 1
Comments to the Author:
I have received a very thorough and constructive review from an expert reviewer, and I have also
read the paper myself. I agree with the reviewer's comments and would like you to revise your
paper according to these suggestions. In particular, please provide the following additional
analyses:
(1) An analysis that collapses across ideology, 2 (fact-check: pre, post) x 2 (myth: 4:1, 4:4) x 2
(congruency: congruent, incongruent).
6
(2) An analysis that defines political ideology according to absolute position on the scale (e.g. into
two groups above vs. below the midpoint), even if this means there are unequal numbers of
participants in the left vs. right groups.
I will leave it up to you as to how to best organize a revised results section. Please consider the
reviewer's suggestions on this point, and his comment that the results section in the current
manuscript was rather hard to follow. The complexity of the design (resulting in reports of up to
4-way interactions) can be challenging for readers, so I would recommend more signposting
along the way, as well as appropriately placing results that are not central to the main hypotheses
into a supplemental results section.
When submitting your revised manuscript, please also provide a point-by-point response letter
addressing the reviewer's comments.
Comments to Author:
Reviewers' Comments to Author:
Reviewer: 1
Comments to the Author(s)
The authors investigate the effect of fact-checks on both beliefs (about the myths/facts presented)
and support for politicians who have been fact-checked. This is a well-researched and obviously
very timely manuscript that I think should be published. However, I do have two concerns that I
think should be addressed. The primary concern pertains to the results and the secondary
concern pertains to the framing of the manuscript.
Results
The most important issue is that the full design is underpowered and the results section is (in my
view, needlessly) hard to follow. There are 12 between subject conditions and only 370
participants (~30 participants per cell). Moreover, even this low level of power is maintained
because of what I take to be an inappropriate split of the sample on political ideology. That is, I
don’t think it is appropriate to split the groups based on sample characteristics (into 3 equally
numerous groups). This is because if the sample skews left (as it does), there are people in the
neutral category that are left-wing and people in the right-wing category that are neutral.
Left/Neutral/Right should be determined based on where they fall on the political spectrum,
even if it means there will be fewer participants in some of the cells. This probably played a large
role in why the left-wing participants were more extreme (as per the analyses on page 17).
Moreover, the neutral group really isn’t relevant here (apart from acting as a control, although it
is hard to interpret data from such people since they could be genuine moderates or just
apathetic). So, one possibility to gain power is to make as the primary test the data recoded so
that the politician and ideology are either congruent (left-wing participant, Shorten condition/
right-wing participant, Turnbull condition) or incongruent (right-wing participant, Shorten
condition/ left-wing participant, Turnbull condition), as done on page 17 (the full ANOVA can
be reported in a supplement). For clarity, this will result in the following design: 2 (fact-check:
pre, post) x 2 (myth: 4:1, 4:4) x 2 (congruency: congruent, incongruent). This means that neutral
participants are dropped and that ideological asymmetry can’t be investigated in the full design,
but it will increase the sample to (I’m guessing) around 50 per cell. I should also note that this
analysis addresses the central issue, as elucidated in the “summary of main results” section (p.
21). It also means that a single central test can be used to test the key motivated reasoning
7
hypothesis: i.e., that fact-check will interact with congruency and that this interaction will be
sourced by a smaller effect in the incongruent case. The authors are free (in my view) to report
whatever additional tests they like, but I think this really should be the central analysis reported
at the beginning of the results section (for all DVs).
Regarding ideological asymmetry, it would make sense to simply correlate the political ideology
measure with a fact-check difference score (post minus pre) separately for the Shorten and
Turnbull conditions. That is, I don’t think the myth-ratio manipulation is important for the
asymmetry question. The correlation will tell you if conservatives are less responsive to the fact-
check than liberals and whether this depends on ideological congruency (Shorten v. Turnbull).
The interaction between ideology and Shorten/Turnbull condition can be tested in a regression as
well (averaging across myth-ratio condition, interacting Shorten/Turnbull condition with
conservatism). As above, this analysis retains the most power while addressing the central
question.
Obviously, these are just suggestions. But, regardless, the full design is underpowered and it is
not appropriate to categorize individuals as left-wing/neutral/right-wing based on sample
characteristics instead of self-identification.
Another note on the results is that the inferences are driven by interpretation of the patterns that
emerge from significant interactions, but follow-up tests weren’t apparently run (with some
exceptions). For example (p.16): “There were two further unexpected interactions: a significant
interaction of fact-check, myth:fact ratio, and political orientation, which was further qualified by
a significant fourway interaction. This result indicated that myth belief reduced more among
neutral participants in the 4:1 than the 4:4 condition, especially for Turnbull myths, while myth
belief reduced similarly regardless of the myth:fact ratio among left-wing and right-wing
participants.” It is unclear if all of the individual effects that are mentioned are significant on their
own. The significant interaction warrants the follow-ups, but it doesn’t mean that every
difference that (once added up to produce a significant interaction) is itself significant. [Note that
the authors did do this for perhaps one of the most central analyses, which is somewhat buried in
the results: last paragraph of page 19 and first paragraph of page 20]. I think my suggested
revisions to the results might simplify things a bit.
Introduction/Framing
My first comment is simple: “Attitude” is used throughout but not fully defined.
I am also a bit unclear on how different is the attitude-protection hypothesis is from the identity-
protective cognition hypothesis (as per Kahan)? One possibility, which the authors may or may
not agree with, is that the former is an important specification of the latter. Kahan’s account says
that people will engage in motivated reasoning to protect their political (or otherwise) identities.
However, this can be taken broadly to imply that any information that might conflict with one’s
identity (such as Trump’s inaccurate statements in Swire et al., 2017) will lead to motivated
reasoning. Here, the specification is that “identity” might be too broad and that motivated
reasoning occurs as a result of conflict with a specific attitude (although, as mentioned, this term
needs to be defined). At any rate, the connection between these accounts should be addressed in
the manuscript. (Although, I should add, the attitude-protection hypothesis isn’t really tested
here.)
I always sign my reviews,
Gordon Pennycook
8
Author's Response to Decision Letter for (RSOS-180593.R0)
See Appendix A.
label_version_2
RSOS-180593.R1 (Revision)
label_author_2
Review form: Reviewer 1 (Gordon Pennycook)
Is the manuscript scientifically sound in its present form?
Yes
Are the interpretations and conclusions justified by the results?
Yes
Is the language acceptable?
Yes
Is it clear how to access all supporting data?
Yes
Do you have any ethical concerns with this paper?
No
Have you any concerns about statistical analyses in this paper?
No
Recommendation?
label_recommendation_2
Accept as is
Comments to the Author(s)
label_comment_2
I thought the authors were very responsive to my comments and did an excellent job on the
revision. The results section, in particular, is vastly improved. Look forward to seeing it in print!
I always sign my reviews,
Gordon Pennycook
label_end_comment
Decision letter (RSOS-180593.R1)
09-Nov-2018
Dear Dr Ecker,
I am pleased to inform you that your manuscript entitled "Does truth matter to voters? The
effects of correcting political misinformation in an Australian sample" is now accepted for
publication in Royal Society Open Science.
9
You can expect to receive a proof of your article in the near future. Please contact the editorial
office (openscience_proofs@royalsociety.org and openscience@royalsociety.org) to let us know if
you are likely to be away from e-mail contact. Due to rapid publication and an extremely tight
schedule, if comments are not received, your paper may experience a delay in publication.
Royal Society Open Science operates under a continuous publication model
(http://bit.ly/cpFAQ). Your article will be published straight into the next open issue and this
will be the final version of the paper. As such, it can be cited immediately by other researchers.
As the issue version of your paper will be the only version to be published I would advise you to
check your proofs thoroughly as changes cannot be made once the paper is published.
On behalf of the Editors of Royal Society Open Science, we look forward to your continued
contributions to the Journal.
Kind regards,
Andrew Dunn
Royal Society Open Science
openscience@royalsociety.org
on behalf of Dr Antonia Hamilton (Subject Editor)
openscience@royalsociety.org
Reviewer comments to Author:
Reviewer: 1
Comments to the Author(s)
I thought the authors were very responsive to my comments and did an excellent job on the
revision. The results section, in particular, is vastly improved. Look forward to seeing it in print!
I always sign my reviews,
Gordon Pennycook
Follow Royal Society Publishing on Twitter: @RSocPublishing
Follow Royal Society Publishing on Facebook:
https://www.facebook.com/RoyalSocietyPublishing.FanPage/
Read Royal Society Publishing's blog: https://blogs.royalsociety.org/publishing/
Appendix A
Response to Reviewers
Editor’s comments
1. Please provide the following additional analyses:
a. An analysis that collapses across ideology, 2 (fact-check: pre, post) x 2 (myth: 4:1,
4:4) x 2 (congruency: congruent, incongruent).
b. An analysis that defines political ideology according to absolute position on the scale
(e.g. into two groups above vs. below the midpoint), even if this means there are
unequal numbers of participants in the left vs. right groups.
RESPONSE: We followed the suggestion of using the scale mid-point to create two groups
rather than three. This did not lead to any major changes in results and their
interpretation/implications. One problem with the suggested fact-check x myth:fact ratio x
congruence analysis, however, is that it ‘hides’ the left-wing bias in our data, so we did not
feel comfortable following this suggestion. Instead, we decided to run a fact-check x
congruence x political orientation analysis—which is also easy to interpret but shows the
bias. We present analyses including the ratio factor in the supplement—as the reviewer
pointed out, that factor was primarily of interest for the analysis of support but not central to
the analysis of beliefs.
2. I will leave it up to you as to how to best organize a revised results section. Please consider
the reviewer's suggestions on this point, and his comment that the results section in the
current manuscript was rather hard to follow. The complexity of the design (resulting in
reports of up to 4-way interactions) can be challenging for readers, so I would recommend
more signposting along the way, as well as appropriately placing results that are not central
to the main hypotheses into a supplemental results section.
RESPONSE: We have followed the reviewer’s suggestions. We have simplified the Results
section substantially, placing additional analyses (ANOVA tables and an additional figure)
into the supplement. We were able to reduce the number of figures by two, as well. We think
the Results section is now much easier to follow.
Reviewer: 1
1. The most important issue is that the full design is underpowered and the results section is
(in my view, needlessly) hard to follow. There are 12 between subject conditions and only
370 participants (~30 participants per cell). Moreover, even this low level of power is
maintained because of what I take to be an inappropriate split of the sample on political
ideology. That is, I don’t think it is appropriate to split the groups based on sample
characteristics (into 3 equally numerous groups). This is because if the sample skews left (as
it does), there are people in the neutral category that are left-wing and people in the right-
wing category that are neutral. Left/Neutral/Right should be determined based on where
they fall on the political spectrum, even if it means there will be fewer participants in some
of the cells. This probably played a large role in why the left-wing participants were more
extreme (as per the analyses on page 17). Moreover, the neutral group really isn’t relevant
here (apart from acting as a control, although it is hard to interpret data from such people
since they could be genuine moderates or just apathetic). So, one possibility to gain power is
to make as the primary test the data recoded so that the politician and ideology are either
congruent (left-wing participant, Shorten condition/ right-wing participant, Turnbull
condition) or incongruent (right-wing participant, Shorten condition/ left-wing participant,
Turnbull condition), as done on page 17 (the full ANOVA can be reported in a supplement).
For clarity, this will result in the following design: 2 (fact-check: pre, post) x 2 (myth: 4:1, 4:4)
x 2 (congruency: congruent, incongruent). This means that neutral participants are dropped
and that ideological asymmetry can’t be investigated in the full design, but it will increase
the sample to (I’m guessing) around 50 per cell. I should also note that this analysis
addresses the central issue, as elucidated in the “summary of main results” section (p. 21). It
also means that a single central test can be used to test the key motivated reasoning
hypothesis: i.e., that fact-check will interact with congruency and that this interaction will be
sourced by a smaller effect in the incongruent case. The authors are free (in my view) to
report whatever additional tests they like, but I think this really should be the central
analysis reported at the beginning of the results section (for all DVs). Regarding ideological
asymmetry, it would make sense to simply correlate the political ideology measure with a
fact-check difference score (post minus pre) separately for the Shorten and Turnbull
conditions. That is, I don’t think the myth-ratio manipulation is important for the asymmetry
question. The correlation will tell you if conservatives are less responsive to the fact-check
than liberals and whether this depends on ideological congruency (Shorten v. Turnbull). The
interaction between ideology and Shorten/Turnbull condition can be tested in a regression
as well (averaging across myth-ratio condition, interacting Shorten/Turnbull condition with
conservatism). As above, this analysis retains the most power while addressing the central
question. Obviously, these are just suggestions. But, regardless, the full design is
underpowered and it is not appropriate to categorize individuals as left-wing/neutral/right-
wing based on sample characteristics instead of self-identification.
Response: We already responded to the first point in response to the editor’s comments. The
correlational approach would also work (the more left-wing, the more belief in Shorten
myths is reduced, r = ~.30; the more right-wing, the more belief in Turnbull myths is reduced,
r = ~.17, so the effect is about half the size for Turnbull vs. Shorten) but we thought it was
largely redundant, so decided not to include this additional analysis.
2. Another note on the results is that the inferences are driven by interpretation of the
patterns that emerge from significant interactions, but follow-up tests weren’t apparently
run (with some exceptions). For example (p.16): “There were two further unexpected
interactions: a significant interaction of fact-check, myth:fact ratio, and political orientation,
which was further qualified by a significant fourway interaction. This result indicated that
myth belief reduced more among neutral participants in the 4:1 than the 4:4 condition,
especially for Turnbull myths, while myth belief reduced similarly regardless of the myth:fact
ratio among left-wing and right-wing participants.” It is unclear if all of the individual effects
that are mentioned are significant on their own. The significant interaction warrants the
follow-ups, but it doesn’t mean that every difference that (once added up to produce a
significant interaction) is itself significant. [Note that the authors did do this for perhaps one
of the most central analyses, which is somewhat buried in the results: last paragraph of page
19 and first paragraph of page 20]. I think my suggested revisions to the results might
simplify things a bit.
Response: We are now more consistent in reporting follow-up contrasts throughout the
Results section.
3. “Attitude” is used throughout but not fully defined.
Response: We now define the term on p.3.
4. I am also a bit unclear on how different is the attitude-protection hypothesis is from the
identity-protective cognition hypothesis (as per Kahan)? One possibility, which the authors
may or may not agree with, is that the former is an important specification of the latter.
Kahan’s account says that people will engage in motivated reasoning to protect their
political (or otherwise) identities. However, this can be taken broadly to imply that any
information that might conflict with one’s identity (such as Trump’s inaccurate statements in
Swire et al., 2017) will lead to motivated reasoning. Here, the specification is that “identity”
might be too broad and that motivated reasoning occurs as a result of conflict with a specific
attitude (although, as mentioned, this term needs to be defined). At any rate, the
connection between these accounts should be addressed in the manuscript. (Although, I
should add, the attitude-protection hypothesis isn’t really tested here.)
Response: We now make the connection explicit in a footnote on p.6: “One could view the
attitude-protection hypothesis as a special case of Kahan’s identity-protection hypothesis
(e.g., [25]), as attitudes are an integral part of a person’s social identity. However, the
emphasis here lies more on the premise that attitude-incongruent corrections may be fully
effective as long as they do not directly call for attitude change.”
Society Open
