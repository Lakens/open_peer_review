A Brücke–Bartley effect for contrast
Joshua A. Solomon and Christopher W. Tyler
Article citation details
R. Soc. open sci. 5: 180171.
http://dx.doi.org/10.1098/rsos.180171
Review timeline
Original submission: 1 February 2018 Note: Reports are unedited and appear as
Revised submission: 18 May 2018 submitted by the referee. The review history
Final acceptance: 6 July 2018 appears in chronological order.
Note: This manuscript was transferred from another Royal Society journal without peer review.
Review History
label_version_1
RSOS-180171.R0 (Original submission)
label_author_1
Review form: Reviewer 1 (Adam Reeves)
Is the manuscript scientifically sound in its present form?
Yes
Are the interpretations and conclusions justified by the results?
Yes
Is the language acceptable?
Yes
Is it clear how to access all supporting data?
Yes
Do you have any ethical concerns with this paper?
No
Have you any concerns about statistical analyses in this paper?
No
© 2018 The Authors. Published by the Royal Society under the terms of the Creative Commons
Attribution License http://creativecommons.org/licenses/by/4.0/, which permits unrestricted use,
provided the original author and source are credited
2
Recommendation?
label_recommendation_1
Accept with minor revision (please list in comments)
Comments to the Author(s)
label_comment_1
See attached file (Appendix A).
label_author_2
Review form: Reviewer 2 (Fred Kingdom)
Is the manuscript scientifically sound in its present form?
Yes
Are the interpretations and conclusions justified by the results?
Yes
Is the language acceptable?
Yes
Is it clear how to access all supporting data?
Yes
Do you have any ethical concerns with this paper?
No
Have you any concerns about statistical analyses in this paper?
No
Recommendation?
label_recommendation_2
Major revision is needed (please make suggestions in comments)
Comments to the Author(s)
label_comment_2
This is a solid piece of research, supporting the idea that temporally flickering and spatially
modulated textures have a greater average perceived contrast than their non-flickering and non-
spatially-modulated counterparts. The experiments are carefully conducted and although as
argued below the method employed seems rather limited in scope, the results nevertheless
appear to be valid. I have a number of comments which hopefully will be taken as helpful for
improving the manuscript.
1. The finding of an expansive non-linearity for texture processing echoes the findings of Graham
and colleagues (e.g. Graham & Sutter, 1998; 2000), which argue for an expansive nonlinearity at
the intermediate stages of texture processing (in between local luminance pick-up and the
encoding of the texture envelope). The stimuli employed by Graham et al. were very different
from the authors’ stimuli, but I presume the non-linearity mediating both types of stimuli is the
same. Graham & Sutter’s work deserves to be acknowledged and discussed, even if critically.
2. In the abstract: “Alternatively, the psychophysical function can be derived from estimates of
the average between easily discriminable intensities”. Well, this is just one of many possible
alternative scaling methods. The authors later mention other early scaling methods, but
surprisingly never discuss what for many is the gold standard of modern scaling procedures:
Maximum Likelihood Difference Scaling, or MLDS (Maloney & Yang, 2003). Unlike MLDS, the
method employed by the authors seems limited in terms of general applicability. I suspect the
3
authors are aware of this, as the independent variables in their study are the temporal and spatial
frequencies of the tests, not their contrasts. Presumably one could not derive the perceptual scale
for contrast using the authors’ method because the spatio-temporal properties of the match (the
“doubler”) and test stimuli are so different. Thus, for example, if test contrast was the variable of
interest, a compressive transducer in the match combined with a linear transducer in the test
could produce the same matches as a linear transducer in the match combined with an expansive
transducer in the test. With MLDS (and most traditional scaling procedures) the stimuli are self-
referential, that is all stimuli have identical spatio-temporal characteristics, apart from, of course,
the dimension of interest (e.g. contrast). It would be helpful if the authors’ method were
discussed in the context of modern scaling methods such as MLDS which do not suffer from such
limitations.
3. Methods. I found the methods section rather opaque, requiring several readings to get the gist.
Some suggestions for improvement:
a). In Eq. 1 what is C0? Is this the contrast of the average annulus luminance with its grey
background? If so what are the units of C0 (Weber?) and what are its values for the various
stimuli?
b) In Eq. 1 what is the significance of the factors of 8 and 4?
c) To grasp the relationship between the parameters w and a in Eq. 1 it might help if a figure was
provided of the luminance profile around the annulus at one time during the temporal waveform
for Experiment 1 and/or of the spatial modulation used in Experiment 2.
d) From Fig. 1 it looks as though the luminance of the trough of the test modulations in b and f,
or the peak in d is equal to the background grey. Is this the case? If so is w and a therefore a
function of C0?
e) I could not fathom the reason for calling the match stimulus the “doubler”. What exactly was
it doubling? If I understand the method correctly, the task for the subject was to set the contrast
of the match to equal either the average or the maximum perceived contrast of the test, not to
match the temporal or spatial frequency of the test. If so why not simply call the match stimulus
what it is: the match.
4. In the luminance modulation condition in Experiment 2 the modulation introduces local
contrast increments and decrements along the waveform. It is well known from both
psychophysics and physiology that contrast increments and decrements are processed by
different mechanisms, and according to the seminal work of Whittle (Whittle, 1992) with different
transducer shapes. Both properties of contrast transduction presumably combine to make the
authors’ task difficult and the results for this condition hard to interpret. This deserves some
discussion.
5. The authors could add some caveats to the conclusion that contrast transduction is expansive.
First, there are many models of contrast transduction (e.g. Legge & Foley, 1980) that involve an
expansive nonlinearity near threshold followed by a compressive nonlinearity at suprathreshold
contrast. I presume that the expansive nonlinearity observed in this study is different from the
near-threshold expansion in these models, and if so this is worth pointing out. Following on
from this, it is also worth pointing out the expansion measured here is for just one contrast level
and is therefore not necessarily a property of the whole contrast range.
6. The corollary to the main conclusion that internal noise variance for contrast transduction is
likely multiplicative is reasonable given the study’s findings. However the literature on this
subject is extensive and there are many studies that support the constant noise assumption (e.g.
Katkov et al., 2006a,b; Gorea & Sagi, 2001; Whittle’s 1986/1992 studies, as argued by Kingdom,
2016), and that the results of some previous studies supporting multiplicative noise (specifically
Kontsevich et al., 2002) when subject to re-analysis have been shown to be just as consistent with
constant noise (Georgeson & Meese, 2006). The claim in the Introduction that “..we seem to have
4
very little evidence supporting the idea of constant noise” is surely putting it a bit strong, so a
more balanced discussion of this issue would seem warranted.
Fred Kingdom, McGill University
References:
Gorea, A., & Sagi, D. (2001). Disentangling signal from noise in visual contrast discrimination.
Nature Neuroscience, 4, 1146–1150.
Graham, N., & Sutter, A. (1998). Spatial summation in simple (Fourier) and complex (non-
Fourier) channels in texture segregation. Vision Research, 38, 231–257.
Graham, N., & Sutter, A. (2000). Normalization: Contrast-gain control in simple (Fourier) and
complex (non-Fourier) pathways of pattern vision. Vision Research, 40, 2737–2761.
Katkov, M., Tsodyks, M., & Sagi, D. (2006a). Singularities in the inverse modeling of 2AFC
contrast discrimination data. Vision Research, 46, 259–266.
Katkov, M., Tsodyks, M., & Sagi, D. (2006b). Analysis of two-alternative force-choice Signal
Detection Theory model. Journal of Mathematical Psychology, 50, 411–420.
Kingdom, F. A. A. (2016). Fixed versus variable internal noise in contrast transduction: the
significance of Whittle's data. Vision Research, 128, 1-5.
Kontsevich, L. L., Chen, C.-C., & Tyler, C. W. (2002a). Separating the effects of response
nonlinearity and internal noise psychophysically. Vision Research, 42, 1771–1784.
Legge, G. E., & Foley, J. M. (1980). Contrast masking in human vision. Journal of the Optical
Society of America, 70, 1458–1471.
Maloney, L. T., & Yang, J. N. (2003). Maximum likelihood difference scaling. Journal of Vision, 3,
573–585.
Georgeson, M. A. & Meese, T. S. (2006). Fixed or variable noise in contrast discrimination? The
jury’s still out. Vision Research, 46, 4294-4303.
Whittle, P. (1986). Increments and decrements: Luminance discrimination. Vision Research, 26,
1677–1691.
Whittle, P. (1992). Brightness, discriminability and the ‘‘crispening effect”. Vision Research, 32,
1493–1507.
label_end_comment
Decision letter (RSOS-180171.R0)
01-May-2018
Dear Dr Solomon,
The editors assigned to your paper ("A Brücke-Bartley effect for contrast") have now received
comments from reviewers. We would like you to revise your paper in accordance with the
5
referee and Associate Editor suggestions which can be found below (not including confidential
reports to the Editor). Please note this decision does not guarantee eventual acceptance.
Please submit a copy of your revised paper within three weeks (i.e. by the 24-May-2018). If we do
not hear from you within this time then it will be assumed that the paper has been withdrawn. In
exceptional circumstances, extensions may be possible if agreed with the Editorial Office in
advance.We do not allow multiple rounds of revision so we urge you to make every effort to
fully address all of the comments at this stage. If deemed necessary by the Editors, your
manuscript will be sent back to one or more of the original reviewers for assessment. If the
original reviewers are not available, we may invite new reviewers.
To revise your manuscript, log into http://mc.manuscriptcentral.com/rsos and enter your
Author Centre, where you will find your manuscript title listed under "Manuscripts with
Decisions." Under "Actions," click on "Create a Revision." Your manuscript number has been
appended to denote a revision. Revise your manuscript and upload a new version through your
Author Centre.
When submitting your revised manuscript, you must respond to the comments made by the
referees and upload a file "Response to Referees" in "Section 6 - File Upload". Please use this to
document how you have responded to the comments, and the adjustments you have made. In
order to expedite the processing of the revised manuscript, please be as specific as possible in
your response.
In addition to addressing all of the reviewers' and editor's comments please also ensure that your
revised manuscript contains the following sections as appropriate before the reference list:
• Ethics statement (if applicable)
If your study uses humans or animals please include details of the ethical approval received,
including the name of the committee that granted approval. For human studies please also detail
whether informed consent was obtained. For field studies on animals please include details of all
permissions, licences and/or approvals granted to carry out the fieldwork.
• Data accessibility
It is a condition of publication that all supporting data are made available either as
supplementary information or preferably in a suitable permanent repository. The data
accessibility section should state where the article's supporting data can be accessed. This section
should also include details, where possible of where to access other relevant research materials
such as statistical tools, protocols, software etc can be accessed. If the data have been deposited in
an external repository this section should list the database, accession number and link to the DOI
for all data from the article that have been made publicly available. Data sets that have been
deposited in an external repository and have a DOI should also be appropriately cited in the
manuscript and included in the reference list.
If you wish to submit your supporting data or code to Dryad (http://datadryad.org/), or modify
your current submission to dryad, please use the following link:
http://datadryad.org/submit?journalID=RSOS&manu=RSOS-180171
• Competing interests
Please declare any financial or non-financial competing interests, or state that you have no
competing interests.
6
• Authors’ contributions
All submissions, other than those with a single author, must include an Authors’ Contributions
section which individually lists the specific contribution of each author. The list of Authors
should meet all of the following criteria; 1) substantial contributions to conception and design, or
acquisition of data, or analysis and interpretation of data; 2) drafting the article or revising it
critically for important intellectual content; and 3) final approval of the version to be published.
All contributors who do not meet all of these criteria should be included in the
acknowledgements.
We suggest the following format:
AB carried out the molecular lab work, participated in data analysis, carried out sequence
alignments, participated in the design of the study and drafted the manuscript; CD carried out
the statistical analyses; EF collected field data; GH conceived of the study, designed the study,
coordinated the study and helped draft the manuscript. All authors gave final approval for
publication.
• Acknowledgements
Please acknowledge anyone who contributed to the study but did not meet the authorship
criteria.
• Funding statement
Please list the source of funding for each author.
Please note that Royal Society Open Science will introduce article processing charges for all new
submissions received from 1 January 2018. Charges will also apply to papers transferred to Royal
Society Open Science from other Royal Society Publishing journals, as well as papers submitted
as part of our collaboration with the Royal Society of Chemistry
(http://rsos.royalsocietypublishing.org/chemistry). If your manuscript is submitted and
accepted for publication after 1 Jan 2018, you will be asked to pay the article processing charge,
unless you request a waiver and this is approved by Royal Society Publishing. You can find out
more about the charges at http://rsos.royalsocietypublishing.org/page/charges. Should you
have any queries, please contact openscience@royalsociety.org.
Once again, thank you for submitting your manuscript to Royal Society Open Science and I look
forward to receiving your revision. If you have any questions at all, please do not hesitate to get
in touch.
Kind regards,
Andrew Dunn
Royal Society Open Science
openscience@royalsociety.org
on behalf of Dr Narayanan Srinivasan (Associate Editor) and Antonia Hamilton (Subject Editor)
openscience@royalsociety.org
Associate Editor's comments (Dr Narayanan Srinivasan):
Two reviewers have commented on the paper. The authors are requested to address all the issues
raised by the reviewers point by point.
7
Comments to Author:
Reviewers' Comments to Author:
Reviewer: 1
Comments to the Author(s)
See attached file.
Reviewer: 2
Comments to the Author(s)
This is a solid piece of research, supporting the idea that temporally flickering and spatially
modulated textures have a greater average perceived contrast than their non-flickering and non-
spatially-modulated counterparts. The experiments are carefully conducted and although as
argued below the method employed seems rather limited in scope, the results nevertheless
appear to be valid. I have a number of comments which hopefully will be taken as helpful for
improving the manuscript.
1. The finding of an expansive non-linearity for texture processing echoes the findings of Graham
and colleagues (e.g. Graham & Sutter, 1998; 2000), which argue for an expansive nonlinearity at
the intermediate stages of texture processing (in between local luminance pick-up and the
encoding of the texture envelope). The stimuli employed by Graham et al. were very different
from the authors’ stimuli, but I presume the non-linearity mediating both types of stimuli is the
same. Graham & Sutter’s work deserves to be acknowledged and discussed, even if critically.
2. In the abstract: “Alternatively, the psychophysical function can be derived from estimates of
the average between easily discriminable intensities”. Well, this is just one of many possible
alternative scaling methods. The authors later mention other early scaling methods, but
surprisingly never discuss what for many is the gold standard of modern scaling procedures:
Maximum Likelihood Difference Scaling, or MLDS (Maloney & Yang, 2003). Unlike MLDS, the
method employed by the authors seems limited in terms of general applicability. I suspect the
authors are aware of this, as the independent variables in their study are the temporal and spatial
frequencies of the tests, not their contrasts. Presumably one could not derive the perceptual scale
for contrast using the authors’ method because the spatio-temporal properties of the match (the
“doubler”) and test stimuli are so different. Thus, for example, if test contrast was the variable of
interest, a compressive transducer in the match combined with a linear transducer in the test
could produce the same matches as a linear transducer in the match combined with an expansive
transducer in the test. With MLDS (and most traditional scaling procedures) the stimuli are self-
referential, that is all stimuli have identical spatio-temporal characteristics, apart from, of course,
the dimension of interest (e.g. contrast). It would be helpful if the authors’ method were
discussed in the context of modern scaling methods such as MLDS which do not suffer from such
limitations.
3. Methods. I found the methods section rather opaque, requiring several readings to get the gist.
Some suggestions for improvement:
a). In Eq. 1 what is C0? Is this the contrast of the average annulus luminance with its grey
background? If so what are the units of C0 (Weber?) and what are its values for the various
stimuli?
b) In Eq. 1 what is the significance of the factors of 8 and 4?
c) To grasp the relationship between the parameters w and a in Eq. 1 it might help if a figure was
provided of the luminance profile around the annulus at one time during the temporal waveform
for Experiment 1 and/or of the spatial modulation used in Experiment 2.
8
d) From Fig. 1 it looks as though the luminance of the trough of the test modulations in b and f,
or the peak in d is equal to the background grey. Is this the case? If so is w and a therefore a
function of C0?
e) I could not fathom the reason for calling the match stimulus the “doubler”. What exactly was
it doubling? If I understand the method correctly, the task for the subject was to set the contrast
of the match to equal either the average or the maximum perceived contrast of the test, not to
match the temporal or spatial frequency of the test. If so why not simply call the match stimulus
what it is: the match.
4. In the luminance modulation condition in Experiment 2 the modulation introduces local
contrast increments and decrements along the waveform. It is well known from both
psychophysics and physiology that contrast increments and decrements are processed by
different mechanisms, and according to the seminal work of Whittle (Whittle, 1992) with different
transducer shapes. Both properties of contrast transduction presumably combine to make the
authors’ task difficult and the results for this condition hard to interpret. This deserves some
discussion.
5. The authors could add some caveats to the conclusion that contrast transduction is expansive.
First, there are many models of contrast transduction (e.g. Legge & Foley, 1980) that involve an
expansive nonlinearity near threshold followed by a compressive nonlinearity at suprathreshold
contrast. I presume that the expansive nonlinearity observed in this study is different from the
near-threshold expansion in these models, and if so this is worth pointing out. Following on
from this, it is also worth pointing out the expansion measured here is for just one contrast level
and is therefore not necessarily a property of the whole contrast range.
6. The corollary to the main conclusion that internal noise variance for contrast transduction is
likely multiplicative is reasonable given the study’s findings. However the literature on this
subject is extensive and there are many studies that support the constant noise assumption (e.g.
Katkov et al., 2006a,b; Gorea & Sagi, 2001; Whittle’s 1986/1992 studies, as argued by Kingdom,
2016), and that the results of some previous studies supporting multiplicative noise (specifically
Kontsevich et al., 2002) when subject to re-analysis have been shown to be just as consistent with
constant noise (Georgeson & Meese, 2006). The claim in the Introduction that “..we seem to have
very little evidence supporting the idea of constant noise” is surely putting it a bit strong, so a
more balanced discussion of this issue would seem warranted.
Fred Kingdom, McGill University
References:
Gorea, A., & Sagi, D. (2001). Disentangling signal from noise in visual contrast discrimination.
Nature Neuroscience, 4, 1146–1150.
Graham, N., & Sutter, A. (1998). Spatial summation in simple (Fourier) and complex (non-
Fourier) channels in texture segregation. Vision Research, 38, 231–257.
Graham, N., & Sutter, A. (2000). Normalization: Contrast-gain control in simple (Fourier) and
complex (non-Fourier) pathways of pattern vision. Vision Research, 40, 2737–2761.
Katkov, M., Tsodyks, M., & Sagi, D. (2006a). Singularities in the inverse modeling of 2AFC
contrast discrimination data. Vision Research, 46, 259–266.
Katkov, M., Tsodyks, M., & Sagi, D. (2006b). Analysis of two-alternative force-choice Signal
Detection Theory model. Journal of Mathematical Psychology, 50, 411–420.
9
Kingdom, F. A. A. (2016). Fixed versus variable internal noise in contrast transduction: the
significance of Whittle's data. Vision Research, 128, 1-5.
Kontsevich, L. L., Chen, C.-C., & Tyler, C. W. (2002a). Separating the effects of response
nonlinearity and internal noise psychophysically. Vision Research, 42, 1771–1784.
Legge, G. E., & Foley, J. M. (1980). Contrast masking in human vision. Journal of the Optical
Society of America, 70, 1458–1471.
Maloney, L. T., & Yang, J. N. (2003). Maximum likelihood difference scaling. Journal of Vision, 3,
573–585.
Georgeson, M. A. & Meese, T. S. (2006). Fixed or variable noise in contrast discrimination? The
jury’s still out. Vision Research, 46, 4294-4303.
Whittle, P. (1986). Increments and decrements: Luminance discrimination. Vision Research, 26,
1677–1691.
Whittle, P. (1992). Brightness, discriminability and the ‘‘crispening effect”. Vision Research, 32,
1493–1507.
Author's Response to Decision Letter for (RSOS-180171.R0)
See Appendix B.
label_version_2
RSOS-180171.R1 (Revision)
label_author_3
Review form: Reviewer 2 (Fred Kingdom)
Is the manuscript scientifically sound in its present form?
Yes
Are the interpretations and conclusions justified by the results?
Yes
Is the language acceptable?
Yes
Is it clear how to access all supporting data?
Not Applicable
Do you have any ethical concerns with this paper?
No
10
Have you any concerns about statistical analyses in this paper?
No
Recommendation?
label_recommendation_3
Accept as is
Comments to the Author(s)
label_comment_3
None
label_end_comment
Decision letter (RSOS-180171.R1)
06-Jul-2018
Dear Dr Solomon,
I am pleased to inform you that your manuscript entitled "A Brücke-Bartley effect for contrast" is
now accepted for publication in Royal Society Open Science.
You can expect to receive a proof of your article in the near future. Please contact the editorial
office (openscience_proofs@royalsociety.org and openscience@royalsociety.org) to let us know if
you are likely to be away from e-mail contact. Due to rapid publication and an extremely tight
schedule, if comments are not received, your paper may experience a delay in publication.
Royal Society Open Science operates under a continuous publication model
(http://bit.ly/cpFAQ). Your article will be published straight into the next open issue and this
will be the final version of the paper. As such, it can be cited immediately by other researchers.
As the issue version of your paper will be the only version to be published I would advise you to
check your proofs thoroughly as changes cannot be made once the paper is published.
In order to raise the profile of your paper once it is published, we can send through a PDF of your
paper to selected colleagues. If you wish to take advantage of this, please reply to this email with
the name and email addresses of up to 10 people who you feel would wish to read your article.
Please note that Royal Society Open Science will introduce article processing charges for all new
submissions received from 1 January 2018. Charges will also apply to papers transferred to Royal
Society Open Science from other Royal Society Publishing journals, as well as papers submitted
as part of our collaboration with the Royal Society of Chemistry
(http://rsos.royalsocietypublishing.org/chemistry). If your manuscript is submitted and
accepted for publication after 1 Jan 2018, you will be asked to pay the article processing charge,
unless you request a waiver and this is approved by Royal Society Publishing. You can find out
more about the charges at http://rsos.royalsocietypublishing.org/page/charges. Should you
have any queries, please contact openscience@royalsociety.org.
On behalf of the Editors of Royal Society Open Science, we look forward to your continued
contributions to the Journal.
Kind regards,
Andrew Dunn
Senior Publishing Editor
Royal Society Open Science
11
openscience@royalsociety.org
on behalf of Dr Narayanan Srinivasan (Associate Editor) and Antonia Hamilton (Subject Editor)
openscience@royalsociety.org
Associate Editor Comments to Author (Dr Narayanan Srinivasan):
Associate Editor: 1
Comments to the Author:
The reviewer is satisfied with the revision and the manuscript is accepted for publication.
Congratulations!
Reviewer comments to Author:
Reviewer: 2
Comments to the Author(s)
None
Appendix A
Review of: A Brücke-Bartley effect for contrast for Proc R. Soc. March 2018
Solomon et al. Manuscript ID RSOS-180171
Nice paper; well written and conceptualized, and the content is suitable for the Journal. I
heartily recommend publication.
The authors show that the classic Brücke-Bartley effect holds not only for bright luminance
differences but also holds for dark ones and for contrast differences. The finding that contrast,
not luminance, is the critical variable in the effect, is new and worthy of note. The low-pass
characteristics shown in Fig. 3 are also important. The variation in the subject’s adjustment
task is also praiseworthy, as this is a potential confound in many previous experiments.
About the psychophysical method; stepping the contrast up and down to make a match is
satisfactory, as long as the subject does not adapt to the stimulus. However Wu et al. found
strong flicker adaptation effects, as have others, and had to design their experiment to
overcome them. I suspect adaptation to the flicker also happened here. If so, the question
arises, did the number of responses (‘c’ or ‘m’) vary enough with condition to need
consideration ?
About equation 1: I found it irritating that the authors pack so much into one equation, then
need to unravel the whole thing in the text. Please separate the +cos and –cos terms, the
former having the adjustable parameter a, i.e. the ‘comparison’, into equ 1a, and latter into
equ 1b (the ‘standard’). Readers will follow this terminology, the use of the sinusoid to
modulate each part spatially can be explained more easily, and the definition of the Heaviside
function (now missing) need not be given (see Wikipedia for several forms of it).
Parameter ‘a’ is called the ‘doubler’ on page 4, but this is only the case for n=2. For 1 < n < 2,
the expansion would leave the fundamental still dominant and therefore not double the
perceived frequency. Actually they constrained n to his interval, given w=0.5, so n=2 is just
at the top end of what they think possible. Anyway, my suspicion is that the authors saw
frequency doubling in pilot work, and so adopted this terminology prior to the main
experiment, which is an acceptable motivation, but not theoretical.
I think what is being said about the distortion product is correct, on page 4, line 55, but I
suspect the authors are implicitly assuming that the transducer follows a power law with n=2;
if so, this should be stated.
Wu et al. found large individual differences in flicker enhancement. The cited maximum at
16Hz applied to 2 of our 3 subjects, but the other subject, AR, was maximal at 6 Hz.
Unfortunately we had no independent measures to decide if the individual differences were
sensory or cognitive. The apparently different results in the current experiment (max at 7.5
Hz) may reflect luck, as there were only 4 subjects, and should not be taken as definitive.
In expt. 2, ‘the carrier had a temporal frequency of zero’. Trivial, but is this possible? The
stimuli don’t last forever.
Grub’s statistic: I have always found this mildly risible. Pruning the outlier is iterated until
there are no outliers left, according to some criterion z-score. But the mean and sigma are re-
calculated each iteration. So the pruning stops at random, depending only on a chance aspect
of the sample (that there happens not to be any observations in some interval). Therefore
almost any value of the mean and sigma can result. I know it is standard to use Grub’s, but I
do suggest that the authors check that pruning was not excessive.
Fig.s 3, 4 legend; at first sight, the fact that the blue error bars are almost as large as the red
ones seems strange. There are pronounced individual differences in the peak of the function,
especially in fig. 3, so I expected that the blue error bars would be much smaller than the red
ones. OK, maybe the reason is that the function is relatively flat-topped, so the error around
the peak would be similar for two subjects even if their peaks differed. But I don’t have a
clear intuition for this result. Anyway, it may not be consequential.
Peripheral flicker non-linearities. I wonder if the authors have checked the m-sequence
electrophysiological data of Erich Sutter. The issue would be whether the higher-order kernels
become weaker, or stronger, on average, as eccentricity increases. I suspect Wu and Sutter
had some relevant data, or maybe Sutter and Tran (1992).
High-frequency cut-off. There was never any effect at 60Hz, not surprisingly given that one
cannot see flicker at this rate. I suggest saving space by simply stating that there were no
effects at 60Hz in any of the conditions, and just leaving it at that. No need to repeat the same
thing over and over for every case, especially as the authors have the same explanation for the
nul effect every time, and no reason to expect things to be any different.
I am not sure that the authors needed to test a temporal band-pass filter (eq. 3), as the data in
Fig. 3 are easy to describe (within the errors of measurement) as low-pass. Moreover, a drop
off at 1 or 2 Hz may reflect some quite different process such as light or dark adaptation. If
the authors have other data which requires a band-pass, OK, but they should clarify this.
(Stockman assumes a low pass temporal filter, even though his flicker data hint at a band-
pass, I think for this reason). Also, the authors construct their band–pass from the product of a
passive 2-pole low-pass and a passive 8-pole high-pass filter, but it has been argued long
since (e.g., Sperling and Sondhi) that the retinal physiology does not support anything more
than a 2-pole feed-forward filtering operation. It the authors accept this, they should note that
their filter is purely descriptive, not meant to capture the underlying physiology. But I still
think the better (more conservative) course is to abandon the band-pass, at least for now, as it
is hardly needed for the data to hand.
The filters the authors’ test act instantaneously, but some flicker data (e.g., Andrew
Stockman’s) suggest that there are filtering delays. Supposing a delay did occur; I am not sure
that this would affect the settings, but the authors might think about whether this could be so,
or not. If higher amplitudes decreased the delay, then the data could fall off with frequency,
even if the filter was flat in amplitude.
I expected to see ‘n’ in equations 2 and 3, but this is missing. Also, n>1 is assumed (see later,
page 13), but since n<1.0 is mentioned in the Introduction (e.g., n=0.6), as some earlier
studies found compression, the authors might also explain here why n>1 is being assumed.
Results: the authors sometimes appear to include the 60Hz settings in the grand average and
sometimes not. I suggest always treating 60Hz as a special case, and excluding all data at this
frequency.
‘Thus, it might be more accurate to say that our Condition 3 results (both Experiments) are
consistent with a linear psychophysical function mapping power spectral density to apparent
contrast.’
See also Yang & Reeves, Neural Networks 1995, we found that the power of the VEP is
proportional to contrast for a very large collection of gratings, previously, it was supposed
that VEP amplitude went with log (contrast).
‘At first glance, both our results and our conclusions resemble those of Meese, Baker, &
Summers [21],….’ I didn’t follow the authors’ argument about why the judgments should or
should not differ, or why one criterion might be better or worse than another. I feel that this
section should be shortened to simply saying that further experimentation will be needed to
assess whether their data and model can be reconciled with the current one. As it is, this
whole rather wordy section seems too vague to add to one’s understanding of either study.
Page 19, line 14. The authors have not convinced me that compression of both signal and
noise, with the former less compressed than the latter, is excluded. I may be missing a point
here.
The Discussion correctly points out that stimulus contrast, not luminance, is the critical
variable in these results, but appears to imply (maybe this was unintentional) that luminance is
not a factor in general. However, if the experiment were to be repeated at a different
luminance levels, it seems quite possible that the filter parameters or value of n, or both,
would change.
Page 18: ‘Thus, despite the individual differences, our results erect a strong hurdle
for models of contrast masking (e.g., [8]) that rely on compressive transduction.’
I am unhappy with this conclusion as stated. It seems quite possible that measures of
discrimination/ masking and of brightness enhancement may both depend on contrast, but to
different extents. Such a divergence is common enough; e.g., as von Kries pointed out, acuity
changes rapidly in the periphery but brightness does not; and it is well known that detection
thresholds are band-pass but contrast matching above threshold is almost flat over frequency.
I would accept a re-wording such as: ‘Thus, despite the individual differences, our results
erect a strong hurdle for models of contrast processing that rely on the compressive
transduction illustrated by masking (e.g., [8])’.
Adam Reeves
Appendix B
Dear Dr. Dunn
Thank you for finding such supportive referees. we’ve removed some of the original
email (in Courier), but we’ve retained everything that deserves comment (in
Helvetica).
Reviewer #1:
I suspect adaptation to the flicker also happened here. If so,
the question arises, did the number of responses (‘c’ or ‘m’)
vary enough with condition to need consideration?
Artefacts of adaptation are always a worry when using the method of adjustment.
However, as neither response rate nor fixation were controlled in our experiment,
the numbers of responses (which, in any case, were not recorded in our data files) is
unlikely to be more than a weak correlate of adaptation. Wu et al. (1996) addressed
adaptation by separating the test and match stimuli in time, rather than in space.
We did this too, and we reported the results at VSS 2017 and APCV 2017. Those
results are qualitatively similar to the results reported in our current manuscript. Not
only did they support an expansive transducer, they also contained large individual
differences. Along with several other small tweaks to our methodology, we switched
from a temporal comparison (as in Wu et al.) to a spatial comparison (as in Petrova
et al., 2013) because we thought it felt less unnatural, and we hoped it might reduce
ndividual differences. Unfortunately, it did not reduce individual differences (and, to
be honest, the task still seemed unnatural at most spatial and temporal
frequencies).
About equation 1: I found it irritating that the authors pack
so much into one equation, then need to unravel the
whole thing in the text. Please separate the +cos and –cos
terms, the former having the adjustable parameter a, i.e.
the ‘comparison’, into equ 1a, and latter into equ 1b (the
‘standard’). Readers will follow this terminology, the use of
the sinusoid to modulate each part spatially can be explained
more easily, and the definition of the Heaviside
function (now missing) need not be given (see Wikipedia for
several forms of it).
OK, we have implemented these suggestions, except that we use the terms
"standard" and "adjustable" to describe the two halves of each annulus.
Parameter ‘a’ is called the ‘doubler’ on page 4, but this is
only the case for n=2. For 1 < n < 2, the expansion would
leave the fundamental still dominant and therefore not double
the perceived frequency.
Actually, when appropriately adjusted the lowest apparent angular frequency in the
annulus doubles (either from 1/2p to 1/p, when there is a distortion product; or from
0 to 0, when there isn't). However, we recognise that this isn't immediately obvious,
so we've renamed parameter a as the "adjuster."
Actually they constrained n
to his interval, given w=0.5, so n=2 is just at the top end of
what they think possible.
Whoa. Wait a minute. The parameter n is a model parameter. Perhaps the comment
is referring to a in our equation –1 = a = w-1?
Anyway, my suspicion is that
the authors saw frequency doubling in pilot work, and so
adopted this terminology prior to the main experiment,
which is an acceptable motivation, but not theoretical.
I think what is being said about the distortion product is
correct, on page 4, line 55, but I suspect the authors are
implicitly assuming that the transducer follows a power law
with n=2; if so, this should be stated.
Again, frequency doubling may not have been the clearest description, but it
effectively was the observer’s task in Experiment 1, Conditions 1 – 3; regardless of
transduction.
Wu et al. found large individual differences in flicker
enhancement. The cited maximum at 16Hz applied to 2 of our
3 subjects, but the other subject, AR, was maximal at 6 Hz.
Unfortunately we had no independent measures to
decide if the individual differences were sensory or
cognitive. The apparently different results in the current
experiment (max at 7.5 Hz) may reflect luck, as there were
only 4 subjects, and should not be taken as definitive.
Agreed!
In expt. 2, ‘the carrier had a temporal frequency of zero’.
Trivial, but is this possible? The stimuli don’t last forever.
By ‘temporal frequency’ we simply meant the stimulus parameter tc–1. This is
clarified in the revision.
Grub’s statistic: I have always found this mildly risible.
Pruning the outlier is iterated until there are no outliers
left,
according to some criterion z-score. But the mean and sigma
are re-calculated each iteration. So the pruning stops at
random, depending only on a chance aspect of the sample (that
there happens not to be any observations in some
interval). Therefore almost any value of the mean and sigma
can result. I know it is standard to use Grub’s, but I do
suggest that the authors check that pruning was not excessive.
As noted in the manuscript, ‘none of the … trials were deemed to be outliers.’ In
other words, there was no pruning.
Fig.s 3, 4 legend; at first sight, the fact that the blue
error bars are almost as large as the red ones seems strange.
We are really glad Adam noticed this. We feel it is an important feature of our results
because It means that the within-subject error is almost as large as the between-
subject error, and the latter is pretty damn large. A thorough investigation of the
difference between these two errors (and how that difference varied with frequency)
was conducted prior to submission. Very little of that analysis remains, beyond an
ANOVA and Footnote [3]. Here is a little more (from Experiment 1; red: Brightness;
green: Darkness, blue: Contrast):
Adjusting to average visibility Adjusting to maximum visibility
6 6
Ratio of SDs Ratio of SDs
5 5
4 4
3 3
2 2
(pooled across : ave within) 1 (pooled across : ave within) 1
5 10 20 50 5 10 20 50
Temporal Frequency (Hz) Temporal Frequency (Hz)
Consensuses seem to build with frequency. The build-up is more subtle and possibly insignificant with brightness and texture, but it’s incontrovertible in the case of
darkness because, in that case, it’s really low at low frequencies.
And from Experiment 2 (NB: the horizontal axes labels are wrong; they should say
Spatial Frequency with units rad–1):
Taken en masse, and with the exception of Experiment 1, Condition 2, these
analyses indicate that between-observer error was at most just twice the within-
observer error. (NB: The RMS error within observers equals the SD between
observers when the Ratio of SDs equals v2.)
We address the issue of large within-observer error in the Discussion, ‘We question
whether their observers had any clearer idea of what was meant by "overall" or
"global" contrast than ours did regarding "average salience" or "average
contrastiness". The latter may have simply recognised that average values must lie
somewhere between the maximum and minimum. Consequently, any point within
that interval could be selected with impunity.’
Note that when the SD ratio equals 1, the difference between black and red curves
in those figures equals the difference between average and maximum levels within
observers. It is large (when modulation frequencies are low), and the difference
between minimum and maximum cannot be any smaller.
There are pronounced individual differences in the peak of the
function, especially in fig. 3, so I expected that the
blue error bars would be much smaller than the red ones. OK,
maybe the reason is that the function is relatively
flattopped,
so the error around the peak would be similar for two subjects
even if their peaks differed. But I don’t have a
clear intuition for this result. Anyway, it may not be
consequential.
Peripheral flicker non-linearities. I wonder if the authors
have checked the m-sequence electrophysiological data of
Erich Sutter. The issue would be whether the higher-order
kernels become weaker, or stronger, on average, as
eccentricity increases. I suspect Wu and Sutter had some
relevant data, or maybe Sutter and Tran (1992).
Sutter & Tran focused on the first order kernel of the conventional ERG only, and
Wu & Sutter found that ERG components specific to the oscillatory potentials
predominated in the periphery, similarly for both first- and second-order
components. Although both studies did examine the effect of eccentricity, it isn’t
clear to us why that should be important; we didn’t control fixation. In addition to
information regarding monitor luminance and viewing distance, we have added the
following paragraph:
The room was darkened, so that most of its light came from the stimulus monitor.
However, no attempt was made to prevent this light from reflecting off the
laboratory’s other contents. The monitor’s viewable size was 19.8 inches. Viewing
was binocular. We did not use artificial pupils nor did we enforce fixation.
High-frequency cut-off. There was never any effect at 60Hz,
not surprisingly given that one cannot see flicker at this
rate. I suggest saving space by simply stating that there were
no effects at 60Hz in any of the conditions, and just
leaving it at that. No need to repeat the same thing over and
over for every case, especially as the authors have the
same explanation for the nul effect every time, and no reason
to expect things to be any different.
OK.
I am not sure that the authors needed to test a temporal band-
pass filter (eq. 3), as the data in Fig. 3 are easy to
describe (within the errors of measurement) as low-pass.
Moreover, a drop off at 1 or 2 Hz may reflect some quite
different process such as light or dark adaptation. If the
authors have other data which requires a band-pass, OK, but
they should clarify this. (Stockman assumes a low pass
temporal filter, even though his flicker data hint at a
bandpass,
I think for this reason).
Although we might have gotten away with a Gaussian, we see no reason not to
include the inhibitory component of Petrova, Henning, & Stockman’s (2013) band-
pass filter, which does allow for the nuance of a low-frequency drop-off (significant
or not). To be clear, this band-pass filter is the filter that ‘Stockman assumes.’
That’s our main reason for using it.
Also, the authors construct their band–pass from the product
of a passive 2-pole lowpass
and a passive 8-pole high-pass filter, but it has been argued
long since (e.g., Sperling and Sondhi) that the
retinal physiology does not support anything more than a 2-
pole feed-forward filtering operation. It the authors
accept this, they should note that their filter is purely
descriptive, not meant to capture the underlying physiology.
But I still think the better (more conservative) course is to
abandon the band-pass, at least for now, as it is hardly
needed for the data to hand.
The filters the authors’ test act instantaneously, but some
flicker data (e.g., Andrew Stockman’s) suggest that there
are filtering delays. Supposing a delay did occur; I am not
sure that this would affect the settings, but the authors
might think about whether this could be so, or not. If higher
amplitudes decreased the delay, then the data could fall
off with frequency, even if the filter was flat in amplitude.
Although we don’t know which of Stockman’s experiments suggest that filter
characteristics might evolve with input (the ones we cite don’t), it seems that this
comment is to remind us that our main result (adjustments significantly greater than
zero) implies expansive transduction, regardless of filter characteristics. This
implication is now reiterated in the last paragraph of the manuscript. Furthermore,
our observers made their adjustments on the basis of steady-state observations,
long after any of the dynamics of the filter characteristic would have taken place
(i.e., the 200ms time-evolution of the temporal impulse response).
I expected to see ‘n’ in equations 2 and 3, but this is
missing.
Equation 3 is the first filter of the sandwich; Equation 2 is the second. The non-
linearity comes in-between.
Also, n>1 is assumed (see later, page 13), but since
n<1.0 is mentioned in the Introduction (e.g., n=0.6), as some
earlier studies found compression, the authors might
also explain here why n>1 is being assumed.
OK. Got it. We weren’t sufficiently clear. On page 13 we said, ‘we will adhere to
Stevens' suggestion of a simple power law, where any exponent n > 1 would
produce a positive distortion product (i.e. one with relatively high salience).’ This
wasn’t an assumption that the exponent (n) was greater than 1, it was an
assumption that apparent intensity varies as a simple power function of physical
intensity. Given this assumption, a ‘positive’ distortion product (indicated by a
positive doubler setting) would imply n > 1; a ‘negative’ distortion product (indicated
by a negative doubler setting) would imply n < 1. The revised manuscript says, "For
the present, we will adhere to Stevens' [1] suggestion of a simple power law....In
this case, any exponent n > 1 will produce a positive distortion product (i.e. one
with relatively high salience)."
Results: the authors sometimes appear to include the 60Hz
settings in the grand average and sometimes not. I
suggest always treating 60Hz as a special case, and excluding
all data at this frequency.
In none of our analyses did we pool data from different temporal frequencies!
‘Thus, it might be more accurate to say that our Condition 3
results (both Experiments) are consistent with a linear
psychophysical function mapping power spectral density to
apparent contrast.’
See also Yang & Reeves, Neural Networks 1995, we found that
the power of the VEP is proportional to contrast for
a very large collection of gratings, previously, it was
supposed that VEP amplitude went with log (contrast).
Nice result, but linear transduction from contrast to VEP does not imply anything
about transduction from contrast (or VEP) to apparent contrast.
‘At first glance, both our results and our conclusions
resemble those of Meese, Baker, & Summers [21],….’ I didn’t
follow the authors’ argument about why the judgments should or
should not differ, or why one criterion might be
better or worse than another. I feel that this section should
be shortened to simply saying that further
experimentation will be needed to assess whether their data
and model can be reconciled with the current one. As it
is, this whole rather wordy section seems too vague to add to
one’s understanding of either study.
OK. Paragraph deleted.
Page 19, line 14. The authors have not convinced me that
compression of both signal and noise, with the former less
compressed than the latter, is excluded. I may be missing a
point here.
Thanks to these reviews, we have now come to appreciate that our data do not
constitute compelling evidence against non-linear-transducer models of contrast
masking. In place of the offending lines, we now write, "... we must accept that
contrast processing may involve further non-linearities (compressive or normalising),
which transform the visual signal after averaging has taken place. As both halves of
our annuli would undergo any such transformation, its effects would not be seen in
our data..."
The Discussion correctly points out that stimulus contrast,
not luminance, is the critical variable in these results, but
appears to imply (maybe this was unintentional) that luminance
is not a factor in general. However, if the
experiment were to be repeated at a different luminance
levels, it seems quite possible that the filter parameters or
value of n, or both, would change.
Totally agree. We now write, "we cannot rule out the possibility that transduction
depends on variables (such as the background luminance) we did not manipulate."
Page 18: ‘Thus, despite the individual differences, our
results erect a strong hurdle for models of contrast
masking (e.g., [8]) that rely on compressive transduction.’
I am unhappy with this conclusion as stated. It seems quite
possible that measures of discrimination/ masking and of
brightness enhancement may both depend on contrast, but to
different extents. Such a divergence is common
enough; e.g., as von Kries pointed out, acuity changes rapidly
in the periphery but brightness does not; and it is well
known that detection thresholds are band-pass but contrast
matching above threshold is almost flat over frequency. I
would accept a re-wording such as: ‘Thus, despite the
individual differences, our results erect a strong hurdle for
models of contrast processing that rely on the compressive
transduction illustrated by masking (e.g., [8])’.
We're unhappy with that conclusion too. See above. We have revised it.
Reviewer #2:
1. The finding of an expansive non-linearity for texture
processing echoes the findings of Graham and colleagues (e.g.
Graham & Sutter, 1998; 2000), which argue for an expansive
nonlinearity at the intermediate stages of texture processing
(in between local luminance pick-up and the encoding of the
texture envelope). The stimuli employed by Graham et al. were
very different from the authors’ stimuli, but I presume the
non-linearity mediating both types of stimuli is the
same. Graham & Sutter’s work deserves to be acknowledged and
discussed, even if critically.
Thank you so much for prompting us to read those papers. We now write, " Further
non-linearities of this nature were proposed by Graham and Sutter (1998), who
made a compelling argument in favour of a filter-rectify-filter model for texture
segmentation, in which the rectifying non-linearity is expansive (a power function
with an exponent ‘somewhat higher than 2’) and output of the second filter is
subject to divisive normalisation. Graham & Sutter’s putative second filter effectively
computes the sum or average of different micropatterns’ (either squares of uniform
luminance or grating patches) transduced energies. A similar filter could play a role
in some of our experiments, where subjects were asked to make decisions on the
basis of the average salience of a stimulus with spatially or temporally modulated
energy."
2. In the abstract: “Alternatively, the psychophysical
function can be derived from estimates of the average between
easily discriminable intensities”. Well, this is just one of
many possible alternative scaling methods. The authors later
mention other early scaling methods, but surprisingly never
discuss what for many is the gold standard of modern scaling
procedures: Maximum Likelihood Difference Scaling, or MLDS
(Maloney & Yang, 2003). Unlike MLDS, the method employed by
the authors seems limited in terms of general
applicability. I suspect the authors are aware of this, as
the independent variables in their study are the temporal and
spatial frequencies of the tests, not their
contrasts. Presumably one could not derive the perceptual
scale for contrast using the authors’ method because the
spatio-temporal properties of the match (the “doubler”) and
test stimuli are so different.
Thus, for example, if test contrast was the variable of
interest, a compressive transducer in the match combined with
a linear transducer in the test could produce the same matches
as a linear transducer in the match combined with an expansive
transducer in the test. With MLDS (and most traditional
scaling procedures) the stimuli are self-referential, that is
all stimuli have identical spatio-temporal characteristics,
apart from, of course, the dimension of interest (e.g.
contrast). It would be helpful if the authors’ method were
discussed in the context of modern scaling methods such as
MLDS which do not suffer from such limitations.
There is no daylight between the notion of a perceptual scale and our definition of a
transducer (mapping average intensity to average apparent intensity). Initially, we
did claim to have derived the transducer for contrast (our reply to his first point
notwithstanding), implicitly assuming that it was invariant with the spatio-temporal
frequency of its modulation. We now recognise that the square-law non-linearity
consistent with all our data may nonetheless not be the only non-linearity between
physical intensity and apparent intensity. We have made this clear in the
aformentioned new paragraph.
3. Methods. I found the methods section rather opaque,
requiring several readings to get the gist. Some suggestions
for improvement:
a). In Eq. 1 what is C0? Is this the contrast of the average
annulus luminance with its grey background? If so what are the
units of C0 (Weber?) and what are its values for the various
stimuli?
C0 was (and is) defined in the paragraph preceding Eq. 1.
b) In Eq. 1 what is the significance of the factors of 8 and
4?
These are simply powers of 2 that appear in the expression's most compact form.
We have adopted the other referee's suggestion for re-formulating Eq. 1.
c) To grasp the relationship between the parameters w and a in
Eq. 1 it might help if a figure was provided of the luminance
profile around the annulus at one time during the temporal
waveform for Experiment 1 and/or of the spatial modulation
used in Experiment 2.
Done. See Fig. 1.
d) From Fig. 1 it looks as though the luminance of the trough
of the test modulations in b and f, or the peak in d is equal
to the background grey. Is this the case? If so is w and a
therefore a function of C0?
It is the case, yes; but no, we fixed w at 0.5 in both experiments. Parameter a was
subject to the constraints described in the sentence immediately before Fig. 1 (C0
played no role in these constraints).
e) I could not fathom the reason for calling the match
stimulus the “doubler”. What exactly was it doubling? If I
understand the method correctly, the task for the subject was
to set the contrast of the match to equal either the average
or the maximum perceived contrast of the test, not to match
the temporal or spatial frequency of the test. If so why not
simply call the match stimulus what it is: the match.
We've settled on the "adjuster."
4. In the luminance modulation condition in Experiment 2 the
modulation introduces local contrast increments and decrements
along the waveform. It is well known from both psychophysics
and physiology that contrast increments and decrements are
processed by different mechanisms, and according to the
seminal work of Whittle (Whittle, 1992) with different
transducer shapes. Both properties of contrast transduction
presumably combine to make the authors’ task difficult and the
results for this condition hard to interpret. This deserves
some discussion.
One of Whittle’s findings was that local (Weber) contrast increments appeared
constant when local Weber contrast increased exponentially. (In Whittle’s phrasing,
brightness increased logarithmically with luminances greater than the background.)
One of Graham & Sutter’s results can be considered a replication of this finding.
Again, we must assume that the expansive non-linearity implied by our data occurs
at a relatively early stage of visual processing. To be consistent with Whittle and
Graham and Sutter, effectively logarithmic compression (or normalisation) must
occur down-stream.
Whittle’s other main finding was that the apparent sizes of local contrast
decrements mirrored those for local contrast increments, only when local contrast
was small. The apparent sizes of large decrements in local contrast, on the other
hand, were best understood within the context of (roughly logarithmic) luminance
transduction, rather than contrast per se.
Whittle found that the symmetry between contrast increments and contrast
decrements broke down for Weber contrasts less than –0.5. Our display could
produce Weber contrasts this low, but only when C0= –0.57 and a > 1.72. Some
observers were never satisfied with adjustments higher than 1.72. Others (PC in
Conditions 2 and 5; JAS in Condition 5) produced them consistently in Experiment
1. Perhaps this is related to the relatively large individual differences in those
conditions.
5. The authors could add some caveats to the conclusion that
contrast transduction is expansive. First, there are many
models of contrast transduction (e.g. Legge & Foley, 1980)
that involve an expansive nonlinearity near threshold followed
by a compressive nonlinearity at suprathreshold contrast. I
presume that the expansive nonlinearity observed in this study
is different from the near-threshold expansion in these
models, and if so this is worth pointing out.
Legge and Foley’s expansive non-linearity was inferred using the implicit
assumption of no uncertainty. Elsewhere (Solomon & Tyler, 2017), we present
evidence inconsistent with this assumption.
Following on from this, it is also worth pointing out the
expansion measured here is for just one contrast level and is
therefore not necessarily a property of the whole contrast
range.
Sure. The revised manuscript says, "Had we collected data using more than one
value of w, a more complicated transducer function might have been indicated”:
6. The corollary to the main conclusion that internal noise
variance for contrast transduction is likely multiplicative is
reasonable given the study’s findings. However the literature
on this subject is extensive and there are many studies that
support the constant noise assumption (e.g. Katkov et al.,
2006a,b; Gorea & Sagi, 2001; Whittle’s 1986/1992 studies, as
argued by Kingdom, 2016), and that the results of some
previous studies supporting multiplicative noise (specifically
Kontsevich et al., 2002) when subject to re-analysis have been
shown to be just as consistent with constant noise (Georgeson
& Meese, 2006). The claim in the Introduction that “..we seem
to have very little evidence supporting the idea of constant
noise” is surely putting it a bit strong, so a more balanced
discussion of this issue would seem warranted.
That’s a fair comment, but we have removed our corollary, given the possibility of
compressive transduction after contrast averaging.
Society Open
