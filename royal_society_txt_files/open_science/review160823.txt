Game-based situation awareness training for child and adult
cyclists
Esko Lehtonen, Jasmiina Airaksinen, Kaisa Kanerva, Anna Rissanen, Riikka Ränninranta
and Veera Åberg
Article citation details
R. Soc. open sci. 4: 160823.
http://dx.doi.org/10.1098/rsos.160823
Review timeline
Original submission: 15 October 2016 Note: Reports are unedited and appear as
1st revised submission: 19 December 2016 submitted by the referee. The review history
2nd revised submission: 3 February 2017 appears in chronological order.
Final acceptance: 23 February 2017
Review History
label_version_1
RSOS-160823.R0 (Original submission)
label_author_1
Review form: Reviewer 1 (Willem Vlakveld)
Is the manuscript scientifically sound in its present form?
No
Are the interpretations and conclusions justified by the results?
Yes
Is the language acceptable?
No
Is it clear how to access all supporting data?
Yes
Do you have any ethical concerns with this paper?
No
Have you any concerns about statistical analyses in this paper?
No
© 2017 The Authors. Published by the Royal Society under the terms of the Creative Commons
Attribution License http://creativecommons.org/licenses/by/4.0/, which permits unrestricted use,
provided the original author and source are credited
2
Recommendation?
label_recommendation_1
Major revision is needed (please make suggestions in comments)
Comments to the Author(s)
label_comment_1
An interactive computer game was developed in which participants watched video clips filmed
from the perspective of a cyclist. Each video was suddenly masked by a gray screen on which 2 or
3 circle appeared. It was the task of participants to select only those circles or that circle on the
spots or spot where a hazard was visible just before the video clip was masked. Hazards could
either be visible other road users on collision course or of who were likely to turn on collision
course (the overt hazards) or object that blocked the view on possible other road users on
collision course (the covert hazards). After a participant had selected a circle or circles the
screenshot of the latest moment the video was visible reappears but with the circles and written
text about why the selected circles or circle was right or wrong superimposed on it. There were
three groups: child cyclists, experienced adult cyclists, and inexperienced adult cyclists.
Measured was how the accuracy in selected circles improved while participants played the game.
Participants’ gaze directions were recorded with a head mounted eye tracker. Working memory
capacity was measured separately after the game. Inexperienced adult cyclists and experienced
adult cyclists did not differ in accuracy scores and were combined in one group. For the groups
also no distinction was found between the accuracy of selected covert hazards and overt hazards.
Therefore there was only one dependent variable regarding accuracy: the sum of the hit rate of
correctly selected hazards and correctly not selected none hazards. For both groups the accuracy
score improved the longer they played the game. There was a main effect of age group (adults
performed better than children) but there was no interaction effect accuracy over time (at the
beginning of the game, at the middle of the game, and at the end of the game) X age group.
Adults fixated more hazard than children and working memory capacity was not a significant
predictor of the accuracy score within each of the two groups. However, it was a significant
predictor when the two groups were combined, but this predictor disappeared when age was
added to the model. This indicates that some other age related predictor than working memory
capacity predicts the accuracy scores (e.g. improved mental models).
This is an important study because lack of situation awareness for latent hazards probably is an
important crash factor for young cyclists and this study shows that it is trainable. The tool to
measure the effectiveness of another hazard perception training program for young cyclists of
this research group applied in an earlier study (Lehtonen, Sahlberg, Rovamo, & Summala) has
become a hazard perception training program in this study by adding feedback to this tool.
I have two major comments:
Some relevant information is missing (see my detailed comments) and words in sentences are
missing (also see my detailed comments).
The purpose of the measurement of gaze directions with a head mounted eye tracker is not clear
to me. What for instance is the association between fixated hazards and the accuracy scores. Does
the number of fixated hazard also increase with phase in the game (beginning, middle, and end)
for both groups? Is the number of fixations a significant predictor in the linear regression with the
accuracy score as dependent variable? I would suggest either leaving the section of gaze
directions out or integrating the results of the gaze directions with the other results. The authors
state that the primary aim was whether the game improved SA for hazard as measured with the
game itself (the accuracy) and eye movements. They haven’t investigated this for the eye
movements.
Minor comments
No information is provided in the abstract about why working memory capacity was measured.
In the abstract the authors speak about targets. I think it is better to speak about hazards (or latent
hazards) or they have to explain what a ‘traffic relevant target is’.
I presume that in line 54 on page 3 (the first page of the introduction) ‘hazard perception skills is
comes..’ a word is missing.
In line 9 of page 4 ‘them’ and ‘to’ have to be reversed.
On page 4 the authors mention studies that show that children are reluctant to act once they have
decided that a gap is acceptable. They do this to indicate that poor hazard perception skills are
3
not the only factor. I think there are many more factors besides poor HP-skills that are relevant
for safe cycling behaviour (e.g. keeping balance (Zeuwts, Vansteenkiste, Cardon, & Lenoir, 2016)
and assessing the speed of other road users (Wann, Poulter, & Purcell, 2011)).
Op page 5 from line 33 to 57, information is provided about the game is too detailed for an
introduction. For the introduction I think it is sufficient to state that the game was based of
SAGAT with feedback.
On page 6 in line 3-5 a hypothesis is mentioned (…better performance in the game was expected
to be positively correlated with looking more and earlier to the targets). However, this hypothesis
is not investigated in the study.
In line 21 on page 6 they speak about WMC capacity. The word capacity has to be deleted
because the C in WMC already stands for capacity. The word ‘a’ at the end of this line has to be
deleted as well.
On page 7 line 27 the authors speak about ‘cyclist (MT)’. What does ‘MT’ mean?
On page 8 is stated that correctly selected hazard was rewarded with 5 points and a not selected
hazard with -5 points. A not selected none hazard was rewarded with 1 point but a wrongly
selected none hazard was not ‘rewarded’ with -1 point. (line 13-18 on page 8). No rationale is
provided for this scoring system. Why not 1 point for a correctly selected hazard, -1 point for a
missed hazard, 1 point for a correctly not selected none hazard, and -1 point for an incorrectly
selected none hazard? What would have been the results when this simple scoring system was
applied?
On page 10 the authors describe a scoring method other than the ‘accuracy method’ based on the
Signal Detection Theory. Op page 10 they do not provide information why they have done this.
When explaining this method they refer to equations in another article. The authors have to
provide these equations in this article and they also have to mention why they have calculated
these different scores. This information now is provided in the results (page 14, section 3.2).
In the text of the Results section no reference is made to the figures 2, 3a, 3b, and 4.
On page 14(line9-15) is mentioned that the response time decreased the longer participants
played the game. Is this for both groups, only the children, or only for the adults?
On page 14 in line 59-60 the authors state that the sensitivity index d’ increased linearly. Figure 3a
shows something different.
The discussion on page 21 starts with a rather long repetition of what is already mentioned in the
introduction (line 6-32). This has to be abbreviated.
I do not understand the sentence “Increase in the accuracy answers be equated with improved in
SA, because it is not possible to give correct answers if the targets were not represented in the
players SA. Line 30-32 0n page 21.
On page 21, line42-43, the authors speak about an assumed learning effect. I haven’t found a
hypothesis about learning effects in this paper.
The authors write: “Even thought (sic) the improvement in accuracy was small, it is noteworthy
that it was produced already after a short playing time. (Line 45-47). The approximate time it toke
to play the game is not mentioned in the study.
On page 23, line 18-32, the authors offer an explanation why experienced adult cyclist and
inexperienced adult cyclists do not differ in accuracy scores. I think one explanation is missing.
Although inexperienced adult cyclists do not cycle, the have gained experience in other traffic
roles. Road users can acquire hazard perception skills in different roles (as a pedestrian, as a
rider, as a car driver). The hazards can be different in these different roles but the concept behind
these hazards are similar. It could be that there is transfer of hazard perception skills from one
traffic role to the other.
In the conclusion on page 23 (line 56-59) the authors write that especially children with their
lower working memory capacity could benefit from training without dual task components. This
not a conclusion based on the results of the present study but something for further research.
On page 24 is mentioned that the poor HP skills of child cyclists is not caused by their limited
working memory capacity but are due to ‘some age related confounding factors’. That adult
cyclists probably have better developed schemata and because of this can recognize more latent
hazard, is not a ‘confounding’ factor but is just another factor than increasing working memory
capacity with age.
References
4
Lehtonen, E., Sahlberg, H., Rovamo, E., & Summala, H. Learning game for training child
bicyclists’ situation awareness. Accident Analysis & Prevention.
doi:http://dx.doi.org/10.1016/j.aap.2016.07.036
Wann, J. P., Poulter, D. R., & Purcell, C. (2011). Reduced Sensitivity to Visual Looming Inflates the
Risk Posed by Speeding Vehicles When Children Try to Cross the Road. Psychological Science,
22(4), 429-434. doi:10.1177/0956797611400917
Zeuwts, L., Vansteenkiste, P., Cardon, G., & Lenoir, M. (2016). Development of cycling skills in 7-
to 12-year-old children. Traffic Injury Prevention, 17(7), 736-742.
doi:10.1080/15389588.2016.1143553
label_author_2
Review form: Reviewer 2
Is the manuscript scientifically sound in its present form?
No
Are the interpretations and conclusions justified by the results?
Yes
Is the language acceptable?
No
Is it clear how to access all supporting data?
Yes
Do you have any ethical concerns with this paper?
No
Have you any concerns about statistical analyses in this paper?
No
Recommendation?
label_recommendation_2
Major revision is needed (please make suggestions in comments)
Comments to the Author(s)
label_comment_2
The present paper evaluates how well children and adults are able to detect road hazards, and
whether this ability improves with practice. Sensitivity was quantified by asking participants to
make hazard detection (yes/no) judgements, in response to passively viewed, pre-recorded
videos. Children are shown to perform more poorly than adults, but the performance of both
children and adults is shown to improve with practice.
Overall I think the research question is cogent, that the methodology was, in general, reasonable,
and I enjoyed reading the paper. However, I do have a number of concerns. In some cases, what
is written appears either factually incorrect, or requires further expansion/clarification. Other
concerns raise question-marks regarding participants’ understanding of the task. The majority of
these concerns could be addressed straightforwardly through revisions. A minority may prove
more challenging.
Major/General Comments:
My main concerns regard the psychophysical structure of the task, which seems to me to be
unfortunately complex (NB: to my mind, it would have been better/easier to ask people to
perform a single, mAFC response at the end of each trial, instead of performing m, non-
5
independent, yes/no responses). If I have understood correctly, each video culminated with
either 2 test locations (1 hazard, 1 non-hazard), or 3 test locations (2 hazard, 1 non-hazard), and
participants were asked to make separate ‘yes’/’no’ responses for each location. Hits were
rewarded with 5 points, Correct rejection = +1 point, False Alarm = +0 point, Miss = -5 points.
Firstly: given the distribution of hazards (more hazards than non-hazards) and also given the
reward structure (large reward for hits, no penalty for false alarm), participants should have been
very strongly biased towards saying ‘yes’. In contrast, the results seemed to show the converse
bias, in favour of saying ‘no’. Does this not suggest that participants didn’t really understand the
task? Are the authors able to explain why people responded in this, distinctly suboptimal
manner?
Secondly: although it is implied that each response was made independently, an ideal observer
who understood the structure of the task would not behave in this manner. For example, an ideal
observer who had successfully detected 2 hazards, would know with certainty that the third
location was empty, and so should always respond ‘no’. Are the authors able to show/evidence
that participants weren’t learning this fact (i.e., learning a better strategy), rather than learning to
be better at detecting hazards per se?
Thirdly: I’m unclear on whether children and adults differed significantly in terms of their overall
points score – can the authors clarify this. My concern is that, given that adults appeared to
exhibit an even more suboptimal bias than children, I find myself wondering whether children
actually scored more poorly than adults? If (*if*) there is no difference in points (or if children
actually scored more highly than adults), then is it reasonable to conclude that children are
poorer at detecting hazards than adults?
P7: “Adults were categorised as experienced cyclists (N=14) or inexperienced cyclists (N=8) based
on their self reported cycling habits.” – why were children not similarly categorised?
P10: I’m unclear on what the point of reporting both %correct and d’ is (and of performing
independent stats using each). If bias==0 then the two measures are equivalent, and to the extend
that bias is not 0, then the metric of %correct is misleading/wrong? I’d suggest concentrating
primarily on d’, and perhaps removing the %correct figure/analysis altogether.
P10: “c is the distance between the criterion and the neutral point”. I believe c is generally defined
as the distance between the observer’s criterion and the *ideal* location (i.e., for the ideal
observer, c==0). Although the ideal criterion location is the neutral (‘0’) point in a more typical,
balanced design, in this experiment the design is distinctly unbalanced. Hazards occur more
frequently than non-hazards, and saying ‘yes’ gives a greater expected reward than saying ‘no’.
For both these reasons the ideal criterion will therefore be somewhat negative (c_ideal < 0). The
authors should compute the ideal criterion location explicitly, and then recomputed ‘c’,
accordingly (at which point the values of c will presumably be even greater than those reported
at present)
Learning rates – it would be helpful for the authors to report the number of individuals that
showed improvements, and the average magnitude of their improvement (either numerically,
and/or with an additional figure)
P22: Regarding the explanation of why “there was no difference between overt and covert
targets” – as it currently stands, I don’t find the stated explanation particularly convincing (“[this
was] probably due to the explicit feedback given in the game”). Are the authors able to provide
some evidence to support this claim? For instance, shouldn’t the claimed ‘feedback effect’ be
apparent in the data (e.g., a large improvement in accuracy after the first instance of feedback).
Or, equivalently, shouldn’t scores for covert targets be substantially lower for children in trial 1,
even if there is no overall difference between overt and covert scores when averaging across all 30
trials?
6
Though meaning was generally clear throughout, grammatical errors need to be corrected in all
sections of the manuscript (particularly with respect to use of the definite/indefinite article,
where I believe English and Finnish differ markedly). In some cases what is written may be
confusing for some readers, and could benefit from rewording. For example: “In the visuomotor
tasks fixations concentrate on objects relevant to the ongoing task, also when the peripheral
accuracy would be sufficient enough”.
Minor/Specific Comments:
Abstract: “…children with their lower working memory capacity” – I’m unclear why – both here
and in the discussion – children’s lower working memory capacity is being highlighted, given
that the authors conclude that “performance in the game cannot be explained by the WMC [sic]”.
Have I misunderstood something?
P3: “… a leading cause for hospitalisation…” – can this claim be made more specific/numeric?
P3: “…Children’s accident characteristics suggests that a lack of visual search or anticipation …
are important factors.” – how so?
P5 “Recently, the contribution of working memory capacity … has been studied” – more detail
required. What precisely has been found?
P10: “accuracy… as the sum of the hit rate and correct rejection rate” – In this case accuracy
would vary between 0 and 2, not between 0 and 100%. Presumably ‘sum’ is a typo, and the
combination of Hits and CRs should be multiplied by 100 (i.e., to convert from proportion to
percentage)?
P10: “In SDT…” – I’m not sure that this paragraph is very helpful/necessary. I suspect only those
readers who are already familiar with SDT will understand it, and it ought to be sufficient to
simply reference an appropriate textbook.
P11: “targets were chosen so that they were distinct from the other targets in the clip and
eccentric enough so that glances to them could be distinguished.” – how were ‘distinct enough’
and ‘eccentric enough’ defined?
P11: “…exclusion was based on the accuracy of the 9 point accuracy test” – how so?
P12: “…due to auto-exposure priority setting…” – I don’t know what this means?
P12: “before the actual game the player practised with three video clips… Answers from the
practise clips are not analysed”. I don’t quite understand why these trials were excluded, given
that the aim of the experiment was to examine learning/practise effects. Could a lot of interesting
learning not have occurred during these 3 trials?
P12: It would be helpful to clarify why Welch’s t-test was used
P13: “With both groups… there was a linear increase…” – the data in Fig2 (and even more so, Fig
3A) don’t look particularly linear to me (?) Perhaps, ‘monotonic’ would be more appropriate?
P17: “…marginally slower… p=.061”; “marginally more time… p=.054”. What is the point of
setting a significance level of 0.05 (“Significance level of p < .05 was used”) if you are then going
to claim differences between groups even when p > 0.05? I strongly suggest you rewrite to clarify
that these ‘trends’ were non-significant.
P21: “… children have been found to have poorer SA than adults in traffic” – how so?
P21: “… because there was more locations with a target present than without.” – and also because
of the asymmetric reward structure (see above).
P23: “we did not find the expected difference between inexperienced and experienced cyclists” –
isn’t another potential factor the relatively small sample sizes? (N=14, N=8)
7
label_end_comment
Decision letter (RSOS-160823)
18th November 2016
Dear Dr Lehtonen,
The editors assigned to your paper ("Game-based situation awareness training for child and adult
cyclists") have now received comments from reviewers. We would like you to revise your paper
in accordance with the referee and Subject Editor suggestions which can be found below (not
including confidential reports to the Editor). Please note this decision does not guarantee
eventual acceptance.
Please submit a copy of your revised paper within three weeks (i.e. by the 9th December 2016). If
we do not hear from you within this time then it will be assumed that the paper has been
withdrawn. In exceptional circumstances, extensions may be possible if agreed with the Editorial
Office in advance.We do not allow multiple rounds of revision so we urge you to make every
effort to fully address all of the comments at this stage. If deemed necessary by the Editors, your
manuscript will be sent back to one or more of the original reviewers for assessment. If the
original reviewers are not available we may invite new reviewers.
To revise your manuscript, log into http://mc.manuscriptcentral.com/rsos and enter your
Author Centre, where you will find your manuscript title listed under "Manuscripts with
Decisions." Under "Actions," click on "Create a Revision." Your manuscript number has been
appended to denote a revision. Revise your manuscript and upload a new version through your
Author Centre.
When submitting your revised manuscript, you must respond to the comments made by the
referees and upload a file "Response to Referees" in "Section 6 - File Upload". Please use this to
document how you have responded to the comments, and the adjustments you have made. In
order to expedite the processing of the revised manuscript, please be as specific as possible in
your response.
In addition to addressing all of the reviewers' and editor's comments please also ensure that your
revised manuscript contains the following sections as appropriate before the reference list:
• Ethics statement (if applicable)
If your study uses humans or animals please include details of the ethical approval received,
including the name of the committee that granted approval. For human studies please also detail
whether informed consent was obtained. For field studies on animals please include details of all
permissions, licences and/or approvals granted to carry out the fieldwork.
• Data accessibility
It is a condition of publication that all supporting data are made available either as
supplementary information or preferably in a suitable permanent repository. The data
accessibility section should state where the article's supporting data can be accessed. This section
should also include details, where possible of where to access other relevant research materials
such as statistical tools, protocols, software etc can be accessed. If the data have been deposited in
an external repository this section should list the database, accession number and link to the DOI
for all data from the article that have been made publicly available. Data sets that have been
deposited in an external repository and have a DOI should also be appropriately cited in the
manuscript and included in the reference list.
If you wish to submit your supporting data or code to Dryad (http://datadryad.org/), or modify
your current submission to dryad, please use the following link:
http://datadryad.org/submit?journalID=RSOS&manu=RSOS-160823
8
• Competing interests
Please declare any financial or non-financial competing interests, or state that you have no
competing interests.
• Authors’ contributions
All submissions, other than those with a single author, must include an Authors’ Contributions
section which individually lists the specific contribution of each author. The list of Authors
should meet all of the following criteria; 1) substantial contributions to conception and design, or
acquisition of data, or analysis and interpretation of data; 2) drafting the article or revising it
critically for important intellectual content; and 3) final approval of the version to be published.
All contributors who do not meet all of these criteria should be included in the
acknowledgements.
We suggest the following format:
AB carried out the molecular lab work, participated in data analysis, carried out sequence
alignments, participated in the design of the study and drafted the manuscript; CD carried out
the statistical analyses; EF collected field data; GH conceived of the study, designed the study,
coordinated the study and helped draft the manuscript. All authors gave final approval for
publication.
• Acknowledgements
Please acknowledge anyone who contributed to the study but did not meet the authorship
criteria.
• Funding statement
Please list the source of funding for each author.
Once again, thank you for submitting your manuscript to Royal Society Open Science and I look
forward to receiving your revision. If you have any questions at all, please do not hesitate to get
in touch.
Yours sincerely,
Alice Power
Editorial Coordinator
Royal Society Open Science
on behalf of Essi Viding
Subject Editor, Royal Society Open Science
openscience@royalsociety.org
Associate Editor's comments:
Associate Editor: 1
Comments to the Author:
Two expert reviewers have read the paper and provided helpful comments on how to improve it.
However, they both also raise some major questions that the authors will need to address.
Comments to Author:
Reviewers' Comments to Author:
Reviewer: 1
Comments to the Author(s)
An interactive computer game was developed in which participants watched video clips filmed
from the perspective of a cyclist. Each video was suddenly masked by a gray screen on which 2 or
9
3 circle appeared. It was the task of participants to select only those circles or that circle on the
spots or spot where a hazard was visible just before the video clip was masked. Hazards could
either be visible other road users on collision course or of who were likely to turn on collision
course (the overt hazards) or object that blocked the view on possible other road users on
collision course (the covert hazards). After a participant had selected a circle or circles the
screenshot of the latest moment the video was visible reappears but with the circles and written
text about why the selected circles or circle was right or wrong superimposed on it. There were
three groups: child cyclists, experienced adult cyclists, and inexperienced adult cyclists.
Measured was how the accuracy in selected circles improved while participants played the game.
Participants’ gaze directions were recorded with a head mounted eye tracker. Working memory
capacity was measured separately after the game. Inexperienced adult cyclists and experienced
adult cyclists did not differ in accuracy scores and were combined in one group. For the groups
also no distinction was found between the accuracy of selected covert hazards and overt hazards.
Therefore there was only one dependent variable regarding accuracy: the sum of the hit rate of
correctly selected hazards and correctly not selected none hazards. For both groups the accuracy
score improved the longer they played the game. There was a main effect of age group (adults
performed better than children) but there was no interaction effect accuracy over time (at the
beginning of the game, at the middle of the game, and at the end of the game) X age group.
Adults fixated more hazard than children and working memory capacity was not a significant
predictor of the accuracy score within each of the two groups. However, it was a significant
predictor when the two groups were combined, but this predictor disappeared when age was
added to the model. This indicates that some other age related predictor than working memory
capacity predicts the accuracy scores (e.g. improved mental models).
This is an important study because lack of situation awareness for latent hazards probably is an
important crash factor for young cyclists and this study shows that it is trainable. The tool to
measure the effectiveness of another hazard perception training program for young cyclists of
this research group applied in an earlier study (Lehtonen, Sahlberg, Rovamo, & Summala) has
become a hazard perception training program in this study by adding feedback to this tool.
I have two major comments:
Some relevant information is missing (see my detailed comments) and words in sentences are
missing (also see my detailed comments).
The purpose of the measurement of gaze directions with a head mounted eye tracker is not clear
to me. What for instance is the association between fixated hazards and the accuracy scores. Does
the number of fixated hazard also increase with phase in the game (beginning, middle, and end)
for both groups? Is the number of fixations a significant predictor in the linear regression with the
accuracy score as dependent variable? I would suggest either leaving the section of gaze
directions out or integrating the results of the gaze directions with the other results. The authors
state that the primary aim was whether the game improved SA for hazard as measured with the
game itself (the accuracy) and eye movements. They haven’t investigated this for the eye
movements.
Minor comments
No information is provided in the abstract about why working memory capacity was measured.
In the abstract the authors speak about targets. I think it is better to speak about hazards (or latent
hazards) or they have to explain what a ‘traffic relevant target is’.
I presume that in line 54 on page 3 (the first page of the introduction) ‘hazard perception skills is
comes..’ a word is missing.
In line 9 of page 4 ‘them’ and ‘to’ have to be reversed.
On page 4 the authors mention studies that show that children are reluctant to act once they have
decided that a gap is acceptable. They do this to indicate that poor hazard perception skills are
not the only factor. I think there are many more factors besides poor HP-skills that are relevant
for safe cycling behaviour (e.g. keeping balance (Zeuwts, Vansteenkiste, Cardon, & Lenoir, 2016)
and assessing the speed of other road users (Wann, Poulter, & Purcell, 2011)).
Op page 5 from line 33 to 57, information is provided about the game is too detailed for an
introduction. For the introduction I think it is sufficient to state that the game was based of
SAGAT with feedback.
10
On page 6 in line 3-5 a hypothesis is mentioned (…better performance in the game was expected
to be positively correlated with looking more and earlier to the targets). However, this hypothesis
is not investigated in the study.
In line 21 on page 6 they speak about WMC capacity. The word capacity has to be deleted
because the C in WMC already stands for capacity. The word ‘a’ at the end of this line has to be
deleted as well.
On page 7 line 27 the authors speak about ‘cyclist (MT)’. What does ‘MT’ mean?
On page 8 is stated that correctly selected hazard was rewarded with 5 points and a not selected
hazard with -5 points. A not selected none hazard was rewarded with 1 point but a wrongly
selected none hazard was not ‘rewarded’ with -1 point. (line 13-18 on page 8). No rationale is
provided for this scoring system. Why not 1 point for a correctly selected hazard, -1 point for a
missed hazard, 1 point for a correctly not selected none hazard, and -1 point for an incorrectly
selected none hazard? What would have been the results when this simple scoring system was
applied?
On page 10 the authors describe a scoring method other than the ‘accuracy method’ based on the
Signal Detection Theory. Op page 10 they do not provide information why they have done this.
When explaining this method they refer to equations in another article. The authors have to
provide these equations in this article and they also have to mention why they have calculated
these different scores. This information now is provided in the results (page 14, section 3.2).
In the text of the Results section no reference is made to the figures 2, 3a, 3b, and 4.
On page 14(line9-15) is mentioned that the response time decreased the longer participants
played the game. Is this for both groups, only the children, or only for the adults?
On page 14 in line 59-60 the authors state that the sensitivity index d’ increased linearly. Figure 3a
shows something different.
The discussion on page 21 starts with a rather long repetition of what is already mentioned in the
introduction (line 6-32). This has to be abbreviated.
I do not understand the sentence “Increase in the accuracy answers be equated with improved in
SA, because it is not possible to give correct answers if the targets were not represented in the
players SA. Line 30-32 0n page 21.
On page 21, line42-43, the authors speak about an assumed learning effect. I haven’t found a
hypothesis about learning effects in this paper.
The authors write: “Even thought (sic) the improvement in accuracy was small, it is noteworthy
that it was produced already after a short playing time. (Line 45-47). The approximate time it toke
to play the game is not mentioned in the study.
On page 23, line 18-32, the authors offer an explanation why experienced adult cyclist and
inexperienced adult cyclists do not differ in accuracy scores. I think one explanation is missing.
Although inexperienced adult cyclists do not cycle, the have gained experience in other traffic
roles. Road users can acquire hazard perception skills in different roles (as a pedestrian, as a
rider, as a car driver). The hazards can be different in these different roles but the concept behind
these hazards are similar. It could be that there is transfer of hazard perception skills from one
traffic role to the other.
In the conclusion on page 23 (line 56-59) the authors write that especially children with their
lower working memory capacity could benefit from training without dual task components. This
not a conclusion based on the results of the present study but something for further research.
On page 24 is mentioned that the poor HP skills of child cyclists is not caused by their limited
working memory capacity but are due to ‘some age related confounding factors’. That adult
cyclists probably have better developed schemata and because of this can recognize more latent
hazard, is not a ‘confounding’ factor but is just another factor than increasing working memory
capacity with age.
References
Lehtonen, E., Sahlberg, H., Rovamo, E., & Summala, H. Learning game for training child
bicyclists’ situation awareness. Accident Analysis & Prevention.
doi:http://dx.doi.org/10.1016/j.aap.2016.07.036
Wann, J. P., Poulter, D. R., & Purcell, C. (2011). Reduced Sensitivity to Visual Looming Inflates the
Risk Posed by Speeding Vehicles When Children Try to Cross the Road. Psychological Science,
22(4), 429-434. doi:10.1177/0956797611400917
11
Zeuwts, L., Vansteenkiste, P., Cardon, G., & Lenoir, M. (2016). Development of cycling skills in 7-
to 12-year-old children. Traffic Injury Prevention, 17(7), 736-742.
doi:10.1080/15389588.2016.1143553
Reviewer: 2
Comments to the Author(s)
The present paper evaluates how well children and adults are able to detect road hazards, and
whether this ability improves with practice. Sensitivity was quantified by asking participants to
make hazard detection (yes/no) judgements, in response to passively viewed, pre-recorded
videos. Children are shown to perform more poorly than adults, but the performance of both
children and adults is shown to improve with practice.
Overall I think the research question is cogent, that the methodology was, in general, reasonable,
and I enjoyed reading the paper. However, I do have a number of concerns. In some cases, what
is written appears either factually incorrect, or requires further expansion/clarification. Other
concerns raise question-marks regarding participants’ understanding of the task. The majority of
these concerns could be addressed straightforwardly through revisions. A minority may prove
more challenging.
Major/General Comments:
My main concerns regard the psychophysical structure of the task, which seems to me to be
unfortunately complex (NB: to my mind, it would have been better/easier to ask people to
perform a single, mAFC response at the end of each trial, instead of performing m, non-
independent, yes/no responses). If I have understood correctly, each video culminated with
either 2 test locations (1 hazard, 1 non-hazard), or 3 test locations (2 hazard, 1 non-hazard), and
participants were asked to make separate ‘yes’/’no’ responses for each location. Hits were
rewarded with 5 points, Correct rejection = +1 point, False Alarm = +0 point, Miss = -5 points.
Firstly: given the distribution of hazards (more hazards than non-hazards) and also given the
reward structure (large reward for hits, no penalty for false alarm), participants should have been
very strongly biased towards saying ‘yes’. In contrast, the results seemed to show the converse
bias, in favour of saying ‘no’. Does this not suggest that participants didn’t really understand the
task? Are the authors able to explain why people responded in this, distinctly suboptimal
manner?
Secondly: although it is implied that each response was made independently, an ideal observer
who understood the structure of the task would not behave in this manner. For example, an ideal
observer who had successfully detected 2 hazards, would know with certainty that the third
location was empty, and so should always respond ‘no’. Are the authors able to show/evidence
that participants weren’t learning this fact (i.e., learning a better strategy), rather than learning to
be better at detecting hazards per se?
Thirdly: I’m unclear on whether children and adults differed significantly in terms of their overall
points score – can the authors clarify this. My concern is that, given that adults appeared to
exhibit an even more suboptimal bias than children, I find myself wondering whether children
actually scored more poorly than adults? If (*if*) there is no difference in points (or if children
actually scored more highly than adults), then is it reasonable to conclude that children are
poorer at detecting hazards than adults?
P7: “Adults were categorised as experienced cyclists (N=14) or inexperienced cyclists (N=8) based
on their self reported cycling habits.” – why were children not similarly categorised?
P10: I’m unclear on what the point of reporting both %correct and d’ is (and of performing
independent stats using each). If bias==0 then the two measures are equivalent, and to the extend
12
that bias is not 0, then the metric of %correct is misleading/wrong? I’d suggest concentrating
primarily on d’, and perhaps removing the %correct figure/analysis altogether.
P10: “c is the distance between the criterion and the neutral point”. I believe c is generally defined
as the distance between the observer’s criterion and the *ideal* location (i.e., for the ideal
observer, c==0). Although the ideal criterion location is the neutral (‘0’) point in a more typical,
balanced design, in this experiment the design is distinctly unbalanced. Hazards occur more
frequently than non-hazards, and saying ‘yes’ gives a greater expected reward than saying ‘no’.
For both these reasons the ideal criterion will therefore be somewhat negative (c_ideal < 0). The
authors should compute the ideal criterion location explicitly, and then recomputed ‘c’,
accordingly (at which point the values of c will presumably be even greater than those reported
at present)
Learning rates – it would be helpful for the authors to report the number of individuals that
showed improvements, and the average magnitude of their improvement (either numerically,
and/or with an additional figure)
P22: Regarding the explanation of why “there was no difference between overt and covert
targets” – as it currently stands, I don’t find the stated explanation particularly convincing (“[this
was] probably due to the explicit feedback given in the game”). Are the authors able to provide
some evidence to support this claim? For instance, shouldn’t the claimed ‘feedback effect’ be
apparent in the data (e.g., a large improvement in accuracy after the first instance of feedback).
Or, equivalently, shouldn’t scores for covert targets be substantially lower for children in trial 1,
even if there is no overall difference between overt and covert scores when averaging across all 30
trials?
Though meaning was generally clear throughout, grammatical errors need to be corrected in all
sections of the manuscript (particularly with respect to use of the definite/indefinite article,
where I believe English and Finnish differ markedly). In some cases what is written may be
confusing for some readers, and could benefit from rewording. For example: “In the visuomotor
tasks fixations concentrate on objects relevant to the ongoing task, also when the peripheral
accuracy would be sufficient enough”.
Minor/Specific Comments:
Abstract: “…children with their lower working memory capacity” – I’m unclear why – both here
and in the discussion – children’s lower working memory capacity is being highlighted, given
that the authors conclude that “performance in the game cannot be explained by the WMC [sic]”.
Have I misunderstood something?
P3: “… a leading cause for hospitalisation…” – can this claim be made more specific/numeric?
P3: “…Children’s accident characteristics suggests that a lack of visual search or anticipation …
are important factors.” – how so?
P5 “Recently, the contribution of working memory capacity … has been studied” – more detail
required. What precisely has been found?
P10: “accuracy… as the sum of the hit rate and correct rejection rate” – In this case accuracy
would vary between 0 and 2, not between 0 and 100%. Presumably ‘sum’ is a typo, and the
combination of Hits and CRs should be multiplied by 100 (i.e., to convert from proportion to
percentage)?
P10: “In SDT…” – I’m not sure that this paragraph is very helpful/necessary. I suspect only those
readers who are already familiar with SDT will understand it, and it ought to be sufficient to
simply reference an appropriate textbook.
P11: “targets were chosen so that they were distinct from the other targets in the clip and
eccentric enough so that glances to them could be distinguished.” – how were ‘distinct enough’
and ‘eccentric enough’ defined?
P11: “…exclusion was based on the accuracy of the 9 point accuracy test” – how so?
P12: “…due to auto-exposure priority setting…” – I don’t know what this means?
13
P12: “before the actual game the player practised with three video clips… Answers from the
practise clips are not analysed”. I don’t quite understand why these trials were excluded, given
that the aim of the experiment was to examine learning/practise effects. Could a lot of interesting
learning not have occurred during these 3 trials?
P12: It would be helpful to clarify why Welch’s t-test was used
P13: “With both groups… there was a linear increase…” – the data in Fig2 (and even more so, Fig
3A) don’t look particularly linear to me (?) Perhaps, ‘monotonic’ would be more appropriate?
P17: “…marginally slower… p=.061”; “marginally more time… p=.054”. What is the point of
setting a significance level of 0.05 (“Significance level of p < .05 was used”) if you are then going
to claim differences between groups even when p > 0.05? I strongly suggest you rewrite to clarify
that these ‘trends’ were non-significant.
P21: “… children have been found to have poorer SA than adults in traffic” – how so?
P21: “… because there was more locations with a target present than without.” – and also because
of the asymmetric reward structure (see above).
P23: “we did not find the expected difference between inexperienced and experienced cyclists” –
isn’t another potential factor the relatively small sample sizes? (N=14, N=8)
Author's Response to Decision Letter for (RSOS-160823)
See Appendix A.
label_version_2
RSOS-160823.R1 (Revision)
label_author_3
Review form: Reviewer 1 (Willem Vlakveld)
Is the manuscript scientifically sound in its present form?
Yes
Are the interpretations and conclusions justified by the results?
Yes
Is the language acceptable?
Yes
Is it clear how to access all supporting data?
Yes
Do you have any ethical concerns with this paper?
No
Have you any concerns about statistical analyses in this paper?
No
Recommendation?
label_recommendation_3
Accept with minor revision (please list in comments)
Comments to the Author(s)
label_comment_3
The authors have revised their article thoroughly. All my comments have been addressed
adequately. I now only have some very minor remarks. On page 11 (2.5 Eye movement analysis)
14
they write “The criterion for exclusion from the eye movement analysis was an unsuccessful
calibration of the eye-movement camera.” Eye trackers need to be calibrated in order to verify
and to adjust that the data that is captured via the eye-movement camera is superimposed at the
correct location of the scene camera (also called world camera). When describing what calibration
means the user guide of the pupil eye tracker states: “Pupil uses two cameras. One camera
records a subject's eye movements -- we call this the eye camera. Another camera records the
subject's field of vision -- we call this the world camera. In order to know what someone is
looking at, we must find the parameters to a function that correlates these two streams of
information. “So the criterion is not an unsuccessful calibration of the eye-movement camera, but
a inaccurate match of the data stream from the eye-movement camera and the field of vision from
the scene camera. In the same section the authors state that data from 22 clips was excluded
because the sample rate had dropped to less than 5 Hz. In section 2.7 (Procedure) they state that
the frame rate varied because ‘auto-exposure priority’ was turned on. I do not understand this.
How can turning on auto-exposure priority affect the sample rate? Is this because of overload of
the CPU of the computer or does it mean that the frame rate is automatically adjusted when the
light conditions change?
Further more two two small typos:
On page 10 (2.4 Game performance measures, third paragraph) the sentence is: “In SDT, it is
assumed that a participants estimates the degree they thinks….”. This should be “In SDT, it is
assumed that participants estimate the degree thy think….”.
On page 24 (4.3. Limitations) they write “It possible that players can read..” This should be: “It is
possible that players can read….”
label_author_4
Review form: Reviewer 2
Is the manuscript scientifically sound in its present form?
No
Are the interpretations and conclusions justified by the results?
No
Is the language acceptable?
Yes
Is it clear how to access all supporting data?
Yes
Do you have any ethical concerns with this paper?
No
Have you any concerns about statistical analyses in this paper?
Yes
Recommendation?
label_recommendation_4
Major revision is needed (please make suggestions in comments)
Comments to the Author(s)
label_comment_4
The authors have addressed/responded many of my concerns. However, three of my main issues
remain outstanding.
15
>>> OUTSTANDING COMMENT (1/3)
### Firstly: given the distribution of hazards (more hazards than non¬hazards) and also given
the reward structure (large reward for hits, no penalty for false alarm), participants should have
been very strongly biased towards saying ‘yes’. In contrast, the results seemed to show the
converse bias, in favour of saying ‘no’. Does this not suggest that participants didn’t really
understand the task? Are the authors able to explain why people responded in this, distinctly
suboptimal manner?
* Thank you for suggesting an alternative way to structure the test with only a single yes/no
question. From a point of view of testing it could indeed make it more straightforward to analyse
and interpret. We will surely consider this in the future research.
The task we gave them was to select those locations where was either an overt or covert 'targets'
(road users or occlusions), and leave others unselected, and we are inclined to think that the
participants understood this task quite well. The points were added because they were tought to
introduce game¬like elements to the task and thus increase motivations to answer correctly. We
think that the reason is that the participants really tried to select locations with target, and not to
find out a strategy to maximise their points. However, we have now calculated and included the
information about the points, which shows that there is still relatively high correlation between
the points and accuracy.
I thank the authors for their thanks, but they do not appear to have answered my question. Do
the statistics of the task not provide a very strong incentive to respond ‘yes’ to every location?
And do the results not show the opposite bias (a over-tendency to respond ‘no’)? Have I
misunderstood? If not, then I think the reader should be alerted to this anomaly, and some
explanation given (an error in calculation? Did people not understand the scoring system? Or are
participants somehow just innately predisposed to be very conservative in their responses on this
task, for some reason?)
>>> OUTSTANDING COMMENT (2/3)
### Secondly: although it is implied that each response was made independently, an ideal
observer who understood the structure of the task would not behave in this manner. For
example, an ideal observer who had successfully detected 2 hazards, would know with certainty
that the third location was empty, and so should always respond ‘no’. Are the authors able to
show/evidence that participants weren’t learning this fact (i.e., learning a better strategy), rather
than learning to be better at detecting hazards per se?
* We said them that any of the locations or all of them could contain a hazard. In one practise clip
and in two game clips all the locations had a target, so it is unlikely that the players would have
started to rely on this kind of strategy.
This would seem to contradict what is stated in the text: “The video clips were chosen so that
they included a situation where it was possible to choose 2 or 3 locations of which 1 or 2 had a
target present and other rest were empty [-sic]”. Does this not imply that there could never be 3
hazards? Perhaps this statement needs to be reworded.
>>> OUTSTANDING COMMENT (3/3)
### P10: “c is the distance between the criterion and the neutral point”. I believe c is generally
defined as the distance between the observer’s criterion and the *ideal* location (i.e., for the ideal
observer, c==0). Although the ideal criterion location is the neutral (‘0’) point in a more typical,
balanced design, in this experiment the design is distinctly unbalanced. Hazards occur more
frequently than non¬hazards, and saying ‘yes’ gives a greater expected reward than saying ‘no’.
For both these reasons the ideal criterion will therefore be somewhat negative (c_ideal < 0). The
authors should compute the ideal criterion location explicitly, and then recomputed ‘c’,
accordingly (at which point the values of c will presumably be even greater than those reported
at present)
* …Regarding this specific point, the definition of c is based on Stanislaw and Todorov (1999)
who write: 'c is defined as the distance between the criterion and the neutral point, where neither
16
response is favored. The neutral point is located where the noise and signal distributions cross
over (i.e., where ß = 1). If the criterion is located at this point, c has a value of 0.' p. 140
The equation for the response bias c is:
c = -[ INVPHI(H) + INVPHI(F) ] / 2
INVPHI is 'inverse phi' function, H is the hit rate and F is the false alarm. Stanislaw and Todorov
(1999) define the hit rate and the false alarm rate in the following way (p. 141): 'In the discussion
below, H is used to indicate the hit rate. This rate is found by dividing the number of hits by the
total number of signal trials. Similarly, the false¬alarm rate, F, is found by dividing the number of
false alarms by the total number of noise trials.'
Thus, the hit rate H nor the false alarm rate F do not convey any information on the number of
signal trials (locations with a target) vs the number of noise trials (locations without a target). In
other words, they are agnostic regarding the unbalanced number of hazards and non¬hazards.
The authors are correct in their definition of c. I was unclear in my original criticism. The problem
is that ‘c’ (as thus defined) is simply an inappropriate measure of bias for the present test. To see
why, note that bias is suppose to measure the distance of the observed criterion, k_obs, from the
ideal location, k_ideal (i.e., bias = k_obs – k_ideal). In cases where the ideal criterion is the
midpoint of two equal-variance Gaussians, then k_ideal = 0.5d’ (i.e., bias = k_obs – 0.5d’). Given
the definition of d’, this can be rearrange to produce the formula: bias = -0.5*[invphi(H) +
invphi(F)]. All of this logic is laid out clearly in, for example, pages 27 & 28 of Wickens:
Elementary SDT.
Now the problem is that in the present test the assumption that k_ideal = 0.5d’ is wrong, since,
given the nature of your study design, we know that the ideal location is not the midpoint of the
two distributions. That is, since observers receive more points for hits, and because ‘signal
present’ occurs more often than ‘signal absent’, the ideal strategy would favor saying ‘yes’ over
saying ‘no’. To take an extreme example, if every location was always a target, the ideal strategy
would trivially be to always say ‘yes’, irrespective of what the sensory input was.
Since we know what the statistics of the task are, it should be perfectly feasible to work out what
the correct value of k_ideal are for each observer (i.e., given the estimated values of d’, and
assuming Gaussian equal variance models for signal and noise), and then compute bias correctly,
using bias = k_obs – k_ideal. Alternatively, the authors could remove their bias analysis. I don’t
think, however, that it is acceptable to just leave it as is.
label_end_comment
Decision letter (RSOS-160823.R1)
8th Jan 2017
Dear Dr Lehtonen:
Manuscript ID RSOS-160823.R1 entitled "Game-based situation awareness training for child and
adult cyclists" which you submitted to Royal Society Open Science, has been reviewed. The
comments of the reviewer(s) are included at the bottom of this letter.
Please submit a copy of your revised paper within three weeks (i.e. by the 30th January 2017). If
we do not hear from you within this time then it will be assumed that the paper has been
withdrawn. In exceptional circumstances, extensions may be possible if agreed with the Editorial
Office in advance. We do not allow multiple rounds of revision so we urge you to make every
effort to fully address all of the comments at this stage. If deemed necessary by the Editors, your
manuscript will be sent back to one or more of the original reviewers for assessment. If the
original reviewers are not available we may invite new reviewers.
17
To revise your manuscript, log into http://mc.manuscriptcentral.com/rsos and enter your
Author Centre, where you will find your manuscript title listed under "Manuscripts with
Decisions." Under "Actions," click on "Create a Revision." Your manuscript number has been
appended to denote a revision. Revise your manuscript and upload a new version through your
Author Centre.
When submitting your revised manuscript, you must respond to the comments made by the
referees and upload a file "Response to Referees" in "Section 6 - File Upload". Please use this to
document how you have responded to the comments, and the adjustments you have made. In
order to expedite the processing of the revised manuscript, please be as specific as possible in
your response.
In addition to addressing all of the reviewers' and editor's comments please also ensure that your
revised manuscript contains the following sections before the reference list:
• Ethics statement
If your study uses humans or animals please include details of the ethical approval received,
including the name of the committee that granted approval. For human studies please also detail
whether informed consent was obtained. For field studies on animals please include details of all
permissions, licences and/or approvals granted to carry out the fieldwork.
• Data accessibility
It is a condition of publication that all supporting data are made available either as
supplementary information or preferably in a suitable permanent repository. The data
accessibility section should state where the article's supporting data can be accessed. This section
should also include details, where possible of where to access other relevant research materials
such as statistical tools, protocols, software etc can be accessed. If the data have been deposited in
an external repository this section should list the database, accession number and link to the DOI
for all data from the article that have been made publicly available. Data sets that have been
deposited in an external repository and have a DOI should also be appropriately cited in the
manuscript and included in the reference list.
• Competing interests
Please declare any financial or non-financial competing interests, or state that you have no
competing interests.
• Authors’ contributions
All submissions, other than those with a single author, must include an Authors’ Contributions
section which individually lists the specific contribution of each author. The list of Authors
should meet all of the following criteria; 1) substantial contributions to conception and design, or
acquisition of data, or analysis and interpretation of data; 2) drafting the article or revising it
critically for important intellectual content; and 3) final approval of the version to be published.
All contributors who do not meet all of these criteria should be included in the
acknowledgements.
We suggest the following format:
AB carried out the molecular lab work, participated in data analysis, carried out sequence
alignments, participated in the design of the study and drafted the manuscript; CD carried out
the statistical analyses; EF collected field data; GH conceived of the study, designed the study,
coordinated the study and helped draft the manuscript. All authors gave final approval for
publication.
• Acknowledgements
Please acknowledge anyone who contributed to the study but did not meet the authorship
criteria.
18
• Funding statement
Please list the source of funding for each author.
Once again, thank you for submitting your manuscript to Royal Society Open Science and I look
forward to receiving your revision. If you have any questions at all, please do not hesitate to get
in touch.
Sincerely,
Alice Power
Royal Society Open Science
openscience@royalsociety.org
on behalf of Essi Viding
Subject Editor, Royal Society Open Science
openscience@royalsociety.org
Associate Editor Comments to Author:
Reviewer 2 highlights three outstanding points. The first two should be straightforward enough
to address in the manuscript. The third point is that the bias calculation is incorrect and doesn't
reflect the fact that the ideal strategy would be for the participant to say "yes". I would agree with
the reviewer's suggestion of either a recalculation of the bias or removing this from the
manuscript.
Comments to Author:
Reviewer: 1
Comments to the Author(s)
The authors have revised their article thoroughly. All my comments have been addressed
adequately. I now only have some very minor remarks. On page 11 (2.5 Eye movement analysis)
they write “The criterion for exclusion from the eye movement analysis was an unsuccessful
calibration of the eye-movement camera.” Eye trackers need to be calibrated in order to verify
and to adjust that the data that is captured via the eye-movement camera is superimposed at the
correct location of the scene camera (also called world camera). When describing what calibration
means the user guide of the pupil eye tracker states: “Pupil uses two cameras. One camera
records a subject's eye movements -- we call this the eye camera. Another camera records the
subject's field of vision -- we call this the world camera. In order to know what someone is
looking at, we must find the parameters to a function that correlates these two streams of
information. “So the criterion is not an unsuccessful calibration of the eye-movement camera, but
a inaccurate match of the data stream from the eye-movement camera and the field of vision from
the scene camera. In the same section the authors state that data from 22 clips was excluded
because the sample rate had dropped to less than 5 Hz. In section 2.7 (Procedure) they state that
the frame rate varied because ‘auto-exposure priority’ was turned on. I do not understand this.
How can turning on auto-exposure priority affect the sample rate? Is this because of overload of
the CPU of the computer or does it mean that the frame rate is automatically adjusted when the
light conditions change?
Further more two two small typos:
On page 10 (2.4 Game performance measures, third paragraph) the sentence is: “In SDT, it is
assumed that a participants estimates the degree they thinks….”. This should be “In SDT, it is
assumed that participants estimate the degree thy think….”.
19
On page 24 (4.3. Limitations) they write “It possible that players can read..” This should be: “It is
possible that players can read….”
Reviewer: 2
Comments to the Author(s)
The authors have addressed/responded many of my concerns. However, three of my main issues
remain outstanding.
>>> OUTSTANDING COMMENT (1/3)
### Firstly: given the distribution of hazards (more hazards than non¬hazards) and also given
the reward structure (large reward for hits, no penalty for false alarm), participants should have
been very strongly biased towards saying ‘yes’. In contrast, the results seemed to show the
converse bias, in favour of saying ‘no’. Does this not suggest that participants didn’t really
understand the task? Are the authors able to explain why people responded in this, distinctly
suboptimal manner?
* Thank you for suggesting an alternative way to structure the test with only a single yes/no
question. From a point of view of testing it could indeed make it more straightforward to analyse
and interpret. We will surely consider this in the future research.
The task we gave them was to select those locations where was either an overt or covert 'targets'
(road users or occlusions), and leave others unselected, and we are inclined to think that the
participants understood this task quite well. The points were added because they were tought to
introduce game¬like elements to the task and thus increase motivations to answer correctly. We
think that the reason is that the participants really tried to select locations with target, and not to
find out a strategy to maximise their points. However, we have now calculated and included the
information about the points, which shows that there is still relatively high correlation between
the points and accuracy.
I thank the authors for their thanks, but they do not appear to have answered my question. Do
the statistics of the task not provide a very strong incentive to respond ‘yes’ to every location?
And do the results not show the opposite bias (a over-tendency to respond ‘no’)? Have I
misunderstood? If not, then I think the reader should be alerted to this anomaly, and some
explanation given (an error in calculation? Did people not understand the scoring system? Or are
participants somehow just innately predisposed to be very conservative in their responses on this
task, for some reason?)
>>> OUTSTANDING COMMENT (2/3)
### Secondly: although it is implied that each response was made independently, an ideal
observer who understood the structure of the task would not behave in this manner. For
example, an ideal observer who had successfully detected 2 hazards, would know with certainty
that the third location was empty, and so should always respond ‘no’. Are the authors able to
show/evidence that participants weren’t learning this fact (i.e., learning a better strategy), rather
than learning to be better at detecting hazards per se?
* We said them that any of the locations or all of them could contain a hazard. In one practise clip
and in two game clips all the locations had a target, so it is unlikely that the players would have
started to rely on this kind of strategy.
This would seem to contradict what is stated in the text: “The video clips were chosen so that
they included a situation where it was possible to choose 2 or 3 locations of which 1 or 2 had a
target present and other rest were empty [-sic]”. Does this not imply that there could never be 3
hazards? Perhaps this statement needs to be reworded.
>>> OUTSTANDING COMMENT (3/3)
20
### P10: “c is the distance between the criterion and the neutral point”. I believe c is generally
defined as the distance between the observer’s criterion and the *ideal* location (i.e., for the ideal
observer, c==0). Although the ideal criterion location is the neutral (‘0’) point in a more typical,
balanced design, in this experiment the design is distinctly unbalanced. Hazards occur more
frequently than non¬hazards, and saying ‘yes’ gives a greater expected reward than saying ‘no’.
For both these reasons the ideal criterion will therefore be somewhat negative (c_ideal < 0). The
authors should compute the ideal criterion location explicitly, and then recomputed ‘c’,
accordingly (at which point the values of c will presumably be even greater than those reported
at present)
* …Regarding this specific point, the definition of c is based on Stanislaw and Todorov (1999)
who write: 'c is defined as the distance between the criterion and the neutral point, where neither
response is favored. The neutral point is located where the noise and signal distributions cross
over (i.e., where ß = 1). If the criterion is located at this point, c has a value of 0.' p. 140
The equation for the response bias c is:
c = -[ INVPHI(H) + INVPHI(F) ] / 2
INVPHI is 'inverse phi' function, H is the hit rate and F is the false alarm. Stanislaw and Todorov
(1999) define the hit rate and the false alarm rate in the following way (p. 141): 'In the discussion
below, H is used to indicate the hit rate. This rate is found by dividing the number of hits by the
total number of signal trials. Similarly, the false¬alarm rate, F, is found by dividing the number of
false alarms by the total number of noise trials.'
Thus, the hit rate H nor the false alarm rate F do not convey any information on the number of
signal trials (locations with a target) vs the number of noise trials (locations without a target). In
other words, they are agnostic regarding the unbalanced number of hazards and non¬hazards.
The authors are correct in their definition of c. I was unclear in my original criticism. The problem
is that ‘c’ (as thus defined) is simply an inappropriate measure of bias for the present test. To see
why, note that bias is suppose to measure the distance of the observed criterion, k_obs, from the
ideal location, k_ideal (i.e., bias = k_obs – k_ideal). In cases where the ideal criterion is the
midpoint of two equal-variance Gaussians, then k_ideal = 0.5d’ (i.e., bias = k_obs – 0.5d’). Given
the definition of d’, this can be rearrange to produce the formula: bias = -0.5*[invphi(H) +
invphi(F)]. All of this logic is laid out clearly in, for example, pages 27 & 28 of Wickens:
Elementary SDT.
Now the problem is that in the present test the assumption that k_ideal = 0.5d’ is wrong, since,
given the nature of your study design, we know that the ideal location is not the midpoint of the
two distributions. That is, since observers receive more points for hits, and because ‘signal
present’ occurs more often than ‘signal absent’, the ideal strategy would favor saying ‘yes’ over
saying ‘no’. To take an extreme example, if every location was always a target, the ideal strategy
would trivially be to always say ‘yes’, irrespective of what the sensory input was.
Since we know what the statistics of the task are, it should be perfectly feasible to work out what
the correct value of k_ideal are for each observer (i.e., given the estimated values of d’, and
assuming Gaussian equal variance models for signal and noise), and then compute bias correctly,
using bias = k_obs – k_ideal. Alternatively, the authors could remove their bias analysis. I don’t
think, however, that it is acceptable to just leave it as is.
Author's Response to Decision Letter for (RSOS-160823.R1)
See Appendix B.
21
label_version_3
RSOS-160823.R2 (Revision)
label_author_5
Review form: Reviewer 2
Is the manuscript scientifically sound in its present form?
Yes
Are the interpretations and conclusions justified by the results?
Yes
Is the language acceptable?
Yes
Is it clear how to access all supporting data?
Yes
Do you have any ethical concerns with this paper?
No
Have you any concerns about statistical analyses in this paper?
No
Recommendation?
label_recommendation_5
Accept as is
Comments to the Author(s)
label_comment_5
The authors have addressed all of my earlier criticisms.
P11, L6: I suggest deleting these words (which will likely be confusing for most readers): "given
the fact that there were more locations with a target than locations without". Alternatively they
could be expanded and put into a footnote.
label_end_comment
Decision letter (RSOS-160823.R2)
23rd February 2017
Dear Dr Lehtonen,
I am pleased to inform you that your manuscript entitled "Game-based situation awareness
training for child and adult cyclists" is now accepted for publication in Royal Society Open
Science.
You can expect to receive a proof of your article in the near future. Please contact the editorial
office (openscience_proofs@royalsociety.org and openscience@royalsociety.org) to let us know if
you are likely to be away from e-mail contact. Due to rapid publication and an extremely tight
schedule, if comments are not received, your paper may experience a delay in publication.
Royal Society Open Science operates under a continuous publication model
(http://bit.ly/cpFAQ). Your article will be published straight into the next open issue and this
will be the final version of the paper. As such, it can be cited immediately by other researchers.
22
As the issue version of your paper will be the only version to be published I would advise you to
check your proofs thoroughly as changes cannot be made once the paper is published.
In order to raise the profile of your paper once it is published, we can send through a PDF of your
paper to selected colleagues. If you wish to take advantage of this, please reply to this email with
the name and email addresses of up to 10 people who you feel would wish to read your article.
On behalf of the Editors of Royal Society Open Science, we look forward to your continued
contributions to the Journal.
Kind regards,
Alice Power
Editorial Coordinator
Royal Society Open Science
openscience@royalsociety.org
http://rsos.royalsocietypublishing.org/
Associate Editor Comments to Author:
Comments to the Author:
The reviewer suggests the following minor editorial change on page 11 that you may wish to
change.
"P11, L6: I suggest deleting these words (which will likely be confusing for most readers): "given
the fact that there were more locations with a target than locations without". Alternatively they
could be expanded and put into a footnote".
Reviewer(s)' Comments to Author:
Reviewer: 2
Comments to the Author(s)
The authors have addressed all of my earlier criticisms.
P11, L6: I suggest deleting these words (which will likely be confusing for most readers): "given
the fact that there were more locations with a target than locations without". Alternatively they
could be expanded and put into a footnote.
manuscript. Below we address the points raised by the reviewers. We have quoted every comment and
then given our response.
Reviewers' comments start with ###, our responses with *.
Reviewer: 1
### … This is an important study because lack of situation awareness for latent hazards probably is an
important crash factor for young cyclists and this study shows that it is trainable. The tool to measure
the effectiveness of another hazard perception training program for young cyclists of this research group
applied in an earlier study (Lehtonen, Sahlberg, Rovamo, & Summala) has become a hazard perception
training program in this study by adding feedback to this tool. I have two major comments: Some
relevant information is missing (see my detailed comments) and words in sentences are missing (also
see my detailed comments).
* We are very glad that the reviewer 1 found the topic of the study important. Below, we have address
the points raised.
### The purpose of the measurement of gaze directions with a head mounted eye tracker is not clear
to me. What for instance is the association between fixated hazards and the accuracy scores. Does the
number of fixated hazard also increase with phase in the game (beginning, middle, and end) for both
groups? Is the number of fixations a significant predictor in the linear regression with the accuracy score
as dependent variable? I would suggest either leaving the section of gaze directions out or integrating
the results of the gaze directions with the other results. The authors state that the primary aim was
whether the game improved SA for hazard as measured with the game itself (the accuracy) and eye
movements. They haven’t investigated this for the eye movements.
* We have now reported the association of the accuracy and eye movement parameters. Because there
was only 10 targets where an area of Interest could be defined without any overlap with other targets, it
is not well justified to make an analysis of the learning effect. Because the order of the clips and thus
also the location of 10 clips used in the eye movement analysis was random, the clips in each phase for
each participant would be different. That would make it analysis very difficult. We have now added
discussion regarding this point.
### Minor comments
### No information is provided in the abstract about why working memory capacity was measured.
In the abstract the authors speak about targets. I think it is better to speak about hazards (or latent
hazards) or they have to explain what a ‘traffic relevant target is’.
* We have now added a short mention about the working memory “The effect of executive working
memory on situation awareness was also studied.” and changed targets to hazards. It is indeed better to
talk about hazards in the abstract.
### I presume that in line 54 on page 3 (the first page of the introduction) ‘hazard perception skills is
comes..’ a word is missing.
* Yes, there was an error which is now corrected to: 'It has been suggested that the main source of
individual differences in HP skill is the ability to use cues to predict latent hazards.'
### In line 9 of page 4 ‘them’ and ‘to’ have to be reversed.
* The order has been corrected.
### On page 4 the authors mention studies that show that children are reluctant to act once they have
decided that a gap is acceptable. They do this to indicate that poor hazard perception skills are not the
only factor. I think there are many more factors besides poor HP-skills that are relevant for safe cycling
behaviour (e.g. keeping balance (Zeuwts, Vansteenkiste, Cardon, & Lenoir, 2016) and assessing the
speed of other road users (Wann, Poulter, & Purcell, 2011)).
* We have now completely revised this section to include more complete and balanced discussion of age
adults' [7,21,29,30]<U+2060>. Covert hazards, like an approaching vehicle which is occluded by road curviness or
parked cars, are especially challenging for children to notice [7,8]<U+2060>. This can be partly due to their lack of
experience in traffic, but their ongoing perceptual, cognitive and motor development play a major role
[31]<U+2060>. Compared with adults, children have less developed attentional skills [32–34]<U+2060>, which can affect
their ability to acquire SA. They are also less sensitive to the visual looming effect which makes it harder
for them to spot an approaching car [35]<U+2060>.In dual-task settings, they often prioritise motor tasks over
perceptual or cognitive tasks [36,37]<U+2060> and poorly coordinate their movements relative to the other
dynamically moving road users [38,39]<U+2060>.
### Op page 5 from line 33 to 57, information is provided about the game is too detailed for an
introduction. For the introduction I think it is sufficient to state that the game was based of SAGAT with
feedback.
* We have now shortened this section in the introduction. In order to make sure that also readers who
are not familiar with SAGAT could understand the basic idea, we still shortly explain how the game
functions. However, the detailed description of the targets/hazards has been moved to the methods.
### On page 6 in line 3-5 a hypothesis is mentioned (…better performance in the game was expected
to be positively correlated with looking more and earlier to the targets). However, this hypothesis is not
investigated in the study.
* Yes, these should have been included. We have now reported the associations in the results.
### In line 21 on page 6 they speak about WMC capacity. The word capacity has to be deleted because
the C in WMC already stands for capacity. The word ‘a’ at the end of this line has to be deleted as well.
* We completely agree. These writing mistakes has been now corrected.
### On page 7 line 27 the authors speak about ‘cyclist (MT)’. What does ‘MT’ mean?
* MT was referring to Marko Tikka, who has been mentioned in the acknowledgements. We have
removed the initials because they are probably more confusing than helpful.
### On page 8 is stated that correctly selected hazard was rewarded with 5 points and a not selected
hazard with -5 points. A not selected none hazard was rewarded with 1 point but a wrongly selected
none hazard was not ‘rewarded’ with -1 point. (line 13-18 on page 8). No rationale is provided for this
scoring system. Why not 1 point for a correctly selected hazard, -1 point for a missed hazard, 1 point for
a correctly not selected none hazard, and -1 point for an incorrectly selected none hazard? What would
have been the results when this simple scoring system was applied?
* This slightly complicated scoring system was a compromise. The motivation was to give a message
that it is never wrong to suspect that there is a hazard somewhere. Better safe than sorry. However, we
still wanted to reward not selecting the empty locations, because otherwise it would be the best strategy
to select all the locations in order to gain the maximum number of points. The locations with a hazard
were given 5 or -5 points, because we wanted to contrast them to the empty one.
The motivation of the scoring system is now briefly explained in 2.3.: 'The motivation of the points
system was to reward correct selection of locations with a target, but at the same time to give the
message that it is never wrong to play it safe and suspect that there might be something. However, it
was still necessary to reward players for not selecting empty locations, because otherwise selecting all
locations would have been an optimal strategy for gaining points.'
### On page 10 the authors describe a scoring method other than the ‘accuracy method’ based on the
Signal Detection Theory. Op page 10 they do not provide information why they have done this. When
explaining this method they refer to equations in another article. The authors have to provide these
equations in this article and they also have to mention why they have calculated these different scores.
This information now is provided in the results (page 14, section 3.2).
* We have now added the motivation to make additional analysis with Signal Detection Theory. The key
reason for doing this is to make sure the accuracy is indeed related to better discrimination of the
targets and not to general tendency to select a location.
### In the text of the Results section no reference is made to the figures 2, 3a, 3b, and 4.
* We are sorry for the omission. The appropriate references has been now added.
### On page 14(line9-15) is mentioned that the response time decreased the longer participants
played the game. Is this for both groups, only the children, or only for the adults?
* The analysis was similar to the accuracy analysis, and it really should have been reported in the same
way. The details has been now included to the manuscript. Polynomial contrasts indicated linear
decrease and there was no significant effects for the age group nor for the interaction.
### On page 14 in line 59-60 the authors state that the sensitivity index d’ increased linearly. Figure 3a
shows something different.
* It's true that based on the figure the trend does not look linear, but quadratic. We used polynomial
contrasts to investigate the trend and found that only the linear term was significant, but the quadratic
term was not. In other words, based on the contrast analysis, it cannot be ruled out that the quadratic
effect is just random variation. Because currently the text and the figure seem to be in mismatch we
removed the 'there was a linear increase' and added: 'Polynomial contrasts indicated that the increase
was linear.' The same applies to all the relevant analyses.
### The discussion on page 21 starts with a rather long repetition of what is already mentioned in the
introduction (line 6-32). This has to be abbreviated.
* The beginning of the discussion has been now substantially abbreviated as suggested.
### I do not understand the sentence “Increase in the accuracy answers be equated with improved in
SA, because it is not possible to give correct answers if the targets were not represented in the players
SA. Line 30-32 0n page 21.
* This sentence has been removed as part of the abbreviation and clarification.
### On page 21, line42-43, the authors speak about an assumed learning effect. I haven’t found a
hypothesis about learning effects in this paper.
* This sentence has been rewritten as: 'The increase in accuracy was accompanied by a decrease in
response time, which would be expected if the players learn more effective ways to acquire SA.'
### The authors write: “Even thought (sic) the improvement in accuracy was small, it is noteworthy
that it was produced already after a short playing time. (Line 45-47). The approximate time it toke to
play the game is not mentioned in the study.
The information of the time it took to play the game, as well as the information of the duration of the
clips, have been now added to the methods section: 'Playing the game took 15-20 minutes, of which 5
min and 44 s was spent watching the videos.'
### On page 23, line 18-32, the authors offer an explanation why experienced adult cyclist and
inexperienced adult cyclists do not differ in accuracy scores. I think one explanation is missing. Although
inexperienced adult cyclists do not cycle, the have gained experience in other traffic roles. Road users
can acquire hazard perception skills in different roles (as a pedestrian, as a rider, as a car driver). The
hazards can be different in these different roles but the concept behind these hazards are similar. It
could be that there is transfer of hazard perception skills from one traffic role to the other.
* Thank you for suggesting this additional point of view. We have now added this to the discussion.
### In the conclusion on page 23 (line 56-59) the authors write that especially children with their lower
working memory capacity could benefit from training without dual task components. This not a
conclusion based on the results of the present study but something for further research.
* We have removed that from the conclusion, because it is not clearly based on the current data.
Instead, only present this idea in the discussion.
### On page 24 is mentioned that the poor HP skills of child cyclists is not caused by their limited
working memory capacity but are due to ‘some age related confounding factors’. That adult cyclists
probably have better developed schemata and because of this can recognize more latent hazard, is not a
‘confounding’ factor but is just another factor than increasing working memory capacity with age.
* We agree, it should not be 'confounding'. We have changed this to: 'Instead, there must be some
other factor involved.' Then we proceed to discuss what it could be.
Reviewer: 2
### … Overall I think the research question is cogent, that the methodology was, in general,
reasonable, and I enjoyed reading the paper. However, I do have a number of concerns. In some cases,
what is written appears either factually incorrect, or requires further expansion/clarification. Other
concerns raise question-marks regarding participants’ understanding of the task. The majority of these
concerns could be addressed straightforwardly through revisions. A minority may prove more
challenging.
* We thank for the generally positive evaluation of the paper. Below we present our responses.
### Major/General Comments:
### My main concerns regard the psychophysical structure of the task, which seems to me to be
unfortunately complex (NB: to my mind, it would have been better/easier to ask people to perform a
single, mAFC response at the end of each trial, instead of performing m, non-independent, yes/no
responses). If I have understood correctly, each video culminated with either 2 test locations (1 hazard,
1 non-hazard), or 3 test locations (2 hazard, 1 non-hazard), and participants were asked to make
separate ‘yes’/’no’ responses for each location. Hits were rewarded with 5 points, Correct rejection = +1
point, False Alarm = +0 point, Miss = -5 points.
Firstly: given the distribution of hazards (more hazards than non-hazards) and also given the reward
structure (large reward for hits, no penalty for false alarm), participants should have been very strongly
biased towards saying ‘yes’. In contrast, the results seemed to show the converse bias, in favour of
saying ‘no’. Does this not suggest that participants didn’t really understand the task? Are the authors
able to explain why people responded in this, distinctly suboptimal manner?
* Thank you for suggesting an alternative way to structure the test with only a single yes/no question.
From a point of view of testing it could indeed make it more straightforward to analyse and interpret. We
will surely consider this in the future research.
The task we gave them was to select those locations where was either an overt or covert 'targets' (road
users or occlusions), and leave others unselected, and we are inclined to think that the participants
understood this task quite well. The points were added because they were tought to introduce game-like
elements to the task and thus increase motivations to answer correctly. We think that the reason is that
the participants really tried to select locations with target, and not to find out a strategy to maximise
their points. However, we have now calculated and included the information about the points, which
shows that there is still relatively high correlation between the points and accuracy.
### Secondly: although it is implied that each response was made independently, an ideal observer
who understood the structure of the task would not behave in this manner. For example, an ideal
observer who had successfully detected 2 hazards, would know with certainty that the third location was
empty, and so should always respond ‘no’. Are the authors able to show/evidence that participants
weren’t learning this fact (i.e., learning a better strategy), rather than learning to be better at detecting
hazards per se?
* We said them that any of the locations or all of them could contain a hazard. In one practise clip and
in two game clips all the locations had a target, so it is unlikely that the players would have started to
rely on this kind of strategy.
Still, it is true that the participants were strongly guided to select at least one location, because all the
clips had at least one location with a target.
### Thirdly: I’m unclear on whether children and adults differed significantly in terms of their overall
points score – can the authors clarify this. My concern is that, given that adults appeared to exhibit an
even more suboptimal bias than children, I find myself wondering whether children actually scored more
poorly than adults? If (*if*) there is no difference in points (or if children actually scored more highly
than adults), then is it reasonable to conclude that children are poorer at detecting hazards than adults?
* The points gained and the accuracy was positively correlated and the adults performed better than
children. We have added a paragraph describing this into the beginning of the results.
### P7: “Adults were categorised as experienced cyclists (N=14) or inexperienced cyclists (N=8) based
on their self reported cycling habits.” – why were children not similarly categorised?
* The children were not categorised based on their cycling habits, because it was deemed too difficult to
get this information reliably. Based on our experiences, the children's self-reported cycling activity is not
very reliable. Asking their parents is not very straightforward either: We were concerned that inclusion
of a long background questionnaire would have increased the opt-out from the experiment.
An extensive background questionnaire would have been needed to trace down the actual pattern of
experience. Cycling with parents in a park is very different to cycling alone or with other children in a
residential street, for example.
The experiment was also run in winter time when very few children cycles actively, so the parents would
have relied on their memories from the past summer time.
Due to these factors, we decided not to make any categorisation for children.
### P10: I’m unclear on what the point of reporting both %correct and d’ is (and of performing
independent stats using each). If bias==0 then the two measures are equivalent, and to the extend that
bias is not 0, then the metric of %correct is misleading/wrong? I’d suggest concentrating primarily on d’,
and perhaps removing the %correct figure/analysis altogether.
We understand the critic of reporting the accuracy answers, because as the reviewer writes, such a
measure is potentially misleading (even though in the current case it does not misrepresent the effects).
However, we see that the great advantage of the accuracy over d' is that it is very easy to understand
and very transparent. Furthermore, from the figure it is easy to see the magnitude of the learning effect
and the group difference and understand what this means in the actual game. Unfortunately d' is not
equally easy to interpret, especially to readers unfamiliar with Signal Detection Theory. Therefore we
have retained the accuracy figure and analysis in the manuscript.
### P10: “c is the distance between the criterion and the neutral point”. I believe c is generally defined
as the distance between the observer’s criterion and the *ideal* location (i.e., for the ideal observer,
c==0). Although the ideal criterion location is the neutral (‘0’) point in a more typical, balanced design,
in this experiment the design is distinctly unbalanced. Hazards occur more frequently than non-hazards,
and saying ‘yes’ gives a greater expected reward than saying ‘no’. For both these reasons the ideal
criterion will therefore be somewhat negative (c_ideal < 0). The authors should compute the ideal
criterion location explicitly, and then recomputed ‘c’, accordingly (at which point the values of c will
presumably be even greater than those reported at present)
* First we want to thank for presenting these question regarding our SDT analysis. There was indeed a
bug (see later) which affected the hit rate and false alarm values which were used in the SDT
calculations, and we would not have necessarily found that without this question. Fortunately, the bug
did not affect the effects or conclusions. Only the magnitude of the values was changed. After correcting
the bug, the c values are indeed much larger.
Regarding this specific point, the definition of c is based on Stanislaw and Todorov (1999) who write:
' c is defined as the distance between the criterion and the neutral point, where neither response is
favored. The neutral point is located where the noise and signal distributions cross over (i.e., where ß =
1). If the criterion is located at this point, c has a value of 0.' p. 140
The equation for the response bias c is:
c = -[ INVPHI(H) + INVPHI(F) ] / 2
INVPHI is 'inverse phi' function, H is the hit rate and F is the false alarm. Stanislaw and Todorov (1999)
define the hit rate and the false alarm rate in the following way (p. 141): 'In the discussion below, H is
used to indicate the hit rate. This rate is found by dividing the number of hits by the total number of
signal trials. Similarly, the false-alarm rate, F, is found by dividing the number of false alarms by the
total number of noise trials.'
Thus, the hit rate H nor the false alarm rate F do not convey any information on the number of signal
trials (locations with a target) vs the number of noise trials (locations without a target). In other words,
they are agnostic regarding the unbalanced number of hazards and non-hazards.
Bug which we found and corrected:
Unfortunately, we had indeed calculated the hit rate and the false alarm rate used in SDT as the
percentage of matching responses among all the responses. In the first version of the manuscript the hit
rate and false alarm rate used in SDT analysis was calculated erroneously as:
hit rate (wrong) = correctly selected locations / all locations
false alarm (wrong) = incorrectly selected locations / all locations
Now the hit rate and false alarm rate has been calculated correctly for the SDT analysis as:
hit rate (correct) = correctely selected locations / all locations with a target
false alarm (correct) = incorrectly selected locatinos / all locations without a target
In other words, in the first version of the manuscript the denominator was too large because:
all locations = all locations with a target + all locations without a target
Fortunately, this error did not change the effects or conclusions. Only the absolute values of d' and c
changed. This is understandable, because the only thing which was affected was the denominator.
All the affected values has been The values reported in Table 1 or used in the analysis of accuracy and in
the analysis of the relationship of the WMC and accuracy were not affected.
### Learning rates – it would be helpful for the authors to report the number of individuals that showed
improvements, and the average magnitude of their improvement (either numerically, and/or with an
additional figure)
* We have added a figure showing this as part of supplementary information.
### P22: Regarding the explanation of why “there was no difference between overt and covert targets”
– as it currently stands, I don’t find the stated explanation particularly convincing (“[this was] probably
due to the explicit feedback given in the game”). Are the authors able to provide some evidence to
support this claim? For instance, shouldn’t the claimed ‘feedback effect’ be apparent in the data (e.g., a
large improvement in accuracy after the first instance of feedback). Or, equivalently, shouldn’t scores for
covert targets be substantially lower for children in trial 1, even if there is no overall difference between
overt and covert scores when averaging across all 30 trials?
* We have now calculated the hit rates of overt and covert targets in the three practise clip. They are
now reported in Table 1 together with the hit rates in the game. The standard deviations are rather
large, which limit the possibility to make any strong conclusions, but the pattern is clear: Hit rates were
lower during the tutorial clips, especially for covert targets. We replaced the previous explanation in the
discussion with this:
'Surprisingly, there was no difference between the overt and covert targets in the current study. The hit
rates in the practise clips suggest that players could have been less accurate with covert targets during
the practise clips, but they quickly learned to look for them as a result of explicit feedback. This raises
two points to consider in the future research: First, have previous studies found a difference between
Second, if the coverts hazards are more challenging, is it possible to teach children to look for them by
giving them clear feedback as in the current study?'
### Though meaning was generally clear throughout, grammatical errors need to be corrected in all
sections of the manuscript (particularly with respect to use of the definite/indefinite article, where I
believe English and Finnish differ markedly). In some cases what is written may be confusing for some
readers, and could benefit from rewording. For example: “In the visuomotor tasks fixations concentrate
on objects relevant to the ongoing task, also when the peripheral accuracy would be sufficient enough”.
* The revised manuscript is now proofread by a native English speaker.
### Minor/Specific Comments:
### Abstract: “…children with their lower working memory capacity” – I’m unclear why – both here and
in the discussion – children’s lower working memory capacity is being highlighted, given that the authors
conclude that “performance in the game cannot be explained by the WMC [sic]”. Have I misunderstood
something?
* We agree that there is no point to highlight it so much. We have removed this from the abstract and
conclusions now. This line of thought belongs more in the discussion/future studies. Instead, we give an
interpretation of the WMC results in the abstract, which are based on our current findings.
### P3: “… a leading cause for hospitalisation…” – can this claim be made more specific/numeric?
* We have now described this more explicitly: 'In Finland between 1998-2007, 47 % of injuries among
0-14 year olds requiring hospital care occurred in cycling.'
### P3: “…Children’s accident characteristics suggests that a lack of visual search or anticipation … are
important factors.” – how so?
* We have now replaced this by:
'Children are often involved in crashes when they have entered the roadway from driveways, sidewalks
or mid-block in a manner which suggests that they have failed to perform a visual search and anticipate
oncoming cars'
### P5 “Recently, the contribution of working memory capacity … has been studied” – more detail
required. What precisely has been found?
We have changed this to:
'Recently, the contribution of working memory capacity (WMC) [45]<U+2060> on HP has been investigated among
adults [46,47]<U+2060>, but no studies linking SA and WMC among children have been made.'
### P10: “accuracy… as the sum of the hit rate and correct rejection rate” – In this case accuracy
would vary between 0 and 2, not between 0 and 100%. Presumably ‘sum’ is a typo, and the combination
of Hits and CRs should be multiplied by 100 (i.e., to convert from proportion to percentage)?
* We have corrected the text: 'Responses in the game were binary (either present or not present). Over
a collection of such responses, it is possible to calculate the accuracy as the percentage of locations
correctly selected or unselected out of all the locations.'
### P10: “In SDT…” – I’m not sure that this paragraph is very helpful/necessary. I suspect only those
readers who are already familiar with SDT will understand it, and it ought to be sufficient to simply
reference an appropriate textbook.
* We have now made the paragraph more compact, but we that presenting some of this information will
be helpful for a reader who is not very familiar with SDT.
### P11: “targets were chosen so that they were distinct from the other targets in the clip and
eccentric enough so that glances to them could be distinguished.” – how were ‘distinct enough’ and
‘eccentric enough’ defined?
with other targets in the video at any moment. The targets were not located at the center of the screen,
so that glances to them could be distinguished from the tendency to look in the direction of the
movement.'
P11: “…exclusion was based on the accuracy of the 9 point accuracy test” – how so?
We have opened our explanation further:
'The criterion for exclusion from the eye movement analysis was an unsuccessful calibration of the eye-
movement camera. Those participants whose average error in a 9 point accuracy test was more than 2
degrees were removed from analysis. In addition, if visual inspection of the eye movement visualisations
indicated that tracking did not function on some part of the screen or was strongly biased, the
participant's data were excluded. The visual inspection of the data was performed before any eye
movement analyses were performed.'
P12: “…due to auto-exposure priority setting…” – I don’t know what this means?
* It means that the video camera was set to prioritise good exposure (= not too dark or too light) even
if it would made the camera slower to capture the frames. The good side of the setting was that the
camera was able to adjust to changes in the illumination conditions when, for example, the seating
position and the content of the video clips changed. Unfortunately, with camera hardware in this specific
device was not really able to do its job. We found the problem in the middle of the measurements, but
decided not to change the setting, because it would have raised an additional question whether the data
recorded with different settings would be comparable.
### P12: “before the actual game the player practised with three video clips… Answers from the
practise clips are not analysed”. I don’t quite understand why these trials were excluded, given that the
aim of the experiment was to examine learning/practise effects. Could a lot of interesting learning not
have occurred during these 3 trials?
* These three clips were there in order to make it sure that all tha participants understood what kind of
things they should pay attention to and how they should answer. During these three clips the
experimenters also explained and answered questions if necessary. Of course a lot of learning does
happen during these three tutorial clips, but the learning is probably strongly related to the logic of the
game itself, and no to the acquisition of SA.
We have now presented the hit rates for overt and covert targets as well as the correct rejection rates in
Table 1 for the tutorial clips also.
### P12: It would be helpful to clarify why Welch’s t-test was used
* Yes, we can do this. In 2.8. we have now the following text: 'Welch's unequal variances t-test was
used when comparing two samples, because equal variance could not be typically assumed.'
It would be wrong and misleading to use Student's t-test when the equal variance cannot be assumed.
From the analysis report which is included with the data, it can be seen that using Student's t-test with
eye movement data gives p < .05 results for all the four measures, but the problem is that the variance
in the groups are rather different.
For consistence, we use Welch's t-test also when the assumption of equal variance could be more readily
done, because the results of Welch' t-test are equal to the Student's t-test when the variances are
equal.
### P13: “With both groups… there was a linear increase…” – the data in Fig2 (and even more so, Fig
3A) don’t look particularly linear to me (?) Perhaps, ‘monotonic’ would be more appropriate?
* It's true that based on the figure the trend does not look linear, but quadratic. We used polynomial
contrasts to investigate the trend and found that only the linear term was significant, but the quadratic
effect is just random variation. Because currently the text and the figure seem to be in mismatch we
removed the 'there was a linear increase' and added: 'Polynomial contrasts indicated that the increase
was linear.' The same applies to all the relevant analyses.
### P17: “…marginally slower… p=.061”; “marginally more time… p=.054”. What is the point of setting
a significance level of 0.05 (“Significance level of p < .05 was used”) if you are then going to claim
differences between groups even when p > 0.05? I strongly suggest you rewrite to clarify that these
‘trends’ were non-significant.
* The text is now changed to: 'The children were slower than adults to make the first glance to a target
and spent less time looking at the examined targets than adults, but these differences were not
statistically significant, Welch’s t(31.41)=-1.937, p=.061, d=0.59, and Welch’s t(22.46)=2.036, p=.054,
d=0.70.'
### P21: “… children have been found to have poorer SA than adults in traffic” – how so?
* Per request of the Reviewer #1 we have rewritten and abbreviated the beginning of the discussion. As
a consequence, this sentence is now removed.
### P21: “… because there was more locations with a target present than without.” – and also because
of the asymmetric reward structure (see above).
* This has been now changed to: '… This suggests that the improvement in accuracy was not due to a
change in the response style, e.g. a player who selects very few locations could increase their accuracy
simply by randomly selecting more locations, because in the game there were more locations with a
target than without, or by inventing a strategy to utilise the reward structure of the game to maximise
points at the expense of accuracy. '
### P23: “we did not find the expected difference between inexperienced and experienced cyclists” –
isn’t another potential factor the relatively small sample sizes? (N=14, N=8)
* This point has been now included.
Reviewer 3:
### The authors investigated the efficacy of a video based game in improving adults’ and childrens’
situation awareness when cycling. I do like the article and any result that can potentially make road
travel safer should not be ignored. The scientific content of the article is well presented and I believe the
paper can make a contribution to the area of hazard perception and situation awareness. The paper
shows that children can learn SA using this task and using the SDT technique goes some way to provide
confirmation of this learning. Eye tracking measures are also included which helps to provide some
insights into the cognitive processing differences involved in SA in adults and children. These are all
strengths of the article. However, there some issues that I feel should be addressed.
* We thank the reviewer for generally positive evaluation of the manuscript. Below we have addressed
the specific points raised by the reviewer.
### Main comment 1
Although the scientific content is presented in a very clear manner, the English grammar needs to
addressed. It will need to be proof-read and revised to uphold the scientific standard of the journal. (But
note that this does not mean it is difficult to read in its current form).
* The manuscript has been now proofread by a native English speaker and changes made accordingly.
### Main comment 2
I think the aspects related to working memory (WM) need a little more attention. I think some of the
difficulty arises when you use the terms HP and SA interchangeably. This is fine for the most part,
however when talking about certain HP tests, usually what’s required is some type of time-sensitive
response e.g. pressing a button or a brake response before you encounter the hazard. This task involves
other cognitive processes (e.g. speed of processing) that are otherwise not utilised to the same extent in
pure SA tasks. HP tasks which target SA more purely would be the likes of the hazard prediction tasks
(e.g. Ventsislavova et al., 2016). SA is more contextually dependent and relies more purely (although
not completely of course) on prior knowledge of the driving scene, and as such, WM might not factor
into SA performance as much. This is, in my opinion, one of the strengths of hazard prediction SA
tasks!
Therefore, without changing much, I think it would be beneficial for the article to separate certain HP
tests and SA a little, and ask the question “is there a link between WM and (specifically) SA…?”.
Although you have correctly identified that there are studies which link WM with some forms of hazard
perception and driving ability I’m unaware of studies showing a link between WM function to specifically
SA skill in driving (although I believe in other fields there has been some work, see Jipp & Ackerman,
2016). But also note that that is in driving, and of course you are dealing with cycling, so it’s certainly
possible that the link between WM and HP isn’t as comparable
* We agree that this is an important thing to clarify, and at the same time, the difference between SA
and HP would deserve an article on its own. Have now attempted to make the distinction more clear by
writing in the introduction: 'The most important distinction between HP and SA is that the HP tasks
measure reactions to hazards, [11,13]<U+2060>, whereas SA tasks probe for the presence of elements, ask for
interpretation of the situation, or ask 'what happens next' [14–17]<U+2060>. This means that HP tasks can be
affected by cognitive processes not used in pure SA tasks, like an individual's interpretation of a hazard,
including their perceived level of risk and their criteria for marking something as a hazard.'
We also thank for the interesting reference to the work by Jipp & Ackermann. We have now shortly
commented it in the discussion: 'Counting Span Task measures especially domain-general or executive
working memory [45,52]<U+2060>. Recently, Jipp and Ackermann [54]<U+2060> found that executive working memory
influences SA in a highly automated air traffic control task. They interpreted these results to mean that
executive working memory counts when the mental models needed in a task are highly complex, which
probably was not the case in the current study. In the game, the acquisition and maintenance of SA may
require mostly domain dependent attentional skills. '
### I feel since you found that adults perform better both at the SA task and the WM task it seems
obvious there would be a positive correlation overall. Indeed, by looking at Figure 4 it is clear there are
two distinct groups. What I think needs to be highlighted more is the second regression performed –
when you split the two groups. It seems you have dismissed this largely by beginning the paragraph
with “noteworthy”. I believe what you have found, i.e. no relationship between WM and SA is an
important null finding as it shows your test may rely more on knowledge – which you correctly allude to
when discussing that age and experience are more important. (But note, I still think WM is likely
important and I like that you also correctly acknowledge that you measured only a specific aspect of
working memory and arguably more appropriate measures of sustained attention akin to driving/cycling
(e.g. Mackenzie and Harris’ work) might be worthy of investigation.)
* Our intention was not to dismiss this. We have now changed the paragraph so that the interpretation
becomes is more clear:
'These regression models suggest that variation in game performance and in PCU score can be explained
by the age group factor. This is especially clear when linear regressions models were calculated for
adults and children separately. PCU score did not predict accuracy among adults (adj. R2=-0.01,
F(1,19)=0.879, p=.36), nor for children (adj. R2=-0.02, F(1,34)=0.231, p=.63).'
### Main comment 3
One other comment relates to the main finding. Essentially, the authors have found that children (and
adults) get better at the SA task. However, practice in any task will improve performance in that specific
task. The study is limited in two ways in this regard. The first is the transferability of the results – and
not simply the transferability to on-road cycling (which the authors acknowledge). Using the SA task
both as the training and assessment tool limits how much you can argue SA skills have been learned; as
they might be specific only to this task. Assessing SA skills in other comparable tests (e.g. What
Happens Next?) post-training would be beneficial. The second is the longitudinal effects of training –
which, again, the authors do indeed mention. A simple future design could take the form of 1) baseline
SA assessment, 2) task intervention using the current task, 3) immediate SA assessment 4) follow-up
SA assessment. Although some limitations are listed - the authors should therefore provide further
discussion points on these limitations above as a more critical evaluation of the research.
that using some other measure of SA would make the result stronger:
'The current results suggest that the game may improve SA, but it is important to note that the current
design was not able to assess if the training in the game transfers to real cycling. It possible that players
can learn visual strategies which support them in the game but would negatively affect steering or
balance in real cycling. Even if the game improved SA in real cycling, it would still be necessary to
evaluate how long-term the effect would be. The case for learning would have been stronger if some
other SA tasks would have been used to confirm learning.'
We have also tried to be very careful not to say that our study would show or demonstrate the game is
effective for learning. Instead, we write in the conclusion that: 'The current results suggest that the
game could be used to train child and adult cyclists' SA, and thus help them to anticipate and avoid
hazards. More research is needed to investigate whether the improvement is permanent and how
training in the game transfers to real-life cycling.'
### Specific comments
Section 1.3 Hazard perception and eye movements
Lines 37 – 54 needs a little more clarification. A naïve reader might find it a little difficult to understand
why all this is important. For example, you mention “…it is not a surprise that the eye movements of the
experienced drivers typically spread out more horizontally…”, but they might not know why an increase
in horizontal scanning is important.
* We decide to integrate this chapter with the previous one and at the same time, we tried to clarify why
this is important. Specifically, we now write that: 'More extensive visual scanning of hazards by
experienced drivers typically results in a larger horizontal spread of eye movements'
###2.3. The Game
What exactly were participants asked to do? I assume it wasn’t to “click on an overt target”, as this
likely wouldn’t make sense to a child.
* That's right. We have clarification to 2.3. Game: 'They were told to keep an eye on the other road
users (overt targets) and occlusions where someone could emerge (covert targets).'
###2.5. Eye movement analyses
The information relating to what eye movements you will be analysing are mentioned in the results
section but should ideally be included here also.
* This information has been now added.
### For your exclusion criteria, do you mean if the sum of the total error for each calibration point
reaches >2, then you exclude? Or do you mean participants were excluded if the average error for the
nine points is 2 deg? If it’s the latter, why was 2 deg chosen? This is rather high for a video based
display screen experiment (usually 0.5 – 1 deg of error is preferable). Especially if the screen was only
23”, then that means distinguishing between AOI fixation locations would be difficult for targets that
appear in close proximity.
* The accuracy measure was average error of the nine point calibration. True, it is surely possible to
achieve 0.5 - 1 deg accuracy in video based design. In good cases, we achieved ~ 1 deg of accuracy. It
is very likely the hardware (it was anyway approximately 800 euros prototype version) was not really
accuracy enough for this purpose.
Distinguishing between proximate AOIs would be indeed very challenging. Therefore, we used only one
AOI per clip and chose such targets which were first either on the right or left side of the screen.
###2.7. Procedure
How far away from the screen were participants facing? It would be useful to provide the visual viewing
angle. This is important because presumably the visual viewing angle was rather small, and if so, your 2
deg exclusion criteria when eye tracking is quite generous (see comment above).
(e.g. so that they would reach the screen). Thus, the viewing distance was also shorted for children. We
have added an addition paragraph of the limitations of the eye movement analysis to the discussion.
### 2.8. Statistical analyses
Performing regression analyses on percentage data is not appropriate and should be transformed (since
you cannot run predictive models with values that range only between 0 – 1), especially given that most
of your values only range from around 60 – 90%. One way to do this is use a Logit function transform.
See one of the references you have mentioned (Mackenzie & Harris, 2016*) for potential guidance.
(*if not online in time, a copy can be found here https://research-repository.st-
andrews.ac.uk/bitstream/handle/10023/9264/Harris_2016_JEP_LinkBetween_AAM.pdf?sequence=1&isAl
lowed=y).
* It is true that using linear regression with untransformed values violates the assumption that the
dependent variable should be unbounded. With this particular data this issue is not very serious. When
comparing the analyses with and without the logit transformation, the results are almost identical. But of
course using logit transformation is the right thing to do. We have now used logit transformed values in
all the regressions calculated. However, we decided to use untransformed values in the Figure 4,
because the untransformed values are easier to interpret. An alternative figure with transformed values
is supplied in the Electronic Supplementary.
### 3. Results
Line 9 – “no practical difference” is not a standard way to describe results. Do you mean no significant
difference?
* Changed: 'The experienced (M=82 %, SD=5] and inexperienced cyclists (M=83 %, SD=6) were in the
same level in accuracy' We also corrected a rounding error 84 % => 83 %.
### 3.1. Learning effect
“Average response time was calculated for each phase”. Was this done for both adults and children
together? If so, it would be more useful to have this broken down for each group separately. Describing
all the effects in the ANOVA fully would provide this and also indicate to the reader if response time
decreased just between start and end, or start and middle, or middle and end etc.
* The analysis was similar to accuracy analysis, and it really should have been reported in the same
way. The details has been now included to the manuscript. Polynomial contrasts indicated linear
decrease and there was no significant effects for the age group nor for the interaction.
### 3.3. Eye movements
I think you need to remind the reader why only 10 clips were chosen and what was the criteria for
selection in this section as well as the Methods.
Also, are you taking the first pixel of when the target appeared as your start time? Or is it when the
target can be identified as a target (which would be a more subjective measure).
* The start time is the time the target was first identifiable. We have replaced the “from the first
appearance” with “from the moment when the target was first identifiable”.
### 3.4. Working memory capacity
Some of your stats are not written in full. Only once are Beta coefficients reported, when these should
be reported in full for every measure. Also your R square change should be reported when reporting
hierarchical type regressions.
* The regression analysis was been now rewritten and the parameters asked have been included.
### 4.2. Adults and children
You’ve mentioned visual scanning here and said “…actually measures relevant cognitive processes”, but
I think you need to be clearer and more specific what you mean by this and why this is important.
* This has been now changed to: 'This suggests that performance in the game is related to visual
scanning of the environment, which is important for acquisition of SA.'
### Be careful with the Mackenzie and Harris (2016) reference here as no HP test was performed in
driving ability and effective eye movements) which included many aspects of driving.
* Thank you for pointing this error out. We have corrected this.
### 4.3. Limitations
I’m not sure I agree that finding no experience differences is a limitation – particularly when this is not
the only study that found no differences. I do agree that such a task may not be sensitive enough to
discriminate between experience groups but compared to driving, the degrees of freedom with which to
identify differences is much narrower. But again I don’t think this is a limitation of the study since it was
not one of the main goals.
* We have moved this from the limitations to the place where we discuss the age group effects.
Thank you for your comments which have been very helpful in improving the manuscript. We hope that
this second revision addresses the outstanding comments by the Reviewer 2. If not, we are also ready
to leave the response bias analysis out.
Reviewer: 1
Comment:
The authors have revised their article thoroughly. All my comments have been addressed adequately. I
now only have some very minor remarks. On page 11 (2.5 Eye movement analysis) they write “The
criterion for exclusion from the eye movement analysis was an unsuccessful calibration of the eye-
movement camera.” Eye trackers need to be calibrated in order to verify and to adjust that the data that
is captured via the eye-movement camera is superimposed at the correct location of the scene camera
(also called world camera). When describing what calibration means the user guide of the pupil eye
tracker states: “Pupil uses two cameras. One camera records a subject's eye movements -- we call this
the eye camera. Another camera records the subject's field of vision -- we call this the world camera. In
order to know what someone is looking at, we must find the parameters to a function that correlates
these two streams of information. “So the criterion is not an unsuccessful calibration of the eye-
movement camera, but a inaccurate match of the data stream from the eye-movement camera and the
field of vision from the scene camera.
Our response:
Yes, we agree. Calibration itself does not tell about the accuracy. By “unsuccessful calibration” we meant
that the two accuracy tests performed before and after each recording session indicated too high
deviation. The accuracy tests measure the deviation between the estimated gaze position (calculated
from the eye camera images with the calibration data) and the actual position of markers which the
participants are asked to gaze at. We have clarified this in the text:
“Participants' data were excluded if the accuracy tests performed before and after a recording session
indicated that the calibration was off or that it had drifted too much during the recording. An average
error of more than two degrees in a 9 point accuracy test was held as an exclusion criteria.”
Comment:
In the same section the authors state that data from 22 clips was excluded because the sample rate had
dropped to less than 5 Hz. In section 2.7 (Procedure) they state that the frame rate varied because
‘auto-exposure priority’ was turned on. I do not understand this. How can turning on auto-exposure
priority affect the sample rate? Is this because of overload of the CPU of the computer or does it mean
that the frame rate is automatically adjusted when the light conditions change?
Our response:
The exact reason for this is not clear to us. We suspect that the hardware (or its built-in software) was
overloaded in some situations when the auto-exposure priority setting was on. We have not found this
behaviour with a new version of the Pupil headsets, so we think that this was a bug in the version of the
headset we used in this study. We have changed the explanation as follows:
“In some clips, the eye camera of the tracker could not hold up a satisfactory frame rate. Excluded clips
had an average sample rate of less than 5 Hz.”
Comment:
Further more two two small typos:
### On page 10 (2.4 Game performance measures, third paragraph) the sentence is: “In SDT, it is
assumed that a participants estimates the degree they thinks….”. This should be “In SDT, it is assumed
that participants estimate the degree thy think….”.
On page 24 (4.3. Limitations) they write “It possible that players can read..” This should be: “It is
possible that players can read….”
Our response:
Thank you for pointing these out. We have corrected them now.
>>> OUTSTANDING COMMENT (1/3)
I thank the authors for their thanks, but they do not appear to have answered my question. Do the
statistics of the task not provide a very strong incentive to respond ‘yes’ to every location? And do the
results not show the opposite bias (a over-tendency to respond ‘no’)? Have I misunderstood? If not,
then I think the reader should be alerted to this anomaly, and some explanation given (an error in
calculation? Did people not understand the scoring system? Or are participants somehow just innately
predisposed to be very conservative in their responses on this task, for some reason?)
Our response:
We have now revised the signal detection theory analysis.
In the first version of the manuscript there was a bug in the calculation of hit rates and false alarm
rates. Unfortunately, the bug fix for the second version introduced another bug: When adjusting for the
0 and 1 values the N was the number of all the possible trials, as it should have been the number of
trials for the specific subset of trials.
When fixing the issue, we decided to use so called ‘log-linear’ transformation for dealing with 0/1 rates
instead (see reference 54, Hautus, 1995), because it should be a better choice based on the literature.
After checking the examples from Wickens we now understand why the use of c as a measure for
response bias is not correct in this case.
We have now calculated observed criterion and ideal criterion given the higher prevalence of locations
with a target according to Wickens (see Methods 2.4). The response bias is now calculated as you have
suggested: bias = observed criterion - ideal criterion.
After all the revision, it actually is so that the response bias is close to zero.
We have not presented the optimal criterion calculation which would have been adjusted both for the
prevalence and the the expected value, because the participants seem to match their criterion according
to the prevalence only. We have added the following to the discussion:
“[...] The players used criterions which were close to the optimal criterions calculated by taking into
account the higher prevalence of locations with a target than without one.
The uneven reward structure of the game could have provided a strong incentive to select locations if
unsure, because hits were rewarded more than false alarms were penalised. However, the players
matched their criterion to the optimal criterion which was adjusted by the prevalence of targets only. If
they would have adjusted for the points too, they should have used less stringent criterions. This
suggests that either the participants chose to use a strategy which maximises the accuracy, or that they
did not understand the point system. “
We replaced Figure 3a and b with a new Table 2, which reports raw hit rates and false alarm rates per
phase, as well as d’, observed criterion, optimal criterion, and response bias.
>>> OUTSTANDING COMMENT (2/3)
### Secondly: although it is implied that each response was made independently, an ideal observer
who understood the structure of the task would not behave in this manner. For example, an ideal
observer who had successfully detected 2 hazards, would know with certainty that the third location was
empty, and so should always respond ‘no’. Are the authors able to show/evidence that participants
weren’t learning this fact (i.e., learning a better strategy), rather than learning to be better at detecting
hazards per se?
* We said them that any of the locations or all of them could contain a hazard. In one practise clip and
in two game clips all the locations had a target, so it is unlikely that the players would have started to
rely on this kind of strategy.
### This would seem to contradict what is stated in the text: “The video clips were chosen so that they
included a situation where it was possible to choose 2 or 3 locations of which 1 or 2 had a target present
statement needs to be reworded.
Our response:
You have understood correctly. We just think that it would be unlikely, but it is true that we cannot know
it for sure. We think that it is not possible to give a definitive answer to that. The experiment was not
designed to take this into account. It is also possible – even likely -- that video clips with 2 or 3 locations
are different to the video clips with only 2 locations, which would make the comparison difficult.
We have now included the following text to the limitations:
“In addition, the allocation of targets may have helped the players. If a clip had three locations, there
was never more than two locations with a target, and if there were two locations, there was more often
one location with a target than two locations with a target. It is possible that players learned to utilise
this statistical feature of the stimuli for their decisions. Further experiments with more a balanced
allocation of targets should be conducted to rule this out.”
>>> OUTSTANDING COMMENT (3/3)
### The authors are correct in their definition of c. I was unclear in my original criticism. The problem
is that ‘c’ (as thus defined) is simply an inappropriate measure of bias for the present test. To see why,
note that bias is suppose to measure the distance of the observed criterion, k_obs, from the ideal
location, k_ideal (i.e., bias = k_obs – k_ideal). In cases where the ideal criterion is the midpoint of two
equal-variance Gaussians, then k_ideal = 0.5d’ (i.e., bias = k_obs – 0.5d’). Given the definition of d’,
this can be rearrange to produce the formula: bias = -0.5*[invphi(H) + invphi(F)]. All of this logic is laid
out clearly in, for example, pages 27 & 28 of Wickens: Elementary SDT.
Now the problem is that in the present test the assumption that k_ideal = 0.5d’ is wrong, since, given
the nature of your study design, we know that the ideal location is not the midpoint of the two
distributions. That is, since observers receive more points for hits, and because ‘signal present’ occurs
more often than ‘signal absent’, the ideal strategy would favor saying ‘yes’ over saying ‘no’. To take an
extreme example, if every location was always a target, the ideal strategy would trivially be to always
say ‘yes’, irrespective of what the sensory input was.
Since we know what the statistics of the task are, it should be perfectly feasible to work out what the
correct value of k_ideal are for each observer (i.e., given the estimated values of d’, and assuming
Gaussian equal variance models for signal and noise), and then compute bias correctly, using bias =
k_obs – k_ideal. Alternatively, the authors could remove their bias analysis. I don’t think, however, that
it is acceptable to just leave it as is.
Our response:
As we wrote in the response to the first point, we have now calculated the observed criterion and
optimal criterion by adjusting for the higher prevalence of targets. The bias was calculated as their
difference as suggested. Because the players seem to match only for the prevalence (not for expected
values/points), we used the optimal criterion based on the prevalence only. This is now discussed also
(as previously shown):
In 4.1
“[...] The players used criterions which were close to the optimal criterions calculated by taking into
account the higher prevalence of locations with a target than without one.
The uneven reward structure of the game could have provided a strong incentive to select locations if
unsure, because hits were rewarded more than false alarms were penalised. However, the players
matched their criterion to the ideal criterion which was adjusted by the prevalence of targets only. If
they would have adjusted for the points too, they should have used less stringent criterions. This
suggests that either the participants chose to use a strategy which maximises the accuracy, or that they
did not understand the point system.”
Society Open
