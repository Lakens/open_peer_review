The left ventral premotor cortex is involved in hand shaping
for intransitive gestures: evidence from a two-person
imitation experiment
Arran T. Reader and Nicholas P. Holmes
Article citation details
R. Soc. open sci. 5: 181356.
http://dx.doi.org/10.1098/rsos.181356
Review timeline
Original submission: 13 November 2017 Note: Reports are unedited and appear as
Revised submission: 16 August 2018 submitted by the referee. The review history
Final acceptance: 13 September 2018 appears in chronological order.
Review History
label_version_1
RSOS-171878.R0 (Original submission)
label_author_1
Review form: Reviewer 1
Is the manuscript scientifically sound in its present form?
No
Are the interpretations and conclusions justified by the results?
No
Is the language acceptable?
No
Is it clear how to access all supporting data?
Not Applicable
Reports © 2018 The Reviewers; Decision Letters © 2018 The Reviewers and Editors;
Responses © 2018 The Reviewers, Editors and Authors. Published by the Royal Society under the
terms of the Creative Commons Attribution License http://creativecommons.org/licenses/by/4.0/,
which permits unrestricted use, provided the original author and source are credited
2
Do you have any ethical concerns with this paper?
No
Have you any concerns about statistical analyses in this paper?
Yes
Recommendation?
label_recommendation_1
Reject
Comments to the Author(s)
label_comment_1
The manuscript by Reader & Homes, investigate the role of the premotor cortex in object-directed
or goal-directed action imitation. Specifically, the authors investigate the effect of left ventral
(PMv) and dorsal (PMd) premotor rTMS stimulation (and vertex as a control) on meaningful or
meaningless action imitation. Effect of brain stimulation is measured on participant movement
kinematics.
In general, the manuscript requires important reorganization. The introduction is weak,
especially in outlining the research question and expected results. The organization of methods is
confusing and would require a more schematic organization. I have important doubts about the
way TMS was applied (i.e. intensities, localization, etc.). The description of analyses is also
confusing to read and, I suspect that at least in some cases, they may not fully correct. The most
critical issue, in my opinion, is that large portions of data seems to be affected by artefact and the
authors made massive use of data interpolation. My biggest fear is that such a large use of
interpolation may have substantially biased the remaining data. Another big issue is that authors
analyse each single sensor as if it was an independent source, while they are not – obvious
biomechanics constraint say the opposite. More importantly, sensors are treated as if by looking
at each one of them, separately, one could tell something about the cortical control of imitation.
This is against what we know about postural coordination and how cortical control of complex
goal directed movement is achieved. Finally, even removing these doubts, most of the results are
not very convincing and do not support authors’ conclusions about the specificity of the PMv
effect.
Please find below the detailed list of comments I can provide.
Introduction
P2, lines 35-36: “Neuroimaging studies of action imitation are frequently focussed on goal-
directed or object-directed behaviour [1, but see 2-14], which may not encompass the same
processes involved in other types of action imitation.”. I would reformulate this sentence.
The first part of the introduction (p2, lines 35-41) is very short. The goal-directed vs object
directed should be illustrated more clearly before discussing the neural regions involved. The
link with apraxia may be increased as well.
Page 2, from line 47, Authors write “F5 has been shown to contain neurons that code for specific
hand-object interactions, rather than their single constituent movements”. However, this goes
against recent monkey data. Please see Tkach, Reimer, & Hatsopoulos, 2007; Kraskov et al., 2009;
Dushanova & Donoghue, 2010; Vigneswaran et al., 2013; Kraskov et al., 2014.
Page 3, from line 51, Authors write “The PMd has also been associated with imitation [16], and
some have suggested that it might be involved in encoding goals for imitation”. However,
encoding the imitation goals is certainly not the main nor the most established idea regarding the
3
function of PMd. PMd is more likely involved in encoding whole arm reaching movements,
building arbitrary sensori-motor association and in action selection.
Description of fMRI studies, page 3 lines 56-67, is confusing.
Page 3 end of intro, is not clear: authors say “We did this by examining both imitation accuracy
(actor-imitator correspondence), and imitation kinematics.”
In general, the whole last paragraph of the introduction is not incisive. I understand that there
were no strong a priori Hp. I’m not asking to force a post-hoc Hp, but I’d like to see a more
focused set of predictions here.
Method
In general, methods are rather confusing. I suggest a substantial editing to simplify and present
all info in a more schematic manner. For example, I would split the section on Materials and
Stimuli. “Motion Capture” should be separated form “TMS & EMG”, “Stimuli” and
“Procedures”. Later these sections are extended and I don’t see why things are repeated twice.
Regarding the stimuli, I also have some doubts. For example, in Figure 1A: the meaningful
actions chosen can be contended. For “shock”: the 3 pictures may have a meaning (left: shock,
middle: speaking loud, right: hearing). For this reason, I would like to see all gestures, may be in
supplementary material.
Later (page 8, lines 199-203), they mention a test to control for this issue: “Following the
completion of all TMS sessions, participants were presented with a questionnaire featuring the
meaningful and meaningless images in a pseudorandom order, with the aim to exclude
participants if they were less than 60% consistent with our own categorisation of the actions. No
participants were excluded on this criterion. Mean±SE rating agreement was 75.0±6.15% for
meaningful actions and 86.5±2.86% for meaningless actions.”
I’m not fully convinced by this “meaningful and meaningless action trials were split into separate
blocks. Task order was counterbalanced across stimulation sites.”. “Since there is evidence to
suggest that performing novel and known actions in a sequence could recruit a single processing
route, whilst presenting them separately recruits separate routes [37, but see 38, and Reader et al.,
under review].”
Was the confederate trained to perform correctly the movement ?
They did three sessions on three days, one by brain region. Were the stimuli presented in each
session the same? If yes, was the order of the session counterbalanced across subjects to avoid an
“habituation” effect?
Each subject was only confederate or imitator or some subjects may have play the two roles (in
different experiments of course)?
Moreover, I also have some concerns about TMS application. Although TMS current direction is
very important, the authors used different coil orientations. This is a bit of a problem.
Also, authors say that “During stimulation over the PMd, the coil was angled such that the wings
did not overlap with the primary motor cortex”. However, there is a negligible field below the
wings and I don’t see why they did this.
In the same section, they also report that “In the case of MEPs being observed with rTMS applied
during natural finger-thumb opposition movements (i.e., repeatedly touching the tip of the
thumb to each of the fingertips), stimulation was reduced by 5% of the maximum stimulator
4
output”. This procedure is sub optimal to achieve their goal. With cyclic movements and [I
suppose] manually operated TMS pulses, one is not able to accurately test if TMS produces a
peripheral response during movements. They should have used a fixed amount of EMG activity
(i.e. 30% maximal) in the most excitable muscle (i.e. FDI).
The whole section 3.4 “TMS parameters” is confusing. Furthermore, authors use a distance
adjusted intensity, but PMd intensity is higher than PMv, why is that?
Page 9, lines 184-197: It is not explained why rTMS was given with that specific timing.
Then, regarding data processing, the authors used RMS jerk of the thumb, but given the kind of
task, I find it quite unusual. I see that velocity and acceleration profiles might be noisy, but if this
is true, things can only be worst when applying a further derivative to the data. In this case, I feel
that the more classical inter-tap interval (ITI) and ITI Sd is much more reliable and informative.
My major concern though is the large number of particularly long artefacts. The descriptive
statistics about average length of interpolated data (page 10, lines 236 and following) are quite
shocking. The number and length of gaps to be interpolated are large enough to doubt how much
real data is present. Also, if artefacts are in part TMS driven, we need to know if the same amount
of reconstruction was needed for PMv, PMd and vertex.
Moving to Data analysis, how did they determine the movement start and end time-point?
P10, lines 250-251: “Any trials in which the participant started moving before the starting tone, or
failed to finish moving within 200ms of the return tone, were also excluded. Following the above
exclusions, a total of 83.4% of trials were maintained for statistical analysis.” 17% of errors is a lot,
given the relaxed criteria set by the authors. Was the task challenging?
I don’t understand how this analysis was performed: “In cases where the t value was at a
significant level for any sequence of samples in the time-series, we performed permutation
testing on the relevant data”.
Later they say that “This is similar to the use of cluster based statistics in fMRI, where a fixed,
arbitrary threshold is used for creating clusters, then a second threshold is calculated for
determining how large a cluster needs to be before it is statistically significant.”. If I understood
correctly, permutations were run on a limited set of time points that were originally significant
with un-corrected t-tests? If this is the case it is a case of double-dipping.
Then I have also some problems on the cross-correlation. P10, lines 256 to 260: “To do this we ran
a cross-correlation analysis between the original actor and imitator velocity curves for each trial
for each tracker, across lags of the difference between the actor and imitator timeseries length
(i.e., if actor movement duration was 755ms, and imitator movement duration was 796ms, then
cross-correlation was performed over a 41ms lag).”
- The rationale behind the choice of best lag is obscure to me. This is the difference total
movement length not the delay between partially overlapping movements. The analysis of lags,
in the subsequent ANOVA, do not say much on kinematic imitation.
- In any case they should report what was the mean and standard deviation lag?
Timeseries should be rescaled to have same length. I would normalize in time and in amplitude,
because what really matters is the shape of velocity profiles, its distribution over time, and not
the speed of execution or the amplitude. The indexes they used are rather unusual: “we took the
maximum r-value (i.e., the point at which the imitator was best correlated with the actor),” the r-
value or the time-point?
5
Later they say: ”We took this time-series-driven approach in order to inform us of possible
differences in peak kinematic values in separate trackers, without the inflated type 1 error that
would occur were we to examine multiple kinematic parameters in multiple trackers.”. I
understand that it doesn’t make much sense to input all sensors data in the same analysis, but
then why they measured so many of them if they do not try to combine them? Movement control
in complex goal-directed action (and imitation is no exception) is not about controlling single
joints separately. Either they formulate some a priori HP, such that one specific marker
kinematics can say something useful, or they must find some way to combine subsets of sensors
into a single signal. Otherwise, reading a long list of independent comparisons, on data that is
certainly not independent, do not help understand the role of premotor cortex on imitation.
Finally, on results. In section 4.1. “Finger-thumb opposition task” all the data report no effect of
stimulation time which the critical effect to demonstrate that rTMS influences behaviour.
Otherwise results can be explained by attentional level in the 3 sessions, the fact that one
stimulation site is just more disturbing for participants.
In section 4.2. “Actor-imitator correspondence” there are a lot of significant effects between
meaningful and meaningless action on different movement features. However, from a motor
control point of view, comparing shoulder or wrist position in the two conditions do not help
much. These are highly interdepended and most critically not independently controlled by the
brain. Authors describe single finger movement features, shoulder or elbow as “gestures” and
this is wrong. Those are simple movements, better, the kinematic recording of an arbitrary body
part. Gestures are higher up in the hierarchy and regards multi-segmental postural
configurations. Furthermore, there were no effects of stimulation time or site which instead are
the critical contrasts.
P10, lines 262-263: they transformed the data before anova. Why? Lack of normality? What about
non parametric tests then?
As I said earlier, when trajectories are not-normalized, the analysis of lags is not really helpful.
Anyway, this part is confusing, it’s difficult to understand what are exactly the two time-series
they compared. Later in the results, they interpret this index as: “Stimulation during observation
compared to stimulation during imitation resulted in a significantly greater lag at the maximum
Z-value” -> “This suggests that participants took longer to optimally match the actor’s hand
movements when they were stimulated during action observation.” (Page 14, Lines 370 to 378)
“Took longer”: Does it mean that they start later the movement or that the movement was slower,
or that the velocity peak was delayed ?
“Optimally match”: does it mean that the higher the correlation value, the longer the time?
I don’t comment any further on the section 4.3. “t-statistic plots and permutation testing”, as I
find it a quite convoluted manner to analyse the data. I’m also not sure I understood what was
done on the data (one of my previous question). Furthermore, I find it conceptually wrong to
analyse each sensor data separately.
label_author_2
Review form: Reviewer 2 (Gregory Kroliczak)
Is the manuscript scientifically sound in its present form?
Yes
Are the interpretations and conclusions justified by the results?
Yes
6
Is the language acceptable?
Yes
Is it clear how to access all supporting data?
Yes
Do you have any ethical concerns with this paper?
No
Have you any concerns about statistical analyses in this paper?
No
Recommendation?
label_recommendation_2
Accept with minor revision (please list in comments)
Comments to the Author(s)
label_comment_2
In their work (MS ID RSOS-171878) entitled “The left ventral premotor cortex is involved in hand
shaping for intransitive gestures: evidence from a two-person imitation experiment”, Reader and
Holmes used repetitive transcranial magnetic stimulation (rTMS) applied over left PMv, left
PMd, or the vertex (a control site) while participants observed or imitated movements performed
by a confederate actor. Significantly lower digit velocity was observed following stimulation over
PMv – but not over PMd or vertex – during action observation (as compared to action imitation).
Thumb movement reversals, as well as accuracy in a finger-thumb opposition task was also
affected following PMv stimulation. Therefore, counter to claims that PMv is critical for
programming object-directed actions, the authors suggest it plays a more general role in hand
shaping, while the targets of actions can be different hand areas themselves. After all, intransitive
(non-object related) gestures were affected following PMv stimulation in their research.
Although some fine-tuning of the argumentation provided in the Introduction might be welcome
(it does not always seem to flow), this is a well thought of and quite original submission,
capitalizing on the neuroimaging and neuropsychological findings related to action observation
and imitation. I do agree with a suggestion that some of the claims from motor-control research
are biased – especially when the emphasis is on object-directed coding rather than on encoding
more general action goals, and a variety of neuroimaging contrasts used in the fMRI literature on
action imitation does not always help in general understanding of the roles of PMv and PMd in
the studied tasks. In short, a good TMS study may shed a new light on these issues, and this
submission meets this goal.
I have only a few requests for clarification:
Although it seemed to me that I understood the timing of stimulation onset (“Stimulation during
observation started 333ms after the point at which the new image appeared on the screen.”
“Stimulation during imitation started 1000ms before the imitator was cued to begin their action.”)
during reading this manuscript again - while writing my opinion - I was not sure why these
specific starting points were selected. (Only when all else is equal, one can compare the effects of
manipulation on the tasks.) I realize that during the analyses some attempts to account for this
discrepancy were made, but I got lost.
As to data pre-processing performed before statistical analyses, it is quite sophisticated and in
general seems right. I am not sure you really need to divide your alpha value cutoff by 8, rather
than by (let’s say) 4, as some of the analyzed traces must be strongly correlated.
7
Is there any update on the status of “Reader et al., under review”. Most journals would not let
you cite any work which is not accepted, yet.
It is a bit difficult to follow all the results you present but your Discussion and conclusions are
generally consistent with what you get. And I like your general conclusions about the putative
role of PMv.
Some fine tuning of the Discussion would be welcome, though.
Minor:
“revealed that that for the thumb RMS”
Gregory Kroliczak
Institute of Psychology
Adam Mickiewicz University in Poznan
label_end_comment
Decision letter (RSOS-171878.R0)
20-Mar-2018
Dear Mr Reader:
Manuscript ID RSOS-171878 entitled "The left ventral premotor cortex is involved in hand
shaping for intransitive gestures: evidence from a two-person imitation experiment" which you
submitted to Royal Society Open Science, has been reviewed. The comments from reviewers are
included at the bottom of this letter.
In view of the criticisms of the reviewers, the manuscript has been rejected in its current form.
However, a new manuscript may be submitted which takes into consideration these comments.
Please note that resubmitting your manuscript does not guarantee eventual acceptance, and that
your resubmission will be subject to peer review before a decision is made.
You will be unable to make your revisions on the originally submitted version of your
manuscript. Instead, revise your manuscript and upload the files via your author centre.
Once you have revised your manuscript, go to https://mc.manuscriptcentral.com/rsos and login
to your Author Center. Click on "Manuscripts with Decisions," and then click on "Create a
Resubmission" located next to the manuscript number. Then, follow the steps for resubmitting
your manuscript.
Your resubmitted manuscript should be submitted by 17-Sep-2018. If you are unable to submit by
this date please contact the Editorial Office.
Please note that Royal Society Open Science will introduce article processing charges for all new
submissions received from 1 January 2018. Charges will also apply to papers transferred to Royal
Society Open Science from other Royal Society Publishing journals, as well as papers submitted
as part of our collaboration with the Royal Society of Chemistry
(http://rsos.royalsocietypublishing.org/chemistry). If your manuscript is submitted and
accepted for publication after 1 Jan 2018, you will be asked to pay the article processing charge,
8
unless you request a waiver and this is approved by Royal Society Publishing. You can find out
more about the charges at http://rsos.royalsocietypublishing.org/page/charges. Should you
have any queries, please contact openscience@royalsociety.org.
We look forward to receiving your resubmission.
Kind regards,
Alice Power
Royal Society Open Science
openscience@royalsociety.org
on behalf of Dr Simon Schultz (Associate Editor) and Antonia Hamilton (Subject Editor)
openscience@royalsociety.org
Associate Editor Comments to Author (Dr Simon Schultz):
Associate Editor: 1
Comments to the Author:
The paper is not suitable for publication at present, however detailed feedback has been given by
the reviewers, which if incorporated fully may allow the paper to be brought into sufficient shape
for publication in our journal.
Reviewers' Comments to Author:
Reviewer: 1
Comments to the Author(s)
The manuscript by Reader & Homes, investigate the role of the premotor cortex in object-directed
or goal-directed action imitation. Specifically, the authors investigate the effect of left ventral
(PMv) and dorsal (PMd) premotor rTMS stimulation (and vertex as a control) on meaningful or
meaningless action imitation. Effect of brain stimulation is measured on participant movement
kinematics.
In general, the manuscript requires important reorganization. The introduction is weak,
especially in outlining the research question and expected results. The organization of methods is
confusing and would require a more schematic organization. I have important doubts about the
way TMS was applied (i.e. intensities, localization, etc.). The description of analyses is also
confusing to read and, I suspect that at least in some cases, they may not fully correct. The most
critical issue, in my opinion, is that large portions of data seems to be affected by artefact and the
authors made massive use of data interpolation. My biggest fear is that such a large use of
interpolation may have substantially biased the remaining data. Another big issue is that authors
analyse each single sensor as if it was an independent source, while they are not – obvious
biomechanics constraint say the opposite. More importantly, sensors are treated as if by looking
at each one of them, separately, one could tell something about the cortical control of imitation.
This is against what we know about postural coordination and how cortical control of complex
goal directed movement is achieved. Finally, even removing these doubts, most of the results are
not very convincing and do not support authors’ conclusions about the specificity of the PMv
effect.
Please find below the detailed list of comments I can provide.
Introduction
9
P2, lines 35-36: “Neuroimaging studies of action imitation are frequently focussed on goal-
directed or object-directed behaviour [1, but see 2-14], which may not encompass the same
processes involved in other types of action imitation.”. I would reformulate this sentence.
The first part of the introduction (p2, lines 35-41) is very short. The goal-directed vs object
directed should be illustrated more clearly before discussing the neural regions involved. The
link with apraxia may be increased as well.
Page 2, from line 47, Authors write “F5 has been shown to contain neurons that code for specific
hand-object interactions, rather than their single constituent movements”. However, this goes
against recent monkey data. Please see Tkach, Reimer, & Hatsopoulos, 2007; Kraskov et al., 2009;
Dushanova & Donoghue, 2010; Vigneswaran et al., 2013; Kraskov et al., 2014.
Page 3, from line 51, Authors write “The PMd has also been associated with imitation [16], and
some have suggested that it might be involved in encoding goals for imitation”. However,
encoding the imitation goals is certainly not the main nor the most established idea regarding the
function of PMd. PMd is more likely involved in encoding whole arm reaching movements,
building arbitrary sensori-motor association and in action selection.
Description of fMRI studies, page 3 lines 56-67, is confusing.
Page 3 end of intro, is not clear: authors say “We did this by examining both imitation accuracy
(actor-imitator correspondence), and imitation kinematics.”
In general, the whole last paragraph of the introduction is not incisive. I understand that there
were no strong a priori Hp. I’m not asking to force a post-hoc Hp, but I’d like to see a more
focused set of predictions here.
Method
In general, methods are rather confusing. I suggest a substantial editing to simplify and present
all info in a more schematic manner. For example, I would split the section on Materials and
Stimuli. “Motion Capture” should be separated form “TMS & EMG”, “Stimuli” and
“Procedures”. Later these sections are extended and I don’t see why things are repeated twice.
Regarding the stimuli, I also have some doubts. For example, in Figure 1A: the meaningful
actions chosen can be contended. For “shock”: the 3 pictures may have a meaning (left: shock,
middle: speaking loud, right: hearing). For this reason, I would like to see all gestures, may be in
supplementary material.
Later (page 8, lines 199-203), they mention a test to control for this issue: “Following the
completion of all TMS sessions, participants were presented with a questionnaire featuring the
meaningful and meaningless images in a pseudorandom order, with the aim to exclude
participants if they were less than 60% consistent with our own categorisation of the actions. No
participants were excluded on this criterion. Mean±SE rating agreement was 75.0±6.15% for
meaningful actions and 86.5±2.86% for meaningless actions.”
I’m not fully convinced by this “meaningful and meaningless action trials were split into separate
blocks. Task order was counterbalanced across stimulation sites.”. “Since there is evidence to
suggest that performing novel and known actions in a sequence could recruit a single processing
route, whilst presenting them separately recruits separate routes [37, but see 38, and Reader et al.,
under review].”
10
Was the confederate trained to perform correctly the movement ?
They did three sessions on three days, one by brain region. Were the stimuli presented in each
session the same? If yes, was the order of the session counterbalanced across subjects to avoid an
“habituation” effect?
Each subject was only confederate or imitator or some subjects may have play the two roles (in
different experiments of course)?
Moreover, I also have some concerns about TMS application. Although TMS current direction is
very important, the authors used different coil orientations. This is a bit of a problem.
Also, authors say that “During stimulation over the PMd, the coil was angled such that the wings
did not overlap with the primary motor cortex”. However, there is a negligible field below the
wings and I don’t see why they did this.
In the same section, they also report that “In the case of MEPs being observed with rTMS applied
during natural finger-thumb opposition movements (i.e., repeatedly touching the tip of the
thumb to each of the fingertips), stimulation was reduced by 5% of the maximum stimulator
output”. This procedure is sub optimal to achieve their goal. With cyclic movements and [I
suppose] manually operated TMS pulses, one is not able to accurately test if TMS produces a
peripheral response during movements. They should have used a fixed amount of EMG activity
(i.e. 30% maximal) in the most excitable muscle (i.e. FDI).
The whole section 3.4 “TMS parameters” is confusing. Furthermore, authors use a distance
adjusted intensity, but PMd intensity is higher than PMv, why is that?
Page 9, lines 184-197: It is not explained why rTMS was given with that specific timing.
Then, regarding data processing, the authors used RMS jerk of the thumb, but given the kind of
task, I find it quite unusual. I see that velocity and acceleration profiles might be noisy, but if this
is true, things can only be worst when applying a further derivative to the data. In this case, I feel
that the more classical inter-tap interval (ITI) and ITI Sd is much more reliable and informative.
My major concern though is the large number of particularly long artefacts. The descriptive
statistics about average length of interpolated data (page 10, lines 236 and following) are quite
shocking. The number and length of gaps to be interpolated are large enough to doubt how much
real data is present. Also, if artefacts are in part TMS driven, we need to know if the same amount
of reconstruction was needed for PMv, PMd and vertex.
Moving to Data analysis, how did they determine the movement start and end time-point?
P10, lines 250-251: “Any trials in which the participant started moving before the starting tone, or
failed to finish moving within 200ms of the return tone, were also excluded. Following the above
exclusions, a total of 83.4% of trials were maintained for statistical analysis.” 17% of errors is a lot,
given the relaxed criteria set by the authors. Was the task challenging?
I don’t understand how this analysis was performed: “In cases where the t value was at a
significant level for any sequence of samples in the time-series, we performed permutation
testing on the relevant data”.
Later they say that “This is similar to the use of cluster based statistics in fMRI, where a fixed,
arbitrary threshold is used for creating clusters, then a second threshold is calculated for
determining how large a cluster needs to be before it is statistically significant.”. If I understood
11
correctly, permutations were run on a limited set of time points that were originally significant
with un-corrected t-tests? If this is the case it is a case of double-dipping.
Then I have also some problems on the cross-correlation. P10, lines 256 to 260: “To do this we ran
a cross-correlation analysis between the original actor and imitator velocity curves for each trial
for each tracker, across lags of the difference between the actor and imitator timeseries length
(i.e., if actor movement duration was 755ms, and imitator movement duration was 796ms, then
cross-correlation was performed over a 41ms lag).”
- The rationale behind the choice of best lag is obscure to me. This is the difference total
movement length not the delay between partially overlapping movements. The analysis of lags,
in the subsequent ANOVA, do not say much on kinematic imitation.
- In any case they should report what was the mean and standard deviation lag?
Timeseries should be rescaled to have same length. I would normalize in time and in amplitude,
because what really matters is the shape of velocity profiles, its distribution over time, and not
the speed of execution or the amplitude. The indexes they used are rather unusual: “we took the
maximum r-value (i.e., the point at which the imitator was best correlated with the actor),” the r-
value or the time-point?
Later they say: ”We took this time-series-driven approach in order to inform us of possible
differences in peak kinematic values in separate trackers, without the inflated type 1 error that
would occur were we to examine multiple kinematic parameters in multiple trackers.”. I
understand that it doesn’t make much sense to input all sensors data in the same analysis, but
then why they measured so many of them if they do not try to combine them? Movement control
in complex goal-directed action (and imitation is no exception) is not about controlling single
joints separately. Either they formulate some a priori HP, such that one specific marker
kinematics can say something useful, or they must find some way to combine subsets of sensors
into a single signal. Otherwise, reading a long list of independent comparisons, on data that is
certainly not independent, do not help understand the role of premotor cortex on imitation.
Finally, on results. In section 4.1. “Finger-thumb opposition task” all the data report no effect of
stimulation time which the critical effect to demonstrate that rTMS influences behaviour.
Otherwise results can be explained by attentional level in the 3 sessions, the fact that one
stimulation site is just more disturbing for participants.
In section 4.2. “Actor-imitator correspondence” there are a lot of significant effects between
meaningful and meaningless action on different movement features. However, from a motor
control point of view, comparing shoulder or wrist position in the two conditions do not help
much. These are highly interdepended and most critically not independently controlled by the
brain. Authors describe single finger movement features, shoulder or elbow as “gestures” and
this is wrong. Those are simple movements, better, the kinematic recording of an arbitrary body
part. Gestures are higher up in the hierarchy and regards multi-segmental postural
configurations. Furthermore, there were no effects of stimulation time or site which instead are
the critical contrasts.
P10, lines 262-263: they transformed the data before anova. Why? Lack of normality? What about
non parametric tests then?
As I said earlier, when trajectories are not-normalized, the analysis of lags is not really helpful.
Anyway, this part is confusing, it’s difficult to understand what are exactly the two time-series
they compared. Later in the results, they interpret this index as: “Stimulation during observation
compared to stimulation during imitation resulted in a significantly greater lag at the maximum
Z-value” -> “This suggests that participants took longer to optimally match the actor’s hand
movements when they were stimulated during action observation.” (Page 14, Lines 370 to 378)
12
“Took longer”: Does it mean that they start later the movement or that the movement was slower,
or that the velocity peak was delayed ?
“Optimally match”: does it mean that the higher the correlation value, the longer the time?
I don’t comment any further on the section 4.3. “t-statistic plots and permutation testing”, as I
find it a quite convoluted manner to analyse the data. I’m also not sure I understood what was
done on the data (one of my previous question). Furthermore, I find it conceptually wrong to
analyse each sensor data separately.
Reviewer: 2
Comments to the Author(s)
In their work (MS ID RSOS-171878) entitled “The left ventral premotor cortex is involved in hand
shaping for intransitive gestures: evidence from a two-person imitation experiment”, Reader and
Holmes used repetitive transcranial magnetic stimulation (rTMS) applied over left PMv, left
PMd, or the vertex (a control site) while participants observed or imitated movements performed
by a confederate actor. Significantly lower digit velocity was observed following stimulation over
PMv – but not over PMd or vertex – during action observation (as compared to action imitation).
Thumb movement reversals, as well as accuracy in a finger-thumb opposition task was also
affected following PMv stimulation. Therefore, counter to claims that PMv is critical for
programming object-directed actions, the authors suggest it plays a more general role in hand
shaping, while the targets of actions can be different hand areas themselves. After all, intransitive
(non-object related) gestures were affected following PMv stimulation in their research.
Although some fine-tuning of the argumentation provided in the Introduction might be welcome
(it does not always seem to flow), this is a well thought of and quite original submission,
capitalizing on the neuroimaging and neuropsychological findings related to action observation
and imitation. I do agree with a suggestion that some of the claims from motor-control research
are biased – especially when the emphasis is on object-directed coding rather than on encoding
more general action goals, and a variety of neuroimaging contrasts used in the fMRI literature on
action imitation does not always help in general understanding of the roles of PMv and PMd in
the studied tasks. In short, a good TMS study may shed a new light on these issues, and this
submission meets this goal.
I have only a few requests for clarification:
Although it seemed to me that I understood the timing of stimulation onset (“Stimulation during
observation started 333ms after the point at which the new image appeared on the screen.”
“Stimulation during imitation started 1000ms before the imitator was cued to begin their action.”)
during reading this manuscript again - while writing my opinion - I was not sure why these
specific starting points were selected. (Only when all else is equal, one can compare the effects of
manipulation on the tasks.) I realize that during the analyses some attempts to account for this
discrepancy were made, but I got lost.
As to data pre-processing performed before statistical analyses, it is quite sophisticated and in
general seems right. I am not sure you really need to divide your alpha value cutoff by 8, rather
than by (let’s say) 4, as some of the analyzed traces must be strongly correlated.
Is there any update on the status of “Reader et al., under review”. Most journals would not let
you cite any work which is not accepted, yet.
It is a bit difficult to follow all the results you present but your Discussion and conclusions are
13
generally consistent with what you get. And I like your general conclusions about the putative
role of PMv.
Some fine tuning of the Discussion would be welcome, though.
Minor:
“revealed that that for the thumb RMS”
Gregory Kroliczak
Institute of Psychology
Adam Mickiewicz University in Poznan
Author's Response to Decision Letter for (RSOS-171878.R0)
See Appendix A.
label_version_2
RSOS-181356.R0
label_author_3
Review form: Reviewer 1
Is the manuscript scientifically sound in its present form?
Yes
Are the interpretations and conclusions justified by the results?
Yes
Is the language acceptable?
Yes
Is it clear how to access all supporting data?
Yes
Do you have any ethical concerns with this paper?
No
Have you any concerns about statistical analyses in this paper?
No
Recommendation?
label_recommendation_3
Accept as is
Comments to the Author(s)
label_comment_3
Authours have addressed the most critical concerns I had previously.
14
label_author_4
Review form: Reviewer 2 (Gregory Kroliczak)
Is the manuscript scientifically sound in its present form?
Yes
Are the interpretations and conclusions justified by the results?
Yes
Is the language acceptable?
Yes
Is it clear how to access all supporting data?
Yes
Do you have any ethical concerns with this paper?
No
Have you any concerns about statistical analyses in this paper?
No
Recommendation?
label_recommendation_4
Accept as is
Comments to the Author(s)
label_comment_4
All my concerns have been appropriately addressed.
Gregory Kroliczak, Ph.D. (prof. UAM, dr hab.)
http://orcid.org/0000-0001-6121-0536
Institute of Psychology, Cognitive Science Program
Head, Action & Cognition Laboratory
Adam Mickiewicz University in Poznan
ul. Szamarzewskiego 89 B / Office# 87
60-568 Poznan, Poland
label_end_comment
Decision letter (RSOS-181356.R0)
13-Sep-2018
Dear Mr Reader,
I am pleased to inform you that your manuscript entitled "The left ventral premotor cortex is
involved in hand shaping for intransitive gestures: evidence from a two-person imitation
experiment" is now accepted for publication in Royal Society Open Science.
You can expect to receive a proof of your article in the near future. Please contact the editorial
office (openscience_proofs@royalsociety.org and openscience@royalsociety.org) to let us know if
you are likely to be away from e-mail contact. Due to rapid publication and an extremely tight
schedule, if comments are not received, your paper may experience a delay in publication.
15
Royal Society Open Science operates under a continuous publication model
(http://bit.ly/cpFAQ). Your article will be published straight into the next open issue and this
will be the final version of the paper. As such, it can be cited immediately by other researchers.
As the issue version of your paper will be the only version to be published I would advise you to
check your proofs thoroughly as changes cannot be made once the paper is published.
You have the opportunity to archive your accepted, unbranded manuscript, but access to the full
text must be embargoed until publication.
Articles are normally press released. For this to be effective we set an embargo on news coverage
corresponding to the publication date of the article. We request that news media and the authors
do not publish stories ahead of this embargo (when final version of the article is available).
In order to raise the profile of your paper once it is published, we can send through a PDF of your
paper to selected colleagues. If you wish to take advantage of this, please reply to this email with
the name and email addresses of up to 10 people who you feel would wish to read your article.
Please note that Royal Society Open Science will introduce article processing charges for all new
submissions received from 1 January 2018. Charges will also apply to papers transferred to Royal
Society Open Science from other Royal Society Publishing journals, as well as papers submitted
as part of our collaboration with the Royal Society of Chemistry
(http://rsos.royalsocietypublishing.org/chemistry).
If your manuscript is newly submitted and subsequently accepted for publication after 1 Jan 2018,
you will be asked to pay the article processing charge, unless you request a waiver and this is
approved by Royal Society Publishing. Manuscripts originally submitted prior to 1 Jan 2018 will
not subject to a charge, even if they are accepted in 2018. You can find out more about the charges
at http://rsos.royalsocietypublishing.org/page/charges. Should you have any queries, please
contact openscience@royalsociety.org.
On behalf of the Editors of Royal Society Open Science, we look forward to your continued
contributions to the Journal.
Kind regards,
Royal Society Open Science Editorial Office
Royal Society Open Science
openscience@royalsociety.org
on behalf of Dr Simon Schultz (Associate Editor) and Prof. Antonia Hamilton (Subject Editor)
openscience@royalsociety.org
Reviewer comments to Author:
Reviewer: 2
Comments to the Author(s)
All my concerns have been appropriately addressed.
Gregory Kroliczak, Ph.D. (prof. UAM, dr hab.)
http://orcid.org/0000-0001-6121-0536
16
Institute of Psychology, Cognitive Science Program
Head, Action & Cognition Laboratory
Adam Mickiewicz University in Poznan
ul. Szamarzewskiego 89 B / Office# 87
60-568 Poznan, Poland
Reviewer: 1
Comments to the Author(s)
Authours have addressed the most critical concerns I had previously.
Appendix A
We would like to thank the editor and reviewers for their time, and constructive commentary on our
work. We believe the manuscript is now much stronger. Importantly, the suggestion by reviewer 1 to
ssess the finger-thumb opposition task using a velocity measure suggests that stimulating PMv during
ctions increases finger movement speed. This has helped in clarifying the effect of stimulation over PMv
n the imitation task – this is better characterised as an effect of online stimulation increased finger speed,
ather than stimulation during observation reducing finger movement speed.
We provide point-by-point responses to comments below, and major changes in manuscript text are
ighlighted in bold.
Reviewers' Comments to Author:
Reviewer: 1
Comments to the Author(s)
he manuscript by Reader & Homes, investigate the role of the premotor cortex in object-directed or goal-
irected action imitation. Specifically, the authors investigate the effect of left ventral (PMv) and dorsal (PMd)
remotor rTMS stimulation (and vertex as a control) on meaningful or meaningless action imitation. Effect of
rain stimulation is measured on participant movement kinematics.
n general, the manuscript requires important reorganization. The introduction is weak, especially in outlining
he research question and expected results. The organization of methods is confusing and would require a more
chematic organization. I have important doubts about the way TMS was applied (i.e. intensities, localization,
tc.). The description of analyses is also confusing to read and, I suspect that at least in some cases, they may not
ully correct. The most critical issue, in my opinion, is that large portions of data seems to be affected by artefact
nd the authors made massive use of data interpolation. My biggest fear is that such a large use of interpolation
may have substantially biased the remaining data. Another big issue is that authors analyse each single sensor as
f it was an independent source, while they are not – obvious biomechanics constraint say the opposite. More
mportantly, sensors are treated as if by looking at each one of them, separately, one could tell something about
he cortical control of imitation. This is against what we know about postural coordination and how cortical
ontrol of complex goal directed movement is achieved. Finally, even removing these doubts, most of the results
re not very convincing and do not support authors’ conclusions about the specificity of the PMv effect.
lease find below the detailed list of comments I can provide.
ntroduction
2, lines 35-36: “Neuroimaging studies of action imitation are frequently focussed on goal-directed or object-
irected behaviour [1, but see 2-14], which may not encompass the same processes involved in other types of
ction imitation.”. I would reformulate this sentence.
This sentence has been changed (lines 47-49).
he first part of the introduction (p2, lines 35-41) is very short. The goal-directed vs object directed should be
llustrated more clearly before discussing the neural regions involved. The link with apraxia may be increased as
well.
The introduction has undergone significant changes at the request of the reviewers. Changes have been
ighlighted in the text.
age 2, from line 47, Authors write “F5 has been shown to contain neurons that code for specific hand-object
nteractions, rather than their single constituent movements”. However, this goes against recent monkey data.
lease see Tkach, Reimer, & Hatsopoulos, 2007; Kraskov et al., 2009; Dushanova & Donoghue, 2010;
Vigneswaran et al., 2013; Kraskov et al., 2014.
We agree that this could be more strongly addressed, since the main point here is that there is not yet
onvincing evidence that premotor mirror neurons could support intransitive action imitation in the way
hat they could support transitive action imitation. We have developed this idea in the introduction (lines
0-55).
age 3, from line 51, Authors write “The PMd has also been associated with imitation [16], and some have
uggested that it might be involved in encoding goals for imitation”. However, encoding the imitation goals is
ertainly not the main nor the most established idea regarding the function of PMd. PMd is more likely involved
n encoding whole arm reaching movements, building arbitrary sensori-motor association and in action selection.
This has been addressed in the new introduction (lines 32-34).
Description of fMRI studies, page 3 lines 56-67, is confusing.
This section has been re-written.
age 3 end of intro, is not clear: authors say “We did this by examining both imitation accuracy (actor-imitator
orrespondence), and imitation kinematics.”
This sentence has now been expanded – see lines 96-98.
n general, the whole last paragraph of the introduction is not incisive. I understand that there were no strong a
riori Hp. I’m not asking to force a post-hoc Hp, but I’d like to see a more focused set of predictions here.
We have now made some suggestions in this final paragraph of the introduction (lines 84-91)
Method
n general, methods are rather confusing. I suggest a substantial editing to simplify and present all info in a more
chematic manner. For example, I would split the section on Materials and Stimuli. “Motion Capture” should be
eparated form “TMS & EMG”, “Stimuli” and “Procedures”. Later these sections are extended and I don’t see
why things are repeated twice.
We have re-organised the methods as suggested.
Regarding the stimuli, I also have some doubts. For example, in Figure 1A: the meaningful actions chosen can
e contended. For “shock”: the 3 pictures may have a meaning (left: shock, middle: speaking loud, right:
earing). For this reason, I would like to see all gestures, may be in supplementary material.
ater (page 8, lines 199-203), they mention a test to control for this issue: “Following the completion of all TMS
essions, participants were presented with a questionnaire featuring the meaningful and meaningless images in a
seudorandom order, with the aim to exclude participants if they were less than 60% consistent with our own
ategorisation of the actions. No participants were excluded on this criterion. Mean±SE rating agreement was
5.0±6.15% for meaningful actions and 86.5±2.86% for meaningless actions.”
All gestures have now been added to Figure 1.
’m not fully convinced by this “meaningful and meaningless action trials were split into separate blocks. Task
rder was counterbalanced across stimulation sites.”. “Since there is evidence to suggest that performing novel
nd known actions in a sequence could recruit a single processing route, whilst presenting them separately
ecruits separate routes [37, but see 38, and Reader et al., under review].”
We appreciate the reviewer’s skepticism over this point, however, there is indeed some evidence in favour
f this hypothesis. For example, the dissociation between meaningful and meaningless action imitation in
praxia can be reduced when the actions are presented in a mixed, rather than in a blocked, fashion
Tessari & Cubelli, 2014, Cortex). We have addressed this topic fully more recently (Reader et al., in
ress). Given this literature, we decided to err on the side of caution and split the action types into blocks,
n the case that actions presented in a mixed fashion could induce a singular processing route.
Was the confederate trained to perform correctly the movement ?
Yes, the confederate had practice for all actions. This has been added in line 114.
hey did three sessions on three days, one by brain region. Were the stimuli presented in each session the same?
f yes, was the order of the session counterbalanced across subjects to avoid an “habituation” effect?
Each subject was only confederate or imitator or some subjects may have play the two roles (in different
xperiments of course)?
All stimulation sites and blocks of stimuli were counterbalanced (line 189). Participants only took part as
he imitator (lines 96-98).
Moreover, I also have some concerns about TMS application. Although TMS current direction is very important,
he authors used different coil orientations. This is a bit of a problem.
Whilst we agree that the effects of TMS on the underlying cortex likely vary depending on the orientation
f the coil, as shown by a large literature on motor cortex TMS eliciting MEPs, there is no evidence (that
we are aware of) as to how this may mediate effects on the premotor cortex for imitation. In this case, it
was more important for us to ensure that the coil positioning resulted in the least possible discomfort for
ur participants, since some orientations were reported as being more uncomfortable than others. We
tate this in lines 156-163.
Also, authors say that “During stimulation over the PMd, the coil was angled such that the wings did not overlap
with the primary motor cortex”. However, there is a negligible field below the wings and I don’t see why they
id this.
Whilst this might be true in theory, this was not the case in practice. As observed with some of our
articipants, particularly those with smaller skulls, the coil position for PMd could overlap substantially
with M1 and induce visible muscle activity.
n the same section, they also report that “In the case of MEPs being observed with rTMS applied during natural
inger-thumb opposition movements (i.e., repeatedly touching the tip of the thumb to each of the fingertips),
timulation was reduced by 5% of the maximum stimulator output”. This procedure is sub optimal to achieve
heir goal. With cyclic movements and [I suppose] manually operated TMS pulses, one is not able to accurately
est if TMS produces a peripheral response during movements. They should have used a fixed amount of EMG
ctivity (i.e. 30% maximal) in the most excitable muscle (i.e. FDI).
We observed EMG activity online to assess this (lines 206-208), but we agree that this could have been a
seful additional measure. Anecdotally, we have found that thresholds for producing visible MEPs in the
EMG seem lower during meaningful active movements such as reach-to-grasp than during isotonic
ontraction of the same muscles. We do not have systematic data on this, however.
he whole section 3.4 “TMS parameters” is confusing. Furthermore, authors use a distance adjusted intensity,
ut PMd intensity is higher than PMv, why is that?
The distance adjusted intensity is based on the distance of the location of the cortical site from the outside
f the skull, and not the distance of the cortical site from M1. PMd is typically further from the scalp than
PMv. Please see Stokes et al (2007), and Meteyard & Holmes (2018) for more detailed information on this
method and on scalp-to-cortex distance across the head.
age 9, lines 184-197: It is not explained why rTMS was given with that specific timing.
This has been addressed in lines 220-226. We have also added an experimental time-line to Figure 1 (part
D).
hen, regarding data processing, the authors used RMS jerk of the thumb, but given the kind of task, I find it
uite unusual. I see that velocity and acceleration profiles might be noisy, but if this is true, things can only be
worst when applying a further derivative to the data. In this case, I feel that the more classical inter-tap interval
ITI) and ITI Sd is much more reliable and informative.
We have taken the reviewer’s suggestion and now report mean velocity for the thumb and for the digits,
nd not the third differential. We have also added the ITI and ITI SD as suggested.
My major concern though is the large number of particularly long artefacts. The descriptive statistics about
verage length of interpolated data (page 10, lines 236 and following) are quite shocking. The number and length
f gaps to be interpolated are large enough to doubt how much real data is present. Also, if artefacts are in part
MS driven, we need to know if the same amount of reconstruction was needed for PMv, PMd and vertex.
We agree that we could have been clearer on this point. Reconstruction was based on the specific
imepoints of TMS-related artefacts for each participant. Since these were (generally) invariant across
onditions for each participant, a standardised removal and interpolation was used for these points for all
onditions for that participant. This has been made clearer in the text (lines 258-261).
As emphasised in the original manuscript, all trials were checked to ensure that this interpolation was
ppropriate. However, to address the reviewer’s concerns, please see below figures highlighting example
racker position raw data before and after pre-processing, artefact removal, and interpolation.
Figure 1 (left): Example data pre-processing for a single trial
(participant 12, wrist tracker in x dimension).
Figure 2 (below): Example pre-processing for single trials
(raw data on left, processed on right); A) Participant 1 wrist
tracker in x dimension, B) Participant 7 index finger tracker
in z dimension, C) Participant 12 shoulder tracker in y
dimension
Moving to Data analysis, how did they determine the movement start and end time-point?
This was done using an arbitrary 12cm/s threshold. This info has now been added to the methods section
line 282). The laboratory typically uses start and end criteria between 5-15cm/s, depending on the task,
articipants, and apparatus being used.
10, lines 250-251: “Any trials in which the participant started moving before the starting tone, or failed to finish
moving within 200ms of the return tone, were also excluded. Following the above exclusions, a total of 83.4% of
rials were maintained for statistical analysis.” 17% of errors is a lot, given the relaxed criteria set by the authors.
Was the task challenging?
Following the reviewer’s comment, we realised that we also had an exclusion based on unusually large
elocities that we had not mentioned in the original manuscript. This has now been added (line 277). The
ask itself was not particularly challenging, and we would not consider the excluded trials ‘errors’ per se,
ut the TMS was distracting for some participants, resulting in a number of false starts.
don’t understand how this analysis was performed: “In cases where the t value was at a significant level for any
equence of samples in the time-series, we performed permutation testing on the relevant data”.
ater they say that “This is similar to the use of cluster based statistics in fMRI, where a fixed, arbitrary
hreshold is used for creating clusters, then a second threshold is calculated for determining how large a cluster
eeds to be before it is statistically significant.”. If I understood correctly, permutations were run on a limited set
f time points that were originally significant with un-corrected t-tests? If this is the case it is a case of double-
ipping.
This is not the case. Permutations were run across the entire timeseries to discover the length of
ignificantly different sequences we could expect by chance. This was the threshold that was used to assess
he statistical significance of the actual experimental comparisons. We have used the same or similar
method in closely-related publications (Naish et al., 2013; Reader and Holmes, 2015)
hen I have also some problems on the cross-correlation. P10, lines 256 to 260: “To do this we ran a cross-
orrelation analysis between the original actor and imitator velocity curves for each trial for each tracker, across
ags of the difference between the actor and imitator timeseries length (i.e., if actor movement duration was
55ms, and imitator movement duration was 796ms, then cross-correlation was performed over a 41ms lag).”
The rationale behind the choice of best lag is obscure to me. This is the difference total movement length not
he delay between partially overlapping movements. The analysis of lags, in the subsequent ANOVA, do not say
much on kinematic imitation.
This analysis has been edited, and outlined below.
In any case they should report what was the mean and standard deviation lag?
This analysis has been edited, and outlined below.
imeseries should be rescaled to have same length. I would normalize in time and in amplitude, because what
eally matters is the shape of velocity profiles, its distribution over time, and not the speed of execution or the
mplitude.
We performed this analysis as suggested, normalising each velocity profile by time (to 120 samples, as in
he t-statistic plots), and amplitude (dividing each point by the maximum timeseries value). The majority
f results are in keeping with our original cross-correlation analysis, but since the lag analysis was less
nformative, we have replaced this. The article now contains the reviewers recommended analysis instead
lines 280-288, supplemental Tables 1-3).
he indexes they used are rather unusual: “we took the maximum r-value (i.e., the point at which the imitator
was best correlated with the actor),” the r-value or the time-point?
After changing the analysis (see above), this part of the text has been removed.
ater they say: ”We took this time-series-driven approach in order to inform us of possible differences in peak
inematic values in separate trackers, without the inflated type 1 error that would occur were we to examine
multiple kinematic parameters in multiple trackers.”. I understand that it doesn’t make much sense to input all
ensors data in the same analysis, but then why they measured so many of them if they do not try to combine
hem? Movement control in complex goal-directed action (and imitation is no exception) is not about controlling
ingle joints separately. Either they formulate some a priori HP, such that one specific marker kinematics can say
omething useful, or they must find some way to combine subsets of sensors into a single signal. Otherwise,
eading a long list of independent comparisons, on data that is certainly not independent, do not help understand
he role of premotor cortex on imitation.
We agree that motor control is indeed synergistic. However, the extraction of motor synergies for
meaningful and meaningless gestures was not the purpose of this experiment. Examining the different
markers apart from each other is useful for assessing shared function in different gesture types, as this
manuscript highlights. For example, effects of rTMS over the PMv were observed only in the digits (as
hown in Figure 4), and not in the elbow. We have made all our data available for re-use
https://osf.io/qab2k), so researchers with expertise in the sorts of synergetic analyses referred to by the
eviewer can re-analyse the data.
inally, on results. In section 4.1. “Finger-thumb opposition task” all the data report no effect of stimulation time
which the critical effect to demonstrate that rTMS influences behaviour. Otherwise results can be explained by
ttentional level in the 3 sessions, the fact that one stimulation site is just more disturbing for participants.
This is a reasonable criticism. Please see the adjusted analysis (ITI, ITI SD, velocity) as suggested above.
n section 4.2. “Actor-imitator correspondence” there are a lot of significant effects between meaningful and
meaningless action on different movement features. However, from a motor control point of view, comparing
houlder or wrist position in the two conditions do not help much. These are highly interdepended and most
ritically not independently controlled by the brain. Authors describe single finger movement features, shoulder
r elbow as “gestures” and this is wrong. Those are simple movements, better, the kinematic recording of an
rbitrary body part. Gestures are higher up in the hierarchy and regards multi-segmental postural configurations.
urthermore, there were no effects of stimulation time or site which instead are the critical contrasts.
Please see our comment regarding motor control above. In the original manuscript, we did not refer to
ingle tracker movements as ‘gestures’. Rather, we stated that the accuracy of the imitator in matching the
osition of the trackers is contingent on the type of gesture performed. As an example: ‘Hand gestures
were significantly better correlated than finger gestures in the shoulder… elbow… wrist… thumb… index
inger… and little finger. This indicates that participants matched the actor’s arm and hand movements
etter when they had to copy a hand gesture.’
n this instance, we were not making a comment regarding the neural control of action, which is of course
ynergistic, but rather that the requirements of the hand gestures lends itself to be better matched – it’s a
impler, less fine-grained task.
10, lines 262-263: they transformed the data before anova. Why? Lack of normality? What about non
arametric tests then?
The r-values were transformed since r-values are not suitable for parametric statistical tests, being
ounded by [-1:1], and non-normally distributed. By normalising the distribution of r-values it was
ossible to use ANOVAs, which ensured that our analyses were consistent and comparable across different
ariables.
As I said earlier, when trajectories are not-normalized, the analysis of lags is not really helpful. Anyway, this part
s confusing, it’s difficult to understand what are exactly the two time-series they compared. Later in the results,
hey interpret this index as: “Stimulation during observation compared to stimulation during imitation resulted in
significantly greater lag at the maximum Z-value” -> “This suggests that participants took longer to optimally
match the actor’s hand movements when they were stimulated during action observation.” (Page 14, Lines 370 to
78)
Took longer”: Does it mean that they start later the movement or that the movement was slower, or that the
elocity peak was delayed ?
Optimally match”: does it mean that the higher the correlation value, the longer the time?\
This sentence has been removed along with the lag analysis.
don’t comment any further on the section 4.3. “t-statistic plots and permutation testing”, as I find it a quite
onvoluted manner to analyse the data. I’m also not sure I understood what was done on the data (one of my
revious question). Furthermore, I find it conceptually wrong to analyse each sensor data separately.
This analysis addresses the concerns that the reviewer has provided above – that the control of action is
ynergistic and not reflected purely by any one tracker. By examining the differences between tracker
ositions over time, it is possible to observe and quantify effects found in more than one tracker.
Reviewer: 2
Comments to the Author(s)
n their work (MS ID RSOS-171878) entitled “The left ventral premotor cortex is involved in hand shaping for
ntransitive gestures: evidence from a two-person imitation experiment”, Reader and Holmes used repetitive
ranscranial magnetic stimulation (rTMS) applied over left PMv, left PMd, or the vertex (a control site) while
articipants observed or imitated movements performed by a confederate actor. Significantly lower digit velocity
was observed following stimulation over PMv – but not over PMd or vertex – during action observation (as
ompared to action imitation). Thumb movement reversals, as well as accuracy in a finger-thumb opposition task
was also affected following PMv stimulation. Therefore, counter to claims that PMv is critical for programming
bject-directed actions, the authors suggest it plays a more general role in hand shaping, while the targets of
ctions can be different hand areas themselves. After all, intransitive (non-object related) gestures were affected
ollowing PMv stimulation in their research.
Although some fine-tuning of the argumentation provided in the Introduction might be welcome (it does not
lways seem to flow), this is a well thought of and quite original submission, capitalizing on the neuroimaging
nd neuropsychological findings related to action observation and imitation. I do agree with a suggestion that
ome of the claims from motor-control research are biased – especially when the emphasis is on object-directed
oding rather than on encoding more general action goals, and a variety of neuroimaging contrasts used in the
MRI literature on action imitation does not always help in general understanding of the roles of PMv and PMd
n the studied tasks. In short, a good TMS study may shed a new light on these issues, and this submission meets
his goal.
As suggested by both reviewers, we have made changes to the introduction.
have only a few requests for clarification:
Although it seemed to me that I understood the timing of stimulation onset (“Stimulation during observation
tarted 333ms after the point at which the new image appeared on the screen.” “Stimulation during imitation
tarted 1000ms before the imitator was cued to begin their action.”) during reading this manuscript again - while
writing my opinion - I was not sure why these specific starting points were selected. (Only when all else is equal,
ne can compare the effects of manipulation on the tasks.) I realize that during the analyses some attempts to
ccount for this discrepancy were made, but I got lost.
We agree that this needs to be clearer. As highlighted in the response to the other reviewer above, changes
ave been made in lines 220-226.
As to data pre-processing performed before statistical analyses, it is quite sophisticated and in general seems
ight. I am not sure you really need to divide your alpha value cutoff by 8, rather than by (let’s say) 4, as some of
he analyzed traces must be strongly correlated.
We agree that the correction method might be conservative, but effects in the same direction that did not
meet this threshold are reported in text, such that it is unlikely that we have excluded any ‘true positives’
rom discussion.
s there any update on the status of “Reader et al., under review”. Most journals would not let you cite any work
which is not accepted, yet.
This article has now been published, and the citation changed.
t is a bit difficult to follow all the results you present but your Discussion and conclusions are generally
onsistent with what you get. And I like your general conclusions about the putative role of PMv.
Thank you.
ome fine tuning of the Discussion would be welcome, though.
The discussion has been made more concise.
Minor:
revealed that that for the thumb RMS”
This sentence has now been removed.
Society Open
