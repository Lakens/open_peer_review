Orientation-invariance of individual differences in three face
processing tasks
G. Meinhardt, B. Meinhardt-Injac and M. Persike
Article citation details
R. Soc. open sci. 6: 181350.
http://dx.doi.org/10.1098/rsos.181350
Review timeline
Original submission: 16 February 2018 Note: Reports are unedited and appear as
1st revised submission: 8 June 2018 submitted by the referee. The review history
2nd revised submission: 15 August 2018 appears in chronological order.
3rd revised submission: 4 November 2018
Final acceptance: 21 November 2018
Review History
label_version_1
RSOS-180230.R0 (Original submission)
label_author_1
Review form: Reviewer 1
Is the manuscript scientifically sound in its present form?
Yes
Are the interpretations and conclusions justified by the results?
No
Is the language acceptable?
Yes
Is it clear how to access all supporting data?
Yes
Reports © 2019 The Reviewers; Decision Letters © 2019 The Reviewers and Editors;
Responses © 2019 The Reviewers, Editors and Authors. Published by the Royal Society under the
terms of the Creative Commons Attribution License http://creativecommons.org/licenses/by/4.0/,
which permits unrestricted use, provided the original author and source are credited
2
Do you have any ethical concerns with this paper?
No
Have you any concerns about statistical analyses in this paper?
No
Recommendation?
label_recommendation_1
Major revision is needed (please make suggestions in comments)
Comments to the Author(s)
label_comment_1
The authors describe the results of a single study that uses an individual-differences approach to
investigate whether or not face inversion leads to “qualitative” differences in face processing. In
previous literature, this has been taken to mean that the ability to encode parts vs. whole-face
features or local shape vs. metric relationships is modulated by face orientation. While there have
been a few attempts to examine this issue with correlational approaches, the authors present data
from a large sample (N~300) in which participants completed a battery of 3 distinct face
recognition tasks in upright and inverted orientation (the CFMT, the CCP and the SPP). The
authors present bivariate correlations and multiple regression analyses that suggest orientation
does NOT disrupt processing in a qualitatively different way, but rather leads to less efficient face
recognition via the same mechanisms. This is largely consistent with prior studies demonstrating
that similar SF channels are used for upright and inverted face recognition, etc.
The methodology used here is straightforward: The authors have used tasks that are either
established standards in the literature (the CFMT) or have been demonstrated to reflect aspects of
face recognition that are widely studied. The implementation of these did not strike me as
unusual in any way, so I have no meaningful criticisms of the authors’ data collection procedures.
Similarly, I think the data analysis itself benefits from being relatively simple. The authors are not
bringing in too many bells and whistles to look for the relationships they are interested in, but are
relying on fairly basic tools for looking at multivariate data. Again, I find little to meaningfully
criticize here. I would like to see the results section contain a little more detail, I think (the
authors present a good bit of their data by describing cases where outcomes “strongly
correspond,” which could be shored up by some concrete statistical statements), but for the most
part I think this is all fine.
The big issue to consider, I think, is whether this set of tasks was well-suited to look for the kinds
of outcomes that could have revealed effects of orientation on processing. On one hand, we have
to be careful here, because there must come a point where you decide that you’ve established a
useful battery and can’t just keep layering on task after task. On the other hand, it’s worth
considering if we’re missing something – are there tasks where prior literature suggests inverted
faces should make observers do something qualitatively different? I think the CCP was a good
target to include for this reason as a means of attacking the idea of parts/wholes in upright and
inverted face recognition. What I didn’t understand was exactly what the purpose of the SPP was,
especially when there are several other widely-cited results that seem like more obvious targets
for the current design. In particular, I was surprised that there wasn’t a direct examination of the
feature spacing vs. feature shape dissociation that continues to influence discussions of face
recognition. Similarly, I was also surprised that there weren’t more attempts to include non-face
objects in the design given that this provides a chance to identify process-specific components.
For example, there is a Cambridge Car Memory task as well, and other studies of congruency
have used houses and other objects as stimuli. To me, these seemed like they would have been
particularly useful to include because they provide the best chance, so to speak, to find the kinds
of orientation-selective processes the authors are talking about.
For me, this is the biggest limitation of the paper. I don’t disagree with the main results, but there
3
is a sort of “God of the gaps” argument that the paper can’t quite do away with: What if you just
didn’t include the right task? To be clear, I say this as a reviewer who generally agrees with the
authors’ main conclusions based on my reading of the current draft and other related literature!
My concern is really about the impact of this result on the field – is it a knockout blow to the idea
of qualitative differences, or is there room to argue that some important chances to see it were left
out? I think the current results are certainly valuable, but I also have moderate concern that it will
seem incomplete to some and be less convincing as a result.
These concerns are offset, however, by the very clear writing throughout the manuscript and the
contextualization of the current results within previous literature on the topic.
label_author_2
Review form: Reviewer 2
Is the manuscript scientifically sound in its present form?
Yes
Are the interpretations and conclusions justified by the results?
No
Is the language acceptable?
No
Is it clear how to access all supporting data?
Not Applicable
Do you have any ethical concerns with this paper?
No
Have you any concerns about statistical analyses in this paper?
Yes
Recommendation?
label_recommendation_2
Major revision is needed (please make suggestions in comments)
Comments to the Author(s)
label_comment_2
This study explored whether turning a face upside-down leads to qualitative changes in face
processing by using an individual-differences approach. The authors reported that there were no
common factors related to face inversion across tasks and suggested ‘no qualitative changes of
face processing by picture-plane inversion’ (from the title). I think that the finding can provide
fruitful insights into the field; however, I believe that the claim is too enthusiastic and is not valid,
because it rests on the implicit assumption that the nature or mechanisms of inversion effects are
identical across the three tasks. I believe that this issue renders the study inconclusive and that
the authors should justify or acknowledge this issue and revise the whole manuscript (including
the title) accordingly.
1. Although the authors claimed that they should find an orientation-dependent factor
(component) if inversion qualitatively changes face processing, it is likely that the effects or
mechanisms of inversion vary depending on tasks. For example, if face inversion induces task A
to disrupt holistic processing, task B to disrupt first-order relations (seeing a stimulus is a face
because its features are arranged with two eyes above a nose, which is above a mouth), and task
C to disrupt second-order relations (perceiving the distances among features), there may be little
4
or no orientation-related shared variance among tasks. In fact, Maurer et al. (2002, Trends Cogn.
Sci.) have already noted that inversion of a face interferes with several distinct types of configural
processing. Thus, it is not surprising at all that the authors found only orientation-invariant, task-
related factors, because how inversion affects behavior or cognition may qualitatively change
across tasks. I believe that the study’s contribution to the field is clearly not the ‘no qualitative
changes of face processing,’ but the ‘(possibility of) qualitative changes among face-related tasks’
by inversion.
2. Alternatively, it is likely that the results simply reflected that the three tasks have a larger
variance than the face orientation, rendering distinct components (between upright and inverted
face conditions) hardly visible. The larger number of levels in the tasks (i.e., 3) compared with
that in face orientation (i.e., 2) may also be intrinsically related to the variance difference. In any
case, following ‘the eigenvalues-greater-than-one rule’ proposed by Kaiser (1960) makes no sense.
Some components may be related to inversion, even though their eigenvalues are less than one.
Although their impacts would be smaller than ‘task-related’ components, but the existence of
such components can provide evidence for some qualitative changes in face processing induced
by inversion. If the authors wanted to claim NO qualitative differences between upright and
inverted face processing, they should show there are really no upright-face- or inverted-face-
specific components. If there are some components related to face orientation, the authors could
evaluate the effects of tasks and inversion in a quantitative, not qualitative (i.e., yes/no), manner.
3. The rationale behind performing multiple repression analyses is unclear. I am not convinced
that the analyses added an additional support for some arguments or resolved remaining issues.
In addition, it is not clear why only CFMT was a dependent variable.
4. Strange expressions are everywhere. I could not understand the texts such as: ‘customary
upright orientation’ (p.2), ‘joint processing of face parts’ (p.2, kind of configural or holistic
processing?), ‘joint or interactive processing of face parts’ (p.2, how do they differ? What is
interactive processing of face parts?), ‘process-specific processing’ (p2, explanation needed),
‘distinguished processes’ (p3, distinct?), ‘To anticipate our results’ (p3, the authors hypothesized
it?), ‘normal views’ (p3, what kind of normal?), and ‘complex facial features’ (p11, what does it
mean by ‘complex’? Are there simple facial features?)
5. It is desirable to plot data with scatter plots and spot outliers.
Minor points:
1. (p.3) “Three hundred and nineteen (314) observers participated in the study.” The number of
participants is unclear. Which (319 or 314) is correct? If the number is 314, please describe why
five participants were excluded.
2. (p.3) “70.8 % were female.” Please report the exact number of participants in real number (222?
But why not 70.7 %?).
3. (p.3) “€30,-” “,.” Not needed.
4. (p.4) “No feedback about correctness” should be “No feedback about responses”
5. (p.4) What are ‘coherent blocks?’
6. (p.4) What are ‘professional photographs?’
7. (p.5) What is ‘CD?’
8. (p.7) “significant at the one percent level” Please report the exact statistical values for each test.
9. (p.11) “However, the fact that the face stimuli were overlaid with noise maskers in the latter
study may have favoured usage of cues just from the eyes region, which proved to be the most
salient region in the masked displays [2]. In the present study, we used unmasked stimuli, but
observed orientation invariance of common variance within and across test conditions.” Gold et
al. (2012, Psychol. Sci.) used unmasked/non-noised stimuli.
10. (p.2) “Activity which varied in close correlation to the behavioral inversion effect was found
only in the fusiform face area [FFA; 14]” Matsuyoshi et al. (2015, J. Neurosci.) reported the OFA
correlated with the behavioral face inversion effect.
11. In addition to alpha, it may be helpful and valid to report Revelle & Zinbarg’s omega total
5
coefficients (2008, Psychometrika) for reliability coefficients.
12. (p.2) ‘Revisiting’ is inappropriate in this context.
label_end_comment
Decision letter (RSOS-180230.R0)
16-May-2018
Dear Professor Meinhardt,
The editors assigned to your paper ("Individual differences indicate no qualitative changes of face
processing by picture-plane inversion") have now received comments from reviewers. We would
like you to revise your paper in accordance with the referee and Associate Editor suggestions
which can be found below (not including confidential reports to the Editor). Please note this
decision does not guarantee eventual acceptance.
Please submit a copy of your revised paper within three weeks (i.e. by the 08-Jun-2018). If we do
not hear from you within this time then it will be assumed that the paper has been withdrawn. In
exceptional circumstances, extensions may be possible if agreed with the Editorial Office in
advance.We do not allow multiple rounds of revision so we urge you to make every effort to
fully address all of the comments at this stage. If deemed necessary by the Editors, your
manuscript will be sent back to one or more of the original reviewers for assessment. If the
original reviewers are not available, we may invite new reviewers.
To revise your manuscript, log into http://mc.manuscriptcentral.com/rsos and enter your
Author Centre, where you will find your manuscript title listed under "Manuscripts with
Decisions." Under "Actions," click on "Create a Revision." Your manuscript number has been
appended to denote a revision. Revise your manuscript and upload a new version through your
Author Centre.
When submitting your revised manuscript, you must respond to the comments made by the
referees and upload a file "Response to Referees" in "Section 6 - File Upload". Please use this to
document how you have responded to the comments, and the adjustments you have made. In
order to expedite the processing of the revised manuscript, please be as specific as possible in
your response.
In addition to addressing all of the reviewers' and editor's comments please also ensure that your
revised manuscript contains the following sections as appropriate before the reference list:
• Ethics statement (if applicable)
If your study uses humans or animals please include details of the ethical approval received,
including the name of the committee that granted approval. For human studies please also detail
whether informed consent was obtained. For field studies on animals please include details of all
permissions, licences and/or approvals granted to carry out the fieldwork.
• Data accessibility
It is a condition of publication that all supporting data are made available either as
supplementary information or preferably in a suitable permanent repository. The data
accessibility section should state where the article's supporting data can be accessed. This section
should also include details, where possible of where to access other relevant research materials
such as statistical tools, protocols, software etc can be accessed. If the data have been deposited in
an external repository this section should list the database, accession number and link to the DOI
6
for all data from the article that have been made publicly available. Data sets that have been
deposited in an external repository and have a DOI should also be appropriately cited in the
manuscript and included in the reference list.
If you wish to submit your supporting data or code to Dryad (http://datadryad.org/), or modify
your current submission to dryad, please use the following link:
http://datadryad.org/submit?journalID=RSOS&manu=RSOS-180230
• Competing interests
Please declare any financial or non-financial competing interests, or state that you have no
competing interests.
• Authors’ contributions
All submissions, other than those with a single author, must include an Authors’ Contributions
section which individually lists the specific contribution of each author. The list of Authors
should meet all of the following criteria; 1) substantial contributions to conception and design, or
acquisition of data, or analysis and interpretation of data; 2) drafting the article or revising it
critically for important intellectual content; and 3) final approval of the version to be published.
All contributors who do not meet all of these criteria should be included in the
acknowledgements.
We suggest the following format:
AB carried out the molecular lab work, participated in data analysis, carried out sequence
alignments, participated in the design of the study and drafted the manuscript; CD carried out
the statistical analyses; EF collected field data; GH conceived of the study, designed the study,
coordinated the study and helped draft the manuscript. All authors gave final approval for
publication.
• Acknowledgements
Please acknowledge anyone who contributed to the study but did not meet the authorship
criteria.
• Funding statement
Please list the source of funding for each author.
Please note that Royal Society Open Science will introduce article processing charges for all new
submissions received from 1 January 2018. Charges will also apply to papers transferred to Royal
Society Open Science from other Royal Society Publishing journals, as well as papers submitted
as part of our collaboration with the Royal Society of Chemistry
(http://rsos.royalsocietypublishing.org/chemistry). If your manuscript is submitted and
accepted for publication after 1 Jan 2018, you will be asked to pay the article processing charge,
unless you request a waiver and this is approved by Royal Society Publishing. You can find out
more about the charges at http://rsos.royalsocietypublishing.org/page/charges. Should you
have any queries, please contact openscience@royalsociety.org.
Once again, thank you for submitting your manuscript to Royal Society Open Science and I look
forward to receiving your revision. If you have any questions at all, please do not hesitate to get
in touch.
Kind regards,
Thadcha Retneswaran
Royal Society Open Science
7
openscience@royalsociety.org
on behalf of Dr Antonia Hamilton (Subject Editor)
openscience@royalsociety.org
Comments to Author:
Reviewers' Comments to Author:
Reviewer: 1
Comments to the Author(s)
The authors describe the results of a single study that uses an individual-differences approach to
investigate whether or not face inversion leads to “qualitative” differences in face processing. In
previous literature, this has been taken to mean that the ability to encode parts vs. whole-face
features or local shape vs. metric relationships is modulated by face orientation. While there have
been a few attempts to examine this issue with correlational approaches, the authors present data
from a large sample (N~300) in which participants completed a battery of 3 distinct face
recognition tasks in upright and inverted orientation (the CFMT, the CCP and the SPP). The
authors present bivariate correlations and multiple regression analyses that suggest orientation
does NOT disrupt processing in a qualitatively different way, but rather leads to less efficient face
recognition via the same mechanisms. This is largely consistent with prior studies demonstrating
that similar SF channels are used for upright and inverted face recognition, etc.
The methodology used here is straightforward: The authors have used tasks that are either
established standards in the literature (the CFMT) or have been demonstrated to reflect aspects of
face recognition that are widely studied. The implementation of these did not strike me as
unusual in any way, so I have no meaningful criticisms of the authors’ data collection procedures.
Similarly, I think the data analysis itself benefits from being relatively simple. The authors are not
bringing in too many bells and whistles to look for the relationships they are interested in, but are
relying on fairly basic tools for looking at multivariate data. Again, I find little to meaningfully
criticize here. I would like to see the results section contain a little more detail, I think (the
authors present a good bit of their data by describing cases where outcomes “strongly
correspond,” which could be shored up by some concrete statistical statements), but for the most
part I think this is all fine.
The big issue to consider, I think, is whether this set of tasks was well-suited to look for the kinds
of outcomes that could have revealed effects of orientation on processing. On one hand, we have
to be careful here, because there must come a point where you decide that you’ve established a
useful battery and can’t just keep layering on task after task. On the other hand, it’s worth
considering if we’re missing something – are there tasks where prior literature suggests inverted
faces should make observers do something qualitatively different? I think the CCP was a good
target to include for this reason as a means of attacking the idea of parts/wholes in upright and
inverted face recognition. What I didn’t understand was exactly what the purpose of the SPP was,
especially when there are several other widely-cited results that seem like more obvious targets
for the current design. In particular, I was surprised that there wasn’t a direct examination of the
feature spacing vs. feature shape dissociation that continues to influence discussions of face
recognition. Similarly, I was also surprised that there weren’t more attempts to include non-face
objects in the design given that this provides a chance to identify process-specific components.
For example, there is a Cambridge Car Memory task as well, and other studies of congruency
have used houses and other objects as stimuli. To me, these seemed like they would have been
particularly useful to include because they provide the best chance, so to speak, to find the kinds
of orientation-selective processes the authors are talking about.
8
For me, this is the biggest limitation of the paper. I don’t disagree with the main results, but there
is a sort of “God of the gaps” argument that the paper can’t quite do away with: What if you just
didn’t include the right task? To be clear, I say this as a reviewer who generally agrees with the
authors’ main conclusions based on my reading of the current draft and other related literature!
My concern is really about the impact of this result on the field – is it a knockout blow to the idea
of qualitative differences, or is there room to argue that some important chances to see it were left
out? I think the current results are certainly valuable, but I also have moderate concern that it will
seem incomplete to some and be less convincing as a result.
These concerns are offset, however, by the very clear writing throughout the manuscript and the
contextualization of the current results within previous literature on the topic.
Reviewer: 2
Comments to the Author(s)
This study explored whether turning a face upside-down leads to qualitative changes in face
processing by using an individual-differences approach. The authors reported that there were no
common factors related to face inversion across tasks and suggested ‘no qualitative changes of
face processing by picture-plane inversion’ (from the title). I think that the finding can provide
fruitful insights into the field; however, I believe that the claim is too enthusiastic and is not valid,
because it rests on the implicit assumption that the nature or mechanisms of inversion effects are
identical across the three tasks. I believe that this issue renders the study inconclusive and that
the authors should justify or acknowledge this issue and revise the whole manuscript (including
the title) accordingly.
1. Although the authors claimed that they should find an orientation-dependent factor
(component) if inversion qualitatively changes face processing, it is likely that the effects or
mechanisms of inversion vary depending on tasks. For example, if face inversion induces task A
to disrupt holistic processing, task B to disrupt first-order relations (seeing a stimulus is a face
because its features are arranged with two eyes above a nose, which is above a mouth), and task
C to disrupt second-order relations (perceiving the distances among features), there may be little
or no orientation-related shared variance among tasks. In fact, Maurer et al. (2002, Trends Cogn.
Sci.) have already noted that inversion of a face interferes with several distinct types of configural
processing. Thus, it is not surprising at all that the authors found only orientation-invariant, task-
related factors, because how inversion affects behavior or cognition may qualitatively change
across tasks. I believe that the study’s contribution to the field is clearly not the ‘no qualitative
changes of face processing,’ but the ‘(possibility of) qualitative changes among face-related tasks’
by inversion.
2. Alternatively, it is likely that the results simply reflected that the three tasks have a larger
variance than the face orientation, rendering distinct components (between upright and inverted
face conditions) hardly visible. The larger number of levels in the tasks (i.e., 3) compared with
that in face orientation (i.e., 2) may also be intrinsically related to the variance difference. In any
case, following ‘the eigenvalues-greater-than-one rule’ proposed by Kaiser (1960) makes no sense.
Some components may be related to inversion, even though their eigenvalues are less than one.
Although their impacts would be smaller than ‘task-related’ components, but the existence of
such components can provide evidence for some qualitative changes in face processing induced
by inversion. If the authors wanted to claim NO qualitative differences between upright and
inverted face processing, they should show there are really no upright-face- or inverted-face-
specific components. If there are some components related to face orientation, the authors could
evaluate the effects of tasks and inversion in a quantitative, not qualitative (i.e., yes/no), manner.
9
3. The rationale behind performing multiple repression analyses is unclear. I am not convinced
that the analyses added an additional support for some arguments or resolved remaining issues.
In addition, it is not clear why only CFMT was a dependent variable.
4. Strange expressions are everywhere. I could not understand the texts such as: ‘customary
upright orientation’ (p.2), ‘joint processing of face parts’ (p.2, kind of configural or holistic
processing?), ‘joint or interactive processing of face parts’ (p.2, how do they differ? What is
interactive processing of face parts?), ‘process-specific processing’ (p2, explanation needed),
‘distinguished processes’ (p3, distinct?), ‘To anticipate our results’ (p3, the authors hypothesized
it?), ‘normal views’ (p3, what kind of normal?), and ‘complex facial features’ (p11, what does it
mean by ‘complex’? Are there simple facial features?)
5. It is desirable to plot data with scatter plots and spot outliers.
Minor points:
1. (p.3) “Three hundred and nineteen (314) observers participated in the study.” The number of
participants is unclear. Which (319 or 314) is correct? If the number is 314, please describe why
five participants were excluded.
2. (p.3) “70.8 % were female.” Please report the exact number of participants in real number (222?
But why not 70.7 %?).
3. (p.3) “€30,-” “,.” Not needed.
4. (p.4) “No feedback about correctness” should be “No feedback about responses”
5. (p.4) What are ‘coherent blocks?’
6. (p.4) What are ‘professional photographs?’
7. (p.5) What is ‘CD?’
8. (p.7) “significant at the one percent level” Please report the exact statistical values for each test.
9. (p.11) “However, the fact that the face stimuli were overlaid with noise maskers in the latter
study may have favoured usage of cues just from the eyes region, which proved to be the most
salient region in the masked displays [2]. In the present study, we used unmasked stimuli, but
observed orientation invariance of common variance within and across test conditions.” Gold et
al. (2012, Psychol. Sci.) used unmasked/non-noised stimuli.
10. (p.2) “Activity which varied in close correlation to the behavioral inversion effect was found
only in the fusiform face area [FFA; 14]” Matsuyoshi et al. (2015, J. Neurosci.) reported the OFA
correlated with the behavioral face inversion effect.
11. In addition to alpha, it may be helpful and valid to report Revelle & Zinbarg’s omega total
coefficients (2008, Psychometrika) for reliability coefficients.
12. (p.2) ‘Revisiting’ is inappropriate in this context.
Author's Response to Decision Letter for (RSOS-180230.R0)
See Appendix A.
label_version_2
RSOS-180230.R1 (Revision)
label_author_3
Review form: Reviewer 1
Is the manuscript scientifically sound in its present form?
Yes
10
Are the interpretations and conclusions justified by the results?
Yes
Is the language acceptable?
Yes
Is it clear how to access all supporting data?
Yes
Do you have any ethical concerns with this paper?
No
Have you any concerns about statistical analyses in this paper?
No
Recommendation?
label_recommendation_3
Accept as is
Comments to the Author(s)
label_comment_3
The authors have addressed the issues I raised in the last round of review. I have no further
substantive comments regarding the manuscript.
label_author_4
Review form: Reviewer 2
Is the manuscript scientifically sound in its present form?
Yes
Are the interpretations and conclusions justified by the results?
No
Is the language acceptable?
Yes
Is it clear how to access all supporting data?
Not Applicable
Do you have any ethical concerns with this paper?
No
Have you any concerns about statistical analyses in this paper?
No
Recommendation?
label_recommendation_4
Reject
Comments to the Author(s)
label_comment_4
I am disappointed that the authors did not revise their manuscript well. Although the authors
had (or have?) contextualized their findings in terms of the qualitative and quantitative
differences debate in upright and inverted face processing, the contribution of the study is still
unclear in the revised manuscript. They now partially withdrew their former claim (e.g., upright
11
and inverted faces are processed by the same mechanisms) but added ‘orientation-invariance’
claim; however, how the orientation-invariance merits the literature is not clearly written. What
line of research does this study contribute to? How does this finding merit the
‘qualitative/quantitative’ difference debate in the face inversion effect? Although I still think that
the finding can provide fruitful insights into the field, I do not recommend publication of this
paper in its current form. I believe that the very clear writing is necessary (in particular, I am
concerned that the Introduction section remains almost unchanged).
1. The authors misunderstood my previous comments. I did not write nor assume “(a) no
common variance across orientations” (from the authors’ response). Indeed, given the moderate
to high correlation between upright and inverted face processing (r ~ 0.4–0.8; e.g., Psalta and
Andrews, 2014, Perception; Rezlescu et al., 2017, JEP:HPP), it is hard to presume ‘(a).’ I just wrote
“it is likely that the effects or mechanisms of inversion vary depending on tasks” and “it is not
surprising at all that the authors found only orientation-invariant, task-related factors, because
how inversion affects behavior or cognition may qualitatively change across tasks.” In addition,
low correlation between tasks and/or almost task-specific principal components are expected
from a previous report (Rezlescu et al., 2017, JEP:HPP), which showed little or no correlation
between face processing tasks unless the task domain is similar (e.g., robust correlation was
found between face perception measures). The task domain was clearly different in the present
study, as the authors have acknowledged (p.3., “face recognition, face perception, and face-
selective attention”). Thus, one can easily expect to find task- or process-specific factors that load
both upright and inverted face conditions. Given the previous findings, I feel the study is not
surprising at all in its current form. Clear writing/justification is necessary.
2. “motivation for choosing CFMT as the criterion was that the attempts to predict CFMT from
other face perception tests has raised significant interest in the past years” (from the authors’
response). I believe that ‘others do it’ does not justify the approach. The authors should clearly
describe why they selected CFMT as the primary dependent variable. Does the authors believe
that memory is the most critical part in face processing? Is it better than face perception and face-
selective attention? How does this multiple regression analysis complement their claims?
3. Abstract. “the findings suggest process-specific but orientation general mechanisms”
‘orientation general’ sounds odd. It should be ‘orientation invariant’. In addition mechanisms of
what? Does it “mechanisms behind the three tasks?”
4. The title “orientation-invariance of individual differences in three face processing tasks” is
somewhat difficult to grasp. I think individual differences is not needed.
label_end_comment
Decision letter (RSOS-180230.R1)
20-Jul-2018
Dear Professor Meinhardt:
I write you in regards to manuscript # RSOS-180230.R1 entitled "Orientation-invariance of
individual differences in three face processing tasks" which you submitted to Royal Society Open
Science.
Regrettably, in view of the criticisms of the reviewer(s) found at the bottom of this letter, your
manuscript has been denied publication in Royal Society Open Science.
Thank you for considering Royal Society Open Science for the publication of your research. I
12
hope the outcome of this specific submission will not discourage you from the submission of
future manuscripts.
Kind regards,
Royal Society Open Science Editorial Office
Royal Society Open Science
openscience@royalsociety.org
on behalf of Prof. Antonia Hamilton (Subject Editor)
openscience@royalsociety.org
Editor comments:
Comments to the Author:
Regrettably, the journal operates a policy that permits only round of major revision, and as you
have not fully satisfied the referees that your paper is now ready for publication, we cannot
consider the paper further for publication.
Reviewer comments to Author:
Reviewer: 1
Comments to the Author(s)
The authors have addressed the issues I raised in the last round of review. I have no further
substantive comments regarding the manuscript.
Reviewer: 2
Comments to the Author(s)
I am disappointed that the authors did not revise their manuscript well. Although the authors
had (or have?) contextualized their findings in terms of the qualitative and quantitative
differences debate in upright and inverted face processing, the contribution of the study is still
unclear in the revised manuscript. They now partially withdrew their former claim (e.g., upright
and inverted faces are processed by the same mechanisms) but added ‘orientation-invariance’
claim; however, how the orientation-invariance merits the literature is not clearly written. What
line of research does this study contribute to? How does this finding merit the
‘qualitative/quantitative’ difference debate in the face inversion effect? Although I still think that
the finding can provide fruitful insights into the field, I do not recommend publication of this
paper in its current form. I believe that the very clear writing is necessary (in particular, I am
concerned that the Introduction section remains almost unchanged).
1. The authors misunderstood my previous comments. I did not write nor assume “(a) no
common variance across orientations” (from the authors’ response). Indeed, given the moderate
to high correlation between upright and inverted face processing (r ~ 0.4–0.8; e.g., Psalta and
Andrews, 2014, Perception; Rezlescu et al., 2017, JEP:HPP), it is hard to presume ‘(a).’ I just wrote
“it is likely that the effects or mechanisms of inversion vary depending on tasks” and “it is not
surprising at all that the authors found only orientation-invariant, task-related factors, because
how inversion affects behavior or cognition may qualitatively change across tasks.” In addition,
low correlation between tasks and/or almost task-specific principal components are expected
from a previous report (Rezlescu et al., 2017, JEP:HPP), which showed little or no correlation
between face processing tasks unless the task domain is similar (e.g., robust correlation was
found between face perception measures). The task domain was clearly different in the present
study, as the authors have acknowledged (p.3., “face recognition, face perception, and face-
13
selective attention”). Thus, one can easily expect to find task- or process-specific factors that load
both upright and inverted face conditions. Given the previous findings, I feel the study is not
surprising at all in its current form. Clear writing/justification is necessary.
2. “motivation for choosing CFMT as the criterion was that the attempts to predict CFMT from
other face perception tests has raised significant interest in the past years” (from the authors’
response). I believe that ‘others do it’ does not justify the approach. The authors should clearly
describe why they selected CFMT as the primary dependent variable. Does the authors believe
that memory is the most critical part in face processing? Is it better than face perception and face-
selective attention? How does this multiple regression analysis complement their claims?
3. Abstract. “the findings suggest process-specific but orientation general mechanisms”
‘orientation general’ sounds odd. It should be ‘orientation invariant’. In addition mechanisms of
what? Does it “mechanisms behind the three tasks?”
4. The title “orientation-invariance of individual differences in three face processing tasks” is
somewhat difficult to grasp. I think individual differences is not needed.
Author's Response to Decision Letter for (RSOS-180230.R1)
See Appendix B.
label_version_3
RSOS-181350.R0
label_author_5
Review form: Reviewer 1
Is the manuscript scientifically sound in its present form?
Yes
Are the interpretations and conclusions justified by the results?
Yes
Is the language acceptable?
Yes
Is it clear how to access all supporting data?
Yes
Do you have any ethical concerns with this paper?
No
Have you any concerns about statistical analyses in this paper?
No
Recommendation?
label_recommendation_5
Accept as is
Comments to the Author(s)
label_comment_5
Following the previous round of review, I indicated that I was generally happy with the current
state of the manuscript and had no further comments. My opinion has not changed since, so I
14
would first of all like to re-iterate that I think this study makes a useful contribution to the face
recognition literature and the manuscript describes the study clearly both in terms of motivation
and execution.
Given the substantial disagreement between the authors and their other reviewer, I would also
like to offer my perspective on the issues raised in the previous round.
First, I agree with the authors that their study is of use to the face recognition community based
on the large sample size they have employed here, and their focus on the correlational structure
observed across tasks and orientation conditions. Their work makes a clear contribution to the
debate regarding quantitative/qualitative debate regarding upright and inverted face processing.
Specifically, with regard to the previous studies discussed in the response to reviews, the authors
are correct that their study includes far more participants than previous studies and includes a
direct analysis of the correlational structure that an individual-differences approach allows you to
examine. These features of the text differentiate the current study from previous related work and
extend our state of knowledge meaningfully.
Second, I also agree with the authors that many of the choices they have made both in designing
their study and describing it in the text are consistent with current practice in the field. For
example, the CFMT is indeed widely used, largely because it is supported by solid psychometric
data. Similarly, terms like “domain-general” etc. are indeed widely used and widely understood
within the field. Referring to their results in terms of orientation invariance is also perfectly clear.
Again, I think the current draft of the manuscript describes an interesting and useful contribution
to the field and I have no further suggestions for improvement.
label_author_6
Review form: Reviewer 3 (Isabel Gauthier)
Is the manuscript scientifically sound in its present form?
No
Are the interpretations and conclusions justified by the results?
Yes
Is the language acceptable?
Yes
Is it clear how to access all supporting data?
Yes
Do you have any ethical concerns with this paper?
No
Have you any concerns about statistical analyses in this paper?
No
Recommendation?
label_recommendation_6
Major revision is needed (please make suggestions in comments)
15
Comments to the Author(s)
label_comment_6
I was asked to read this version of the paper following an appeal made by the authors. I will sign
my review (Isabel Gauthier), because I think the review process for this paper so far has suffered
from a a very negative tone from all sides and it can only benefit from the perspective of a more
neutral reviewer. To be fair, who knows what "neutral" means and I will abundantly cite some of
my work below, not because I want it cited, but because much of what we have done seems
relevant to the points I want to make. I hope this is useful.
I have been an editor for many years and I would like to suggest that in the future, the editors at
the journal do what they can to avoid such a negative and harsh exchange. At APA journals we
are under instructions not to pass along reviews (or replies) that have such a tone - it is easy
enough to return those to reviewers/authors with instructions to tone it down and be more
constructive. I am sorry if I seem to be lecturing everyone here, but I think it is important to
acknowledge that some real damage has been done to the process by allowing the exchange to
unfold like this.
My reading of R2’s concerns are that they may be unclear or at time unfounded, but the replies
are defensive and the tone often pretty offensive. If I were the parties involved, I would not want
this presented in open peer review, it would merely be an example of what not to do. In the
future, if authors get frustrated in this manner and want to suggest that a reviewer is not being
careful or honest, tI suggest that they save such comments for the action editor. These sorts of
accusations are pretty much never helpful. It’s really quite difficult to completely set all of this
aside and evaluate the paper on its own merit but I will try to do this. My hope is that if the editor
chooses to allow the authors to revise the paper, the might not send it to R2 for evaluation (they
can evaluate whether the authors have addressed R2’s concerns on their own). I honestly do not
think this exchange is going anywhere.
My own evaluation is that the paper is overly long and complex for what it delivers. I really do
believe there is an important contribution in showing that common variance across tasks is
orientation invariant, but I think the message is getting lost. In my opinion, if the authors want to
have an impact, the paper should be trimmed as much as possible. While I think the presentation
has a lot of weaknesses, I do think the question is very important, the results are quite
compelling, and that the bar for claims of qualitative differences should always be very high.
I think most readers are going to get lost in the complex analyses and miss the point, which I
think is valid and important. The analyses seem to me to be competently performed, but they
may be at time overkill and their presentation is not geared towards readers who are not familiar
with multivariate analyses (which is a lot of readers in the area of face recognition).
Perhaps the main result could be appreciated more easily in the analysis for each and every test?
The claim from many authors is that there is a "different" mechanism that is used for upright
faces that is not used for inverted faces. In each test, can we not simply look at whether there is
evidence for any reliable variance in the upright scores that is not predicted by inverted scores
(after addressing attenuation)? I would not be surprised if in each case the disattenuated
correlation is very high, and there is no evidence of much else going on. If that was the case for
each task, nothing else might be needed (that is, how could PCA and regression extract anything
else that is orientation specific?)
An example of this logic was used here (this is not inversion, but the claim is the same: people
have argued there is an addition process for whole faces than face parts, but face part scores
predict all the non-error variance in whole scores...)
Sunday, M.A., Richler, J.J. & Gauthier, I. (in press). Limited evidence of individual differences in
16
holistic processing in different versions of the part-whole paradigm. Attention, Perception &
Psychophysics, in press. (https://www.readcube.com/articles/10.3758/s13414-017-1311-
z?author_access_token=3k9Ne6TXhXpl3x-
AImhvJJAH0g46feNdnc402Wrhzyp_ok_NmuYiesPHqmzoDRNXmmobXlBNgK7ocFN3WJPeEA
RdT0pabd9FOeJFVSuf-tcPXTz46qhC_pOVyYINnmPt93LNj41vEiZnnmFbzPapsw%3D%3D)
This is just an idea, maybe starting with showing that there isn't much in each test that suggests
an upright-specific mechanism could be followed by a subset of the complex analyses presented
by the authors, presented in a more easily digested form. Again, there may be nothing wrong
with the analyses the authors present, but I would urge them to consider whether the message
may be much more important than the analyses they likely spent a lot of time perfecting?
Other possible things to cut/simplify:
- separating the CFMT in parts with their reliability... the test has established reliability, the
different parts are not important here, and so just reporting overall reliability in the text should
be enough.
- comparing effect sizes across tasks and lengthy discussion group averaged results (this is not
important to the questions at hand and nothing theoretical hinges on this). These results are not
surprising, they can be presented very clearly in a table, very succinctly in the text, with minimal
discussion.
- SPP low and high opacity: we are told that this is to induce "high and low levels of competition"
but it's not clear how this is important to the current goals. I am not seeing what is gained
conceptually by having these hi and lo conditions - this should be either explained, or these
conditions could be averaged if the common construct is the one of interest? This would make for
more reliable measures (per Table 2).
Clarifications needed:
"Face-selective attention" is a very confusing term. In part this is because the association of
selective and faces tends to mean specific to faces (as in "face-selective area"). Second, this may be
used because the composite task and its variants have been deemed to measure selective-
attention (but "face-selective attention") is ambiguous about the grouping of the terms, at least to
this reader. In addition, the design of one of the tasks is essentially the same as the composite
task, with congruent and incongruent trials, and so a discussion of whether this is supposed to
measure holistic processing (i.e. would it be expected to correlate with the standard composite
task) would be helpful to understand the construct that is targeted).
page 9 line 33- I would remove that the CFMT is developed to study "delayed" face identity
recognition. It is a test of memory, but there is no real "delay" aside from the fact that the same set
of faces have to be kept in mind across all trials (but since the are continuously used and studied
many times, it is more clearly a learning test than a LTM test). I have never seen it presented like
this and Duchaine and Nakayama did not use this term.
Footnote on page 9. This is misleading and problematic. The VHPT-F, as does the regular
composite task, shows high reliability of individual conditions. It is the congruency effect, which
is the measure of HP, that tends to be unreliable in the standard task, and that was great
improved in the VHPT-F.
Critically, as far as I can tell, the authors do not present the reliability of the congruency effects
here. Table 2 includes reliability for separate conditions and for the total test (a strange
17
construct?) but not for the congruency effects. They will be much lower I expect, and this will
provide a real comparison with other tasks (such as the VHPT-F).
It is important to individual differences studies that authors be very clear about what their tests
measure - this claim suggests that the CCP is an alternative to the composite task, and so this
would mean that it should measure holistic processing. Either this is the case, and it should be
made clear, or it is not, and it makes no sense to say the CCP was preferred to tests of HP. Is there
any evidence that these different tests converge to measure the same thing? The VHPT-F was
shown to correlate with the standard composite task (Wang et a., 2016) - is there anything similar
for the CCP?
Wang, C.-C., Ross, D.A., Gauthier, I., Richler, J.J. (2016). Validation of the Vanderbilt Holistic Face
Processing Test. Frontiers In Psychology: Perception Science, 7, 1837.
The link to the data takes me to a dataset on dinosaurs!
page 8 line 27: "First studies focusing on the relations of face recognition and face perception
found that face recognition was surprisingly dissociated from holistic face perception [38], while
later studies showed some association [29,30], especially when the face perception ability was
tested with broader item variability [39]."
This 39 reference is to our work and the latest on this in fact shows that there is no association
between HP and CFMT, when face stimuli are not repeated in the HP task (so that claim about
item variability here seems backwards?). We have found that the correlation between CFMT and
congruency appears to be entirely due to this confound, a contribution of face learning to both
tests. This entire part regarding the relation between HP and face recognition should be revised,
because it does not appear that results depend on partial vs. complete designs, instead they
appear to depend on repetition of face stimuli - a test that is more reliable (VHPT-F) and shows a
very large average composite effect but does not repeat stimuli has not shown any correlation
with CFMT in several large samples.
Richler, J.J., Floyd, R.J. & Gauthier, I. (2015). About-Face on Face Recognition Ability and Holistic
Processing, Journal of Vision, 15(9):15.
This is relevant to the predictions made for P2 on page 13. In fact, the whole set of predictions
here is quite confusing, because the authors do not separate the test from the specific indices
measured by the test. A composite test (and the CCP) has individual conditions, each of which
plausibly has a strong contribution from face recognition ability (and there is no question in my
mind that these individual conditions should correlate with CFMT). But the references they cite
(28-30) concern the possible correlation between the congruency effect and CFMT scores. It's a
completely different construct. The authors here do not use individual differences in congruency
in their analyses, and they should make that clear from the start (their analyses, even based on
conditions that come from a test that could measure HP, are not relevant to HP). They may be
able to suggest that something different is going on in congruent and incongruent conditions, but
this is all very lose and speculative as they do not use congruency in their individual differences
analyses (readers might be confused because it is reported for averaged results).
For an example (no need to cite this!), see a recent paper we published in Psychological Review,
in which we use the composite task in a training study with objects, we do observe increased
congruency, but the individual differences in the individual conditions are very strongly
correlated with domain-general variance for other tasks.
Richler, J. J., Tomarken, A. J., Sunday, M. A., Vickery, T. J., Ryan, K. F., Floyd, J. R., Sheinberg, D.,
18
Wong, A. C.-N. & Gauthier, I. (in press). Individual Differences in Object
Recognition. Psychological
Review. (https://www.dropbox.com/s/vy3ho4vmwir1b3d/Richler2018PR.pdf?dl=0)
In Table 5, most of the strongest correlations are among the SPPo across orientations, does that
suggest more common variance across orientation for objects than faces?
minor:
page 7 line 13 - "Neural mechanisms which process upright faces are assumed to be no longer
engaged in the processing of inverted faces." as far as I know, the common assumption (Whether
I believe it or not) is that mechanisms for inverted faces would be the same as those for general
objects, and they would be engaged still for upright faces, but in that case there would be
additional mechanisms involved for upright faces. The phrasing is conceptually confusing, it
would be much clear to set up inverted faces as a baseline (the claim that inverted faces differ
from common objects is a lot more rare).
(on page 13 in their discussion of P1, the same sort of thing happens, where some special
inverted-specific variance is said to possibly emerge -> but models that suggest a qualitative
difference suggest that it is upright faces that are different, not inverted faces)
page 8 line 21 - "Predicting face recognition, which is regarded as the core ability of the face
processing domain [27],"
This sentence is unclear, the reader cannot know exactly what you mean by "face recognition"
here (what is measured in a test like CFMT? or a latent construct based on several tests? does it
require LTM involvement or just matching across views" - and in addition, whether is is regarded
as "the core" seems like somebody's opinion more than anything. I also don't think this point is
needed.
page 13 line 25: my preference would be to remove "neural mechanisms" and just used
mechanisms here (and elsewhere) - of course, psychological mechanisms arise from the brain, but
other than that, nothing here speaks to neural mechanisms.
page 19 - line 36 - note that adding the CCMT might not be a good approach, given cars have
been repeatedly found to be special (sometimes more than faces) in individual differences studies
with many categories. This is summarized here:
Richler, J.J., Wilmer, J.B., Gauthier, I. (2017). General object recognition is specific: evidence from
novel and familiar objects. Cognition, 166: 42-55.
Sunday, M.A., Dodd, M.D., Tomarken, A.J., Gauthier, I. (in press). How faces (and cars) may
become special. Vision
Research. (https://www.dropbox.com/s/r94ckvahdgpvyfo/SuDoToGa17.pdf?dl=0)
19
label_end_comment
Decision letter (RSOS-181350.R0)
27-Sep-2018
Dear Professor Meinhardt,
The Subject Editor assigned to your paper ("Orientation-invariance of individual differences in
three face processing tasks") has now received comments from reviewers. We would like you to
revise your paper in accordance with the referee and Associate Editor suggestions which can be
found below (not including confidential reports to the Editor). Please note this decision does not
guarantee eventual acceptance.
Please submit a copy of your revised paper before 20-Oct-2018. Please note that the revision
deadline will expire at 00.00am on this date. If we do not hear from you within this time then it
will be assumed that the paper has been withdrawn. In exceptional circumstances, extensions
may be possible if agreed with the Editorial Office in advance. We do not allow multiple rounds
of revision so we urge you to make every effort to fully address all of the comments at this stage.
If deemed necessary by the Editors, your manuscript will be sent back to one or more of the
original reviewers for assessment. If the original reviewers are not available we may invite new
reviewers.
To revise your manuscript, log into http://mc.manuscriptcentral.com/rsos and enter your
Author Centre, where you will find your manuscript title listed under "Manuscripts with
Decisions." Under "Actions," click on "Create a Revision." Your manuscript number has been
appended to denote a revision. Revise your manuscript and upload a new version through your
Author Centre.
When submitting your revised manuscript, you must respond to the comments made by the
referees and upload a file "Response to Referees" in "Section 6 - File Upload". Please use this to
document how you have responded to each of the comments, and the adjustments you have
made. In order to expedite the processing of the revised manuscript, please be as specific as
possible in your response.
In addition to addressing all of the reviewers' and editor's comments please also ensure that your
revised manuscript contains the following sections before the reference list:
• Ethics statement
If your study uses humans or animals please include details of the ethical approval received,
including the name of the committee that granted approval. For human studies please also detail
whether informed consent was obtained. For field studies on animals please include details of all
permissions, licences and/or approvals granted to carry out the fieldwork.
• Data accessibility
It is a condition of publication that all supporting data are made available either as
supplementary information or preferably in a suitable permanent repository. The data
accessibility section should state where the article's supporting data can be accessed. This section
should also include details, where possible of where to access other relevant research materials
such as statistical tools, protocols, software etc can be accessed. If the data has been deposited in
an external repository this section should list the database, accession number and link to the DOI
for all data from the article that has been made publicly available. Data sets that have been
deposited in an external repository and have a DOI should also be appropriately cited in the
manuscript and included in the reference list.
20
If you wish to submit your supporting data or code to Dryad (http://datadryad.org/), or modify
your current submission to dryad, please use the following link:
http://datadryad.org/submit?journalID=RSOS&manu=RSOS-181350
• Competing interests
Please declare any financial or non-financial competing interests, or state that you have no
competing interests.
• Authors’ contributions
All submissions, other than those with a single author, must include an Authors’ Contributions
section which individually lists the specific contribution of each author. The list of Authors
should meet all of the following criteria; 1) substantial contributions to conception and design, or
acquisition of data, or analysis and interpretation of data; 2) drafting the article or revising it
critically for important intellectual content; and 3) final approval of the version to be published.
All contributors who do not meet all of these criteria should be included in the
acknowledgements.
We suggest the following format:
AB carried out the molecular lab work, participated in data analysis, carried out sequence
alignments, participated in the design of the study and drafted the manuscript; CD carried out
the statistical analyses; EF collected field data; GH conceived of the study, designed the study,
coordinated the study and helped draft the manuscript. All authors gave final approval for
publication.
• Acknowledgements
Please acknowledge anyone who contributed to the study but did not meet the authorship
criteria.
• Funding statement
Please list the source of funding for each author.
Please note that Royal Society Open Science charge article processing charges for all new
submissions that are accepted for publication. Charges will also apply to papers transferred to
Royal Society Open Science from other Royal Society Publishing journals, as well as papers
submitted as part of our collaboration with the Royal Society of Chemistry
(http://rsos.royalsocietypublishing.org/chemistry). If your manuscript is newly submitted and
subsequently accepted for publication, you will be asked to pay the article processing charge,
unless you request a waiver and this is approved by Royal Society Publishing. You can find out
more about the charges at http://rsos.royalsocietypublishing.org/page/charges. Should you
have any queries, please contact openscience@royalsociety.org.
Once again, thank you for submitting your manuscript to Royal Society Open Science and I look
forward to receiving your revision. If you have any questions at all, please do not hesitate to get
in touch.
Kind regards,
Royal Society Open Science Editorial Office
Royal Society Open Science
openscience@royalsociety.org
on behalf of Prof. Antonia Hamilton (Subject Editor)
21
openscience@royalsociety.org
Associate Editor Comments to Author:
Please ensure that you address the substantial concerns raised by the adjudicating referee here.
The Editors noted, among other issues, that the authors have not provided the 'for review' Dryad
repository link. In the event that the Editors and referees do not consider you to have fully
responded to the referees' concerns in the revision, the paper may not be considered further for
publication.
Reviewer comments to Author:
Reviewer: 3
Comments to the Author(s)
I was asked to read this version of the paper following an appeal made by the authors. I will sign
my review (Isabel Gauthier), because I think the review process for this paper so far has suffered
from a a very negative tone from all sides and it can only benefit from the perspective of a more
neutral reviewer. To be fair, who knows what "neutral" means and I will abundantly cite some of
my work below, not because I want it cited, but because much of what we have done seems
relevant to the points I want to make. I hope this is useful.
I have been an editor for many years and I would like to suggest that in the future, the editors at
the journal do what they can to avoid such a negative and harsh exchange. At APA journals we
are under instructions not to pass along reviews (or replies) that have such a tone - it is easy
enough to return those to reviewers/authors with instructions to tone it down and be more
constructive. I am sorry if I seem to be lecturing everyone here, but I think it is important to
acknowledge that some real damage has been done to the process by allowing the exchange to
unfold like this.
My reading of R2’s concerns are that they may be unclear or at time unfounded, but the replies
are defensive and the tone often pretty offensive. If I were the parties involved, I would not want
this presented in open peer review, it would merely be an example of what not to do. In the
future, if authors get frustrated in this manner and want to suggest that a reviewer is not being
careful or honest, tI suggest that they save such comments for the action editor. These sorts of
accusations are pretty much never helpful. It’s really quite difficult to completely set all of this
aside and evaluate the paper on its own merit but I will try to do this. My hope is that if the editor
chooses to allow the authors to revise the paper, the might not send it to R2 for evaluation (they
can evaluate whether the authors have addressed R2’s concerns on their own). I honestly do not
think this exchange is going anywhere.
My own evaluation is that the paper is overly long and complex for what it delivers. I really do
believe there is an important contribution in showing that common variance across tasks is
orientation invariant, but I think the message is getting lost. In my opinion, if the authors want to
have an impact, the paper should be trimmed as much as possible. While I think the presentation
has a lot of weaknesses, I do think the question is very important, the results are quite
compelling, and that the bar for claims of qualitative differences should always be very high.
I think most readers are going to get lost in the complex analyses and miss the point, which I
think is valid and important. The analyses seem to me to be competently performed, but they
may be at time overkill and their presentation is not geared towards readers who are not familiar
with multivariate analyses (which is a lot of readers in the area of face recognition).
Perhaps the main result could be appreciated more easily in the analysis for each and every test?
22
The claim from many authors is that there is a "different" mechanism that is used for upright
faces that is not used for inverted faces. In each test, can we not simply look at whether there is
evidence for any reliable variance in the upright scores that is not predicted by inverted scores
(after addressing attenuation)? I would not be surprised if in each case the disattenuated
correlation is very high, and there is no evidence of much else going on. If that was the case for
each task, nothing else might be needed (that is, how could PCA and regression extract anything
else that is orientation specific?)
An example of this logic was used here (this is not inversion, but the claim is the same: people
have argued there is an addition process for whole faces than face parts, but face part scores
predict all the non-error variance in whole scores...)
Sunday, M.A., Richler, J.J. & Gauthier, I. (in press). Limited evidence of individual differences in
holistic processing in different versions of the part-whole paradigm. Attention, Perception &
Psychophysics, in press. (https://www.readcube.com/articles/10.3758/s13414-017-1311-
z?author_access_token=3k9Ne6TXhXpl3x-
AImhvJJAH0g46feNdnc402Wrhzyp_ok_NmuYiesPHqmzoDRNXmmobXlBNgK7ocFN3WJPeEA
RdT0pabd9FOeJFVSuf-tcPXTz46qhC_pOVyYINnmPt93LNj41vEiZnnmFbzPapsw%3D%3D)
This is just an idea, maybe starting with showing that there isn't much in each test that suggests
an upright-specific mechanism could be followed by a subset of the complex analyses presented
by the authors, presented in a more easily digested form. Again, there may be nothing wrong
with the analyses the authors present, but I would urge them to consider whether the message
may be much more important than the analyses they likely spent a lot of time perfecting?
Other possible things to cut/simplify:
- separating the CFMT in parts with their reliability... the test has established reliability, the
different parts are not important here, and so just reporting overall reliability in the text should
be enough.
- comparing effect sizes across tasks and lengthy discussion group averaged results (this is not
important to the questions at hand and nothing theoretical hinges on this). These results are not
surprising, they can be presented very clearly in a table, very succinctly in the text, with minimal
discussion.
- SPP low and high opacity: we are told that this is to induce "high and low levels of competition"
but it's not clear how this is important to the current goals. I am not seeing what is gained
conceptually by having these hi and lo conditions - this should be either explained, or these
conditions could be averaged if the common construct is the one of interest? This would make for
more reliable measures (per Table 2).
Clarifications needed:
"Face-selective attention" is a very confusing term. In part this is because the association of
selective and faces tends to mean specific to faces (as in "face-selective area"). Second, this may be
used because the composite task and its variants have been deemed to measure selective-
attention (but "face-selective attention") is ambiguous about the grouping of the terms, at least to
this reader. In addition, the design of one of the tasks is essentially the same as the composite
task, with congruent and incongruent trials, and so a discussion of whether this is supposed to
measure holistic processing (i.e. would it be expected to correlate with the standard composite
task) would be helpful to understand the construct that is targeted).
23
page 9 line 33- I would remove that the CFMT is developed to study "delayed" face identity
recognition. It is a test of memory, but there is no real "delay" aside from the fact that the same set
of faces have to be kept in mind across all trials (but since the are continuously used and studied
many times, it is more clearly a learning test than a LTM test). I have never seen it presented like
this and Duchaine and Nakayama did not use this term.
Footnote on page 9. This is misleading and problematic. The VHPT-F, as does the regular
composite task, shows high reliability of individual conditions. It is the congruency effect, which
is the measure of HP, that tends to be unreliable in the standard task, and that was great
improved in the VHPT-F.
Critically, as far as I can tell, the authors do not present the reliability of the congruency effects
here. Table 2 includes reliability for separate conditions and for the total test (a strange
construct?) but not for the congruency effects. They will be much lower I expect, and this will
provide a real comparison with other tasks (such as the VHPT-F).
It is important to individual differences studies that authors be very clear about what their tests
measure - this claim suggests that the CCP is an alternative to the composite task, and so this
would mean that it should measure holistic processing. Either this is the case, and it should be
made clear, or it is not, and it makes no sense to say the CCP was preferred to tests of HP. Is there
any evidence that these different tests converge to measure the same thing? The VHPT-F was
shown to correlate with the standard composite task (Wang et a., 2016) - is there anything similar
for the CCP?
Wang, C.-C., Ross, D.A., Gauthier, I., Richler, J.J. (2016). Validation of the Vanderbilt Holistic Face
Processing Test. Frontiers In Psychology: Perception Science, 7, 1837.
The link to the data takes me to a dataset on dinosaurs!
page 8 line 27: "First studies focusing on the relations of face recognition and face perception
found that face recognition was surprisingly dissociated from holistic face perception [38], while
later studies showed some association [29,30], especially when the face perception ability was
tested with broader item variability [39]."
This 39 reference is to our work and the latest on this in fact shows that there is no association
between HP and CFMT, when face stimuli are not repeated in the HP task (so that claim about
item variability here seems backwards?). We have found that the correlation between CFMT and
congruency appears to be entirely due to this confound, a contribution of face learning to both
tests. This entire part regarding the relation between HP and face recognition should be revised,
because it does not appear that results depend on partial vs. complete designs, instead they
appear to depend on repetition of face stimuli - a test that is more reliable (VHPT-F) and shows a
very large average composite effect but does not repeat stimuli has not shown any correlation
with CFMT in several large samples.
Richler, J.J., Floyd, R.J. & Gauthier, I. (2015). About-Face on Face Recognition Ability and Holistic
Processing, Journal of Vision, 15(9):15.
This is relevant to the predictions made for P2 on page 13. In fact, the whole set of predictions
here is quite confusing, because the authors do not separate the test from the specific indices
measured by the test. A composite test (and the CCP) has individual conditions, each of which
plausibly has a strong contribution from face recognition ability (and there is no question in my
mind that these individual conditions should correlate with CFMT). But the references they cite
24
(28-30) concern the possible correlation between the congruency effect and CFMT scores. It's a
completely different construct. The authors here do not use individual differences in congruency
in their analyses, and they should make that clear from the start (their analyses, even based on
conditions that come from a test that could measure HP, are not relevant to HP). They may be
able to suggest that something different is going on in congruent and incongruent conditions, but
this is all very lose and speculative as they do not use congruency in their individual differences
analyses (readers might be confused because it is reported for averaged results).
For an example (no need to cite this!), see a recent paper we published in Psychological Review,
in which we use the composite task in a training study with objects, we do observe increased
congruency, but the individual differences in the individual conditions are very strongly
correlated with domain-general variance for other tasks.
Richler, J. J., Tomarken, A. J., Sunday, M. A., Vickery, T. J., Ryan, K. F., Floyd, J. R., Sheinberg, D.,
Wong, A. C.-N. & Gauthier, I. (in press). Individual Differences in Object
Recognition. Psychological
Review. (https://www.dropbox.com/s/vy3ho4vmwir1b3d/Richler2018PR.pdf?dl=0)
In Table 5, most of the strongest correlations are among the SPPo across orientations, does that
suggest more common variance across orientation for objects than faces?
minor:
page 7 line 13 - "Neural mechanisms which process upright faces are assumed to be no longer
engaged in the processing of inverted faces." as far as I know, the common assumption (Whether
I believe it or not) is that mechanisms for inverted faces would be the same as those for general
objects, and they would be engaged still for upright faces, but in that case there would be
additional mechanisms involved for upright faces. The phrasing is conceptually confusing, it
would be much clear to set up inverted faces as a baseline (the claim that inverted faces differ
from common objects is a lot more rare).
(on page 13 in their discussion of P1, the same sort of thing happens, where some special
inverted-specific variance is said to possibly emerge -> but models that suggest a qualitative
difference suggest that it is upright faces that are different, not inverted faces)
page 8 line 21 - "Predicting face recognition, which is regarded as the core ability of the face
processing domain [27],"
This sentence is unclear, the reader cannot know exactly what you mean by "face recognition"
here (what is measured in a test like CFMT? or a latent construct based on several tests? does it
require LTM involvement or just matching across views" - and in addition, whether is is regarded
as "the core" seems like somebody's opinion more than anything. I also don't think this point is
needed.
page 13 line 25: my preference would be to remove "neural mechanisms" and just used
mechanisms here (and elsewhere) - of course, psychological mechanisms arise from the brain, but
other than that, nothing here speaks to neural mechanisms.
page 19 - line 36 - note that adding the CCMT might not be a good approach, given cars have
been repeatedly found to be special (sometimes more than faces) in individual differences studies
with many categories. This is summarized here:
25
Richler, J.J., Wilmer, J.B., Gauthier, I. (2017). General object recognition is specific: evidence from
novel and familiar objects. Cognition, 166: 42-55.
Sunday, M.A., Dodd, M.D., Tomarken, A.J., Gauthier, I. (in press). How faces (and cars) may
become special. Vision
Research. (https://www.dropbox.com/s/r94ckvahdgpvyfo/SuDoToGa17.pdf?dl=0)
Reviewer: 1
Comments to the Author(s)
Following the previous round of review, I indicated that I was generally happy with the current
state of the manuscript and had no further comments. My opinion has not changed since, so I
would first of all like to re-iterate that I think this study makes a useful contribution to the face
recognition literature and the manuscript describes the study clearly both in terms of motivation
and execution.
Given the substantial disagreement between the authors and their other reviewer, I would also
like to offer my perspective on the issues raised in the previous round.
First, I agree with the authors that their study is of use to the face recognition community based
on the large sample size they have employed here, and their focus on the correlational structure
observed across tasks and orientation conditions. Their work makes a clear contribution to the
debate regarding quantitative/qualitative debate regarding upright and inverted face processing.
Specifically, with regard to the previous studies discussed in the response to reviews, the authors
are correct that their study includes far more participants than previous studies and includes a
direct analysis of the correlational structure that an individual-differences approach allows you to
examine. These features of the text differentiate the current study from previous related work and
extend our state of knowledge meaningfully.
Second, I also agree with the authors that many of the choices they have made both in designing
their study and describing it in the text are consistent with current practice in the field. For
example, the CFMT is indeed widely used, largely because it is supported by solid psychometric
data. Similarly, terms like “domain-general” etc. are indeed widely used and widely understood
within the field. Referring to their results in terms of orientation invariance is also perfectly clear.
Again, I think the current draft of the manuscript describes an interesting and useful contribution
to the field and I have no further suggestions for improvement.
Author's Response to Decision Letter for (RSOS-181350.R0)
See Appendix C.
26
label_version_4
RSOS-181350.R1 (Revision)
label_author_7
Review form: Reviewer 3 (Isabel Gauthier)
Is the manuscript scientifically sound in its present form?
Yes
Are the interpretations and conclusions justified by the results?
Yes
Is the language acceptable?
Yes
Is it clear how to access all supporting data?
Yes
Do you have any ethical concerns with this paper?
No
Have you any concerns about statistical analyses in this paper?
No
Recommendation?
label_recommendation_7
Accept as is
Comments to the Author(s)
label_comment_7
The authors have addressed all my comments, thank you!
label_end_comment
Decision letter (RSOS-181350.R1)
21-Nov-2018
Dear Professor Meinhardt,
I am pleased to inform you that your manuscript entitled "Orientation-invariance of individual
differences in three face processing tasks" is now accepted for publication in Royal Society Open
Science.
You can expect to receive a proof of your article in the near future. Please contact the editorial
office (openscience_proofs@royalsociety.org and openscience@royalsociety.org) to let us know if
you are likely to be away from e-mail contact. Due to rapid publication and an extremely tight
schedule, if comments are not received, your paper may experience a delay in publication.
Royal Society Open Science operates under a continuous publication model
(http://bit.ly/cpFAQ). Your article will be published straight into the next open issue and this
will be the final version of the paper. As such, it can be cited immediately by other researchers.
As the issue version of your paper will be the only version to be published I would advise you to
check your proofs thoroughly as changes cannot be made once the paper is published.
27
On behalf of the Editors of Royal Society Open Science, we look forward to your continued
contributions to the Journal.
Kind regards,
Andrew Dunn
Royal Society Open Science Editorial Office
Royal Society Open Science
openscience@royalsociety.org
on behalf of Prof Antonia Hamilton (Subject Editor)
openscience@royalsociety.org
Comments to the Author(s)
The authors have addressed all my comments, thank you!
Follow Royal Society Publishing on Twitter: @RSocPublishing
Follow Royal Society Publishing on Facebook:
https://www.facebook.com/RoyalSocietyPublishing.FanPage/
Read Royal Society Publishing's blog: https://blogs.royalsociety.org/publishing/
Appendix A
Dear Editor, dear referees,
When reading the reviews we felt that reviewers‘ major reservations concerned the point that orientation-
nvariance of individual differences may be apt to generally rule out the hypothesis that qualitative changes of
processing go along with picture-plane inversion.
We hope that the revised ms is now clear in this respect. Evidence from individual differences relies on
ommon variance. Individual difference analysis can only reveal what is captured in correlation structures, and
which factors modulate correlation structures. Larger parts of the revised Discussion critically evaluate principal
imitations of the chosen approach, and also specific limitations of the current study.
We tightly focus on the finding of orientation-invariance in the revealed correlation structures, and tone down
general claims concerning the qualitative/quantitative debate. Accordingly, we changed title and also the
abstract in places. The Predictions section is important for understanding the different implications for
orrelation structures which follow from process change or process invariance linked to inversion. This section
s now more explicit, and sharpens the crucial observations which have to be revealed in data analysis.
We think both reviewers did a great job and helped us sharpening the paper. We also feel that scope, relevance
and meaning of our findings for a central debate of face perception research has now become much clearer.
Please see detailed reply to the comments below. New text in the revised manuscript comes in blue color.
Comments to Author:
Reviewers' Comments to Author:
Reviewer: 1
Comments to the Author(s)
The authors describe the results of a single study that uses an individual-
differences approach to investigate whether or not face inversion leads to
“qualitative” differences in face processing. In previous literature, this
has been taken to mean that the ability to encode parts vs. whole-face
features or local shape vs. metric relationships is modulated by face
orientation. While there have been a few attempts to examine this issue
with correlational approaches, the authors present data from a large sample
(N~300) in which participants completed a battery of 3 distinct face
recognition tasks in upright and inverted orientation (the CFMT, the CCP
and the SPP). The authors present bivariate correlations and multiple
regression analyses that suggest orientation does NOT disrupt processing in
a qualitatively different way, but rather leads to less efficient face
recognition via the same mechanisms. This is largely consistent with prior
studies demonstrating that similar SF channels are used for upright and
inverted face recognition, etc.
The methodology used here is straightforward: The authors have used tasks
that are either established standards in the literature (the CFMT) or have
been demonstrated to reflect aspects of face recognition that are widely
studied. The implementation of these did not strike me as unusual in any
way, so I have no meaningful criticisms of the authors’ data collection
procedures. Similarly, I think the data analysis itself benefits from being
relatively simple. The authors are not bringing in too many bells and
whistles to look for the relationships they are interested in, but are
relying on fairly basic tools for looking at multivariate data. Again, I
find little to meaningfully criticize here. I would like to see the results
section contain a little more detail, I think (the authors present a good
bit of their data by describing cases where outcomes “strongly correspond,”
which could be shored up by some concrete statistical statements), but for
the most part I think this is all fine.
The big issue to consider, I think, is whether this set of tasks was well-
suited to look for the kinds of outcomes that could have revealed effects
of orientation on processing. On one hand, we have to be careful here,
because there must come a point where you decide that you’ve established a
useful battery and can’t just keep layering on task after task. On the
other hand, it’s worth considering if we’re missing something – are there
tasks where prior literature suggests inverted faces should make observers
do something qualitatively different? I think the CCP was a good target to
include for this reason as a means of attacking the idea of parts/wholes in
upright and inverted face recognition. What I didn’t understand was exactly
what the purpose of the SPP was, especially when there are several other
widely-cited results that seem like more obvious targets for the current
design. In particular, I was surprised that there wasn’t a direct
examination of the feature spacing vs. feature shape dissociation that
continues to influence discussions of face recognition. Similarly, I was
also surprised that there weren’t more attempts to include non-face objects
in the design given that this provides a chance to identify process-
specific components. For example, there is a Cambridge Car Memory task as
well, and other studies of congruency have used houses and other objects as
stimuli. To me, these seemed like they would have been particularly useful
to include because they provide the best chance, so to speak, to find the
kinds of orientation-selective processes the authors are talking about.
For me, this is the biggest limitation of the paper. I don’t disagree with
the main results, but there is a sort of “God of the gaps” argument that
the paper can’t quite do away with: What if you just didn’t include the
right task? To be clear, I say this as a reviewer who generally agrees with
the authors’ main conclusions based on my reading of the current draft and
other related literature! My concern is really about the impact of this
result on the field – is it a knockout blow to the idea of qualitative
differences, or is there room to argue that some important chances to see
it were left out? I think the current results are certainly valuable, but I
also have moderate concern that it will seem incomplete to some and be less
convincing as a result.
These concerns are offset, however, by the very clear writing throughout
the manuscript and the contextualization of the current results within
previous literature on the topic.
Thanks a lot for your detailed comments and your appreciation oft the manuscript! We fully agree that the
potential generality of our findings is limited by the specific test selection (see new 2nd last par of Discussion).
Please note, this is just a first attempt to contribute to the qualitative/quantitative debate with the individual
differences approach. Please also note that we fully acknowledge that the approach is inherently incomplete,
ince it relies just on what tasks have in common. So, we will certainly not see “a knockout blow to the idea of
qualitative differences“ from individual difference data, even if evidence accumulates with new test batteries
also showing that if tasks correlate, they do so for both orientations, and across them. Despite the principal
imitations of the approach, we find it is worthy of pursuing further with other test batteries – maybe
orientation-invariance of common variance in face processing tests could be further validated.
Please note also we have added further analyses, i.e. distance analysis (see new Sections) and comparison with
pearman rank correlations (see new Tab. 9). We hops this now better meets your expectations of richer
analyses for individual differences data.
Reviewer: 2
Comments to the Author(s)
This study explored whether turning a face upside-down leads to qualitative
changes in face processing by using an individual-differences approach. The
authors reported that there were no common factors related to face
inversion across tasks and suggested ‘no qualitative changes of face
processing by picture-plane inversion’ (from the title). I think that the
finding can provide fruitful insights into the field; however, I believe
that the claim is too enthusiastic and is not valid, because it rests on
the implicit assumption that the nature or mechanisms of inversion effects
are identical across the three tasks. I believe that this issue renders the
study inconclusive and that the authors should justify or acknowledge this
issue and revise the whole manuscript (including the title) accordingly.
Thanks for this comment. It is, however, not true that our major claim of orientation invariance of common
ariance rests on the implit assumption that inversion switches on a processing mode which is shared by all
onditions with inverted stimuli. Whether this potential effect of inversion exists or not is definitely an
nteresting question, which can be decided at the data. The crucial test whether inversion changes the
processing mode, or not, is whether correlations across orientations and within the same orientations are the
ame, or not. We have made this point very clear in the new enlarged Predictions section, which oulines the
different predictions from the two alternative hypotheses. We return to it at several places in the revised ms,
and come to it in the revised Discussion.
1. Although the authors claimed that they should find an orientation-
dependent factor (component) if inversion qualitatively changes face
processing, it is likely that the effects or mechanisms of inversion vary
depending on tasks. For example, if face inversion induces task A to
disrupt holistic processing, task B to disrupt first-order relations
(seeing a stimulus is a face because its features are arranged with two
eyes above a nose, which is above a mouth), and task C to disrupt second-
order relations (perceiving the distances among features), there may be
little or no orientation-related shared variance among tasks. In fact,
Maurer et al. (2002, Trends Cogn. Sci.) have already noted that inversion
of a face interferes with several distinct types of configural processing.
Thus, it is not surprising at all that the authors found only orientation-
invariant, task-related factors, because how inversion affects behavior or
cognition may qualitatively change across tasks. I believe that the study’s
contribution to the field is clearly not the ‘no qualitative changes of
face processing,’ but the ‘(possibility of) qualitative changes among face-
related tasks’ by inversion.
Thanks for this comment. You suggest that inversion switches on processing that is (i) different from upright
and (ii) specific for each task, i.e. not shared among tasks. Then we should see (a) no common variance across
orientations and (b) no common variance across tasks for inverted presentation. However, our results show
hat if there is common variance across tasks, it is in upright, inverted and across orientations likewise. This is
at odds with the expectation from the case you describe.
We acknowledge that just the failure to find a orientation-specific, task general factor (i.e., a general “part-
based“ mode some authors have in mind) is no conclusive evidence against a potential qualitative change,
because it could be so as you describe (see revised Predictions section and new pars in Discussion). It could also
be that inversion changes the processing mode in each task, and exactly the same tasks are linked via shared
processing modes in either orientation. Then, we would see that the same tasks correlate in either orientation.
However, we would not see correlations across orientations, because the processes for upright and inverted
timuli are different ones. Hence, same correlations in upright, inverted and across orientations are clear
evidence against a change of processes induced by inversion in shared task processing. Please see our revised
Predictions section, which includes a longer par on the expectations from process change and process
nvariance related to changing orientations.
2. Alternatively, it is likely that the results simply reflected that the
three tasks have a larger variance than the face orientation, rendering
distinct components (between upright and inverted face conditions) hardly
visible. The larger number of levels in the tasks (i.e., 3) compared with
that in face orientation (i.e., 2) may also be intrinsically related to the
variance difference. In any case, following ‘the eigenvalues-greater-than-
one rule’ proposed by Kaiser (1960) makes no sense. Some components may be
related to inversion, even though their eigenvalues are less than one.
Although their impacts would be smaller than ‘task-related’ components, but
the existence of such components can provide evidence for some qualitative
changes in face processing induced by inversion. If the authors wanted to
claim NO qualitative differences between upright and inverted face
processing, they should show there are really no upright-face- or inverted-
face-specific components. If there are some components related to face
orientation, the authors could evaluate the effects of tasks and inversion
in a quantitative, not qualitative (i.e., yes/no), manner.
We do not understand the variance argument. PCA decomposes the correlation matrix, and no other data
enter in the solution. The variance of each variable is 1 (diagonal elements of R). Since each test condition was
measured for upright and inverted stimuli, the variance for conditions with upright and inverted stimuli is
dentical (sum=7 for each orientation). Sorry, we cannot follow you here - we have ascertained by measuring
each task in both orientations that each test condition was free to correlate with another one, and in either
orientation.
You further suggest to look for orientation-specific loadings in the factors with small Eigenvalues.
irst, we agree that the Lambda > 1 criterion is not well suited in all situations. However, additionally using the
Horn criterion from parallel analysis again suggests that there are 4 common factors at the maximum (58.5%
ommon var) – adding more would not be justified by any objective criteria. This would not be sound (see new
ig. 3 and Principal component section).
When looking for sig. loadings in the higher no. factors with small Eigenvalues you find some (notably smaller
ones than the loadings printed boldface in Tab. 8) in the PCA loadings matrix - but just a few ones, distributed
across the remainder 10 factors. These single loadings indicate variance unique to a test condition&orientation,
which don’share significant proportions of variance with others.
To decide whether the picture changes when not only the first 4 factors, but all factors are included (=full
ariable representation) we added a test on the distances in full and four factor space (see new Section
Distance analysis). If using only the first 4 factors ignores significant components which represent specific
orientation tuning for some tasks, the results for same orientations and across them should change for both
olutions. The test shows that, for both factor solutions, the distances of the test conditions in factor space
agree within the same orientations and across them. The test results are rather clear (see new Tabs 10 & 11).
This is additional evidence that the finding of equal corelations across and with orientations holds for the
measurement variables, and is no artifact of the factor solution, since the PCA fully represents the variables,
and the variable distances are direct transforms of the zero order correlations in the complete PCA.
Please note the new final paragraphs of Discussion. We fully achnowledge that one cannot rule out potential
orientation-related qualitative changes of processing with individual differences analysis. Potential changes in
omponents which don’t share variance are not captured. Note that the four factor solution indicates that
here is at least 40% of variance left to task specific and spurious components which do not rely on common
processes. We cannot say anything about the effects of inversion in these components.
Please also note that we also fully acknowledge that our unique results regarding orientation invariance of
ndividual differences may be due to the specific test selection (2nd last par of Discussion).
3. The rationale behind performing multiple repression analyses is unclear.
I am not convinced that the analyses added an additional support for some
arguments or resolved remaining issues. In addition, it is not clear why
only CFMT was a dependent variable.
The rationale was to prove whether equal predictability results when criterion and predictors have same or
opposite orientation (added to multiple regression results section). A further motivation for choosing CFMT as
he criterion was that the attempts to predict CFMT from other face perception tests has raised significant
nterest in the past years. See new par in Predictions section, new sentence in Multiple regression results
ection and please see cited literature.
4. Strange expressions are everywhere. I could not understand the texts
such as: ‘customary upright orientation’ (p.2)
eplaced by “usual“
‘joint processing of face parts’ (p.2, kind of configural or holistic
processing?)
ephrased
, ‘joint or interactive processing of face parts’ (p.2, how do they differ?
What is interactive processing of face parts?)
ephrased
, ‘process-specific processing’ (p2, explanation needed)
Added in brackets
, ‘distinguished processes’ (p3, distinct?), ‘To anticipate our results’
eplaced by “distinct“
(p3, the authors hypothesized it?)
Cannot find this expression
, ‘normal views’ (p3, what kind of normal?)
eplaced by “upright“
, and ‘complex facial features’ (p11, what does it mean by ‘complex’? Are
there simple facial features?)
complex“ deleted
5. It is desirable to plot data with scatter plots and spot outliers.
This gives 91 scatter-plots. We have made a survey of plots in a separate xls file that could be added as
electronic supplement.
Minor points:
1. (p.3) “Three hundred and nineteen (314) observers participated in the
study.” The number of participants is unclear. Which (319 or 314) is
correct? If the number is 314, please describe why five participants were
excluded.
word corrected
2. (p.3) “70.8 % were female.” Please report the exact number of
participants in real number (222? But why not 70.7 %?).
number inserted
3. (p.3) “€30,-” “,.” Not needed.
deleted
4. (p.4) “No feedback about correctness” should be “No feedback about
responses”
orrected
5. (p.4) What are ‘coherent blocks?’
Coherent deleted
6. (p.4) What are ‘professional photographs?’
ephrased
7. (p.5) What is ‘CD?’
deleteed-abbreviation not necessary
8. (p.7) “significant at the one percent level” Please report the exact
statistical values for each test.
eported
9. (p.11) “However, the fact that the face stimuli were overlaid with noise
maskers in the latter study may have favoured usage of cues just from the
eyes region, which proved to be the most salient region in the masked
displays [2]. In the present study, we used unmasked stimuli, but observed
orientation invariance of common variance within and across test
conditions.” Gold et al. (2012, Psychol. Sci.) used unmasked/non-noised
stimuli.
Thanx for drawing our attention to this interesting paper. (now cited, Discussion)
10. (p.2) “Activity which varied in close correlation to the behavioral
inversion effect was found only in the fusiform face area [FFA; 14]”
Matsuyoshi et al. (2015, J. Neurosci.) reported the OFA correlated with the
behavioral face inversion effect.
Thanx again for drawing our attention to an interesting paper. (now cited, Intro)
11. In addition to alpha, it may be helpful and valid to report Revelle &
Zinbarg’s omega total coefficients (2008, Psychometrika) for reliability
coefficients.
n the current attempts to predict face recognition (e.g. Wang et al, 2012,2016; Richler et. al 2011,
2012.2014,2015; Wilmer et al 2010; Gauthier et al, 2018) use standard coefficients (Split half, Cronbach alpha,
Guttman L2). There are currently no studies using the recently introduced omega for experimental tests. We
are clearly lacking standards here. Why do you think could it be helpful to introduce a new reliability measure
n a paper about the inversion effect? On the original Dunn et al. Article (2014) we have found only a single
itation from the vision field (Schweinberger/Edwards7Neyer 2015).
13. ‘Revisiting’ is inappropriate in this context.
Rephrased.
**********************************************
Appendix B
Point-by-point Reply to the comments of Ref2
Reviewer comments to Author:
Reviewer: 1
Comments to the Author(s)
The authors have addressed the issues I raised in the last round of review.
I have no further substantive comments regarding the manuscript.
Reviewer: 2
Comments to the Author(s)
I am disappointed that the authors did not revise their manuscript well.
Although the authors had (or have?) contextualized their findings in terms
of the qualitative and quantitative differences debate in upright and
inverted face processing, the contribution of the study is still unclear in
the revised manuscript. They now partially withdrew their former claim
(e.g., upright and inverted faces are processed by the same mechanisms) but
added ‘orientation-invariance’ claim; however, how the orientation-
invariance merits the literature is not clearly written. What line of
research does this study contribute to? How does this finding merit the
‘qualitative/quantitative’ difference debate in the face inversion effect?
Although I still think that the finding can provide fruitful insights into
the field, I do not recommend publication of this paper in its current
form. I believe that the very clear writing is necessary (in particular, I
am concerned that the Introduction section remains almost unchanged).
The novel contribution of this work is very clear. We contribute to the quantitative/qualitative debate, which
has a long tradition in the face processing literature from a new angle, individual differences. Contrary to your
laims made below, this is the first study which addresses whether/how correlations within and across face
processing domains depend on stimulus orientation. Again contrary to your claims made below, the results are
novel and not already expected from other studies. In agreement with arguments from the first round of
eviewing, we focus on the empirical finding of orientation invariance in our presentation, but clearly (see
Discussion and Conclusion) state that we interpret our findings in favour of the claim that stimulus inversion
does not change the processing mechanisms behind the shared variance components – since any variety of
assuming orientation-specific mechanisms fails to be in agreement with the observed correlation structure.
You didn’t read the ms carefully, or simply didn’t understand the carefully written text, if you think that we
partly withdrew our former claim“.
We present clear and new empirical findings, ending in a clear-cut message, which clearly merits the
qualitative/quantitative debate of inversion effect. We have also outlined that it remains to be seen whether
orientation invariance of correlation structures can generalize to a broader battery of tests than used here.
pecific limitations of the approach for contribution to the qualitative/quantitative debate are identified and
outlined in last pars of Discussion. The Discussion is rich and illuminates many important issues of the q/q
debate, and the specific contributions to it from our findings with the individual differences approach.
That said, your opinion that the contribution of our work to the field is unclear is not comprehensible.
1. The authors misunderstood my previous comments. I did not write nor
assume “(a) no common variance across orientations” (from the authors’
response). Indeed, given the moderate to high correlation between upright
and inverted face processing (r ~ 0.4–0.8; e.g., Psalta and Andrews, 2014,
Perception; Rezlescu et al., 2017, JEP:HPP), it is hard to presume ‘(a).’ I
just wrote “it is likely that the effects or mechanisms of inversion vary
depending on tasks” and “it is not surprising at all that the authors found
only orientation-invariant, task-related factors, because how inversion
affects behavior or cognition may qualitatively change across tasks.”
A. We have have done our best to understand. Your suggestion to explain our findings with “task-specific
nversion mechanisms“ was already dismissed with our first reply. Assuming neural pathways specific for task
and orientation cannot explain the data, since we found (a) substantial correlations across orientation in all
asks and (b) same correlations among tasks irrespective of orientation (see our detailed comment to your
point 1 of review, 3rd par of Predictions (p8) and last par of Discussion, p13). Please see that observing
orientation-invariant, task-related factors is at odds with assuming task and orientation specific channels.
Moreover, we do not believe that there is a “mechanism of inversion“ in our brain, as your comments suggest
detailed in your point1 of first review). Picture-plane inversion is a physical image transformation. The simple
and plain question is whether a rotated face image is handled by the same neural modules than an upright one
n a given task.
et’s say it with the examples you mentioned in point 1 of your review: if in composite task inversion “disrupts
holistic processing“ (active in upright) and in task B spacing processing (active in upright), then (i) upright and
nverted within each task should not substantially correlate, and (ii) whether there are correlations among
asks in inverted depends on which kind of information drives processing in inverted. If these are the same
ones in either task (e.g. merely “feature-tuned“ channels) then we should see a task-general factor tuned to
he inverted orientation (which is clearly absent in the data). If we land in two new task and orientation specific
processing modes, then it is hard to say whether they have something in common, or not. But it is highly
unlikely that they share the same amount of variance than the upright conditions, and consistently for 7 test
onditions. We have already said this last time. Apparently, you still have not fully considered the possible
cenarios before you wrote your comments. Please see that “task-specific inversion mechanisms“ are clearly
no possible explanation for our data.
We have modified and simplified Predictions, and added a footnote to elucidate te contrasting predictions
rom the concurrent views (all in green).
In addition, low correlation between tasks and/or almost task-specific
principal components are expected from a previous report (Rezlescu et al.,
2017, JEP:HPP), which showed little or no correlation between face
processing tasks unless the task domain is similar (e.g., robust
correlation was found between face perception measures). The task domain
was clearly different in the present study, as the authors have
acknowledged (p.3., “face recognition, face perception, and face-selective
attention”). Thus, one can easily expect to find task- or process-specific
factors that load both upright and inverted face conditions. Given the
previous findings, I feel the study is not surprising at all in its current
form. Clear writing/justification is necessary.
B. Our study clearly reports two task-common factors (as already stated in the abstract, a common factor for
ace recognition and face perception, a second common factor for face recognition and face-selective
attention). It is wrong to say that we found only task-specific factors.
urther, your claim that “one can easily expect to find task- or process-specific
factors that load both upright and inverted face conditions“ comes from your
private imagination. It is purely ad-hoc, arbitrary and unsubstantiated from the literature. Particularly the claim
hat one can easily expect correlations across orientations follows from nothing and is an unsubstantiated ad-
hoc assertion.
We have carefully looked at the Rezlescu et al., 2017, JEP:HPP study.
i) The study is about the relation of inversion, part/whole and composite effects, all defined by measures
derived from original test scores, and the correlations of these meaures with the Cambridge Face Perception
Test (albeit the title says it‘s about Recognition, which is really msleading). In the whole article, correlations
among the test conditions in upright and inverted are not reported. There is no correlation table, like our Table
5, and there is also no principal component analysis. Just one correlation is reported in the text (there p. 5,
=.52 between CFPT and a self-constructed face matching test, both in upright orientation). Contrary to your
laim (little or no correlation between face processing tasks unless the task
domain is similar) the authors wrote: “In practice, the substantial correlation (r =.52, p < .001) between
our measures of face perception abilities—CFPT and Face Matching upright— demonstrates that our study can
eveal common mechanisms underlying different test performances.“ We can hardly decide, because the
orrelations are not shown in the article.
ii) No word is said in the article about the correlation structure among the 4 tests, and whether this structure
s the same or different for either orientation. This study does neither address nor report the dependency of
est correlations on stimulus orientation.
We also looked at the Psalta and Andrews, (2014) study you mention. The study compares inversion effects in
emotion recognition for normal and thatcherized faces in a small sample of 12 subjects (!). In a small par in
esults (last par p. 719) very high response correlations of correct responses (r>.9) between upright and
nverted and normal and thatcherized condition are reported. These findings do not appear in the abstract, and
hes are not further interpreted or discussed in Discussion.
To cite this study in the context of (large sample) individual differences analysis is misleading, and
nappropriate. Further, the reported correlations are obscure (method of calculating them was not described,
orrelations are larger than reliabilities, which is puzzling). Nobody would conclude from this report (from 12
ubjects) that upright and inverted condition should correlate in different face processing tests, and across
hem.
rom both studies we cannot see how orientation-invariance of the test correlation structure is a already
nown, expected and nonsurprising finding. Both studies simply do not state anything about the correlation
tructure of face tests from different domains, and its dependency on stimulus orientation.
We reiterate that revealing the correlation structure of face recognition, face perception and face selective
attention and its dependency on stimulus orientation is a novel contribution to the face processing literature.
like to express and to communicate to you that trying to evoke the impression that our study is irrelevant and
not novel by referring to these two studies reflects no sound scientific conduct in this review process.
2. “motivation for choosing CFMT as the criterion was that the attempts to
predict CFMT from other face perception tests has raised significant
interest in the past years” (from the authors’ response). I believe that
‘others do it’ does not justify the approach. The authors should clearly
describe why they selected CFMT as the primary dependent variable. Does the
authors believe that memory is the most critical part in face processing?
Is it better than face perception and face-selective attention? How does
this multiple regression analysis complement their claims?
t is a sound motivation to contribute results enlarging the validity spectrum of the CFMT, since this test
meanwhile has become a standard assessment of face recognition (see, e.g. Richler et al. 2015, JoV). The
esults obtained here also show that face recognition is the more complex ability, which includes a perceptual
and a face-tuned attentional component, while the latter components appear independent. It is reasonable to
nclude more complex abilities if you want to reveal individual differences structures. You should not use too
narrow, specialized abilities. We give a motivation in the 2nd last par of revised Intro (green text). The last par
oft he Prediction Section was adapted accordingly (green text).
econd, the multiple regression analysis is a powerful and striking demonstration that the relative orientations
of criterion and predictor do not matter for predictor regression weights and explained variance. We disagree
hat these results are easily seen from the PCA results and are therefore superfluous. You would not be able to
guess these results correctly by knowing only the loadings patterns. You think so because you know the results
a-posteriori. The relationships of PCA and multiple regression are not so easy.
3. Abstract. “the findings suggest process-specific but orientation general
mechanisms” ‘orientation general’ sounds odd. It should be ‘orientation
invariant’. In addition mechanisms of what? Does it “mechanisms behind the
three tasks?”
The abstract is well written and well understandable for any reader familiar with the field. Terms “domain-
general“ and “object-general“, “category-general“ etc. are also used by Yovel and Kanwisher and in latest work
of Gauthier group (Richler et al., 2017, Cognition), so it doesn’t sound too odd and it‘s clear that we mean a
mechanism that generalizes over orientations. The observed correlation structure is orientation-invariant
observation), but the assumed processing mechanisms behind handle all orientations, so they are orientation-
general.
4. The title “orientation-invariance of individual differences in three
face processing tasks” is somewhat difficult to grasp. I think individual
differences is not needed.
This would result in a wrong claim about our findings. In fact, we did NOT find that performance was
orientation-invariant – performance was changed dramatically by inversion. We found that the correlation
tructures (indiv. difference patterns) were not changed by inversion.
Appendix C
Dear Reviewer3, dear Isabelle Gauthier,
hank you for your willingness to enter this review process, and thanks a lot for your comments.
We agree that the main message of the paper could be much better delivered without too much complex
analyses and justifications.
Reading your suggestions for testing orienation-invariance, I guess you had a strong orientation-invariance
principle in mind, claiming that all processing in upright could be fully predicted by processing in inverted. If
rue, this would indeed be strong proof against any qualitative changes. I believe, claims in this direction
aused the hefty reactions we have seen. In our 1st response to reviewers and revised ms we hoped that we
ould make it clear that the data support a weaker claim of orientation-invariance, all shared task processing is
hared independent of orientation, concluded from same correlation structures. It’s our task to convey the
main message and its implications correctly, plain and easily understandable.
To do so, I liked your idea to start with the attempt to predict upright from inverted for each test condition
i.e., testing the strong claim) followed by methods apt to reveal the correlation structure of the test battery.
This helped to better distinguish whats going on in a single test condition from the shared processes involved
within and between tasks. Following this idea gave the revised paper a new, slim, and straightforward
tructure, and it helped to distinguish strong and weaker claim of orientation-invariance, thus avoiding
misunderstandings.
n view of the very clear results (such a stunningly clear factor loadings pattern has rarely been reported for
ognitive/perceptual tests, I believe), it is indeed unnecessary to write a lengthy predictions section and report
overly many analyses. We have now concentrated predictions on the major qualitative aspects, and analyse
only with regression and PCA (i.e., basic correlation methods). Distance analysis has been skipped and rank
orrelation PCA was moved to the Appendix. The sections on single test results and their discussion were
rimmed considerably.
You also commented on the CCP, its putative relation to the composite paradigm, and the section in the
ntroduction about the relation of holistic processing measures with the CFMT. We have revised the whole
ection, using the literature you recommended. Thank you for providing access to your in-press papers, which
we don’t have otherwise. In your comments I read you see need to further clarify validity aspects of the CCP, in
ts relation to the other tests of the battery, but also in its relation to the composite paradigm. We have
dedicated a new section (Discussion of individual difference results) to validity aspects, while the new General
Discussion focuses the implications of orientation-invariant correlation structures. Please understand we could
not really cover the issues about holistic measures – this is beyond the topic of this work, and should be
addressed in an own paper, we think. We make this clear in the Introduction, as you suggested. But we have
ncluded an Appendix where the interested reader sees what comes out for difference and regression based
measures of the CCP’s congruency effect. This also helped to further clarify CCP validity. (I guess from one of
our comments that you might be surprised to see that the reliability of the CE difference measure is still
easonably good. This is a mere consequence of the fact that congruent and incongruent conditions were quite
eliable and their intercorrelation is small. Please note we didn’t report reliability for the total CCP (congruent
and incongruent combined) in Table 2, which would indeed be strange. I think this was a misunderstanding.
You also find some considerations about relations among CCP and composite paradigm in the Discussion of
ndividual difference results. However, since we didn’t measure the composite paradigm along along with the
CCP here, we cannot be more precise.)
You also recommended to use averages from SPP conditions in individual differences analysis and report no
details for CFMT parts reliability, for the sake of brevity. Well, we need the opacity conditions to be able to
eport interactions with orientation (relevant for Discussion, see new General Discussion). Further, it is
mportant for us to stay with the original measures from all conditions of the original test to maintain full
ransparency of results. Some readers could think that orientation-invariance of correlations may be an artifact
of averaging, and that we try to hide conditions which do not comply with the general principle. I personally
believe there is scientific value in providing detailed information about the original observations – this also
oncerns the reliabilities for CFMT parts for inverted faces, which some readers might find valuable for own
analyses, since they are not reported elsewhere.
You remarked that SPP_o intercorrelations were high. We are cautios with interpreting this, since the common
ariance of SPP_o conditions declined 4% when estimated on the basis of rank correlations (see Appendix B).
The test was clearly easier than the gender categorization task.
You requested clarification of the term “face-selective attention“. At many places in the revised ms we make it
lear that “face-selective attention“ (SPP) refers to object-based attention to faces, which is distinct from and
unconfounded with spatial attention. An object-based attention task cannot be solved by confining or directing
patial attention to locations X or Y, and suppressing information from other regions. This should be clear now
see also last sentence of Discussion of individual difference results).
We have addressed all your “Minors“. We hope it is now more clear that inverted faces engage areas along the
ommon object route while upright faces are more localized. See new 1st par of Intro and 2nd par of General
Discussion. Thanks for the hint to car specificity, we have changed accordingly (last par of General Discussion).
The link to dryad data is tested… and working!
We didn’t mark changes with colors, because the text was largely rewritten in all its parts. A whole reading is
necessary. We hope you find it stands good now.
incerely, G. Meinhardt
Dear Reviewer 1
Thank you for your review, your anew engagement, and the time you spent on our paper. You saw that Rev. 3
ikes to see the paper more slim and succint, but also likes to see more about test (construct) validity. We have
done our best to arrive at a succint presentation with a straightforward train of thought guiding us through the
analyses. We included the distance analysis In the last round to substantiate that the structure of variables
based on all the variables, not only the 4 factor solution) is the same for upright and inverted stimuli. Since you
aid in your 1st review that our analyses could be richer in this and that respect, I hope you can live with the
new solution to concentrate just on correlation methods to stay slim. Regarding reorganization of the ms in this
ound, I see advantages in the solution that we now discuss validity aspects of the battery and across-tasks
elations apart from the main point, orientation-invariance, in the General Discussion. We hope that we have
now arrived at a solution that covers all one could meaningfully say about orientation-invariance of common
est variance, and its implications for putative changes of face processing mechanisms.
incerely, G. Meinhardt
Society Open
