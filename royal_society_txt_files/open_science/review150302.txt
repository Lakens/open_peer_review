An advanced shape-fitting algorithm applied to quadrupedal
mammals: improving volumetric mass estimates
Charlotte A. Brassey and James D. Gardiner
Article citation details
R. Soc. open sci. 2: 150302.
http://dx.doi.org/10.1098/rsos.150302
Review timeline
Original submission: 7 May 2015 Note: Reports are unedited and appear as
1st revised submission: 29 June 2015 submitted by the referee. The review history
2nd revised submission: 19 July 2015 appears in chronological order.
Final acceptance: 23 July 2015
Review History
label_version_1
RSOS-150194.R0 (Original submission)
label_author_1
Review form: Reviewer 1 (John Hutchinson)
Is the manuscript scientifically sound in its present form?
Yes
Are the interpretations and conclusions justified by the results?
Yes
Is the language acceptable?
Yes
Is it clear how to access all supporting data?
Somewhat clear-
prior data are from http://www.animalsimulation.org
Mammoth scan data are from http://3d.si.edu
lines 250-252 show how to get the relevant code
but the giant sloth data are not provided. These ideally should be. NHM is very proprietary
about usage of its image data but Morphomuseum.org would be a good museum-friendly place
to share these data on. I urge they use it for this.
© 2015 The Authors. Published by the Royal Society under the terms of the Creative Commons
Attribution License http://creativecommons.org/licenses/by/4.0/, which permits unrestricted use,
provided the original author and source are credited
2
I have concerns that the http://www.animalsimulation.org storage site is just a lab website and
these data thus have very uncertain longevity. Ideally the data should be on a public repository
with some permanence. I leave this decision to the authors+editors, especially as the data are
originally from another paper.
Do you have any ethical concerns with this paper?
No
Have you any concerns about statistical analyses in this paper?
No
Recommendation?
label_recommendation_1
Accept with minor revision (please list in comments)
Comments to the Author(s)
label_comment_1
I can see the value of this study and it just needs minor amendments. The writing is nice and
concise and clear.
"do not require manual segmentation of skeletons" L34- I suggest not using "segmentation" as this
is easily confused with segmentation of CT data. How about "manual separation of body
segments from skeletons"?
Line ~106: To be self-serving but perhaps fair, Ref 20 applied similar shrink-wrapping and
polygonal hull methods to T. rex's body (figs5,6) and an ostrich's torso. Seldom acknowledged
and done differently in some ways than later approaches, but the usage of digitized and 3D
scanned data was not radically different, except that it did not blend traditional scaling
approaches with 3D volumetric ones as the later convex hulls studies did.
Line 409-10: "However... our results are sensitive to the mounting of the skeleton."
Lines 411-3: rather than a "WI Sellers, pers. comm" citation here, please explain why the scapula's
position is tricky, so readers know- e.g. surrounding soft tissues.
Generally- the point might well be made in the paper that this approach apparently avoids the
problem of overlapping leg segments, which previously published convex hulls seem to have--
i.e. the manually crafted + shrinkwrapped leg/body segments overlap, causing potential
overestimates of body mass. This is visible in many of the published 3D hulls and has not yet
been noted in the literature, to my knowledge.
A worthy contribution to the literature and methodological choices.
-Prof. John R. Hutchinson, The Royal Veterinary College
label_author_2
Review form: Reviewer 2 (R Farina)
Is the manuscript scientifically sound in its present form?
Yes
Are the interpretations and conclusions justified by the results?
Yes
Is the language acceptable?
Yes
3
Is it clear how to access all supporting data?
Yes, it is clear from reading the paper how to access all supporting data.
Do you have any ethical concerns with this paper?
No
Have you any concerns about statistical analyses in this paper?
No
Recommendation?
label_recommendation_2
Accept with minor revision (please list in comments)
Comments to the Author(s)
label_comment_2
This manuscript is a significative advance in improving body mass estimations of fossil
vertebrates whose complete skeletons are known. For doing that, they propose a recently
developed and very useful volumetric technique that implies fotogrammetry and a shape-fitting
algorithm, the alpha shapes. The method is applied to two well-known giant extinct Quaternary
mammals, ie the woolly mammoth (Mammuthus primigenius) and the giant ground sloth
Megatherium americanum.
All the research is well-conducted and correctly expressed, so I recomend publication as it stands,
except for a minor detail that should be corrected: Fariña et al. 1998 (reference number 41 in the
manuscript) did not use "a volumetric sculpting technique" for estimating "a body mass of 3800
kg for the ground sloth M. americanum". Instead, they used a set of 44 allometric equations based
on a modern database of craniodental and appendicular dimensions and obtained estimations of
6265 kg (arithmetic mean), 2543 kg (geometric mean), 2903 kg (median), 2896 kg (mode). It is
noteworthy that the average of those four statistics is about 3650 kg, very similar to the ~3700 kg
the authors obtained with their method. The result of a volumetric technique cited in Fariña et al.
1998 is from Casinos, A. 1996 (Bipedalism and quadrupedalism in Megatherium: an attempt at
biomechanical reconstruction. Lethaia 29: 87-96). I'd like to recommend the authors to check that
paper to enhance their discussion of the subject.
label_author_3
Review form: Reviewer 3 (Peter Falkingham)
Is the manuscript scientifically sound in its present form?
No
Are the interpretations and conclusions justified by the results?
No
Is the language acceptable?
Yes
Is it clear how to access all supporting data?
Supplementary scripts were not available during review (not in submission system and dryad
link not complete).
No mention of making the additional skeletons used available (this may be a restriction of the
relevant museums)
Do you have any ethical concerns with this paper?
No
4
Have you any concerns about statistical analyses in this paper?
No
Recommendation?
label_recommendation_3
Major revision is needed (please make suggestions in comments)
Comments to the Author(s)
label_comment_3
Please see attached PDF (Appendix A).
label_end_comment
Decision letter (RSOS-150194)
08-Jun-2015
Dear Dr Brassey:
Manuscript ID RSOS-150194 entitled "An advanced shape-fitting algorithm applied to the
vertebrate skeleton: improving volumetric mass estimates" which you submitted to Royal Society
Open Science, has been reviewed. The comments from reviewers are included at the bottom of
this letter.
In view of the criticisms of the reviewers, the manuscript has been rejected in its current form.
However, a new manuscript may be submitted which takes into consideration these comments.
Please note that resubmitting your manuscript does not guarantee eventual acceptance, and that
your resubmission will be subject to peer review before a decision is made.
You will be unable to make your revisions on the originally submitted version of your
manuscript. Instead, revise your manuscript and upload the files via your author centre.
Once you have revised your manuscript, go to https://mc.manuscriptcentral.com/rsos and login
to your Author Center. Click on "Manuscripts with Decisions," and then click on "Create a
Resubmission" located next to the manuscript number. Then, follow the steps for resubmitting
your manuscript.
Your resubmitted manuscript should be submitted by 06-Dec-2015. If you are unable to submit
by this date please contact the Editorial Office.
I look forward to a resubmission.
Sincerely,
Emilie Aime
Senior Publishing Editor, Royal Society Open Science
openscience@royalsociety.org
Subject Editor comments:
Whereas the reviewers were generally encouraging about the paper, one reviewer brings up a
critical shortcoming of the method that very possibly could be a fatal flaw. I agree with the
reviewer that the authors should test their model further because of the sensitivity to skeletal
pose and the alpha value chosen; there is, as they say, no sense in having to write another paper
in six months correcting the faults of this one. And this could make a much better contribution
out of this paper.
5
Associate Editor Comments to Author:
Associate Editor: 1
Comments to the Author:
Your manuscript has been evaluated by 3 expert reviewers, and reviewers 1 and 3 are
enthusiastic about the contribution of the paper and suggest only minor revisions. Reviewer 2 has
some additional concerns about the presentation of the alpha-shape fitting method as compared
to convex hulling, and in particular the potential sensitivity of the results to the alpha value
chosen. Reviewer 2 has asked that the authors address several points before the manuscript be
considered for publication. If the authors are able to address the points raised, I would be happy
to see a revised version of this manuscript.
Please also note that reviewers 1 and 2 both raised concerns about open access to the data and
associated scripts. In particular, Reviewer 1 encourages the authors to attempt to make the giant
sloth data available, commenting that while the NHM is proprietary about use of its image data,
Morphomuseum.org would be a good museum-friendly place to share these data. Additionally,
reviewer 1 raises the concern that the http://www.animalsimulation.org site is only a lab
website, and therefore has uncertain longevity. If possible, the authors should deposit the data
on a public repository that has more permanence. Reviewer 2 suggests that the authors ensure
that the Matlab scripts are compatible with an open-source alternative such as FreeMat or Octave.
In the revised version of this manuscript, please address these concerns to the extent possible, in
line with the open-data policies of RSOS.
Reviewers' Comments to Author:
Reviewer: 1
Comments to the Author(s)
I can see the value of this study and it just needs minor amendments. The writing is nice and
concise and clear.
"do not require manual segmentation of skeletons" L34- I suggest not using "segmentation" as this
is easily confused with segmentation of CT data. How about "manual separation of body
segments from skeletons"?
Line ~106: To be self-serving but perhaps fair, Ref 20 applied similar shrink-wrapping and
polygonal hull methods to T. rex's body (figs5,6) and an ostrich's torso. Seldom acknowledged
and done differently in some ways than later approaches, but the usage of digitized and 3D
scanned data was not radically different, except that it did not blend traditional scaling
approaches with 3D volumetric ones as the later convex hulls studies did.
Line 409-10: "However... our results are sensitive to the mounting of the skeleton."
Lines 411-3: rather than a "WI Sellers, pers. comm" citation here, please explain why the scapula's
position is tricky, so readers know- e.g. surrounding soft tissues.
Generally- the point might well be made in the paper that this approach apparently avoids the
problem of overlapping leg segments, which previously published convex hulls seem to have--
i.e. the manually crafted + shrinkwrapped leg/body segments overlap, causing potential
overestimates of body mass. This is visible in many of the published 3D hulls and has not yet
been noted in the literature, to my knowledge.
A worthy contribution to the literature and methodological choices.
-Prof. John R. Hutchinson, The Royal Veterinary College
6
Reviewer: 2
Comments to the Author(s)
Please see attached PDF
Reviewer: 3
Comments to the Author(s)
This manuscript is a significative advance in improving body mass estimations of fossil
vertebrates whose complete skeletons are known. For doing that, they propose a recently
developed and very useful volumetric technique that implies fotogrammetry and a shape-fitting
algorithm, the alpha shapes. The method is applied to two well-known giant extinct Quaternary
mammals, ie the woolly mammoth (Mammuthus primigenius) and the giant ground sloth
Megatherium americanum.
All the research is well-conducted and correctly expressed, so I recomend publication as it stands,
except for a minor detail that should be corrected: Fariña et al. 1998 (reference number 41 in the
manuscript) did not use "a volumetric sculpting technique" for estimating "a body mass of 3800
kg for the ground sloth M. americanum". Instead, they used a set of 44 allometric equations based
on a modern database of craniodental and appendicular dimensions and obtained estimations of
6265 kg (arithmetic mean), 2543 kg (geometric mean), 2903 kg (median), 2896 kg (mode). It is
noteworthy that the average of those four statistics is about 3650 kg, very similar to the ~3700 kg
the authors obtained with their method. The result of a volumetric technique cited in Fariña et al.
1998 is from Casinos, A. 1996 (Bipedalism and quadrupedalism in Megatherium: an attempt at
biomechanical reconstruction. Lethaia 29: 87-96). I'd like to recommend the authors to check that
paper to enhance their discussion of the subject.
Author's Response to Decision Letter for (RSOS-150194)
See Appendix B.
label_version_2
RSOS-150302.R1 (Revision)
label_author_4
Review form: Reviewer 1 (Peter Falkingham)
Is the manuscript scientifically sound in its present form?
Yes
Are the interpretations and conclusions justified by the results?
Yes
Is the language acceptable?
Yes
Is it clear how to access all supporting data?
Yes
Do you have any ethical concerns with this paper?
No
7
Have you any concerns about statistical analyses in this paper?
No
Recommendation?
label_recommendation_4
Accept with minor revision (please list in comments)
Comments to the Author(s)
label_comment_4
The authors have made considerable improvements to the text, and I feel that generally it is more
or less suitable for publication.
Couple of things are brought up by the authors response to reviewers:
--
The authors have added:
However when dealing with highly fragmentary material, fossils known to have undergone
taphonomic deformation, or fossil species for which no close modern relative exists, it may be
necessary to conduct additional sensitivity analyses to quantify the effect of articulation on
resulting mass estimates.
I still think this is too generous  It /will/ be necessary is far more apt.
--
This is a paper about modern quadrupedal mammals, applied to fossil quadrupedal mammals.
It is beyond the scope of this paper to anticipate the likely applications of alpha shapes to other
vertebrate groups.
Then, quite simply, the title must be changed to An advanced shape-fitting algorithm applied to
quadrupedal mammals. The title currently refers to the vertebrate skeleton but in their own
words, other vertebrate groups are beyond the scope of the paper (as an aside, I feel advanced is
a little self aggrandizing here).
--
The addition of a-shapes also benefits from the ability to fit shapes to complete skeletons, and
removes the need for time-consuming manual segmentation (ln 366) is still one sided  this
should be:
a-shapes benefit from the ability to fit shapes to complete skeletons, and removes the need for
time-consuming manual segmentation, but does require significant parameter testing for any
given dataset
i.e. the drawback should be mentioned in the same context as the benefit. This also reiterates that
any other workers using the method /must/ verify on their own dataset first.
Peter L. Falkingham
label_end_comment
Decision letter (RSOS-150302)
16-Jul-2015
Dear Dr Brassey
On behalf of the Editor, I am pleased to inform you that your Manuscript RSOS-150302 entitled
"An advanced shape-fitting algorithm applied to the vertebrate skeleton: improving volumetric
mass estimates" has been accepted for publication in Royal Society Open Science subject to minor
revision in accordance with the referee suggestions. Please find the referees' comments at the end
of this email.
8
The reviewers and Subject Editor have recommended publication, but also suggest some minor
revisions to your manuscript. Therefore, I invite you to respond to the comments and revise your
manuscript.
 Ethics statement
If your study uses humans or animals please include details of the ethical approval received,
including the name of the committee that granted approval. For human studies please also detail
whether informed consent was obtained. For field studies on animals please include details of all
permissions, licences and/or approvals granted to carry out the fieldwork.
 Data accessibility
It is a condition of publication that all supporting data are made available either as
supplementary information or preferably in a suitable permanent repository. The data
accessibility section should state where the article's supporting data can be accessed. This section
should also include details, where possible of where to access other relevant research materials
such as statistical tools, protocols, software etc can be accessed. If the data has been deposited in
an external repository this section should list the database, accession number and link to the DOI
for all data from the article that has been made publicly available. Data sets that have been
deposited in an external repository and have a DOI should also be appropriately cited in the
manuscript and included in the reference list.
 Competing interests
Please declare any financial or non-financial competing interests, or state that you have no
competing interests.
 Authors contributions
All submissions, other than those with a single author, must include an Authors Contributions
section which individually lists the specific contribution of each author. The list of Authors
should meet all of the following criteria; 1) substantial contributions to conception and design, or
acquisition of data, or analysis and interpretation of data; 2) drafting the article or revising it
critically for important intellectual content; and 3) final approval of the version to be published.
All contributors who do not meet all of these criteria should be included in the
acknowledgements.
We suggest the following format:
AB carried out the molecular lab work, participated in data analysis, carried out sequence
alignments, participated in the design of the study and drafted the manuscript; CD carried out
the statistical analyses; EF collected field data; GH conceived of the study, designed the study,
coordinated the study and helped draft the manuscript. All authors gave final approval for
publication.
 Acknowledgements
Please acknowledge anyone who contributed to the study but did not meet the authorship
criteria.
 Funding statement
Please list the source of funding for each author.
Because the schedule for publication is very tight, it is a condition of publication that you submit
the revised version of your manuscript within 7 days (i.e. by the 25-Jul-2015). If you do not think
you will be able to meet this date please let me know immediately.
To revise your manuscript, log into https://mc.manuscriptcentral.com/rsos and enter your
Author Centre, where you will find your manuscript title listed under "Manuscripts with
Decisions". Under "Actions," click on "Create a Revision." You will be unable to make your
9
revisions on the originally submitted version of the manuscript. Instead, revise your manuscript
and upload a new version through your Author Centre.
When submitting your revised manuscript, you will be able to respond to the comments made by
the referees and upload a file "Response to Referees" in "Section 6 - File Upload". You can use this
to document any changes you make to the original manuscript. In order to expedite the
processing of the revised manuscript, please be as specific as possible in your response to the
referees.
When uploading your revised files please make sure that you have:
1) A text file of the manuscript (tex, txt, rtf, docx or doc), references, tables (including captions)
and figure captions. Do not upload a PDF as your "Main Document".
2) A separate electronic file of each figure (EPS or print-quality PDF preferred (either format
should be produced directly from original creation package), or original software format)
3) Included a 100 word media summary of your paper when requested at submission. Please
ensure you have entered correct contact details (email, institution and telephone) in your user
account
4) Included the raw data to support the claims made in your paper. You can either include your
data as electronic supplementary material or upload to a repository and include the relevant doi
within your manuscript
5) Included your supplementary files in a format you are happy with (no line numbers,
vancouver referencing, track changes removed etc) as these files will NOT be edited in
production
Once again, thank you for submitting your manuscript to Royal Society Open Science and I look
forward to receiving your revision. If you have any questions at all, please do not hesitate to get
in touch.
Best wishes
Emilie Aime
Senior Publishing Editor
openscience@royalsociety.org
Associate Editor Comments to Author:
Associate Editor
Comments to the Author:
The authors have addressed the previous concerns about sensitivity to alpha-shape value, and
Peter Falkingham has now raised only a few minor additional points for the authors to address.
Thank you for also responding to my queries about open access to data and code. I appreciate
that this can be challenging to achieve with complex and multi-source data sets. The additional
efforts made by the authors should allow any reasonably motivated researcher to access and
make use of the source data and analysis code.
Comments to Author:
Reviewer: 2
Comments to the Author(s)
The authors have made considerable improvements to the text, and I feel that generally it is more
or less suitable for publication.
10
Couple of things are brought up by the authors response to reviewers:
--
The authors have added:
However when dealing with highly fragmentary material, fossils known to have undergone
taphonomic deformation, or fossil species for which no close modern relative exists, it may be
necessary to conduct additional sensitivity analyses to quantify the effect of articulation on
resulting mass estimates.
I still think this is too generous  It /will/ be necessary is far more apt.
--
This is a paper about modern quadrupedal mammals, applied to fossil quadrupedal mammals.
It is beyond the scope of this paper to anticipate the likely applications of alpha shapes to other
vertebrate groups.
Then, quite simply, the title must be changed to An advanced shape-fitting algorithm applied to
quadrupedal mammals. The title currently refers to the vertebrate skeleton but in their own
words, other vertebrate groups are beyond the scope of the paper (as an aside, I feel advanced is
a little self aggrandizing here).
--
The addition of a-shapes also benefits from the ability to fit shapes to complete skeletons, and
removes the need for time-consuming manual segmentation (ln 366) is still one sided  this
should be:
a-shapes benefit from the ability to fit shapes to complete skeletons, and removes the need for
time-consuming manual segmentation, but does require significant parameter testing for any
given dataset
i.e. the drawback should be mentioned in the same context as the benefit. This also reiterates that
any other workers using the method /must/ verify on their own dataset first.
Peter L. Falkingham
Author's Response to Decision Letter for (RSOS-150302)
See Appendix C.
Appendix A
The paper presents an alternative method to convex hulling for determining body mass from
skeletons. I have actually been working on the alpha-shape fitting method for a couple of years now
(indeed I think I recall discussing my work with the lead author some time last year in London,
though perhaps I am mistaken)  so have quite a lot of experience in working with the algorithm.
Unfortunately, I have found that it is very sensitive to mount pose and selection of the alpha value,
and that this sensitivity outweighs the benefits of not having to manually segment the skeleton. The
authors do discuss this in the paper, but I dont think that enough fail-cases are presented, and the
method is presented as a very cut and dry this is better (we consider a-shapes to be
methodologically superior to convex hulls) when that simply isnt the case. (Similarly: the a-
shapes technique presented here circumvents any potential issues does not acknowledge that
convex hulling also circumvents those issues).
To illustrate the sensitivity of the alpha value, I previously ran an iterative alpha shape calculation on
an Asian elephant skeleton (the skeleton in Falkingham 2012), to calculate volume over a range of
alpha values:
As can be seen from the graph, the value arrived at by the convex hull method occurs where change
n alpha value has a particularly strong effect on volume estimation. Even small variations from this
alpha value will greatly over- or under-estimate mass, so if two workers were to arrive at slightly
different alpha values, they would get very different results.
ts my opinion that the vagaries inherent in the method (i.e. selection of an alpha value via the
refinement coefficient) make the method far more subjective than convex hulling, and as such
represent a likelihood of the method being misused by workers assuming the method is objective
when it is ultimately not (or at least requires considerable work to find a suitable and objective a-
value).
The advantages over convex hulling proposed here are that the volume more closely matches the
skeleton without needing to manually segment or pose the skeleton first. But what is needed
nstead, is rigorous testing in each case that the correct alpha value has been selected. I fail to see
this as an advantage.
f RSOS considers this paper worthy of publication, I feel the following should be addressed by the
authors:
Rather than directing readers to the expensive software matlab along with associate mathworks files
and the custom script (which unfortunately is not available in the submission system so I cant see
what it does beyond calling an alpha shape function), why not simply suggest using Meshlab which
has the menu function Alpha Complex/Shape? This is simpler, and is in accordance with the open
nature of RSOS. [Though I do note in the current version of meshlab there are issues with the alpha
shape being watertight. Perhaps the authors would also consider making sure their scripts are
compatible with FreeMat]
t is also worth discussing that the processing time for alpha-shapes is considerably longer than that
for convex hulls (a low alpha and a several million point+ point cloud can take minutes, vs < 1s for a
convex hull).
Basing the ideal alpha value on an average distance from a centroid (lref) is open to issues  while
ordered laser scanning may produce relatively even scans, photogrammetry may result in extremely
dense and sparse areas of the point cloud depending on how the photos were taken, colouration
and detail of the specimen, and lighting. I suggest the authors at least test how lref varies between
different models of a single specimen (i.e. several photogrammetric models generated with different
photo sets and laser scans).
n the papers using convex hulling that have followed Sellers et al, primarily those by Bates et al, the
convex hulling method can be used to carry out sensitivity analyses on cranial and caudal
distribution of mass (by increasing cranial hulls, and decreasing caudal hulls and vice versa).
Similarly, Brassey et als stegosaur paper Dermal armour was treated seperately. Both of these
studies would require segmenting the skeleton anyway, removing the primary advantage proposed
here of alpha-shape fitting. This should be discussed as a weakness of the method presented here.
Figure 1 should have a real reference shape from which the points are derived for comparison with
the alpha shapes, and it should also have an image of the alpha shape derived using relevant values
of lref and k as they are calculated for the dataset of skeletons. Though I want to acknowledge that
this figure is excellent at showing how sensitive the outline is to alpha values (radius values). Note
that the caption refers to alpha values, but the figure itself uses radius. radius is not used
elsewhere in the manuscript and should be replaced with alpha value (Radius is the variable name
n the AlphaVol function written by Lundgren).
think it would be informative for readers to include figures similar to the graph above, for a range
of animals used in the study.
ncluding bipeds (Emu, ostrich, human) would be useful at this stage, as if the method is adopted, it
will undoubtedly be applied to large bipedal dinosaurs. Similarly, including birds which have a
different bulk density to mammals would be useful. It is likely the method would need different
regressions. This is something the original convex hulling paper by Sellers et al should have done too,
n retrospect.
There is a paragraph on p21 stating that there is no a priori reason why using lref is optimal. The
authors state that future work may look into what is the best reference. Surely if that is the case,
this manuscript would be the place to do that, rather than leaving readers with a potentially sub-
optimal reference value only to produce another small paper down the line which says sorry, you
should have been doing it this way all along.
Peter L. Falkingham
Appendix B
Reply to Reviewers Comments
Brassey and Gardiner - An advanced shape-fitting algorithm applied to the vertebrate
skeleton: improving volumetric mass estimates
The authors would like to thank their reviewers and editors for their insightful
comments. We are particularly grateful to Dr Peter Falkingham for his detailed and
considered review, which has undoubtedly improved the quality of our manuscript.
We have addressed the editors and reviewers concerns below, and attach an
amended manuscript for further consideration.
Subject Editors Comments
We understand that the comments of Reviewer 2 appear to suggest that the
technique presented here is highly sensitive to the alpha shape value chosen.
However, there does seem to be some misunderstanding about how method actually
works. There appears to be a misconception that we choose the most appropriate
level of refinement for any given skeleton and the technique is therefore subjective.
In fact the opposite is the case. We calculate regressions of mass against alpha
volumes of 14 animals for 200 values of refinement coefficient. That is, each data
point in Figure 2 is a correlation coefficient of one regression in which all the
skeletons are fitted with the exact same value of k. We subsequently take the
regression model and refinement level with the highest correlation coefficient as
being the optimal equation, and then apply it to a fossil skeleton also fitted with an
alpha shape of the same refinement. Of course, calculated volumes are sensitive to
the refinement chosen, and therefore some values of k are better predictors of mass
than others. But it is this exact phenomenon that we seek to investigate. The process
is therefore entirely objective and we disagree that this represents a potentially fatal
flaw in our approach. However, we understand that any misunderstanding or
misinterpretation about how the alpha shapes technique works suggests a lack of
clarity in our methodology section, and opens up the potential for misapplication of
the technique in the future. We have therefore put considerable effort into ensuring
that our methodology is clearly explained to rectify any uncertainty in our approach:
It is important to note that whilst the avol at certain values of refinement coefficients is
likely to closely match the physiological volume of the animal, we are not attempting
to directly calculate the refinement coefficient that most closely produces
physiological volume, and from that calculate mass. Rather we are investigating avol
at various degrees of refinement as a correlate for body mass (similar to previous
models based on femoral length or cross sectional area). Indeed the avol which best
correlates (i.e. highest r2) to body mass may be significantly larger or smaller than
physiological volume.
And:
The avol for both Mammuthus primigenius and Megatherium americanum were then
calculated at optimum k and body masses predicted. It is again worth highlighting
that the k value at which r2 is highest may result in an avol that differs considerably
from the physiological volume.
With regards to sensitivity to posture, this is also accounted for in our technique to
some degree. At higher levels of refinement, the alpha shapes effectively shrink-wrap
closely around the limb bones, and therefore postural effects cannot be incorporated
into the predictive model. Interestingly however, we find that these tight fitting models
perform worse as mass estimation equations than models with correlation
coefficients that produce coarser fits. Indeed, the best-performing model is one in
which the ribcage is entirely enclosed and the left and right appendages of the
forelimb and hindlimb are joined together. In this instance, we acknowledge that the
resulting mass predictions may be affected by limb posture. However, as discussed
in-text, it could equally be that incorporating postural variability has a beneficial effect
on the predictive performance of the model i.e. that limb posture itself contains a
body mass signal.
With regards to fossil taxa posture, our implementation of alpha shapes shares the
same drawback as convex hulling, in that resulting volumes will be sensitive to the
articulation of the fossil skeleton. We have sought to present a technique that
involves minimal user input, being based upon point clouds derived from articulated
museum specimens. However, there is an assumption that the articulated fossils
skeleton has been mounted in a pose that is representative of the posture of the live
organism to the same extent as the modern individuals. In the case of Pleistocene
mammals that form the basis of our study, we feel we can be confident in the
articulation of the skeletons, given the volume and quality of skeletal material
available upon which the mounts are based. However, in the case of large dinosaurs
(upon which admittedly most volumetric mass estimation techniques have been
applied in the past), no modern analogs exist and fossil skeletons can be
taphonomically deformed or incomplete. In this instance, a sensitivity analysis of
articulation on alpha shape volume would be advisable, much the same as has
previously been required in convex hulling studies by Bates et al. and Brassey et al.
We agree with Reviewer 2 that more attention ought to be drawn to this limitation,
and we have added a section to the Discussion, detailing the importance of
sensitivity analyses when conducting volumetric mass estimation on incomplete or
damaged skeletons:
Broadly speaking, we may be confident in the articulation of M. americanum and M.
primigenius mounts due to the wealth of available fossil material, high preservation
quality and occurrence of modern closely-related species. However when dealing
with highly fragmentary material, fossils known to have undergone taphonomic
deformation, or fossil species for which no close modern relative exists, it may be
necessary to conduct additional sensitivity analyses to quantify the effect of
articulation on resulting mass estimates. This is particularly the case when
undertaking volumetric reconstructions of dinosaur species, and previous work has
benefitted from the use of sensitivity analyses to rigorously bracket mass estimates
with upper and lower bound volume estimates
Associate Editors Comments
With regards to open access to the 3D data and scripts, we have looked into
MorphoMuseum as a potential host for the Megatherium data. However, they state
they only accept 3D surface data or CT stacks, yet our giant sloth is a point cloud.
Instead, we have amended the text to state that the model is available by request
from the curator of fossil mammals at the NHM, Pip Brewer. We have deposited the
model with Pip, and we have been reassured that the data will be uploaded to the
NHMs online catalogue so it will not be misplaced. Additionally a note will be added
to the specimens catalogue entry to highlight that a 3D model is available. In terms
of the Oxford Museum modern mammal dataset, we will place an additional copy of
the files on Dryad upon acceptance of the manuscript.
We investigated making the MATLAB script compatible with an open-sourced
alternative such as Octave. However, in our code we make use of the statistics
toolbox and a third-party function called alphavol (cited in-text). We tried to run the
code on Octave, but the requirement for a function called trirep did not seem to be
supported by Octave. However, all our MATLAB scripts will be made available and
can be read in a simple text editor and modified as required. The alphavol script will
also be supplied and is easily readable, and documentation for any MATLAB function
(including those in the stats toolbox) is available through the MathWorks website.
With regards to the sensitivity of our methodology to the alpha value chosen, we
have discussed this further in our reply to the Subject Editor (above) and Reviewer 2
(below).
Reviewer 1 Comments
"do not require manual segmentation of skeletons" L34- I suggest not using
"segmentation" as this is easily confused with segmentation of CT data. How about
"manual separation of body segments from skeletons"?
Corrected
Line ~106: To be self-serving but perhaps fair, Ref 20 applied similar shrink-wrapping
and polygonal hull methods to T. rex's body (figs5,6) and an ostrich's torso. Seldom
acknowledged and done differently in some ways than later approaches, but the
usage of digitized and 3D scanned data was not radically different, except that it did
not blend traditional scaling approaches with 3D volumetric ones as the later convex
hulls studies did.
We have added more detail to the description of Ref. 20;. The initial application of
NURBS to an extinct species involved the shrink-wrapping of polygonal hulls around
landmark points digitised from the skeleton of a Tyrannosaurus rex [20]. Models were
subsequently manipulated using via points to replicate the fleshed-out appearance
of the animal
Line 409-10: "However... our results are sensitive to the mounting of the skeleton."
Corrected
Lines 411-3: rather than a "WI Sellers, pers. comm" citation here, please explain why
the scapula's position is tricky, so readers know- e.g. surrounding soft tissues.
We have added additional detail;.The positioning of the scapula is especially
difficult to constrain due to a lack of osteological correlates. In articulated mammal
skeletons, the scapula is often attached directly to the ribcage for ease of mounting.
In reality, shoulder muscles such as the M. Serratus anterior and M. Subscapularis
run between scapula and the ribcage, and the scapula sits some distance from the
ribs.
Generally- the point might well be made in the paper that this approach apparently
avoids the problem of overlapping leg segments, which previously published convex
hulls seem to have-- i.e. the manually crafted + shrinkwrapped leg/body segments
overlap, causing potential overestimates of body mass. This is visible in many of the
published 3D hulls and has not yet been noted in the literature, to my knowledge.
It is true that we end up with apparently overlapping segments in previously
published figures of convex hulling applied to skeletons. But again, its worth
emphasizing that the goal of convex hull analysis (and this alpha shape analysis)
should be to find a variable that is strongly correlated to body mass and use it in a
mass prediction capacity. It just so happens that in this case the variable is a volume
(m3), but it is ideologically comparable to predictive models based on midshaft cross-
sectional area (m2) or length (m). It will be the case that convex hull volume will
correlate to the physiological volume of the animal, but in mass prediction studies we
do not seek to directly reconstruct this body volume. We look to find the correlation
directly between convex hull or alpha-shape volume and body mass.
In previous convex hulling studies, we have applied the technique to segmented
skeletons. The variable of interest in this case is the summed volume of each of the
convex hulled segments. But there is no predictive value in visualizing the articulated
convex hulls around the skeleton; we could just as easily figure them as exploded
apart elements akin to an engineering diagram. The overlapping leg segments are
just an artifact of us recombining the segment convex hulls to produce an attractive
figure that intuitively resembles an animal. All that matters for the mass prediction is
the summed volume of the individual parts, and how that correlates to mass.
Weve run into this confusion before. I (C.Brassey) typically use convex hulling or
alpha-shapes because Im interested in estimating the mass of an animal. I might
then use this mass as in input for FEA, or for looking at patterns of body mass over
geological time. But crucially, Ive not needed the volume of the live animal. The
confusion arises because my colleagues might use these volumetric techniques for
estimating mass and segment inertial properties, for studies of center of mass or gait
simulations. In these instances, they are attempting to reconstruct fleshed-out body
volume from convex hull volume, and these studies require their own set of caveats.
Bearing this in mind, convex hulling as a mass prediction exercise does not suffer
from a problem of overlapping segments. Therefore we cannot say that our alpha-
shapes techniques is advantageous is this sense. Rather it avoids the problem of
segmentation in the first place.
Reviewer 3 Comments
All the research is well-conducted and correctly expressed, so I recomend
publication as it stands, except for a minor detail that should be corrected: Fariña et
al. 1998 (reference number 41 in the manuscript) did not use "a volumetric sculpting
technique" for estimating "a body mass of 3800 kg for the ground sloth M.
americanum". Instead, they used a set of 44 allometric equations based on a modern
database of craniodental and appendicular dimensions and obtained estimations of
6265 kg (arithmetic mean), 2543 kg (geometric mean), 2903 kg (median), 2896 kg
(mode). It is noteworthy that the average of those four statistics is about 3650 kg,
very similar to the ~3700 kg the authors obtained with their method. The result of a
volumetric technique cited in Fariña et al. 1998 is from Casinos, A. 1996 (Bipedalism
and quadrupedalism in Megatherium: an attempt at biomechanical reconstruction.
Lethaia 29: 87-96). I'd like to recommend the authors to check that paper to enhance
their discussion of the subject.
Were happy to correct the misattribution of the volumetric mass estimation to Fariña
et al. Apologies for that. And well include the summary statistics of mean, median
and mode from Farina et al. We do not, however, consider that carrying out an
averaging of these four statistics to arrive at 3650 kg as the reviewer suggests is a
sensible approach. The agreement between this value and our result could simply be
coincidence. Considered separately, the geometric mean, arithmetic mean, median
and mode are all valid statistical properties of the dataset. However, a combination of
all of these properties has no mathematical relevance.
Reviewer 2 Comments
We thank Peter for his detailed review and we value his opinion on these matters. In
terms of addressing some particular concerns:
Cthe method is presented as a very cut and dry this is better (we consider a-
shapes to be methodologically superior to convex hullsC) when that simply isnt the
case. (Similarly: the a-shapes technique presented here circumvents any potential
issuesC does not acknowledge that convex hulling also circumvents those issues)
we consider a-shapes to be methodologically superior to convex hulls; has been
changed to a-shapes also benefits from the ability to fit shapes to complete
skeletons, and removes the need for time-consuming manual segmentation.
the a-shapes technique presented here circumvents any potential issues; has
been changed to both convex hulling and the a-shapes technique presented here
circumvent;
Its my opinion that the vagaries inherent in the method (i.e. selection of an alpha
value via the refinement coefficient) make the method far more subjective than
convex hulling, and as such represent a likelihood of the method being misused by
workers assuming the method is objective when it is ultimately not (or at least
requires considerable work to find a suitable and objective a-value).
We disagree with Reviewer 2s comments that alpha shapes is far more subjective
technique than convex hulling. Much of this is covered in our response to the Subject
Editors comments above. As Reviewer 2 highlights, previous applications by Bates
et al. and Brassey et al. of convex hulling have required the subdivision of the
skeleton. In these instances, the users have, in effect, arbitrarily increased the
refinement of the fit of convex hulls. For example, when applying convex hulling, how
many segments to we divide the leg into? Just one for the whole leg? Or do we
separate out the stylopodium from the zeugopodium? Do we separate out the tarsals
(as in birds), or do we include the tarsals into the foot segment (as in mammals)?
Should we model the trunk as just one segment? Or should we separate out the
thoracic from the lumbosacral regions? These are all considerations for the convex
hulling methods. In contrast, the alpha shapes technique presented here
systematically generates regression models for a large range of shape refinements,
and the optimum model is objectively selected as the best-performing model on the
basis of refinement coefficients, without any a priori decisions regarding how to
subdivide the skeleton. There is nothing unpredictable about this method, it is entirely
automated with zero user input, and optimum models are selected in the script on
the basis of highest correlation coefficient.
In terms of the method being misused, we have added appropriate caveats to
highlight the importance of selecting an appropriate modern group as a basis for the
analysis, and the need to rerun the analysis to determine a new predictive model for
a given group. We have also written a detailed readme file to accompany the Matlab
script to assist future users in applying our technique.
The advantages over convex hulling proposed here are that the volume more closely
matches the skeleton without needing to manually segment or pose the skeleton first.
But what is needed instead, is rigorous testing in each case that the correct alpha
value has been selected. I fail to see this as an advantage.
Whilst we sympathize with Reviewer 2 that our technique involves more rigorous
testing and is therefore fairly computationally expensive (as we have now made
clearer in-text, see later comments), we feel that shifting the onus away from human
intervention and manual processing of models towards computer processing is a
step in the right direction as it reduces the potential for bias and user error.
Additionally, Reviewer 2s notion that the correct alpha value is being selected is a
bit of a misinterpretation. For every value of k, we fit a corresponding alpha shape to
each of the 14 skeletons, and a regression model is generated. This is repeated 200
times, and the best-performing model selected on the basis of correlation coefficient.
We make no judgment about what the correct alpha value is, this would imply we
are trying to reconstruct the original form of the animals. Rather we are objectively
determining which alpha shapes have volumes most closely correlated to body
mass.
Rather than directing readers to the expensive software matlab along with associate
mathworks files and the custom script (which unfortunately is not available in the
submission system so I cant see what it does beyond calling an alpha shape
function), why not simply suggest using Meshlab which has the menu function Alpha
Complex/Shape? This is simpler, and is in accordance with the open nature of
label_version_3
RSOS. [Though I do note in the current version of meshlab there are issues with the
alpha shape being watertight. Perhaps the authors would also consider making sure
their scripts are compatible with FreeMat]
As discussed in the comments to the Associate Editor, we attempted to get our
Matlab script working in Octave, but its dependency on a function called trirep
meant this was not possible. We agree that the open nature of RSOS is best
supported by making code openly available, and our .m files will be included on data
dryad. The .m files can be opened and read in any text editor, such that the
interested reader will be able to follow our methodology and could rewrite our code in
any programming language they wish. We understand that an alpha shapes
function is present in Meshlab, and we have included a sentence drawing attention to
this fact:
For those wishing to explore the a-shapes technique without using MATLAB, an a-
shapes function is incorporated within the freely available software Meshlab
(http://meshlab.sourceforge.net)
However, we disagree that Meshlab is simpler than using Matlab in our case. It
would admittedly be easier to use Meshlab to create one alpha-shape, but to fit 200
alpha shapes ranging from very fine to very coarse fit to each of 14 skeletons and do
subsequent regressions could be extremely laborious. Furthermore, we still do not
know of a good way of stripping the resulting calculated volumes out of Meshlab into
text files for further processing (although wed happily take any advice on that). In
Matlab however, reference lengths can be calculated, thousands of alpha shapes
may be fitted, volumes extracted, and regression analyses conducted, all within the
same package. Thus dramatically reducing the amount of user intervention required,
and reducing the risk of transcription errors.
To the editors: As mentioned above all scripts used in the analysis and a readme text
file with instruction of how to use the scripts will be made available to all readers on
dryad. For the time being however, we have attached the readme and Matlab file to
the end of this document, for the benefit of the reviewers to look over our analysis.
It is also worth discussing that the processing time for alpha-shapes is considerably
longer than that for convex hulls (a low alpha and a several million point+ point cloud
can take minutes, vs < 1s for a convex hull).
We have now included a discussion of processing times:
Whilst the a-shapes methodology removes the need for manual segmentation, the
computer processing time required for the shape-fitting stage is considerably greater
than that of convex hulling. On a standard dual-core workstation with 8GB RAM, the
calculation of 200 a-shapes of increasing refinement coefficient for a single skeleton
comprising 500,000 points took on average 68 minutes. Considering we repeated
this process 10 times per skeleton, and included a dataset of 14 species, this results
in considerable processing time. In contrast, when the dataset was downsampled to
10,000 points per skeleton, processing time was reduced to <1 minute per skeleton.
This is still markedly slower than convex hulling however, which requires <1 second
per skeleton.
Basing the ideal alpha value on an average distance from a centroid (lref) is open to
issues  while ordered laser scanning may produce relatively even scans,
photogrammetry may result in extremely dense and sparse areas of the point cloud
depending on how the photos were taken, colouration and detail of the specimen,
and lighting. I suggest the authors at least test how lref varies between different
models of a single specimen (i.e. several photogrammetric models generated with
different photo sets and laser scans).
Wed like to thank Peter for this suggestion; its a good idea. We resampled our
photogrammetric model of the giant sloth in Geomagic four different ways: a random
downsample, uniform downsample, grid downsample and curvature-based
downsample (all downsampled to 500,000 points, using the default values suggested
by Geomagic). We then recalculated lref (based on distance from centroid) and the
resulting predicted body masses on these new point cloud models:
lref (m) body mass (kg) % difference
Original model used in-text 1.131 3706 NA
Uniform downsample 1.164 3806 2.7% increase
Random downsample 1.132 3710 0.1% increase
Grid downsample 1.151 3796 2.4% increase
Curvature-based downsample 1.139 3723 0.5% increase
Downsampling using these various approaches producies very different distributions
of points. Yet this actually makes very little difference to estimated body mass
percentage-wise, especially considered in light of the typical errors associated with
mass prediction. We therefore do not consider variation in lref as a function of point
cloud distribution to be a concern in our technique.
In the papers using convex hulling that have followed Sellers et al, primarily those by
Bates et al, the convex hulling method can be used to carry out sensitivity analyses
on cranial and caudal distribution of mass (by increasing cranial hulls, and
decreasing caudal hulls and vice versa). Similarly, Brassey et als stegosaur paper
Dermal armour was treated seperately. Both of these studies would require
segmenting the skeleton anyway, removing the primary advantage proposed here of
alpha-shape fitting. This should be discussed as a weakness of the method
presented here.
Theres two different issues raised here:
1. The application of volumetric techniques to mass estimation vs. mass
distribution: Agreed, Bates et al. and Sellers et al. (Argentinosaurus) use
segmented convex hulling to reconstruct the distribution of mass in fossil
species. And yes, if you wanted to estimate segment properties from a
volumetric model, you would of course need to segment it. But, as we
mention in our discussion, we are not advocating that at all for alpha shapes.
As we make clear in the last paragraph, we think its crucial that future work
on modern animals better quantifies the relationship between fleshed out
segment properties and convex hull segment properties before we continue
to use these techniques to estimate center of mass. So we wouldnt call this a
weakness of our method. In fact, wed argue its a strength of our paper that
were being honest about the current limitations with regards to estimating
fossil segment inertial properties, and about the need for more modern data.
But weve added an extra sentence to really bring this point home:
Until such data is available, the application of a-shapes in its current form should be
restricted to straightforward mass estimation
2. Dermal armour: The alpha shapes technique presented here does not a priori
require the removal of these features. In the case of the Oxford mammal hall
dataset, some species were missing horns or antlers at the time of scanning,
and they were therefore removed from others in order to be consistent. If,
however, someone wanted to derive a predictive alpha shapes model from
modern deer species, and apply it to Megaloceros for example, it would be
possible to do so without removing antlers. Because we calculate alpha
shapes for a wide range of refinement coefficients, those at lower values of k
would fit tightly around the contours of the antlers, whilst those at higher
values of k would form large blobs around the antlers. Whichever model had
the highest correlation coefficient could then be used as a predictive model
applied to Megaloceros.
As for dinosaurs, we know there are no ideal extant modern analogues, and
as with any fossil mass estimation study, it would require careful thought with
regards to an appropriate modern dataset on which the base the predictive
model. I would be comfortable applying a deer-based model to Megaloceros
without antler segmentation. I would be comfortable applying an armadillo-
based model to a pampathere without segmenting the osteoderms etc etc.
But in both instances, the close phylogenetic relationship between the
modern sample and fossil taxa implies a similar physiological or
biomechanical relationship between ornament size and body mass would be
present in both. For the plates of stegosaurs, or scutes of ankylosaurs, we
cannot support that supposition when applying a mammal-based model.
In summary, the alpha shapes technique presented here does not require the
segmentation of unusual ornamentations such as horns or antlers, especially
when present in both modern and fossil taxa. When applied to fossil features
that have no modern analogue however, the judicious approach would be
isolate out the structures prior to shape-fitting, and add on additional mass
calculated from surfaced volume and predicted density, as conducted by
Brassey et al. on stegosaur plates. We have amended the text to include this
caveat:
When fitting a-shapes to the modern OUMNH dataset, antlers were missing from
some museum skeletons, and we therefore manually removed antlers and tusks from
the models prior to further analysis for consistency. The a-shapes technique
presented here does however accommodate for the inclusion of unusual accessory
structures such as horns and antlers, and their removal is not a prerequisite. a-
shapes could be used to derive a cervid-based predictive model to be applied to
fossil deer, for example, without the removal of antlers. However, a more cautious
approach is needed if the predictive model is to be applied to a distantly-related fossil
group possessing unusual structures, such as the armour of thyreophoran dinosaurs.
In instances when fossil accessory structures are not homologous to those present in
the modern dataset, we suggest a more judicious approach followed by Brassey et
al. [11] in which the features are removed and surfaced separately, and resulting
masses added to those predicted via shape-fitting.
Figure 1 should have a real reference shape from which the points are derived for
comparison with the alpha shapes, and it should also have an image of the alpha
shape derived using relevant values of lref and k as they are calculated for the
dataset of skeletons. Though I want to acknowledge that this figure is excellent at
showing how sensitive the outline is to alpha values (radius values). Note that the
caption refers to alpha values, but the figure itself uses radius. radius is not used
elsewhere in the manuscript and should be replaced with alpha value (Radius is the
variable name in the AlphaVol function written by Lundgren).
We have included an additional real reference shape in Figure 1, and we have
amended the figure label to read alpha value rather than radius. With regards to
adding an image of the alpha shape derived using relevant values of lref, we use lref
when dealing with a comparative dataset as a means of size-normalizing our values
of alpha, such that any given value of k provides an equal coarseness of fit to any
skeleton. Figure 1 is an entirely hypothetical example of a point cloud shaped as a
star. There is no need to size-normalize the values of alpha used to generate the
shapes, as we are not comparing the fits across a comparative dataset.
I think it would be informative for readers to include figures similar to the graph
above, for a range of animals used in the study.
This is unnecessary. We include an example of the camel skeleton fitted with alpha
shapes of 4 levels of refinement coefficient as part of Figure 2. Including other
animals would just be repetitive and would not add to understanding.
Including bipeds (Emu, ostrich, human) would be useful at this stage, as if the
method is adopted, it will undoubtedly be applied to large bipedal dinosaurs.
Similarly, including birds which have a different bulk density to mammals would be
useful. It is likely the method would need different regressions. This is something the
original convex hulling paper by Sellers et al should have done too, in retrospect.
This is a paper about modern quadrupedal mammals, applied to fossil quadrupedal
mammals. It is beyond the scope of this paper to anticipate the likely applications of
alpha shapes to other vertebrate groups. This is a techniques paper, presenting a
new method and all the relevant code necessary for others to go away and apply it to
different groups. Undoubtedly, applying alpha shapes to theropods would require a
whole new analysis being run on a dataset of modern birds. We highlight this in-text.
And we recognize that our colleagues will be interested in this methodology, and may
want to apply it to their study groups of interest. We therefore understand that we
have a responsibility to adequately describe the caveats associated with alpha-
shapes, in order to minimize the risk of misapplication of the technique.
We have therefore improved and extended the discussion to incorporate more detail
for those who may wish to apply this method to other groups. We do not consider it
necessary to incorporate an additional analysis of modern birds for application to
theropod dinosaurs. However, since original submission, we have made a
considerable effort to improve our Matlab script so that users may modify the
methodology to operate on a subdirectory containing models of whatever group of
vertebrates they are interested in. We have also written an extensive readme file to
accompany the .m file. At the end of this file, we have attached the new readme file,
and our Matlab script for the editors and reviewers reference.
There is a paragraph on p21 stating that there is no a priori reason why using lref is
optimal. The authors state that future work may look into what is the best reference.
Surely if that is the case, this manuscript would be the place to do that, rather than
leaving readers with a potentially suboptimal reference value only to produce another
small paper down the line which says sorry, you should have been doing it this way
all along.
We agree, and we have investigated other possible reference lengths to use for size-
normalizing alpha values. We have included an additional paragraph in the methods
and results covering this analysis. However, we found that our metric of lref (mean
distance of each point in the skeleton from the centroid) was still most tightly
correlated to body mass compared to other metrics investigated, and thus has not
changed our interpretation of the data or recommendations for future applications:
There is no a priori reason why mean distance to centroid ought to be the optimal
method for size-normalising a. We therefore also investigated other skeletal
dimensions as potential metrics for mass-normalisation, such as maximum height,
maximum length, and length of bounding box diagonal, all of which may be non-
subjectively extracted from the models. In addition, we also investigated shoulder
height and hip height as potential metrics, both of which require some user
intervention to determine the location at which measurements are taken.
And:
In terms of choice of reference length, relative to alternative metrics, our measure of
lref (mean distance of points from centroid) was closely related to overall body mass
(r2=0.91). This compared favourably to other metrics such as maximum skeleton
height (r2=0.61), bounding box diagonal length (r2=0.79) and maximum length
(r2=0.87). We also found shoulder height and hip height to be relatively poorly
correlated to mass in this sample (r2=0.72 and 0.64 respectively). We therefore
consider our choice of reference length to be justified in this instance, and to be the
preferred means of size-normalising values of a across a comparative dataset.
Readme file to accompany MATLAB script
Mass Prediction tool
James Gardiner 2015
j.d.gardiner@salford.ac.uk
jamesdavidgardiner@gmail.com
See Brassey and Gardiner 2015 for more details on the method used in this tool.
To use the mass prediction tool, please follow the instructions below.
Please ensure that following files/folders are in the root folder (mass prediction tool)
1. alphavol.m
2. regress_volumes_and_predict_mass.m
3. caclulate_skeleton_volumes.m
4. settings.txt
5. names_and_masses.txt
6. modern_animals (folder)
7. fossil_animal (folder)
Place all the files for the modern animals in the modern_animals folder. Each
modern animal must have its own folder within the modern_animals folder, which
contains the .asc files that make up the skeletons. This can be one file for the whole
skeleton or separate files (i.e. right leg, skull, tail etc). The .asc files should be in the
units of metres and be three columns x y and z which are space delimited. All files
should have the same number of header lines. No file or folder name should contain
any spaces or non-standard characters.
Edit the names_and_masses.txt file, with each modern animal and its body mass in
kilograms (please dont put the units after the number), in two separate columns
separated by a comma. There should be no header line in this file. The name of the
modern animal here should exactly match the folder name that the .asc files have
been placed in. Again the names should have no spaces or non-standard characters.
The file/files for the fossil animal you are estimating the mass of should go into the
fossil_animal folder. It doesnt need its own folder within the fossil_animal folder. But
the files should be the same .asc files as the modern animals, with the same number
of header lines.
In the file settings.txt, set how many repeats you want the code to run for each
animal (default set to 10). Set the downsample value you want the code to use. This
must be smaller than the model with the smallest number of points (either modern
animal or fossil animal). Set how many header lines the .asc files have for both
modern animals and fossil animal.
First, run the calculate_skeleton_volumes.m matlab code, this will create the
necessary data from the modern animals to allow the mass prediction code to work.
Two folders called volume_results and animal_figures will be created. The
volume_results contains the data which will be used with the mass prediction code.
The animal_figures code allows the user to check how the alpha_shapes code is
fitting to the skeletons. Each modern animal has several figures created. The number
in the figures name is the refinement coefficient for that figure.
Second, run the regress_volumes_and_predict_mass.m matlab code which will run
a regression for each level of refinement coefficient, select the coefficient that
produces the highest R2 value and then use this model and refinement coefficient to
predict the mass of the fossil animal. Figure 1 shows the alpha-shape fit to the fossil
animal. Figure 2 shows the R-squared of modern animal regression equations at
every refinement coefficient tested by the code. The red circle indicates the
maximum R2 and hence refinement coefficient selected. Figure 3 shows the
regression equation used (i.e. the equation that produce the highest R-squared), with
the modern animals plotted in solid squares and the predicted fossil animal mass is
an open square. The regression equation used and predicted body mass are also
shown.
MATLAB script (file 1)
% fit alpha shapes to skeletons and calculate volumes
% James Gardiner 2015
% j.d.gardiner@salford.ac.uk
% jamesdavidgardiner@gmail.com
%
% see Brassey and Gardiner 2015 for paper on technique
close all
clear all
% find data files for modern animals
all_animals_folder_files = dir('modern_animals');
folders_index = [all_animals_folder_files.isdir];
modern_animals = all_animals_folder_files(folders_index);
modern_animals = modern_animals(3:end);
% read in settings to be used
settings = csvread('settings.txt',0,1);
% create figure that will be used to output png files of each fit
figure('color','w')
% run following code for all modern animals
for i = 1:length(modern_animals)
clearvars -except i modern_animals volume settings
% select current animal
current_animal = modern_animals(i).name % will display current animal
% in Matlab command window
files = dir(['modern_animals/' current_animal '/*asc']);
position = 1;
% read in all files for current animal one by one and collate
for j=1:length(files);
filename = strcat(...
'modern_animals/',current_animal,'/',files(j).name);
number_of_header_lines = settings(3);
data = dlmread(filename,' ',number_of_header_lines,0);
x_temp = data(:,1);
y_temp = data(:,2);
z_temp = data(:,3);
x_raw(position:position + length(x_temp) -1,1) = x_temp;
y_raw(position:position + length(x_temp) -1,1) = y_temp;
z_raw(position:position + length(x_temp) -1,1) = z_temp;
position = length(x_raw)+1;
end
% set repeats and downsampling from settings file
repeats = settings(1);
downsample_value = settings(2);
% repeat section below for the set number of repeats
for k = 1:repeats;
% randomly downsample raw modern animal data to require level
index = randsample(length(x_raw),downsample_value);
x_subsample = x_raw(index);
y_subsample = y_raw(index);
z_subsample = z_raw(index);
% move data so centroid is at the origin
x_subsample_centered = x_subsample - mean(x_subsample);
y_subsample_centered = y_subsample - mean(y_subsample);
z_subsample_centered = z_subsample - mean(z_subsample);
% calculate distance of every point from centroid (origin)
[~,~,radii] = cart2sph(x_subsample_centered,...
y_subsample_centered,...
z_subsample_centered);
% create a distribution of numbers
% from which to base refinement coefficients
distribution_of_numbers = -4:0.1:4;
refinement_coefficients = exp(distribution_of_numbers);
% repeat section below for number of refinement coefficients
for n = 1:length(refinement_coefficients);
% calculate radius (alpha) to use in alpha shapes fit
radius_for_alphavol = mean(radii).*refinement_coefficients(n);
% call alpha shapes fitting function (alphavol.m)
% to calculate volume
[V,S] = alphavol(...
[x_subsample_centered ...
y_subsample_centered ...
z_subsample_centered],...
radius_for_alphavol,1);
% collate volumes
volume_repeats(n,k) = V;
% on last repeat export figure of fit as png
if k == repeats
figures_folder = 'animal_figures';
if ~exist(figures_folder,'dir')
mkdir(figures_folder);
end
print('-dpng',[figures_folder '/' current_animal '_' ...
num2str(refinement_coefficients(n)) '.png']);
end
% collate alpha (radius) and reference length
radius_to_export(n) = radius_for_alphavol;
ref_length_to_export(n) = mean(radii);
clear V S radius_for_alphavol
end
end
% find mean volume at each refinement
% coefficient for the number of repeats
volume_means = mean(volume_repeats,2);
% collate data to export
data_to_export = [refinement_coefficients' volume_means ...
radius_to_export' ref_length_to_export'];
% export data for current animal
volumes_folder = 'volume_results';
if ~exist(volumes_folder,'dir')
mkdir(volumes_folder)
end
fid_write = fopen([volumes_folder '/' current_animal '.csv'], 'w');
fprintf(fid_write,...
'refinement coefficient,volume,alpha radius,ref. length\n\n');
fclose(fid_write);
dlmwrite([volumes_folder '/' current_animal '.csv'],data_to_export,...
'-append')
end
MATLAB script (file 2)
% regression fits and predict mass of fossil animal
% James Gardiner 2015
% j.d.gardiner@salford.ac.uk
% jamesdavidgardiner@gmail.com
%
% see Brassey and Gardiner 2015 for paper on technique
close all
clear all
% call in data on animal names and their masses
fid_masses = fopen('names_and_masses.txt','r');
names_and_masses = textscan(fid_masses,'%s%f','delimiter',',');
fclose(fid_masses);
animals = names_and_masses{1};
masses = names_and_masses{2};
% read in settings
settings = csvread('settings.txt',0,1);
% call in data for all modern animals
for i = 1:length(animals)
current_animal = animals{i};
data = csvread(['volume_results/',current_animal,'.csv'],1,0);
coefficients_all(:,i) = data(:,1);
volumes(:,i) = data(:,2);
% radii(:,i) = data(:,3);
% ref_lengths(:,i) = data(:,4);
end
coefficients = coefficients_all(:,1);
% caculate the natural log of volumes and masses for regressions
volumes_logged = log(volumes);
masses_logged = log(masses);
% run regression equation of volumes and masses at
% every refinement coefficient
for i = 1:length(volumes_logged(:,1))
X = (volumes_logged(i,:)');
Y = (masses_logged);
[B,~,~,~,STATS] = regress(Y,[ones(length(X),1) X]);
B_all{i} = B; % coefficient of regression equation
STATS_all{i} = STATS; % statistics of regression equation
end
% Work out which coefficient gives the best fit (higesht R_squared)
for i = 1:length(coefficients)
R_squared(i) = STATS_all{i}(1); % find R_squared of each regression
end
R_squared_best = max(R_squared);
index = find(R_squared == R_squared_best);
coefficient_best = coefficients(index);
% call in fossil animal data
fossil_animal_files = dir('fossil_animal/*.asc');
position = 1;
% call in all files that make up fossil animal and collate data
for j=1:length(fossil_animal_files);
filename = strcat(fossil_animal_files(j).name);
number_of_header_lines = settings(3);
data = dlmread(['fossil_animal/' filename],' ',...
number_of_header_lines,0);
x_temp = data(:,1);
y_temp = data(:,2);
z_temp = data(:,3);
x_fossil(position:position + length(x_temp) -1,1) = x_temp;
y_fossil(position:position + length(x_temp) -1,1) = y_temp;
z_fossil(position:position + length(x_temp) -1,1) = z_temp;
position = length(x_fossil)+1;
end
% set repeats and downsampling from settings
repeats = settings(1);
downsample_value = settings(2);
% repeat section below for set number of repeats
for i = 1:repeats;
% downsample fossil animal to level set
index_fossil = randsample(length(x_fossil),downsample_value);
x_fossil_subsample = x_fossil(index_fossil);
y_fossil_subsample = y_fossil(index_fossil);
z_fossil_subsample = z_fossil(index_fossil);
% position fossil animal's centroid at the origin
x_fossil_subsample_centered = x_fossil_subsample - ...
mean(x_fossil_subsample);
y_fossil_subsample_centered = y_fossil_subsample - ...
mean(y_fossil_subsample);
z_fossil_subsample_centered = z_fossil_subsample - ...
mean(z_fossil_subsample);
% calculate the distnace of every point from centroid (origin)
[~,~,radii_fossil] = ...
cart2sph(x_fossil_subsample_centered,...
y_fossil_subsample_centered,...
z_fossil_subsample_centered);
radius_for_alphavol_fossil = mean(radii_fossil).*coefficient_best;
% run alphavol code to fit an alpha shape at the best redinement
% coefficient to the fossil animal
if i<repeats
[V_fossil_temp(i),S_fossil] = alphavol(...
[x_fossil_subsample y_fossil_subsample z_fossil_subsample],...
radius_for_alphavol_fossil);
else
% on final repeat run alphavol code and plot figure
figure('color','w')
[V_fossil_temp(i),S_fossil] = alphavol(...
[x_fossil_subsample y_fossil_subsample z_fossil_subsample],...
radius_for_alphavol_fossil,1);
V_fossil = mean(V_fossil_temp);
V_fossil_logged = log(V_fossil);
hold on
plot3(...
x_fossil_subsample,y_fossil_subsample,z_fossil_subsample,'.k')
end
end
% create data for regression line on regression figure
volumes_fit = [min(volumes_logged(index,:)) max(volumes_logged(index,:))];
masses_fit = volumes_fit.*B_all{index}(2) + B_all{index}(1);
% calculate the logged fossil animal mass
fossil_mass_logged = V_fossil_logged.*B_all{index}(2) + B_all{index}(1);
% unlog data and apply correction factor based on
% Smith 1993, Logarithmic Transformation Bias in Allometry,
% AMERICAN JOURNAL OF PHYSICAL ANTHROPOLOGY
fossil_mass = exp(fossil_mass_logged);
correction_factor = exp(((STATS(4))^2)/2);
fossil_mass_corrected = fossil_mass.*correction_factor;
% plot regression R_squared against refinement coefficient and highlight
% best refinement coefficient
figure('color','w')
semilogx(coefficients,R_squared,'k')
hold on
semilogx(coefficient_best,R_squared_best,'ro')
box off
axis_limits = axis;
axis_limits(3) = 0.7;
axis(axis_limits)
xlabel('refinement coefficient')
ylabel('regression R^2')
% plot regression fit with highest R_squared and show predicted fossil
% animal mass
figure('color','w')
marker_size = 5;
h = plot(volumes_logged(index,:),masses_logged,'ko');
hold on
set(h,'markersize',marker_size,'markerfacecolor','k')
marker_size = 7;
h = plot(V_fossil_logged,fossil_mass_logged,'ks');
text(V_fossil_logged,fossil_mass_logged,...
[' ' num2str(fossil_mass_corrected,4) ' kg'])
title(['y = ' num2str(B_all{index}(2)) 'x + ' num2str(B_all{index}(1))])
set(h,'markersize',marker_size)
plot(volumes_fit,masses_fit,'k')
box off
xlabel('ln [ volume (m^3) ]')
ylabel('ln [ mass (kg) ]')
Appendix C
Reply to Reviewers Comments
Brassey and Gardiner - An advanced shape-fitting algorithm applied to the vertebrate
skeleton: improving volumetric mass estimates
We thank the reviewers and editors for their quick responses on this paper, and have
made all the final changes suggested by Peter Falkingham.
Reviewer 2:
The authors have added:
However when dealing with highly fragmentary material, fossils known to have
undergone taphonomic deformation, or fossil species for which no close modern
relative exists, it may be necessary to conduct additional sensitivity analyses to
quantify the effect of articulation on resulting mass estimates.. I still think this is too
generous  It /will/ be necessary is far more apt.
Corrected to *it will be necessary to conduct*.
This is a paper about modern quadrupedal mammals, applied to fossil quadrupedal
mammals. It is beyond the scope of this paper to anticipate the likely applications of
alpha shapes to other vertebrate groups.
Then, quite simply, the title must be changed to An advanced shape-fitting algorithm
applied to quadrupedal mammals. The title currently refers to the vertebrate
skeleton but in their own words, other vertebrate groups are beyond the scope of the
paper (as an aside, I feel advanced is a little self aggrandizing here).
Corrected to An advanced shape-fitting algorithm applied to quadrupedal mammals
The addition of a-shapes also benefits from the ability to fit shapes to complete
skeletons, and removes the need for time-consuming manual segmentation (ln 366)
is still one sided  this should be:
a-shapes benefit from the ability to fit shapes to complete skeletons, and removes
the need for time-consuming manual segmentation, but does require significant
parameter testing for any given dataset
i.e. the drawback should be mentioned in the same context as the benefit. This also
reiterates that any other workers using the method /must/ verify on their own dataset
first.
Corrected to but does require significant parameter testing for any given dataset
Society Open
