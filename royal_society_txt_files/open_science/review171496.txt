The influence of evaluative right/wrong feedback on
phonological and semantic processes in word learning
Saloni Krishnan, Elise Sellars, Helena Wood, Dorothy V. M. Bishop and Kate E. Watkins
Article citation details
R. Soc. open sci. 5: 171496.
http://dx.doi.org/10.1098/rsos.171496
Review timeline
Original submission: 3 August 2017 Note: Reports are unedited and appear as
1st revised submission: 3 November 2017 submitted by the referee. The review history
2nd revised submission: 1 July 2018 appears in chronological order.
3rd revised submission: 7 August 2018
Final acceptance: 9 August 2018
Review History
label_version_1
RSOS-171055.R0 (Original submission)
label_author_1
Review form: Reviewer 1 (Nate Kornell)
Is the language acceptable?
Yes
Do you have any ethical concerns with this paper?
No
Have you any concerns about statistical analyses in this paper?
No
Recommendation?
label_recommendation_1
Major revision
Comments to the Author(s)
label_comment_1
Comparing the effects of feedback on semantic versus phonological learning is an interesting
research question that seems worth pursuing, and this method seems like a good start. My
© 2018 The Authors. Published by the Royal Society under the terms of the Creative Commons
Attribution License http://creativecommons.org/licenses/by/4.0/, which permits unrestricted use,
provided the original author and source are credited
2
overall impression is positive, but I have a few suggestions and concerns. They have to do with
terminology, error rates, and the use of multiple tests.
1. The term feedback is used to refer to a lot of different things in the psychology literature.
Different types of feedback have different effects. This isn’t the authors’ fault, but it did mean
that, for me at least, the precise definition of feedback wasn’t made clear until partway through
the method section. In this experiment, it means yes/no feedback followed by a subsequent
(delayed) chance to restudy. It would have helped if that had been explained near the outset of
the intro. As it was, when I was reading the intro, the authors would talk about a finding and I
wasn’t sure whether it applied to the current research because I didn’t know what kind of
feedback the current research was about. (Also, coming from the adult memory literature, the
term “standard feedback” didn’t seem right to me.)
2. Error rates might need more attention. Here’s why: If you ask me an easy question, it is likely
that a) I will get it right, and b) I will know I’m right. In this situation, feedback will have little
effect on learning. I’ll know I’m right and your feedback will confirm what I already know. (Or at
least this is my understanding of the literature. The authors might want to look up research on
the “hypercorrection effect” for evidence about this at the semantic level. At a more implicit level
I’m not so sure, although research on the relationship between surprisingness and learning, e.g.,
the Rescorla-Wagner model of conditioning, also fits with the idea that unsurprising feedback
doesn't affect learning.) Based on thinking about error rates I see a couple of problems with the
method.
2a. First, the learning task in blocks 1, 2, 4, and 6 (the reproduce blocks) seems fairly trivial. I
expect participants will, in fact, get most answers right and know they are right. Thus the
feedback manipulation might not matter in these blocks. The only time it will matter, then, is in
blocks 3 and 5. This is not a fatal problem, as it does not introduce a confounding variable or
anything. It might, however, mean that the effects of feedback will end up being relatively small;
if learning is built up over 6 blocks and feedback is only manipulated twice, the effect of the
manipulation might get drowned out. If true, this might mean that the the actual effect sizes will
be smaller than the authors are currently predicting.
2b. The other problem has to do with comparing semantic and phonological learning. I am
guessing that participants will find the semantic task (naming a characteristic that is visible)
easier than the phonological task (producing a semantically unrelated non-word) during the
learning blocks. If this is true, and we assume that feedback has more effect when tests are more
difficult, then we should expect to see more effect of feedback in the phonological condition than
in the semantic condition. Crucially, this prediction is based on error rates, and seems like it
should be true even if the general effect of feedback on semantic versus phonological learning is
the same. In short, unless the error rate in semantic and phonological performance during the
learning phase is about the same, then error rates are a confounding variable that will make it
difficult to interpret effects of feedback when comparing semantic versus phonological learning.
3. All items are going to be tested twice. The problem is that the first test is a learning event. Items
that are answered correctly get strengthened, items that aren’t answered correctly don’t
(especially because there’s no feedback; see Spellman & Bjork, 1992). I have two concerns about
this. Before spelling them out, here’s my recommendation: Either only do the delayed test, or
manipulate whether the test happens immediately or after a delay (this manipulation could be
done on an individual item level or at the participant level).
3a. Test 1 will affect test 2. The effect will be that test 2 will end up being similar to test 1. Items
that were answered correctly, and therefore strengthened, are likely to be answered correctly
again. Items that weren’t answered correctly the first time won’t be the second time. Therefore,
3
test 2 will look like test 1, and reflect differences in short-term learning at least as much as long-
term learning. In other words, test 2 won’t be a good measure of long-term learning. This kind of
“double jeopardy” is a no-no in the testing effect literature.
3b. The fact that semantic and phonological tests will be given during test 1 seems like it will mix
things up in unpredictable ways. Here’s my guess. If I’ve only been tested on the semantic aspect
of an item and then I get a test on the phonological during test 1, that will mean my memory for
that item will become more of a mix of phonological and semantic. Thus, I expect that when test 2
comes around, test 1 will have further diminished the difference between semantic and
phonological memory on the final test. This could be another reason effect sizes might be smaller
than expected.
Here’s a minor comment. Lines 67-74 tripped me up. Why is it a problem that “the number of
exposures to the correct answer is not controlled for.”? It seems like the number of exposures is
what is being manipulated, in which case it doesn't need to be controlled. And I didn’t
understand the sentence that followed.
In summary, I would recommend making a few changes. Comment 1 is a relatively easy fix,
comment 3 is easy if you’re willing to remove the immediate test, and comment 2 might be tricky
to deal with and could involve some pilot testing to get similar levels of performance during the
learning phase.
Nate Kornell
Williams College
label_author_2
Review form: Reviewer 2 (Jo Taylor)
Is the language acceptable?
Yes
Do you have any ethical concerns with this paper?
No
Have you any concerns about statistical analyses in this paper?
No
Recommendation?
label_recommendation_2
Accept in principle
Comments to the Author(s)
label_comment_2
See attached word doc (Appendix A).
label_author_3
Review form: Reviewer 3 (Peter Verkoeijen)
Is the language acceptable?
Yes
4
Do you have any ethical concerns with this paper?
No
Have you any concerns about statistical analyses in this paper?
No
Recommendation?
label_recommendation_3
Accept with minor revision
Comments to the Author(s)
label_comment_3
Please see the attached file for my comments (Appendix B).
label_end_comment
Decision letter (RSOS-171055.R0)
06-Sep-2017
Dear Dr Krishnan,
The Editors assigned to your Stage 1 Registered Report ("The influence of feedback on
phonological and semantic processes in word learning") have now received comments from
reviewers. We would like you to revise your paper in accordance with the referee and editors
suggestions which can be found below (not including confidential reports to the Editor). Please
note this decision does not guarantee eventual acceptance.
Please submit a copy of your revised paper within three weeks (i.e. by the 28-Sep-2017). If
deemed necessary by the Editors, your manuscript will be sent back to one or more of the original
reviewers for assessment. If the original reviewers are not available we may invite new reviewers.
To revise your manuscript, log into http://mc.manuscriptcentral.com/rsos and enter your
Author Centre, where you will find your manuscript title listed under "Manuscripts with
Decisions." Under "Actions," click on "Create a Revision." Your manuscript number has been
appended to denote a revision. Revise your manuscript and upload a new version through your
Author Centre.
When submitting your revised manuscript, you must respond to the comments made by the
referees and upload a file "Response to Referees" in "Section 6 - File Upload". Please use this to
document how you have responded to the comments, and the adjustments you have made. In
order to expedite the processing of the revised manuscript, please be as specific as possible in
your response.
Once again, thank you for submitting your manuscript to Royal Society Open Science and I look
forward to receiving your revision. If you have any questions at all, please do not hesitate to get
in touch.
Kind regards,
Alice Power
Editorial Coordinator
Royal Society Open Science
5
on behalf of Chris Chambers
Registered Reports Editor, Royal Society Open Science
openscience@royalsociety.org
Associate Editor Comments to Author:
Three reviewers have now appraised the manuscript. The assessments are broadly positive but
raise a number of major concerns that span the full range of Stage 1 review criteria, from
clarifying the theoretical rationale of the study (including visualisation of hypotheses) to details
about the methodological procedures (e.g. counterbalancing, inclusion of a free recall test) and
analyses. A major revision is therefore recommended.
Comments to Author:
Reviewer: 1
Comments to the Author(s)
Comparing the effects of feedback on semantic versus phonological learning is an interesting
research question that seems worth pursuing, and this method seems like a good start. My
overall impression is positive, but I have a few suggestions and concerns. They have to do with
terminology, error rates, and the use of multiple tests.
1. The term feedback is used to refer to a lot of different things in the psychology literature.
Different types of feedback have different effects. This isn’t the authors’ fault, but it did mean
that, for me at least, the precise definition of feedback wasn’t made clear until partway through
the method section. In this experiment, it means yes/no feedback followed by a subsequent
(delayed) chance to restudy. It would have helped if that had been explained near the outset of
the intro. As it was, when I was reading the intro, the authors would talk about a finding and I
wasn’t sure whether it applied to the current research because I didn’t know what kind of
feedback the current research was about. (Also, coming from the adult memory literature, the
term “standard feedback” didn’t seem right to me.)
2. Error rates might need more attention. Here’s why: If you ask me an easy question, it is likely
that a) I will get it right, and b) I will know I’m right. In this situation, feedback will have little
effect on learning. I’ll know I’m right and your feedback will confirm what I already know. (Or at
least this is my understanding of the literature. The authors might want to look up research on
the “hypercorrection effect” for evidence about this at the semantic level. At a more implicit level
I’m not so sure, although research on the relationship between surprisingness and learning, e.g.,
the Rescorla-Wagner model of conditioning, also fits with the idea that unsurprising feedback
doesn't affect learning.) Based on thinking about error rates I see a couple of problems with the
method.
2a. First, the learning task in blocks 1, 2, 4, and 6 (the reproduce blocks) seems fairly trivial. I
expect participants will, in fact, get most answers right and know they are right. Thus the
feedback manipulation might not matter in these blocks. The only time it will matter, then, is in
blocks 3 and 5. This is not a fatal problem, as it does not introduce a confounding variable or
anything. It might, however, mean that the effects of feedback will end up being relatively small;
if learning is built up over 6 blocks and feedback is only manipulated twice, the effect of the
manipulation might get drowned out. If true, this might mean that the the actual effect sizes will
be smaller than the authors are currently predicting.
2b. The other problem has to do with comparing semantic and phonological learning. I am
6
guessing that participants will find the semantic task (naming a characteristic that is visible)
easier than the phonological task (producing a semantically unrelated non-word) during the
learning blocks. If this is true, and we assume that feedback has more effect when tests are more
difficult, then we should expect to see more effect of feedback in the phonological condition than
in the semantic condition. Crucially, this prediction is based on error rates, and seems like it
should be true even if the general effect of feedback on semantic versus phonological learning is
the same. In short, unless the error rate in semantic and phonological performance during the
learning phase is about the same, then error rates are a confounding variable that will make it
difficult to interpret effects of feedback when comparing semantic versus phonological learning.
3. All items are going to be tested twice. The problem is that the first test is a learning event. Items
that are answered correctly get strengthened, items that aren’t answered correctly don’t
(especially because there’s no feedback; see Spellman & Bjork, 1992). I have two concerns about
this. Before spelling them out, here’s my recommendation: Either only do the delayed test, or
manipulate whether the test happens immediately or after a delay (this manipulation could be
done on an individual item level or at the participant level).
3a. Test 1 will affect test 2. The effect will be that test 2 will end up being similar to test 1. Items
that were answered correctly, and therefore strengthened, are likely to be answered correctly
again. Items that weren’t answered correctly the first time won’t be the second time. Therefore,
test 2 will look like test 1, and reflect differences in short-term learning at least as much as long-
term learning. In other words, test 2 won’t be a good measure of long-term learning. This kind of
“double jeopardy” is a no-no in the testing effect literature.
3b. The fact that semantic and phonological tests will be given during test 1 seems like it will mix
things up in unpredictable ways. Here’s my guess. If I’ve only been tested on the semantic aspect
of an item and then I get a test on the phonological during test 1, that will mean my memory for
that item will become more of a mix of phonological and semantic. Thus, I expect that when test 2
comes around, test 1 will have further diminished the difference between semantic and
phonological memory on the final test. This could be another reason effect sizes might be smaller
than expected.
Here’s a minor comment. Lines 67-74 tripped me up. Why is it a problem that “the number of
exposures to the correct answer is not controlled for.”? It seems like the number of exposures is
what is being manipulated, in which case it doesn't need to be controlled. And I didn’t
understand the sentence that followed.
In summary, I would recommend making a few changes. Comment 1 is a relatively easy fix,
comment 3 is easy if you’re willing to remove the immediate test, and comment 2 might be tricky
to deal with and could involve some pilot testing to get similar levels of performance during the
learning phase.
Nate Kornell
Williams College
Reviewer: 2
Comments to the Author(s)
See attached word doc.
7
Reviewer: 3
Comments to the Author(s)
Please see the attached file for my comments.
Author's Response to Decision Letter for (RSOS-171055.R0)
See Appendix C.
label_version_2
RSOS-171496.R0
label_author_4
Review form: Reviewer 2 (Jo Taylor)
Is the language acceptable?
Yes
Do you have any ethical concerns with this paper?
No
Have you any concerns about statistical analyses in this paper?
No
Recommendation?
label_recommendation_4
Accept in principle
Comments to the Author(s)
label_comment_4
The authors' suggested amendments based on pilot work seem excellent.
label_author_5
Review form: Reviewer 3 (Peter Verkoeijen)
Is the language acceptable?
Yes
Do you have any ethical concerns with this paper?
No
Have you any concerns about statistical analyses in this paper?
No
Recommendation?
label_recommendation_5
Accept in principle
8
Comments to the Author(s)
label_comment_5
The minor changes that were made to the protocol do not affect the quality of the study. In fact,
using 11 blocks of training instead of six improves the study. Hence, I will remain with my
accept-in-principle decision.
label_end_comment
Decision letter (RSOS-171496.R0)
15-Nov-2017
Dear Dr Krishnan
On behalf of the Editor, I am pleased to inform you that your Manuscript RSOS-171496 entitled
"The influence of feedback on phonological and semantic processes in word learning" has been
accepted in principle for publication in Royal Society Open Science.
**At this time, please note the recently introduced requirement to register the approved protocol
on a recognised public repository at the point of IPA (see below)**
The reviewers' and editors' comments are included at the end of this email.
You may now progress to Stage 2 and complete the study as approved. Before commencing data
collection we ask that you:
1) Update the journal office as to the anticipated completion date of your study.
2) Register your approved protocol on the Open Science Framework (https://osf.io/) or other
recognised repository, either publicly or privately under embargo until submission of the Stage 2
manuscript. Please note that a time-stamped, independent registration of the protocol is
mandatory under journal policy, and manuscripts that do not conform to this requirement cannot
be considered at Stage 2. The protocol should be registered unchanged from its current approved
state, with the time-stamp preceding implementation of the approved study design.
Following completion of your study, we invite you to resubmit your paper for peer review as a
Stage 2 Registered Report. Please note that your manuscript can still be rejected for publication at
Stage 2 if the Editors consider any of the following conditions to be met:
• The results were unable to test the authors’ proposed hypotheses by failing to meet the
approved outcome-neutral criteria.
• The authors altered the Introduction, rationale, or hypotheses, as approved in the Stage 1
submission.
• The authors failed to adhere closely to the registered experimental procedures. Please note that
any deviations from the approved experimental procedures must be communicated to the editor
immediately for approval, and prior to the completion of data collection. Failure to do so can
result in revocation of in-principle acceptance and rejection at Stage 2 (see complete guidelines for
further information).
• Any post-hoc (unregistered) analyses were either unjustified, insufficiently caveated, or overly
dominant in shaping the authors’ conclusions.
• The authors’ conclusions were not justified given the data obtained.
9
We encourage you to read the complete guidelines for authors concerning Stage 2 submissions at
http://rsos.royalsocietypublishing.org/content/registered-reports. Please especially note the
requirements for data sharing, reporting the URL of the independently registered protocol, and
that withdrawing your manuscript will result in publication of a Withdrawn Registration.
Once again, thank you for submitting your manuscript to Royal Society Open Science and we
look forward to receiving your Stage 2 submission. If you have any questions at all, please do not
hesitate to get in touch. We look forward to hearing from you shortly with the anticipated
submission date for your stage two manuscript.
Kind regards,
Alice Power
Editorial Coordinator
Royal Society Open Science
on behalf of Chris Chambers
Registered Reports Editor, Royal Society Open Science
openscience@royalsociety.org
Reviewers' comments to Author:
Reviewer: 2
The authors' suggested amendments based on pilot work seem excellent.
Reviewer: 3
The minor changes that were made to the protocol do not affect the quality of the study. In fact,
using 11 blocks of training instead of six improves the study. Hence, I will remain with my
accept-in-principle decision.
Author's Response to Decision Letter for (RSOS-171496.R0)
We are pleased to submit a Stage 2 manuscript for review. We have included a track changes
version of the Stage 1 manuscript, so it is clear that the only changes to the introduction/
methods are changing the tense the manuscript is written in, the move of some material to the
Appendix, and to clarify any points where necessary.
label_version_3
RSOS-171496.R1 (Revision)
label_author_6
Review form: Reviewer 1 (Nate Kornell)
Is the language acceptable?
Yes
Do you have any ethical concerns with this paper?
No
10
Have you any concerns about statistical analyses in this paper?
No
Recommendation?
label_recommendation_6
Accept with minor revision
Comments to the Author(s)
label_comment_6
I don't have any major criticisms. With respect to the specific questions posed by the journal, e.g.,
"Whether the authors’ conclusions are justified given the data," I see no problems.
What follows isn't criticism, and I'm afraid it won't be of much help when it comes to editorial
decision making, but I have a few suggestions for the authors to consider. So here they are.
The intro had more conjecture than I personally like. This is a matter of opinion so ignore it if you
wish. But it seemed like some of the discussion about what you might find, what it might mean,
why you might find it could have been saved for the discussion section so that we could hear
some of the answers instead of the conjecture and you didn't have to talk about it twice.
Section 3.12 Analyses seemed redundant. It seemed like a mix between redundancy with the
hypotheses that had come before and redundancy with the analyses that were coming later.
Could this section be removed or integrated into the results section?
I'd suggest being consistent in how the term feedback is used. For one thing, pick a way of
referring to feedback that tells the participant whether they were right or wrong and then stick to
it. You mostly stick to "evaluative," but I have to say, I think my favorite would be "right/wrong"
(followed by "yes/no"). I just think this is the most telegraphic and easiest for readers to
immediately understand. But of course I'm not the author, it's up to you.
I also think the meaning of feedback should clarified earlier in the manuscript. I made this
request in my first review and the manuscript improved significantly, so I feel like I'm nagging
(for which I apologize). I just think the fact that it's evaluative feedback should be made clear way
up front, in the abstract and ideally in the title. I'm imagining, for example, that "the influence of
right/wrong feedback on ..." could be a cool title.
In the first paragraph of the discussion, the authors suggest that right/wrong feedback should be
used in phonological learning. I found myself disagreeing because it seems to me that even better
advice would be to do corrective feedback (i.e., tell them whether they are right/wrong and what
the right answer is), as you say at 678-704. In other words, just because right/wrong feedback is
better than no right/wrong feedback doesn't mean it should be recommended.
In the discussion of why feedback helped with phonological learning, I don't have a criticism, but
I will throw in a suggestion. Perhaps the difference is that with phonological learning the
participants aren't good at knowing whether they are right or wrong. They might be benefiting
because, without feedback, even after they hear the correct pronunciation they still think their
response was right (this seems to happen in a very different domain, where metacomprehension
of passages has been shown to be pretty bad even after corrective feedback; I think this is
summarized in Dunlosky & Lipko, 2007). Of course this won't happen with your semantics
condition as much because it's easy to tell whether a semantic response is right or wrong, so
when you hear it later, you get information that makes the feedback redundant. Semantics, and
words, are categories, and you usually either said the right word or not, whereas with
phonology, you can be close but wrong or close enough and right. (Incidentally, I'm so
uninformed I don't know whether this has been done, but it'd be cool to know whether people
11
truly are prone to mistakenly thinking their inaccurate pronunciations are accurate even after
hearing the word repeated, and whether this is less true with semantic information, because that
seems like it would go a long way toward helping explain your findings.)
What follows are smaller than minor, so I'll call them minuscule comments.
Lines 65-7 made me think, if that's the definition of feedback then does that mean when they
don't get feedback there is no opportunity to learn the correct response later? Maybe clarify that
this is not the case.
Lines 143-7 made me think the study was confounded because it seemed like if they didn't get
right/wrong feedback they did get corrective feedback on the other feature.
In figure 1c the word corrective doesn't seem right.
Figure 3 was hard to understand. Maybe you could put in the means? And maybe you could
signal how many points/lines are overlapping using changes in thickness? (Also, with grey lines,
maybe remove the grey background?)
Nate Kornell
label_author_7
Review form: Reviewer 2 (Jo Taylor)
Is the language acceptable?
Yes
Do you have any ethical concerns with this paper?
No
Have you any concerns about statistical analyses in this paper?
No
Recommendation?
label_recommendation_7
Accept with minor revision
Comments to the Author(s)
label_comment_7
See attached document (Appendix D).
label_author_8
Review form: Reviewer 3 (Peter Verkoeijen)
Is the language acceptable?
Yes
Do you have any ethical concerns with this paper?
No
12
Have you any concerns about statistical analyses in this paper?
No
Recommendation?
label_recommendation_8
Accept with minor revision
Comments to the Author(s)
label_comment_8
The present paper is a Stage 2 manuscript in which confirmatory and exploratiry analyses as well
as a discussion are added to a previously approved pre-registered study. Hence, my review will
only focus on a limited number of evaluation criteria.
First, the rationale and the hypothesis in this stage 2 manuscript are the soem as in the apporved
pre-registration. Second, as far as I can judge from the stage 2 paper, the experimental procedure
and the confirmatory analyses have been conducted according to plan. Third, the positive
controls that were added to the pre-registration revealed the expected outcomes. Fourth,
although there were some floor effects (in the phonological condition) in the outcomes of the
planned/confirmatory analyses, these do not invalidate the outcomes and the conclusions from
the present experiment.Fifht, the exploratory analyses are informative and sound. I do have,
however, one relatively minor issues with these exploratiry analyses. Specifically, for some of
them, the authors report the outcomes of null--hypothesis-significance-testing procedures.
However, because it is hard - or perhaps even impossible - to control the Type 1 error in
exploratory analyses (see for example de Groot, A. D., Wagenmakers, E-J., Borsboom, D.,
Verhagen, J., Kievit, R., Bakker, M., ... van der Maas, H. L. J. (2014). The meaning of "significance"
for different types of research. Acta Psychologica, 148, 188-194), I would recommend the authors
to drop the NHST outcomes and to constrain the exploratory findings to descriptive statistics and
measures of effect sizes. Finally, the discussion and conclusion is justified given the results of the
experiment.
label_end_comment
Decision letter (RSOS-171496.R1)
31-Jul-2018
Dear Dr Krishnan:
On behalf of the Editor, I am pleased to inform you that your Stage 2 Registered Report RSOS-
171496.R1 entitled "The influence of feedback on phonological and semantic processes in word
learning" has been deemed suitable for publication in Royal Society Open Science subject to
minor revision in accordance with the referee suggestions. Please find the referees' comments at
the end of this email.
The reviewers and Subject Editor have recommended publication, but also suggest some minor
revisions to your manuscript. Therefore, I invite you to respond to the comments and revise your
manuscript.
Please also ensure that all the below editorial sections are included where appropriate -- if any
section is not applicable to your manuscript, please can we ask you to nevertheless include the
heading, but explicitly state that the heading is inapplicable. An example of these sections is
attached with this email.
13
• Ethics statement
If your study uses humans or animals please include details of the ethical approval received,
including the name of the committee that granted approval. For human studies please also detail
whether informed consent was obtained. For field studies on animals please include details of all
permissions, licences and/or approvals granted to carry out the fieldwork.
• Data accessibility
It is a condition of publication that all supporting data are made available either as
supplementary information or preferably in a suitable permanent repository. The data
accessibility section should state where the article's supporting data can be accessed. This section
should also include details, where possible of where to access other relevant research materials
such as statistical tools, protocols, software etc can be accessed. If the data has been deposited in
an external repository this section should list the database, accession number and link to the DOI
for all data from the article that has been made publicly available. Data sets that have been
deposited in an external repository and have a DOI should also be appropriately cited in the
manuscript and included in the reference list.
If you wish to submit your supporting data or code to Dryad (http://datadryad.org/), or modify
your current submission to dryad, please use the following link:
http://datadryad.org/submit?journalID=RSOS&manu=(Document not available)
• Competing interests
Please declare any financial or non-financial competing interests, or state that you have no
competing interests.
• Authors’ contributions
All submissions, other than those with a single author, must include an Authors’ Contributions
section which individually lists the specific contribution of each author. The list of Authors
should meet all of the following criteria; 1) substantial contributions to conception and design, or
acquisition of data, or analysis and interpretation of data; 2) drafting the article or revising it
critically for important intellectual content; and 3) final approval of the version to be published.
All contributors who do not meet all of these criteria should be included in the
acknowledgements.
We suggest the following format:
AB carried out the molecular lab work, participated in data analysis, carried out sequence
alignments, participated in the design of the study and drafted the manuscript; CD carried out
the statistical analyses; EF collected field data; GH conceived of the study, designed the study,
coordinated the study and helped draft the manuscript. All authors gave final approval for
publication.
• Acknowledgements
Please acknowledge anyone who contributed to the study but did not meet the authorship
criteria.
• Funding statement
Please list the source of funding for each author.
Because the schedule for publication is very tight, it is a condition of publication that you submit
the revised version of your manuscript within 7 days (i.e. by the 08-Aug-2018). If you do not
think you will be able to meet this date please let me know immediately.
14
To revise your manuscript, log into https://mc.manuscriptcentral.com/rsos and enter your
Author Centre, where you will find your manuscript title listed under "Manuscripts with
Decisions". Under "Actions," click on "Create a Revision." You will be unable to make your
revisions on the originally submitted version of the manuscript. Instead, revise your manuscript
and upload a new version through your Author Centre.
When submitting your revised manuscript, you will be able to respond to the comments made by
the referees and upload a file "Response to Referees" in "Section 6 - File Upload". You can use this
to document any changes you make to the original manuscript. In order to expedite the
processing of the revised manuscript, please be as specific as possible in your response to the
referees.
When uploading your revised files please make sure that you have:
1) A text file of the manuscript (tex, txt, rtf, docx or doc), references, tables (including captions)
and figure captions. Do not upload a PDF as your "Main Document".
2) A separate electronic file of each figure (EPS or print-quality PDF preferred (either format
should be produced directly from original creation package), or original software format)
3) Included a 100 word media summary of your paper when requested at submission. Please
ensure you have entered correct contact details (email, institution and telephone) in your user
account
4) Included the raw data to support the claims made in your paper. You can either include your
data as electronic supplementary material or upload to a repository and include the relevant doi
within your manuscript
5) All supplementary materials accompanying an accepted article will be treated as in their final
form. Note that the Royal Society will neither edit nor typeset supplementary material and it will
be hosted as provided. Please ensure that the supplementary material includes the paper details
where possible (authors, article title, journal name).
Supplementary files will be published alongside the paper on the journal website and posted on
the online figshare repository (https://figshare.com). The heading and legend provided for each
supplementary file during the submission process will be used to create the figshare page, so
please ensure these are accurate and informative so that your files can be found in searches. Files
on figshare will be made available approximately one week before the accompanying article so
that the supplementary material can be attributed a unique DOI.
Please note that Royal Society Open Science will introduce article processing charges for all new
submissions received from 1 January 2018. Registered Reports submitted and accepted after this
date will ONLY be subject to a charge if they subsequently progress to and are accepted as Stage
2 Registered Reports. If your manuscript is submitted and accepted for publication after 1
January 2018 (i.e. as a full Stage 2 Registered Report), you will be asked to pay the article
processing charge, unless you request a waiver and this is approved by Royal Society Publishing.
You can find out more about the charges at
http://rsos.royalsocietypublishing.org/page/charges. Should you have any queries, please
contact openscience@royalsociety.org.
Once again, thank you for submitting your manuscript to Royal Society Open Science and I look
forward to receiving your revision. If you have any questions at all, please do not hesitate to get
in touch.
Kind regards,
Royal Society Open Science Editorial Office
15
Royal Society Open Science
openscience@royalsociety.org
on behalf of Professor Chris Chambers (Registered Reports Editor, Royal Society Open Science)
openscience@royalsociety.org
Associate Editor Comments to Author (Professor Chris Chambers):
Associate Editor: 1
Comments to the Author:
The Stage 2 manuscript was returned to the three expert reviewers who assessed it at Stage 1. The
assessments are broadly positive and mainly highlight minor issues of clarity and interpretation.
As a general point, please note that beyond minor clarifications and typographic and
grammatical corrections, no changes should be made to the approved Introduction and Methods.
This means that some of the reviewer's comments, while well intentioned and very sensible for a
regular paper are not applicable given the strict criteria for a Stage 2 RR. I will provide some
specific guidance below on the key issues to address (or not) in light of the Stage 2 criteria.
Reviewer 1 offers a number of helpful suggestions for improving clarity and the use of consistent
terminology. The reviewer also notes some concerns with the level of conjecture in the
Introduction and redundancy of the description of the hypotheses in the Methods. These are
sensible suggestions for a regular paper, but please note that these aspects of the manuscript
should not be revised because doing so would deviate too substantially from the approved Stage
1 protocol. This exemption does not apply to the reviewer's comments on the Discussion and
interpretation of results which should be addressed, and the reviewer also makes some
suggestions for potentially amending the title and abstract (which can be revised at Stage 2).
Reviewer 2 focuses mainly on the results and discussion, offering some suggestions for additional
exploratory analyses. In my reading these are sensible recommendations. Note, however, that
under the Stage 2 guidelines, authors are not required to undertake additional exploratory
analyses unless they are necessary to justify the conclusions. In this case, while the suggested
analyses could very well increase the impact and usefulness of the work (as the reviewer notes),
they do not meet the threshold to be required for Stage 2 acceptance; therefore I will let you
decide whether to include them, and whether you do or not will not influence the final editorial
decision. The reviewer also recommends some minor restructuring of the exploratory analyses to
better link some of the exploratory outcomes to the confirmatory outcomes. In a Stage 2 RR it is
often more straightforward to separate confirmatory and exploratory outcomes into separate
sections, but authors are welcome to include tightly linked exploratory and confirmatory
analyses within the same sections of the results provided they are clearly distinguished (or
alternatively the exploratory analyses could be signposted in the confirmatory section, with the
reader directed to the later exploratory section). Reviewer 2 also makes some minor suggestions
for improving the clarity of the Introduction and Methods, which sufficiently minor that they can
be made.
Finally, Reviewer 3 recommends that you abandon the use of inferential statistics in the
exploratory analyses. I agree with the reviewer that the interpretation of p values in exploratory
analyses is difficult, however it is not a settled issue that this invalidates altogether the use of
frequentist statistical techniques (and there is no standard policy on this in the RR guidelines). I
will therefore let you decide whether and if so how to address this point. From an editorial point
of view, I am happy for you to maintain the use of inferential statistics in the exploratory analyses
precisely because they are transparently exploratory, so readers will be equipped to judge them
accordingly, but perhaps you could forewarn the less studied reader with a footnote (and
16
associated reference) or other remark commenting on the fact that p values for the exploratory
analyses should - as always - be interpreted with caution.
Given the positive assessments and relatively minor revisions that are needed, provided the
revised submission addresses all of the reviewers' points through revision or rebuttal, final Stage
2 acceptance should be forthcoming without requiring further in-depth review.
Comments to Author:
Reviewer: 1
Comments to the Author(s)
I don't have any major criticisms. With respect to the specific questions posed by the journal, e.g.,
"Whether the authors’ conclusions are justified given the data," I see no problems.
What follows isn't criticism, and I'm afraid it won't be of much help when it comes to editorial
decision making, but I have a few suggestions for the authors to consider. So here they are.
The intro had more conjecture than I personally like. This is a matter of opinion so ignore it if you
wish. But it seemed like some of the discussion about what you might find, what it might mean,
why you might find it could have been saved for the discussion section so that we could hear
some of the answers instead of the conjecture and you didn't have to talk about it twice.
Section 3.12 Analyses seemed redundant. It seemed like a mix between redundancy with the
hypotheses that had come before and redundancy with the analyses that were coming later.
Could this section be removed or integrated into the results section?
I'd suggest being consistent in how the term feedback is used. For one thing, pick a way of
referring to feedback that tells the participant whether they were right or wrong and then stick to
it. You mostly stick to "evaluative," but I have to say, I think my favorite would be "right/wrong"
(followed by "yes/no"). I just think this is the most telegraphic and easiest for readers to
immediately understand. But of course I'm not the author, it's up to you.
I also think the meaning of feedback should clarified earlier in the manuscript. I made this
request in my first review and the manuscript improved significantly, so I feel like I'm nagging
(for which I apologize). I just think the fact that it's evaluative feedback should be made clear way
up front, in the abstract and ideally in the title. I'm imagining, for example, that "the influence of
right/wrong feedback on ..." could be a cool title.
In the first paragraph of the discussion, the authors suggest that right/wrong feedback should be
used in phonological learning. I found myself disagreeing because it seems to me that even better
advice would be to do corrective feedback (i.e., tell them whether they are right/wrong and what
the right answer is), as you say at 678-704. In other words, just because right/wrong feedback is
better than no right/wrong feedback doesn't mean it should be recommended.
In the discussion of why feedback helped with phonological learning, I don't have a criticism, but
I will throw in a suggestion. Perhaps the difference is that with phonological learning the
participants aren't good at knowing whether they are right or wrong. They might be benefiting
because, without feedback, even after they hear the correct pronunciation they still think their
response was right (this seems to happen in a very different domain, where metacomprehension
of passages has been shown to be pretty bad even after corrective feedback; I think this is
summarized in Dunlosky & Lipko, 2007). Of course this won't happen with your semantics
condition as much because it's easy to tell whether a semantic response is right or wrong, so
when you hear it later, you get information that makes the feedback redundant. Semantics, and
17
words, are categories, and you usually either said the right word or not, whereas with
phonology, you can be close but wrong or close enough and right. (Incidentally, I'm so
uninformed I don't know whether this has been done, but it'd be cool to know whether people
truly are prone to mistakenly thinking their inaccurate pronunciations are accurate even after
hearing the word repeated, and whether this is less true with semantic information, because that
seems like it would go a long way toward helping explain your findings.)
What follows are smaller than minor, so I'll call them minuscule comments.
Lines 65-7 made me think, if that's the definition of feedback then does that mean when they
don't get feedback there is no opportunity to learn the correct response later? Maybe clarify that
this is not the case.
Lines 143-7 made me think the study was confounded because it seemed like if they didn't get
right/wrong feedback they did get corrective feedback on the other feature.
In figure 1c the word corrective doesn't seem right.
Figure 3 was hard to understand. Maybe you could put in the means? And maybe you could
signal how many points/lines are overlapping using changes in thickness? (Also, with grey lines,
maybe remove the grey background?)
Nate Kornell
Reviewer: 2
Comments to the Author(s)
See attached document
Reviewer: 3
Comments to the Author(s)
The present paper is a Stage 2 manuscript in which confirmatory and exploratiry analyses as well
as a discussion are added to a previously approved pre-registered study. Hence, my review will
only focus on a limited number of evaluation criteria.
First, the rationale and the hypothesis in this stage 2 manuscript are the soem as in the apporved
pre-registration. Second, as far as I can judge from the stage 2 paper, the experimental procedure
and the confirmatory analyses have been conducted according to plan. Third, the positive
controls that were added to the pre-registration revealed the expected outcomes. Fourth,
although there were some floor effects (in the phonological condition) in the outcomes of the
planned/confirmatory analyses, these do not invalidate the outcomes and the conclusions from
the present experiment.Fifht, the exploratory analyses are informative and sound. I do have,
however, one relatively minor issues with these exploratiry analyses. Specifically, for some of
them, the authors report the outcomes of null--hypothesis-significance-testing procedures.
However, because it is hard - or perhaps even impossible - to control the Type 1 error in
exploratory analyses (see for example de Groot, A. D., Wagenmakers, E-J., Borsboom, D.,
Verhagen, J., Kievit, R., Bakker, M., ... van der Maas, H. L. J. (2014). The meaning of "significance"
for different types of research. Acta Psychologica, 148, 188-194), I would recommend the authors
to drop the NHST outcomes and to constrain the exploratory findings to descriptive statistics and
measures of effect sizes. Finally, the discussion and conclusion is justified given the results of the
experiment.
18
Author's Response to Decision Letter for (RSOS-171496.R1)
See Appendix E.
label_end_comment
Decision letter (RSOS-171496.R2)
09-Aug-2018
Dear Dr Krishnan:
It is a pleasure to fully accept your Stage 2 Registered Report entitled "The influence of evaluative
right/wrong feedback on phonological and semantic processes in word learning" in its current
form for publication in Royal Society Open Science.
Please note that Royal Society Open Science will introduce article processing charges for all new
submissions received from 1 January 2018. Registered Reports submitted and accepted after this
date will ONLY be subject to a charge if they subsequently progress to and are accepted as Stage
2 Registered Reports. If your manuscript is submitted and accepted for publication after 1
January 2018 (i.e. as a full Stage 2 Registered Report), you will be asked to pay the article
processing charge, unless you request a waiver and this is approved by Royal Society Publishing.
You can find out more about the charges at
http://rsos.royalsocietypublishing.org/page/charges. Should you have any queries, please
contact openscience@royalsociety.org.
Thank you for your fine contribution. On behalf of the Editors of Royal Society Open Science, we
look forward to your continued contributions to the Journal.
Kind regards,
Royal Society Open Science Editorial Office
Royal Society Open Science
openscience@royalsociety.org
on behalf of Professor Chris Chambers (Subject Editor)
openscience@royalsociety.org
Appendix A
1. The significance of the research question(s)
The primary question addressed by this study is whether feedback enhances
learning. This question is often not directly addressed by experimental
studies; instead we assume that feedback is helpful. From a practical
perspective, it is important to know whether feedback is helpful, since
providing it requires assessing response accuracy, which is not trivial if the
response involves spoken production. The question of whether feedback is
helpful is also important theoretically, for example, in debates about the
value of implicit vs explicit learning. The study also addresses whether
feedback is particularly important for semantic or phonological learning,
since previous research provides mixed evidence. It would have been nice to
have some theoretical motivation for considering this question, since it is not
clear to me why feedback would be important for one but not the other.
Finally, the study addresses whether providing semantic information during
learning enhances phonological learning. This is well motivated by the
existing literature.
2. The logic, rationale, and plausibility of the proposed hypotheses
The proposed hypotheses are entirely sensible based on the existing
literature and the experimental design.
3. The soundness and feasibility of the methodology and analysis pipeline
(including statistical power analysis where applicable)
I did have some questions about the experimental design, which I will detail
below.
a) The participant counterbalancing was well explained, but the stimulus
counterbalancing less so. I’ve tried to figure out the best way of
counterbalancing the stimuli that are described (see below table) but it
doesn’t quite work as there are 8 possible combinations and only 12 stimuli
per list. Perhaps it was not considered necessary to counterbalance the
stimuli in this way, and instead items were just randomised across each
feature. If this is the case, I think some justification is required. And some
further description or a table such as the one below would be helpful for the
reader to understand the stimulus sets fully.
list1 list2
Ite syllabl featur feedba syllabl feedba featur
m es type e ck es type ck e
anim concre anim concre
1 2 al te yes 2 al no te
anim abstra anim abstra
2 2 al ct yes 2 al no ct
anim concre anim concre
3 2 al te yes 2 al no te
abstra abstra
4 2 plant ct yes 2 plant no ct
concre concre
5 2 plant te yes 2 plant no te
abstra abstra
6 2 plant ct yes 2 plant no ct
anim abstra anim abstra
7 3 al ct yes 3 al no ct
anim concre anim concre
8 3 al te yes 3 al no te
anim abstra anim abstra
9 3 al ct yes 3 al no ct
concre concre
10 3 plant te yes 3 plant no te
abstra abstra
11 3 plant ct yes 3 plant no ct
concre concre
12 3 plant te yes 3 plant no te
b) Method section 3.4 is entitled “word learning task” and then section
3.7 is “procedure for the training phase”. I was confused by the difference
between these. The word-learning task sounds like the recall blocks (1, 2, 4,
6) of the training phase, but perhaps it was an initial task completed by
participants before the training phase? An overview diagram of the
experiment as experienced by participants would help to resolve this
confusion.
c) I am concerned that recalling the concrete semantic attributes is
trivial, since participants are always presented with the picture, and the
picture contains these features. I think performance will be at ceiling from
block 1, preventing this condition from being used meaningfully. I
understand that it is difficult to get around this, but one thought I did have
was to have black and white pictures and then the concrete features could
contain colour information, for example, has blue stripes. I know that the
concrete-abstract manipulation was really only there as a sanity check, but if
semantic learning is at ceiling for half the items from the beginning there will
be less power to assess the rest of your questions.
d) The current design will not determine whether it is feedback
following a recall trial or following a repeat trial that is important. You could
perhaps only provide feedback on the recall blocks, since the repeat blocks
will almost certainly yield near to ceiling performance anyway. To increase
the power of the feedback manipulation it might also be worth having blocks
1, 3, 5 as repeat blocks, and blocks 2, 4, 6 as recall blocks.
4. Whether the clarity and degree of methodological detail would be
sufficient to replicate exactly the proposed experimental procedures
and analysis pipeline
In general the methods are comprehensive, but there were a few points
that required greater clarity, which were outlined in my response to
question 3.
5. Whether the authors provide a sufficiently clear and detailed
description of the methods to prevent undisclosed flexibility in the
experimental procedures or analysis pipeline
Yes.
6. Whether the authors have considered sufficient outcome-neutral
conditions (e.g. positive controls) for ensuring that the results obtained
are able to test the stated hypotheses
Yes.
Further comments
I think there is a mistake in section 3.11.3, “We will use a 2 x 2 x 2 mixed
ANOVA of cued-recall accuracy, modelling the between-subject factor
training focus (semantic/phonological), time (Week 0/Week 1), and the
within-subject factors time (Week 0/ Week 1), cued recall condition
(semantic/phonological), and feedback (standard/none).”
I think that time is a within-subject factor and not a between-subject factor,
but here it is described as both.
In the same section I think that an additional clause is needed as follows:
“Our prediction is an interaction between training focus and cued recall
condition, in that training in the semantic condition will lead to better
performance in the semantic cued recall test, WHEREAS TRAINING IN THE
PHONOLOGICAL CONDITION WILL LEAD TO BETTER PERFORMANCE IN
THE PHONOLOGICAL CUED RECALL TEST. HOWEVER, if attention to
semantic context improves phonological learning also, we would also expect
to find a main effect of training focus.”
In section 3.11.4 I think an addition is required to the following sentence:
“Our prediction is that there will be an interaction between the between-
subject factor of training condition (semantic/ phonological) and THE
WITHIN-SUBJECT FACTOR OF feedback (standard/none),…”
Reviewed by Jo Taylor, j.taylor13@aston.ac.uk
Appendix B
Review Royal Society Open Science manuscript RSOS-171055
Below, I will provide my feedback on the registered report submitted to the Royal
Society of Open Science, filed under manuscript number 171055. I will give my
feedback on a point-by-point basis according to the bullets listed in the review form.
The significance of the research question(s)
Evaluating the significance of the research question is difficult for me because I am
not an expert in research on spoken vocabulary learning. That said, I think the
authors clearly outline the broader relevance of the research project as well as the
rationale for conducting the proposed experiment. Regarding the introduction, I only
have a few points the authors might want to attend to.
- In the first and second paragraph of the introduction, the authors mention
foreign vocabulary learning but that may be somewhat misleading because
the task participants will face in their proposed study does not entirely mimic
what happens during foreign vocabulary learning. In foreign vocabulary
learning, which can be trained using programs such as Duolingo and Rosetta
Stone, people do not learn new meanings. Instead, they “simply” need to
form a connection between a new phonological form and a known
phonological form, which are both related to a known meaning. For example,
when learning German, people need to relate a new phonological form of
“das Auto” to a known one, namely “car” without learning a new
concept/object (assuming that people know what a car is). The process in the
present experiment models seems to be more similar to native-language
vocabulary learning in which people learn phonological and lexical
characteristics of new concept. Hence, I would refrain from referring to
foreign language vocabulary learning in the introduction and instead focus on
indicate very precisely what kind of vocabulary learning is the focus of the
1
present study. Again, I would say that the process in the study mostly
resembles native-language vocabulary learning. If that is correct then it
would be useful to add references about (native language) vocabulary
instructions to the introduction. See for example: Blachowicz and colleagues
(2006) for an open access if am not mistaken review that may provide
relevant background information
(http://onlinelibrary.wiley.com/doi/10.1598/RRQ.41.4.5/epdf).
- The factor time is also included in the experiment, but from the introduction,
it is not exactly clear what the authors expect with respect to this factor. I
think it would be good to add a specific prediction to the hypotheses. Should
there be no specific expectation, it would be good to state that the factor is
included for exploratory purposes.
-
The logic, rationale, and plausibility of the proposed hypotheses
The hypotheses are clear and the first two follow clearly from the introduction. The
third hypotheses – arguably the crucial one – refers to a three-way interaction if am
not mistaken, i.e., the interaction between feedback and training focus differs per
outcome measure. I think it would be good to specify the expected relationships as
precisely as possible. A mock-up table or bar chart with the expected pattern would
be very insightful here.
The soundness and feasibility of the methodology and analysis pipeline
(including statistical power analysis where applicable)
The experimental procedure is solid and I do not see reasons why the authors should
have problems carrying out the proposed plan. However, I do have some feedback
points:
- I did not see why a free recall test should be included in the procedure. It
seemed to me that all hypotheses could be addressed without this measure.
Consequently, I would advise the authors to drop the free recall part of the
testing procedure.
2
- Please provide some information about the test location. I assume
participants will be tested in cubicles, perhaps in small groups, but I could
not find any information about this in the paper.
- Please provide constraints of generality. See: Simons, D. J., Shoda, Y., &
Lindsay, D. S. (2017). Constraints on generality (COG): A proposed addition
to all empirical papers. Perspectives on Psychological Science. Online First.
DOI: 10.1177/1745691617708630.
- Interrater agreement will be measured for the recorded responses. It would be
good if the authors would indicate a minimum level that is required to use the
data in their analyses
- There seems to be a small error in the naming of one of the ANOVA’s. On
page 10, the authors write:
“ We will use a 2 x 2 x 2 mixed ANOVA of cued-recall accuracy, modelling the
between-subject factor training focus (semantic/phonological), time (Week 0/Week
1), and the within-subject factors time (Week 0/ Week 1), cued recall condition
(semantic/phonological), and feedback (standard/none).”
I think this should be:
“ We will use a 2 x 2 x 2 x 2 mixed ANOVA of cued-recall accuracy, modelling the
between-subject factor training focus (semantic/phonological), and the within-subject
factors time (Week 0/ Week 1), cued recall condition (semantic/phonological), and
feedback (standard/none).”
- In the analysis plan, the authors repeatedly refer to mediation where I think
they mean moderation.
Whether the clarity and degree of methodological detail would be sufficient to
replicate exactly the proposed experimental procedures and analysis pipeline
3
The method and analysis section is sufficiently clear for replication purposes,
However, it would be very helpful if the authors could make their materials and
program scripts publicly available, for example on an Open Science Framework.
Whether the authors provide a sufficiently clear and detailed description of the
methods to prevent undisclosed flexibility in the experimental procedures or
analysis pipeline
Because ANOVA’s are very sensitive to outliers, I think it would be good if the
authors would describe how they will detect outliers and how they will deal with
them if they are present. Anguinis and colleagues (2013) provide some very useful
guidelines that might be helpful.
Furthermore, I think the authors need to describe exactly what kind of follow-up
comparisons they will perform in case of relevant interaction effects and how they
will control for multiple comparisons. For example, “if the 3-way interaction between
training focus, cued-recall condition and feedback is significant, we will conduct two
2 x 2 repeated measures ANOVA to examine the interaction between cued-recall
condition and feedback per training focus condition. If the interaction is significant,
under a Bonferroni-corrected alpha level of p < .025, we will conduct Bonferroni-
corrected paired samples t-tests to test to compare the feedback and the no-feedback
condition for each of the cued-recall measures.”
Whether the authors have considered sufficient outcome-neutral conditions (e.g.
positive controls) for ensuring that the results obtained are able to test the stated
hypotheses
They tow planned positive-control analyses seem be to sufficient to demonstrate
whether the procedure will allow for the detection of some well-established
relationships.
4
Appendix C
Response to Editor and Reviewers
Reviewers' comments to Author:
Reviewer: 3
The authors worked hard to address the feedback that the two other
reviewers and I raised. This has led to a considerable improvement of
the research plan and I advised the editor to accept the revised plan as
is.
Reviewer: 2
The authors have considered and addressed each of my previous
comments and I think the study is now well motivated and designed
and the planned analyses are sensible. They have also provided more
details such that the study could now be replicated.
We were delighted to receive positive reviews and an acceptance of our
revised protocol. However, as indicated in the revision we submitted, we
intended to complete pilot testing to assess error rates across the
phonological and semantic training conditions. In the process of doing
so, we found that learning following 2 blocks of repeat + reproduce was
not particularly high in either training condition, and this led us to be
concerned about possible floor effects when assessing learning a week
after training. We therefore attempted a slightly longer training protocol,
with 11 alternating blocks of the repeat and reproduce conditions
(Appendix 1). We find that following this protocol, accuracy is balanced
across the semantic and phonological conditions at the final test (Figure
2, Appendix 1). We therefore suggest that we do 11 blocks of training,
rather than the 6 we originally proposed.
We have therefore made minor modifications to the draft of our protocol
that reflect the proposed change to our training paradigm. Specifically,
Figure 1 is updated to reflect this slightly modified training regime, and
the following lines have been edited:
Lines 229-235: “Pilot testing was conducted with 8 participants (4
assigned to each condition) who were not enrolled in the final study, who
received between 5-6 blocks of reproduction practice (see Appendix 1
for further details). Five or six retrieval blocks were interleaved in
between these blocks. Accuracy were calculated by averaging the
number of correct responses in the retrieval blocks. The chosen
phonological and semantic stimuli showed accuracy rates of 79.17% and
87.5% in the final recall block (for the phonological and semantic training
condition respectively)”
Lines 288-290: “Blocks 1, 3, 5, 7, 9 and 11 will be the Reproduce
blocks. During these, participants will be asked to overtly repeat the
pseudoword or semantic feature, according to the training condition.”
Line 298: “Blocks 2,4, 6, 8 and 10 will be the cued Recall blocks.”
We note that the hypotheses and analysis plan remain entirely
unchanged, as this is only assessed at the time-point a week after
training. We would be very grateful if you could approve the minor
change to our protocol.
Appendix D
I have very few comments on the introduction and methods, given that I
already reviewed these at stage 1.
1. I noticed one incorrectly worded sentence on p45, line 111:
“Furthermore, another argument IS ABOUT the value of feedback for
vocabulary learning IS THAT although immediate feedback might lead to
greater learning efficiency in the short term,…”
2. I wasn’t sure why some of Figure 1 was greyed out, e.g., panel D?
3. In section 3.8, I would recommend adding information about how
responses were scored as correct or incorrect. It only became apparent to
me quite late on in the results that something such as “saying “hupip has
multiple tendrils”, instead of “hupip has several tendrils”,…” would be
classed as incorrect. You might also want to motivate this decision, as
typically I would imagine that responses such as this would be classed as
correct in semantic learning, when the meaning is identical, just the choice of
words differs. Also, I would like to know whether participants were told that
this kind of response would class as incorrect? This is relevant to a point
made in the Discussion (lines 696-694)
“In contrast, for semantic learning, participants believe they have to retrieve
a gist, rather than the correct combination of words. Here, evaluative right/
wrong feedback may do very little to shape access to the precise semantic
representation.”
Such a pronlem would likely be enhanced if participants were not told what
counts as correct/incorrect.
My suggestions for improving the results and discussion are below.
4. I would really like to see learning curves (i.e. performance in the cued
recall blocks) for the four main conditions: phonological learning with and
without feedback, semantic learning with and without feedback. This kind of
information is important for those of us who conduct learning studies, so we
can see what to expect from participants, for example. These data seem
especially important to provide given that the error analysis from the final
block of training (section 4.5.4) shows that performance during learning was
far better in the semantic than the phonological condition, and also that
phonological learning showed much greater individual variability. Given
these differences, I also think it would be very informative to present an
analysis examining the influence of feedback on performance during
learning, i.e. a block (5 blocks) x information type (phonological vs semantic)
x feedback (with/without) ANOVA. I appreciate that you had not planned to
analyse these data, and I should have recommended this at Stage 1, but I do
think it would be interesting to see if feedback influences semantic learning,
given that it does not seem to influence retention.
5. On p17 I felt that I could do with a little more help understanding the
key results. I think I am correct in thinking that the interaction between
feedback and recall condition indicates that cued recall of phonological
information was better following both semantic and phonological learning
with feedback than without feedback, whereas cued recall of semantics was
not influenced by feedback? This was not what you predicted, I don’t think,
instead you expected either a 2-way interaction between training condition
and feedback whereby cued recall of phonological information was better
following phonological learning with feedback than without feedback, and
cued recall of semantic information was better following semantic learning
with than without feedback, or a 3-way interaction where one of these
effects was present but the other was not (or feedback had the reverse
effect in one condition). I think it would help to clarify that the effect you
observed was not exactly what you had expected and to have a statement
(something like mine at the start of this comment!) to explain what the effect
shows. Also, it is somewhat confusing that lines 491-492 state “Although this
was an effect we predicted, it is important to note that the effect size is smaller
than we expected (we predicted d=0.4).” I don’t think this was quite the
effect you predicted… Clarifying this finding would then help the reader to
understand the motivation for the first follow-up exploratory analysis
(section 4.5.1).
6. On a related note, I would personally prefer section 4.5.1 to be within
section 4.4 given that it clarifies the slightly strange 2x2 interaction, but I
understand that anything that wasn’t pre-specified should be in an
Exploratory section. You could perhaps include it in section 4.4 but state that
this was a follow-up analysis that wasn’t planned and isn’t in fact justified by
the results of the main ANOVA. In this section, I think it would be more
informative to also examine whether the effect of feedback on phonological
recall holds when the semantic learning condition is examined on its own,
given that this was the really unexpected result. This would help to
demonstrate that the effect of feedback (within the phonological cued recall
task) was driven by primarily the phonological learning condition, despite the
lack of an interaction. If you decide to do this then Figure 3 should include all
8 conditions.
7. P18, line 526 seems somewhat ungrammatical “as we were reducing
half our dataset”. Perhaps say “losing half our dataset”?
8. In section 4.5.4. I would find the reporting of each error type easier to
understand in proportions or percentages, but perhaps that’s just a personal
thing.
9. The first line of the Discussion (line 575) is not very well worded “In
this study, we evaluated whether evaluative feedback…”
10. Line 710 states “(see Appendix 4)” but I couldn’t find a reference to
Appendix 3. And also the appendices are not provided.
11. I’m also a bit confused as to what is likely to be in Appendix 4. In the
text that first references it (Results, section 4.5.1), it is not clear that this is
data from the training trials, but this is certainly what seems to be implied by
line 709-710 of the Discussion.
“Somewhat surprisingly, we did not observe an effect of feedback in the
training trials (see Appendix 4).”
This then has an impact on my understanding of sections 4.5.2 and 4.5.3. Are
these also analyses of the training data? I don’t think they can be given that
line 534 says “as previously reported” implying that these are the same data
as presented in sections 4.2 to 4.4… If none of the data reported in the
manuscript is the training data (other than section 4.5.4, the error analysis),
then what is the evidence for the statement in lines 709-710? If there are
data in Appendix 4 that show a total lack of a feedback effect during training
this is really important and should not only be in an appendix. This also
further justifies my suggestion to include an analysis of the training data (see
comment 4).
12. Lines 719-720 are somewhat misleading, since directing attention to
semantic facts did have an effect on phonological learning, it resulted in it
being at floor! “Beyond the effects of feedback, we found that directing
attention to semantic facts did not have a substantial effect on phonological
learning,…”
13. Lines 725-726 are somewhat ungrammatical/unclear: “Our data
suggests that rather than the presence of semantic information, the designs
used in previous studies may actually boost overall motivation or attention to
phonology. However, this does not indicate that providing context is of no
benefit at all during learning.” What is meant by “rather than the presence
of semantic information”? and what is being referred to that “does not
indicate that providing context is of no benefit”?
14. Lines 730-732 also contain grammatical errors: “To shed further light
on this issue, a follow up study where the same material where participants
are given some opportunities to learn phonology/ semantics during
training…”
15. Line 755 should read “Our data indicate that…”
Appendix E
Response to Editor and Reviewers
Associate Editor Comments to Author (Professor Chris
Chambers):
Associate Editor: 1
Comments to the Author:
The Stage 2 manuscript was returned to the three expert reviewers
who assessed it at Stage 1. The assessments are broadly positive and
mainly highlight minor issues of clarity and interpretation.
We are delighted that the reviewers thought we had followed the
protocols we set out in Stage 1, and that they still found the findings to
be of interest. Below, we respond to the concerns they have raised.
As a general point, please note that beyond minor clarifications and
typographic and grammatical corrections, no changes should be made
to the approved Introduction and Methods. This means that some of
the reviewer's comments, while well intentioned and very sensible for a
regular paper are not applicable given the strict criteria for a Stage 2
RR. I will provide some specific guidance below on the key issues to
address (or not) in light of the Stage 2 criteria.
Thank you for the directions you have provided! They made revising
this paper much easier.
Reviewer 1 offers a number of helpful suggestions for improving clarity
and the use of consistent terminology. The reviewer also notes some
concerns with the level of conjecture in the Introduction and
redundancy of the description of the hypotheses in the Methods. These
are sensible suggestions for a regular paper, but please note that
these aspects of the manuscript should not be revised because doing
so would deviate too substantially from the approved Stage 1 protocol.
This exemption does not apply to the reviewer's comments on the
Discussion and interpretation of results which should be addressed,
and the reviewer also makes some suggestions for potentially
amending the title and abstract (which can be revised at Stage 2).
1
We have not revised the introduction in light of these comments.
However, we have used Reviewer 1’s suggestion for the title and
abstract. We have also responded to the concerns Dr. Kornell raises
about our discussion and interpretation of results.
Reviewer 2 focuses mainly on the results and discussion, offering
some suggestions for additional exploratory analyses. In my reading
these are sensible recommendations. Note, however, that under the
Stage 2 guidelines, authors are not required to undertake additional
exploratory analyses unless they are necessary to justify the
conclusions. In this case, while the suggested analyses could very well
increase the impact and usefulness of the work (as the reviewer
notes), they do not meet the threshold to be required for Stage 2
acceptance; therefore I will let you decide whether to include them, and
whether you do or not will not influence the final editorial decision. The
reviewer also recommends some minor restructuring of the exploratory
analyses to better link some of the exploratory outcomes to the
confirmatory outcomes. In a Stage 2 RR it is often more
straightforward to separate confirmatory and exploratory outcomes into
separate sections, but authors are welcome to include tightly linked
exploratory and confirmatory analyses within the same sections of the
results provided they are clearly distinguished (or alternatively the
exploratory analyses could be signposted in the confirmatory section,
with the reader directed to the later exploratory section). Reviewer 2
also makes some minor suggestions for improving the clarity of the
Introduction and Methods, which sufficiently minor that they can be
made.
In this case, we have made the edits to the introduction (as you say,
these are mostly grammatical). We have also chosen to signpost the
exploratory analyses in the confirmatory section, rather than move them
to the confirmatory section. Finally, we have included the additional
exploratory analyses recommended by this reviewer.
Finally, Reviewer 3 recommends that you abandon the use of inferential
statistics in the exploratory analyses. I agree with the reviewer that the
interpretation of p values in exploratory analyses is difficult, however it
is not a settled issue that this invalidates altogether the use of frequentist
statistical techniques (and there is no standard policy on this in the RR
2
guidelines). I will therefore let you decide whether and if so how to
address this point. From an editorial point of view, I am happy for you to
maintain the use of inferential statistics in the exploratory analyses
precisely because they are transparently exploratory, so readers will be
equipped to judge them accordingly, but perhaps you could forewarn the
less studied reader with a footnote (and associated reference) or other
remark commenting on the fact that p values for the exploratory
analyses should - as always - be interpreted with caution.
We still report the inferential statistics. However, we are grateful for the
advice to forewarn readers about the possibility of Type 1 errors, which
we have now done (lines 519-523).
Given the positive assessments and relatively minor revisions that are
needed, provided the revised submission addresses all of the reviewers'
points through revision or rebuttal, final Stage 2 acceptance should be
forthcoming without requiring further in-depth review.
Reviewer: 1 (Nate Kornell)
I don't have any major criticisms. With respect to the specific questions
posed by the journal, e.g., "Whether the authors’ conclusions are
justified given the data," I see no problems.
Thank you for your careful reading and constructive comments, both on
the Stage 1 manuscript and this submission.
What follows isn't criticism, and I'm afraid it won't be of much help when
it comes to editorial decision making, but I have a few suggestions for
the authors to consider. So here they are.
The intro had more conjecture than I personally like. This is a matter of
opinion so ignore it if you wish. But it seemed like some of the discussion
about what you might find, what it might mean, why you might find it
could have been saved for the discussion section so that we could hear
some of the answers instead of the conjecture and you didn't have to
talk about it twice.
3
This is an interesting point, and one that is worth us bearing in mind for
future registered reports! However, as the editor notes, this would mean
changing the introduction which is not possible with a registered report.
Section 3.12 Analyses seemed redundant. It seemed like a mix between
redundancy with the hypotheses that had come before and redundancy
with the analyses that were coming later. Could this section be removed
or integrated into the results section?
Again, we were reluctant to change this section as it is the introduction
and methods that were pre-registered, and we think it might help
readers judge whether we conducted the analyses we pre-registered.
I'd suggest being consistent in how the term feedback is used. For one
thing, pick a way of referring to feedback that tells the participant
whether they were right or wrong and then stick to it. You mostly stick
to "evaluative," but I have to say, I think my favorite would be
"right/wrong" (followed by "yes/no"). I just think this is the most
telegraphic and easiest for readers to immediately understand. But of
course I'm not the author, it's up to you.
We have now looked through the document and stick with evaluative
feedback. We highlight at salient points (the beginning of sections) that
this refers to right/ wrong feedback.
I also think the meaning of feedback should clarified earlier in the
manuscript. I made this request in my first review and the manuscript
improved significantly, so I feel like I'm nagging (for which I apologize).
I just think the fact that it's evaluative feedback should be made clear
way up front, in the abstract and ideally in the title. I'm imagining, for
example, that "the influence of right/wrong feedback on ..." could be a
cool title.
We agree, and have now added evaluative right/wrong to the title and
abstract.
In the first paragraph of the discussion, the authors suggest that
right/wrong feedback should be used in phonological learning. I found
myself disagreeing because it seems to me that even better advice
would be to do corrective feedback (i.e., tell them whether they are
right/wrong and what the right answer is), as you say at 678-704. In
4
other words, just because right/wrong feedback is better than no
right/wrong feedback doesn't mean it should be recommended.
This is an important point – we have now tempered this statement.
Page 22: “Our results indicate that evaluative feedback can improve
retention of phonological forms, but such feedback does not appear to
be of benefit for semantic learning. This suggests that during training, it
may be more beneficial to give evaluative feedback when targeting
phonological learning, rather than when targeting semantic learning.
Although we have explored evaluative feedback here, it may be the case
that evaluative feedback combined with providing the right answer could
yield even greater benefits during phonological learning. A role for
external feedback in shaping phonological learning is potentially exciting
from the perspective of designing more effective training programs.”
In the discussion of why feedback helped with phonological learning, I
don't have a criticism, but I will throw in a suggestion. Perhaps the
difference is that with phonological learning the participants aren't good
at knowing whether they are right or wrong. They might be benefiting
because, without feedback, even after they hear the correct
pronunciation they still think their response was right (this seems to
happen in a very different domain, where metacomprehension of
passages has been shown to be pretty bad even after corrective
feedback; I think this is summarized in Dunlosky & Lipko, 2007). Of
course this won't happen with your semantics condition as much
because it's easy to tell whether a semantic response is right or wrong,
so when you hear it later, you get information that makes the feedback
redundant. Semantics, and words, are categories, and you usually either
said the right word or not, whereas with phonology, you can be close but
wrong or close enough and right. (Incidentally, I'm so uninformed I don't
know whether this has been done, but it'd be cool to know whether
people truly are prone to mistakenly thinking their inaccurate
pronunciations are accurate even after hearing the word repeated, and
whether this is less true with semantic information, because that seems
like it would go a long way toward helping explain your findings.)
This is a really interesting argument, and one I hadn’t been able to
articulate very clearly! We’ve now added this to our discussion (page
26).
5
“Meta-cognition, or one’s ability to judge their own learning, may also
play a role in learning. For example, differences in meta-comprehension
are linked to learning from text passages. Learners who were better able
to judge their own learning accuracy improving after a period of restudy,
while those with poor judgement accuracy did not really improve [44].
Meta-cognition is likely to differ across the two domains we tested here.
Participants are likely to be quite good at judging whether their semantic
responses are right or wrong, perhaps making the evaluative feedback
they receive redundant. On the other hand, when learning phonological
forms, participants may not feel confident about their productions,
especially when they produce a response close to the target but not
quite the right answer. Receiving evaluative feedback could cue them to
pay closer attention to a phonological form if they were incorrect, and
strengthen their representation of the form if they were correct.
Evaluative right/wrong feedback may therefore allow participants to
improve their meta-cognition of phonological learning.”
What follows are smaller than minor, so I'll call them minuscule
comments.
Lines 65-7 made me think, if that's the definition of feedback then does
that mean when they don't get feedback there is no opportunity to learn
the correct response later? Maybe clarify that this is not the case.
We have now added a line to clarify this point (page 3).
“Here, we define evaluative feedback as a cue that highlights the
accuracy of a response, without correcting it, but with an opportunity to
learn the correct response later. We contrast this with a no feedback
condition, where there is no cue highlighting response accuracy, but
learners do receive a later opportunity to learn the correct response.”
Lines 143-7 made me think the study was confounded because it
seemed like if they didn't get right/wrong feedback they did get corrective
feedback on the other feature.
This is now reworded to emphasise that participants only get
evaluative feedback.
In figure 1c the word corrective doesn't seem right.
We have now changed this to evaluative feedback, thanks for picking
this up.
6
Figure 3 was hard to understand. Maybe you could put in the means?
And maybe you could signal how many points/lines are overlapping
using changes in thickness? (Also, with grey lines, maybe remove the
grey background?)
In this figure, we now use vertical jitter, implemented using R’s jitter
function. This allows for clearer visualisation of any overlapping points.
We have also removed the gray background and show the median
score in each box plot.
Reviewer: 2
I have very few comments on the introduction and methods, given that
I already reviewed these at stage 1.
1. I noticed one incorrectly worded sentence on p45, line 111:
“Furthermore, another argument IS ABOUT the value of feedback for
vocabulary learning IS THAT although immediate feedback might lead
to greater learning efficiency in the short term,...”
This is now corrected.
2. I wasn’t sure why some of Figure 1 was greyed out, e.g., panel
D?
We have now removed the greying out applied to some of the panels in
the figure. Our original intention was to de-emphasise some elements
that were repetitive, but we have found that it raises more questions than
it answers.
3. In section 3.8, I would recommend adding information about
how responses were scored as correct or incorrect. It only
became apparent to me quite late on in the results that
something such as “saying “hupip has multiple tendrils”, instead
of “hupip has several tendrils”,...” would be classed as incorrect.
You might also want to motivate this decision, as typically I
would imagine that responses such as this would be classed as
correct in semantic learning, when the meaning is identical, just
7
the choice of words differs. Also, I would like to know whether
participants were told that this kind of response would class as
incorrect? This is relevant to a point made in the Discussion
(lines 696-694)
“In contrast, for semantic learning, participants believe they have to
retrieve a gist, rather than the correct combination of words. Here,
evaluative right/ wrong feedback may do very little to shape access to
the precise semantic representation.”
Such a problem would likely be enhanced if participants were
not told what counts as correct/incorrect.
We did make it clear to the participants that we were looking for the exact
wording they had been taught. During training, responses that
resembled this kind of response were marked as incorrect, and in the
feedback trials, participants would have been aware that this was
incorrect. We have added some information to this effect in section 3.8.
Although the reviewer is right that this would ordinarily not matter for
semantic training, we were trying to make the phonological and semantic
conditions as similar as possible. Indeed, for phonological forms,
substituting a syllable or changing the order would be considered an
incorrect.
My suggestions for improving the results and discussion are below.
4. I would really like to see learning curves (i.e. performance in the
cued recall blocks) for the four main conditions: phonological
learning with and without feedback, semantic learning with and
without feedback. This kind of information is important for those
of us who conduct learning studies, so we can see what to
expect from participants, for example. These data seem
especially important to provide given that the error analysis from
the final block of training (section 4.5.4) shows that performance
during learning was far better in the semantic than the
phonological condition, and also that phonological learning
showed much greater individual variability. Given these
differences, I also think it would be very informative to present
an analysis examining the influence of feedback on
8
performance during learning, i.e. a block (5 blocks) x information
type (phonological vs semantic) x feedback (with/without)
ANOVA. I appreciate that you had not planned to analyse these
data, and I should have recommended this at Stage 1, but I do
think it would be interesting to see if feedback influences
semantic learning, given that it does not seem to influence
retention.
We absolutely agree, and had in fact presented the results of this very
analysis in Appendix 4. However, we note from your comments below
that the appendices were not available during the review process. In
brief, the results of this analysis suggested that feedback did not
influence performance during learning in either training condition. We
have now moved these analyses to exploratory analyses in the main text
(pages 20-21).
5. On p17 I felt that I could do with a little more help understanding
the key results. I think I am correct in thinking that the
interaction between feedback and recall condition indicates that
cued recall of phonological information was better following both
semantic and phonological learning with feedback than without
feedback, whereas cued recall of semantics was not influenced
by feedback? This was not what you predicted, I don’t think,
instead you expected either a 2-way interaction between
training condition and feedback whereby cued recall of
phonological information was better following phonological
learning with feedback than without feedback, and cued recall of
semantic information was better following semantic learning with
than without feedback, or a 3-way interaction where one of
these effects was present but the other was not (or feedback
had the reverse effect in one condition). I think it would help to
clarify that the effect you observed was not exactly what you
had expected and to have a statement (something like mine at
the start of this comment!) to explain what the effect shows.
Thanks for pointing this out! We have now clarified this idea by adding
a statement like the one you have proposed (page 17).
Also, it is somewhat confusing that lines 491- 492 state
9
“Although this was an effect we predicted, it is important to note
that the effect size is smaller than we expected (we predicted
d=0.4).” I don’t think this was quite the effect you predicted...
Clarifying this finding would then help the reader to understand
the motivation for the first follow-up exploratory analysis (section
4.5.1).
We have now removed this line, and now show the motivation for the
first exploratory analysis (page 17).
6. On a related note, I would personally prefer section 4.5.1 to be
within section 4.4 given that it clarifies the slightly strange 2x2
interaction, but I understand that anything that wasn’t pre-
specified should be in an Exploratory section. You could
perhaps include it in section 4.4 but state that this was a follow-
up analysis that wasn’t planned and isn’t in fact justified by the
results of the main ANOVA. In this section, I think it would be
more informative to also examine whether the effect of feedback
on phonological recall holds when the semantic learning
condition is examined on its own, given that this was the really
unexpected result. This would help to demonstrate that the
effect of feedback (within the phonological cued recall task) was
driven by primarily the phonological learning condition, despite
the lack of an interaction. If you decide to do this then Figure 3
should include all 8 conditions.
We now include the requested analyses (pages 18-19). However, we
did not add to Figure 3, especially as Reviewer 1 pointed out that it
was already a little confusing.
7. P18, line 526 seems somewhat ungrammatical “as we were
reducing half our dataset”. Perhaps say “losing half our
dataset”?
Thanks for the suggestion, we now use the suggested wording.
8. In section 4.5.4. I would find the reporting of each error type
easier to understand in proportions or percentages, but perhaps
that’s just a personal thing.
10
We did go back and forth about this when drafting this section, but
eventually chose to stick to the number of trials as that was consistent
with the rest of the paper.
9. The first line of the Discussion (line 575) is not very well worded
“In this study, we evaluated whether evaluative feedback...”
This line is now reworded:
“In this study, we assessed whether evaluative (right/wrong) feedback
would influence long-term word learning, and whether such feedback
would have differential effects on the learning of phonological forms
and semantic facts.”
10. Line 710 states “(see Appendix 4)” but I couldn’t find a reference
to Appendix 3. And also the appendices are not provided.
We have now moved this particular analysis to the main text.
11. I’m also a bit confused as to what is likely to be in Appendix 4.
In the text that first references it (Results, section 4.5.1), it is not
clear that this is data from the training trials, but this is certainly
what seems to be implied by line 709-710 of the Discussion.
“Somewhat surprisingly, we did not observe an effect of feedback in the
training trials (see Appendix 4).”
We are also glad the journal followed up and sent you the appendices.
This then has an impact on my understanding of sections 4.5.2
and 4.5.3. Are these also analyses of the training data? I don’t
think they can be given that line 534 says “as previously reported”
implying that these are the same data as presented in sections
4.2 to 4.4... If none of the data reported in the manuscript is the
training data (other than section 4.5.4, the error analysis), then
what is the evidence for the statement in lines 709-710? If there
are data in Appendix 4 that show a total lack of a feedback effect
during training this is really important and should not only be in
an appendix. This also further justifies my suggestion to include
an analysis of the training data (see comment 4).
11
We have now included the analysis of the training data in the main text,
under exploratory analyses (pages 19-20). However, as mentioned in
the discussion, looking at performance during training may not be
representative of performance in a test condition.
12. Lines 719-720 are somewhat misleading, since directing
attention to semantic facts did have an effect on phonological
learning, it resulted in it being at floor! “Beyond the effects of
feedback, we found that directing attention to semantic facts did
not have a substantial effect on phonological learning,...”
This was unclearly written! We have now reworded this line as follows
(page 27):
“Beyond the effects of feedback, we found that directing attention to
semantic facts did not have a facilitatory effect on phonological
learning, a result that might appear to be at odds with other findings in
the literature”
13. Lines 725-726 are somewhat ungrammatical/unclear: “Our data
suggests that rather than the presence of semantic information,
the designs used in previous studies may actually boost overall
motivation or attention to phonology. However, this does not
indicate that providing context is of no benefit at all during
learning.” What is meant by “rather than the presence of
semantic information”? and what is being referred to that “does
not indicate that providing context is of no benefit”?
Again, this was not clearly explained. We have now reworded as follows
(page 28):
“Our data suggest that designs used in previous studies may actually
boost overall motivation or attention to phonology, rather than provide a
boost to memory by giving information about the meaning of the referent.
However, our data do not indicate that providing semantic context is of
no benefit at all during learning. One issue with our design is that
participants in the semantic training condition were never given an
opportunity to practice phonological recall, and vice versa.”
14. Lines 730-732 also contain grammatical errors: “To shed further
12
light on this issue, a follow up study where the same material
where participants are given some opportunities to learn
phonology/ semantics during training...”
Thank you for catching this. This is now corrected.
15. Line 755 should read “Our data indicate that...”
Thanks for picking this up, it’s now corrected.
Reviewer: 3
The present paper is a Stage 2 manuscript in which confirmatory and
exploratiry analyses as well as a discussion are added to a previously
approved pre-registered study. Hence, my review will only focus on a
limited number of evaluation criteria.
First, the rationale and the hypothesis in this stage 2 manuscript are the
soem as in the apporved pre-registration. Second, as far as I can judge
from the stage 2 paper, the experimental procedure and the confirmatory
analyses have been conducted according to plan. Third, the positive
controls that were added to the pre-registration revealed the expected
outcomes. Fourth, although there were some floor effects (in the
phonological condition) in the outcomes of the planned/confirmatory
analyses, these do not invalidate the outcomes and the conclusions from
the present experiment. Fifht, the exploratory analyses are informative
and sound. I do have, however, one relatively minor issues with these
exploratiry analyses. Specifically, for some of them, the authors report
the outcomes of null--hypothesis-significance-testing procedures.
However, because it is hard - or perhaps even impossible - to control
the Type 1 error in exploratory analyses (see for example de Groot, A.
D., Wagenmakers, E-J., Borsboom, D., Verhagen, J., Kievit, R., Bakker,
M., ... van der Maas, H. L. J. (2014). The meaning of "significance" for
different types of research. Acta Psychologica, 148, 188-194), I would
recommend the authors to drop the NHST outcomes and to constrain
the exploratory findings to descriptive statistics and measures of effect
sizes. Finally, the discussion and conclusion is justified given the results
of the experiment.
13
We’d like to thank the reviewer for evaluating our work, and are pleased
that they feel that the analyses presented and conclusions reached are
fitting with our Stage 1 pre-registration.
We’d also like to thank the reviewer for their suggestion to drop the
NHST procedures for exploratory analyses. In this case, we have
chosen not to drop inferential analyses because most readers in the
topic area are likely to be familiar with this statistical approach, and may
be surprised to find these statistics are not reported. Instead, as the
editor suggests, we now highlight that these p-values should be
interpreted with caution. However, we would like to thank the reviewer
for pointing us to the de Groot et al. paper – we now reference it in our
cautionary note (page 17).
“In this section, we report the results of analyses that we had not planned
to conduct in advance of collecting the data. Instead, the intention of
these analyses is to understand the patterns in the data we collected,
and generate hypotheses for the future. It is worth noting that inferential
statistics, particularly p-values, are difficult to interpret for such
exploratory analyses (de Groot et al., 2014). Consequently, they should
consequently be interpreted with caution.”
14
Society Open
